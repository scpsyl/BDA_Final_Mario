[2024-11-19 20:12:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 235
train_sample_count: 235
avg_envstep_per_episode: 58.75
avg_sample_per_episode: 58.75
avg_envstep_per_sec: 452.75772776044107
avg_train_sample_per_sec: 452.75772776044107
avg_episode_per_sec: 7.706514515071337
collect_time: 0.5190413892269135
reward_mean: 325.0
reward_std: 176.28244018554688
reward_max: 630.0
reward_min: 210.0
total_envstep_count: 1149
total_train_sample_count: 1135
total_episode_count: 4
total_duration: 0.5190413892269135
[2024-11-19 20:12:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 773
train_sample_count: 773
avg_envstep_per_episode: 193.25
avg_sample_per_episode: 193.25
avg_envstep_per_sec: 443.7136016508295
avg_train_sample_per_sec: 443.7136016508295
avg_episode_per_sec: 2.2960600344156763
collect_time: 1.7421147269862038
reward_mean: 642.75
reward_std: 49.89175796508789
reward_max: 727.0
reward_min: 597.0
total_envstep_count: 2154
total_train_sample_count: 2124
total_episode_count: 8
total_duration: 2.261156116213117
[2024-11-19 20:12:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 327
train_sample_count: 327
avg_envstep_per_episode: 109.0
avg_sample_per_episode: 109.0
avg_envstep_per_sec: 438.69529217977976
avg_train_sample_per_sec: 438.69529217977976
avg_episode_per_sec: 4.02472745119064
collect_time: 0.7453920883791787
reward_mean: 385.6666564941406
reward_std: 224.3885498046875
reward_max: 703.0
reward_min: 227.0
total_envstep_count: 3160
total_train_sample_count: 3135
total_episode_count: 11
total_duration: 3.0065482045922955
[2024-11-19 20:12:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 586
train_sample_count: 586
avg_envstep_per_episode: 195.33333333333334
avg_sample_per_episode: 195.33333333333334
avg_envstep_per_sec: 434.2971815542826
avg_train_sample_per_sec: 434.2971815542826
avg_episode_per_sec: 2.2233644106874535
collect_time: 1.3493064769676755
reward_mean: 509.6666564941406
reward_std: 210.09573364257812
reward_max: 690.0
reward_min: 215.0
total_envstep_count: 4150
total_train_sample_count: 4117
total_episode_count: 14
total_duration: 4.355854681559971
[2024-11-19 20:12:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 596
train_sample_count: 596
avg_envstep_per_episode: 198.66666666666666
avg_sample_per_episode: 198.66666666666666
avg_envstep_per_sec: 435.26955741653666
avg_train_sample_per_sec: 435.26955741653666
avg_episode_per_sec: 2.190954148069815
collect_time: 1.3692664461476463
reward_mean: 454.6666564941406
reward_std: 163.92750549316406
reward_max: 578.0
reward_min: 223.0
total_envstep_count: 5155
total_train_sample_count: 5097
total_episode_count: 17
total_duration: 5.7251211277076175
[2024-11-19 20:12:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1037
train_sample_count: 1037
avg_envstep_per_episode: 259.25
avg_sample_per_episode: 259.25
avg_envstep_per_sec: 431.9625659196521
avg_train_sample_per_sec: 431.9625659196521
avg_episode_per_sec: 1.666200832862689
collect_time: 2.4006709882191246
reward_mean: 461.75
reward_std: 245.28286743164062
reward_max: 759.0
reward_min: 201.0
total_envstep_count: 6151
total_train_sample_count: 6122
total_episode_count: 21
total_duration: 8.125792115926743
[2024-11-19 20:12:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 265
train_sample_count: 265
avg_envstep_per_episode: 265.0
avg_sample_per_episode: 265.0
avg_envstep_per_sec: 424.09518699861536
avg_train_sample_per_sec: 424.09518699861536
avg_episode_per_sec: 1.60035919622119
collect_time: 0.6248597204685211
reward_mean: 744.0
reward_std: 0.0
reward_max: 744.0
reward_min: 744.0
total_envstep_count: 7110
total_train_sample_count: 7083
total_episode_count: 22
total_duration: 8.750651836395264
[2024-11-19 20:12:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1658
train_sample_count: 1658
avg_envstep_per_episode: 276.3333333333333
avg_sample_per_episode: 276.3333333333333
avg_envstep_per_sec: 428.27332910043356
avg_train_sample_per_sec: 428.27332910043356
avg_episode_per_sec: 1.549843169241617
collect_time: 3.8713594504765103
reward_mean: 531.3333129882812
reward_std: 231.85316467285156
reward_max: 756.0
reward_min: 210.0
total_envstep_count: 8105
total_train_sample_count: 8069
total_episode_count: 28
total_duration: 12.622011286871775
[2024-11-19 20:12:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 343
train_sample_count: 343
avg_envstep_per_episode: 171.5
avg_sample_per_episode: 171.5
avg_envstep_per_sec: 429.5551018624718
avg_train_sample_per_sec: 429.5551018624718
avg_episode_per_sec: 2.5046944715012933
collect_time: 0.7985005847045353
reward_mean: 590.5
reward_std: 3.5
reward_max: 594.0
reward_min: 587.0
total_envstep_count: 9080
total_train_sample_count: 9036
total_episode_count: 30
total_duration: 13.420511871576311
[2024-11-19 20:13:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 96
train_sample_count: 96
avg_envstep_per_episode: 48.0
avg_sample_per_episode: 48.0
avg_envstep_per_sec: 434.3846574373018
avg_train_sample_per_sec: 434.3846574373018
avg_episode_per_sec: 9.04968036327712
collect_time: 0.22100228071212769
reward_mean: 220.5
reward_std: 9.5
reward_max: 230.0
reward_min: 211.0
total_envstep_count: 10047
total_train_sample_count: 10008
total_episode_count: 32
total_duration: 13.641514152288439
[2024-11-19 20:13:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 90
train_sample_count: 90
avg_envstep_per_episode: 90.0
avg_sample_per_episode: 90.0
avg_envstep_per_sec: 409.6994685938562
avg_train_sample_per_sec: 409.6994685938562
avg_episode_per_sec: 4.552216317709513
collect_time: 0.21967321634292603
reward_mean: 605.0
reward_std: 0.0
reward_max: 605.0
reward_min: 605.0
total_envstep_count: 11014
total_train_sample_count: 10986
total_episode_count: 33
total_duration: 13.861187368631365
[2024-11-19 20:13:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1345
train_sample_count: 1345
avg_envstep_per_episode: 672.5
avg_sample_per_episode: 672.5
avg_envstep_per_sec: 430.32086293127503
avg_train_sample_per_sec: 430.32086293127503
avg_episode_per_sec: 0.6398823240613755
collect_time: 3.1255746952125003
reward_mean: 522.0
reward_std: 301.0
reward_max: 823.0
reward_min: 221.0
total_envstep_count: 11996
total_train_sample_count: 11959
total_episode_count: 35
total_duration: 16.986762063843866
[2024-11-19 20:13:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2764
train_sample_count: 2764
avg_envstep_per_episode: 460.6666666666667
avg_sample_per_episode: 460.6666666666667
avg_envstep_per_sec: 428.1907347221314
avg_train_sample_per_sec: 428.1907347221314
avg_episode_per_sec: 0.9295023184995617
collect_time: 6.455067276954651
reward_mean: 629.1666870117188
reward_std: 208.16534423828125
reward_max: 889.0
reward_min: 213.0
total_envstep_count: 12976
total_train_sample_count: 12947
total_episode_count: 41
total_duration: 23.441829340798517
[2024-11-19 20:13:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 255
train_sample_count: 255
avg_envstep_per_episode: 127.5
avg_sample_per_episode: 127.5
avg_envstep_per_sec: 443.8969195484289
avg_train_sample_per_sec: 443.8969195484289
avg_episode_per_sec: 3.4815444670465014
collect_time: 0.5744576922484808
reward_mean: 398.0
reward_std: 183.0
reward_max: 581.0
reward_min: 215.0
total_envstep_count: 13958
total_train_sample_count: 13910
total_episode_count: 43
total_duration: 24.016287033046996
[2024-11-19 20:13:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 585
train_sample_count: 585
avg_envstep_per_episode: 292.5
avg_sample_per_episode: 292.5
avg_envstep_per_sec: 437.01819457257454
avg_train_sample_per_sec: 437.01819457257454
avg_episode_per_sec: 1.4940792976840156
collect_time: 1.3386170353208269
reward_mean: 710.5
reward_std: 13.5
reward_max: 724.0
reward_min: 697.0
total_envstep_count: 15405
total_train_sample_count: 15359
total_episode_count: 45
total_duration: 25.354904068367823
[2024-11-19 20:13:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 2356
train_sample_count: 2356
avg_envstep_per_episode: 589.0
avg_sample_per_episode: 589.0
avg_envstep_per_sec: 432.11628960625046
avg_train_sample_per_sec: 432.11628960625046
avg_episode_per_sec: 0.7336439551888803
collect_time: 5.452236022268023
reward_mean: 420.0
reward_std: 205.4251708984375
reward_max: 715.0
reward_min: 210.0
total_envstep_count: 16361
total_train_sample_count: 16323
total_episode_count: 49
total_duration: 30.807140090635848
[2024-11-19 20:13:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 186
train_sample_count: 186
avg_envstep_per_episode: 93.0
avg_sample_per_episode: 93.0
avg_envstep_per_sec: 433.3517285907934
avg_train_sample_per_sec: 433.3517285907934
avg_episode_per_sec: 4.659696006352617
collect_time: 0.42921254890305655
reward_mean: 405.5
reward_std: 184.5
reward_max: 590.0
reward_min: 221.0
total_envstep_count: 17351
total_train_sample_count: 17313
total_episode_count: 51
total_duration: 31.236352639538904
[2024-11-19 20:13:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 245
train_sample_count: 245
avg_envstep_per_episode: 245.0
avg_sample_per_episode: 245.0
avg_envstep_per_sec: 433.09023325859687
avg_train_sample_per_sec: 433.09023325859687
avg_episode_per_sec: 1.7677152377901912
collect_time: 0.5657019742897579
reward_mean: 587.0
reward_std: 0.0
reward_max: 587.0
reward_min: 587.0
total_envstep_count: 18310
total_train_sample_count: 18278
total_episode_count: 52
total_duration: 31.802054613828663
[2024-11-19 20:13:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1325
train_sample_count: 1325
avg_envstep_per_episode: 1325.0
avg_sample_per_episode: 1325.0
avg_envstep_per_sec: 431.0695867490726
avg_train_sample_per_sec: 431.0695867490726
avg_episode_per_sec: 0.3253355371691114
collect_time: 3.0737496699605673
reward_mean: 1619.0
reward_std: 0.0
reward_max: 1619.0
reward_min: 1619.0
total_envstep_count: 19285
total_train_sample_count: 19243
total_episode_count: 53
total_duration: 34.87580428378923
[2024-11-19 20:14:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1052
train_sample_count: 1052
avg_envstep_per_episode: 1052.0
avg_sample_per_episode: 1052.0
avg_envstep_per_sec: 432.87765560924436
avg_train_sample_per_sec: 432.87765560924436
avg_episode_per_sec: 0.41148066122551746
collect_time: 2.4302478688103806
reward_mean: 585.0
reward_std: 0.0
reward_max: 585.0
reward_min: 585.0
total_envstep_count: 21012
total_train_sample_count: 20979
total_episode_count: 54
total_duration: 37.30605215259961
[2024-11-19 20:14:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1211
train_sample_count: 1211
avg_envstep_per_episode: 403.6666666666667
avg_sample_per_episode: 403.6666666666667
avg_envstep_per_sec: 430.9640786981195
avg_train_sample_per_sec: 430.9640786981195
avg_episode_per_sec: 1.067623646650998
collect_time: 2.8099789747170036
reward_mean: 338.6666564941406
reward_std: 172.06459045410156
reward_max: 582.0
reward_min: 216.0
total_envstep_count: 22033
total_train_sample_count: 21986
total_episode_count: 57
total_duration: 40.11603112731662
[2024-11-19 20:14:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 42
train_sample_count: 42
avg_envstep_per_episode: 42.0
avg_sample_per_episode: 42.0
avg_envstep_per_sec: 422.45750922383127
avg_train_sample_per_sec: 422.45750922383127
avg_episode_per_sec: 10.058512124376934
collect_time: 0.0994182825088501
reward_mean: 229.0
reward_std: 0.0
reward_max: 229.0
reward_min: 229.0
total_envstep_count: 22992
total_train_sample_count: 22952
total_episode_count: 58
total_duration: 40.21544940982547
[2024-11-19 20:14:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1780
train_sample_count: 1780
avg_envstep_per_episode: 890.0
avg_sample_per_episode: 890.0
avg_envstep_per_sec: 428.1125548233357
avg_train_sample_per_sec: 428.1125548233357
avg_episode_per_sec: 0.48102534249813
collect_time: 4.157785096338817
reward_mean: 845.0
reward_std: 209.0
reward_max: 1054.0
reward_min: 636.0
total_envstep_count: 23951
total_train_sample_count: 23916
total_episode_count: 60
total_duration: 44.37323450616429
[2024-11-19 20:14:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1363
train_sample_count: 1363
avg_envstep_per_episode: 681.5
avg_sample_per_episode: 681.5
avg_envstep_per_sec: 421.1654124582549
avg_train_sample_per_sec: 421.1654124582549
avg_episode_per_sec: 0.6179976705183491
collect_time: 3.236258153404508
reward_mean: 804.0
reward_std: 98.0
reward_max: 902.0
reward_min: 706.0
total_envstep_count: 24941
total_train_sample_count: 24907
total_episode_count: 62
total_duration: 47.609492659568794
[2024-11-19 20:14:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2244
train_sample_count: 2244
avg_envstep_per_episode: 748.0
avg_sample_per_episode: 748.0
avg_envstep_per_sec: 421.92195618968793
avg_train_sample_per_sec: 421.92195618968793
avg_episode_per_sec: 0.5640667863498502
collect_time: 5.318519140992845
reward_mean: 955.3333129882812
reward_std: 525.7517700195312
reward_max: 1697.0
reward_min: 539.0
total_envstep_count: 25915
total_train_sample_count: 25879
total_episode_count: 65
total_duration: 52.92801180056164
[2024-11-19 20:14:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 99
train_sample_count: 99
avg_envstep_per_episode: 99.0
avg_sample_per_episode: 99.0
avg_envstep_per_sec: 436.0975872572272
avg_train_sample_per_sec: 436.0975872572272
avg_episode_per_sec: 4.405026133911385
collect_time: 0.22701340913772583
reward_mean: 622.0
reward_std: 0.0
reward_max: 622.0
reward_min: 622.0
total_envstep_count: 26874
total_train_sample_count: 26842
total_episode_count: 66
total_duration: 53.15502520969937
[2024-11-19 20:14:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 724
train_sample_count: 724
avg_envstep_per_episode: 362.0
avg_sample_per_episode: 362.0
avg_envstep_per_sec: 428.2500699186414
avg_train_sample_per_sec: 428.2500699186414
avg_episode_per_sec: 1.183011242869175
collect_time: 1.6906010082789829
reward_mean: 724.0
reward_std: 10.0
reward_max: 734.0
reward_min: 714.0
total_envstep_count: 27833
total_train_sample_count: 27806
total_episode_count: 68
total_duration: 54.84562621797835
[2024-11-19 20:14:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1744
train_sample_count: 1744
avg_envstep_per_episode: 872.0
avg_sample_per_episode: 872.0
avg_envstep_per_sec: 426.37326235925417
avg_train_sample_per_sec: 426.37326235925417
avg_episode_per_sec: 0.4889601632560254
collect_time: 4.090312770434789
reward_mean: 843.5
reward_std: 206.5
reward_max: 1050.0
reward_min: 637.0
total_envstep_count: 28831
total_train_sample_count: 28782
total_episode_count: 70
total_duration: 58.93593898841314
[2024-11-19 20:14:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1528
train_sample_count: 1528
avg_envstep_per_episode: 305.6
avg_sample_per_episode: 305.6
avg_envstep_per_sec: 425.7562397172651
avg_train_sample_per_sec: 425.7562397172651
avg_episode_per_sec: 1.3931814126873858
collect_time: 3.5889080592564175
reward_mean: 563.4000244140625
reward_std: 293.23480224609375
reward_max: 953.0
reward_min: 218.0
total_envstep_count: 29810
total_train_sample_count: 29770
total_episode_count: 75
total_duration: 62.52484704766956
[2024-11-19 20:15:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 479
train_sample_count: 479
avg_envstep_per_episode: 159.66666666666666
avg_sample_per_episode: 159.66666666666666
avg_envstep_per_sec: 418.81481217429786
avg_train_sample_per_sec: 418.81481217429786
avg_episode_per_sec: 2.623057278753431
collect_time: 1.143703579902649
reward_mean: 538.6666870117188
reward_std: 228.0604248046875
reward_max: 774.0
reward_min: 230.0
total_envstep_count: 30783
total_train_sample_count: 30753
total_episode_count: 78
total_duration: 63.66855062757221
[2024-11-19 20:15:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1707
train_sample_count: 1707
avg_envstep_per_episode: 853.5
avg_sample_per_episode: 853.5
avg_envstep_per_sec: 423.53671454440837
avg_train_sample_per_sec: 423.53671454440837
avg_episode_per_sec: 0.496235166425786
collect_time: 4.0303471727030615
reward_mean: 839.0
reward_std: 190.0
reward_max: 1029.0
reward_min: 649.0
total_envstep_count: 31781
total_train_sample_count: 31728
total_episode_count: 80
total_duration: 67.69889780027528
[2024-11-19 20:15:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 593
train_sample_count: 593
avg_envstep_per_episode: 296.5
avg_sample_per_episode: 296.5
avg_envstep_per_sec: 425.30204254128006
avg_train_sample_per_sec: 425.30204254128006
avg_episode_per_sec: 1.4344082379132548
collect_time: 1.3943032026290894
reward_mean: 814.5
reward_std: 180.5
reward_max: 995.0
reward_min: 634.0
total_envstep_count: 32748
total_train_sample_count: 32705
total_episode_count: 82
total_duration: 69.09320100290437
[2024-11-19 20:15:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 47
train_sample_count: 47
avg_envstep_per_episode: 47.0
avg_sample_per_episode: 47.0
avg_envstep_per_sec: 445.53634122810365
avg_train_sample_per_sec: 445.53634122810365
avg_episode_per_sec: 9.479496621874546
collect_time: 0.10549083352088928
reward_mean: 227.0
reward_std: 0.0
reward_max: 227.0
reward_min: 227.0
total_envstep_count: 33715
total_train_sample_count: 33688
total_episode_count: 83
total_duration: 69.19869183642525
[2024-11-19 20:15:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1288
train_sample_count: 1288
avg_envstep_per_episode: 322.0
avg_sample_per_episode: 322.0
avg_envstep_per_sec: 427.1913458265089
avg_train_sample_per_sec: 427.1913458265089
avg_episode_per_sec: 1.3266811982189717
collect_time: 3.0150423518248965
reward_mean: 531.5
reward_std: 317.0776672363281
reward_max: 946.0
reward_min: 221.0
total_envstep_count: 34736
total_train_sample_count: 34676
total_episode_count: 87
total_duration: 72.21373418825016
[2024-11-19 20:15:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 3615
train_sample_count: 3615
avg_envstep_per_episode: 723.0
avg_sample_per_episode: 723.0
avg_envstep_per_sec: 428.4933994613658
avg_train_sample_per_sec: 428.4933994613658
avg_episode_per_sec: 0.5926603035426913
collect_time: 8.436536022594996
reward_mean: 940.5999755859375
reward_std: 446.3821716308594
reward_max: 1792.0
reward_min: 593.0
total_envstep_count: 35731
total_train_sample_count: 35711
total_episode_count: 92
total_duration: 80.65027021084515
[2024-11-19 20:15:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 584
train_sample_count: 584
avg_envstep_per_episode: 194.66666666666666
avg_sample_per_episode: 194.66666666666666
avg_envstep_per_sec: 439.729176243798
avg_train_sample_per_sec: 439.729176243798
avg_episode_per_sec: 2.2588827546770447
collect_time: 1.3280901781150274
reward_mean: 534.0
reward_std: 211.685302734375
reward_max: 758.0
reward_min: 250.0
total_envstep_count: 36736
total_train_sample_count: 36679
total_episode_count: 95
total_duration: 81.97836038896018
[2024-11-19 20:15:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 791
train_sample_count: 791
avg_envstep_per_episode: 197.75
avg_sample_per_episode: 197.75
avg_envstep_per_sec: 436.55807342052975
avg_train_sample_per_sec: 436.55807342052975
avg_episode_per_sec: 2.207626161418608
collect_time: 1.811900977577482
reward_mean: 605.0
reward_std: 445.0146179199219
reward_max: 1329.0
reward_min: 239.0
total_envstep_count: 37717
total_train_sample_count: 37662
total_episode_count: 99
total_duration: 83.79026136653766
[2024-11-19 20:15:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 104
train_sample_count: 104
avg_envstep_per_episode: 104.0
avg_sample_per_episode: 104.0
avg_envstep_per_sec: 433.62182067784283
avg_train_sample_per_sec: 433.62182067784283
avg_episode_per_sec: 4.169440583440797
collect_time: 0.2398403286933899
reward_mean: 635.0
reward_std: 0.0
reward_max: 635.0
reward_min: 635.0
total_envstep_count: 38684
total_train_sample_count: 38630
total_episode_count: 100
total_duration: 84.03010169523105
[2024-11-19 20:15:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 677
train_sample_count: 677
avg_envstep_per_episode: 338.5
avg_sample_per_episode: 338.5
avg_envstep_per_sec: 434.7595763429368
avg_train_sample_per_sec: 434.7595763429368
avg_episode_per_sec: 1.284370978856534
collect_time: 1.557182490825653
reward_mean: 755.5
reward_std: 47.5
reward_max: 803.0
reward_min: 708.0
total_envstep_count: 39642
total_train_sample_count: 39595
total_episode_count: 102
total_duration: 85.5872841860567
[2024-11-19 20:15:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 800
train_sample_count: 800
avg_envstep_per_episode: 800.0
avg_sample_per_episode: 800.0
avg_envstep_per_sec: 437.7010042264364
avg_train_sample_per_sec: 437.7010042264364
avg_episode_per_sec: 0.5471262552830455
collect_time: 1.8277316987514496
reward_mean: 909.0
reward_std: 0.0
reward_max: 909.0
reward_min: 909.0
total_envstep_count: 40601
total_train_sample_count: 40563
total_episode_count: 103
total_duration: 87.41501588480816
[2024-11-19 20:16:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2154
train_sample_count: 2154
avg_envstep_per_episode: 359.0
avg_sample_per_episode: 359.0
avg_envstep_per_sec: 431.19231757703756
avg_train_sample_per_sec: 431.19231757703756
avg_episode_per_sec: 1.2010928066212745
collect_time: 4.995450781924385
reward_mean: 701.1666870117188
reward_std: 249.70677185058594
reward_max: 1022.0
reward_min: 239.0
total_envstep_count: 41619
total_train_sample_count: 41577
total_episode_count: 109
total_duration: 92.41046666673255
[2024-11-19 20:16:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 137
train_sample_count: 137
avg_envstep_per_episode: 45.666666666666664
avg_sample_per_episode: 45.666666666666664
avg_envstep_per_sec: 449.9110591136961
avg_train_sample_per_sec: 449.9110591136961
avg_episode_per_sec: 9.852066987891156
collect_time: 0.3045046286923545
reward_mean: 236.6666717529297
reward_std: 12.47219181060791
reward_max: 250.0
reward_min: 220.0
total_envstep_count: 42609
total_train_sample_count: 42590
total_episode_count: 112
total_duration: 92.7149712954249
[2024-11-19 20:16:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 156
train_sample_count: 156
avg_envstep_per_episode: 52.0
avg_sample_per_episode: 52.0
avg_envstep_per_sec: 436.5119375724776
avg_train_sample_per_sec: 436.5119375724776
avg_episode_per_sec: 8.394460337932262
collect_time: 0.3573785424232483
reward_mean: 210.0
reward_std: 7.4833149909973145
reward_max: 220.0
reward_min: 202.0
total_envstep_count: 43583
total_train_sample_count: 43562
total_episode_count: 115
total_duration: 93.07234983784815
[2024-11-19 20:16:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 396
train_sample_count: 396
avg_envstep_per_episode: 396.0
avg_sample_per_episode: 396.0
avg_envstep_per_sec: 430.4446888075159
avg_train_sample_per_sec: 430.4446888075159
avg_episode_per_sec: 1.086981537392717
collect_time: 0.9199788272380829
reward_mean: 712.0
reward_std: 0.0
reward_max: 712.0
reward_min: 712.0
total_envstep_count: 44542
total_train_sample_count: 44522
total_episode_count: 116
total_duration: 93.99232866508623
[2024-11-19 20:16:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1480
train_sample_count: 1480
avg_envstep_per_episode: 370.0
avg_sample_per_episode: 370.0
avg_envstep_per_sec: 433.164928900121
avg_train_sample_per_sec: 433.164928900121
avg_episode_per_sec: 1.170716024054381
collect_time: 3.4167124373572215
reward_mean: 573.75
reward_std: 226.65213012695312
reward_max: 834.0
reward_min: 210.0
total_envstep_count: 45562
total_train_sample_count: 45510
total_episode_count: 120
total_duration: 97.40904110244345
[2024-11-19 20:16:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1391
train_sample_count: 1391
avg_envstep_per_episode: 463.6666666666667
avg_sample_per_episode: 463.6666666666667
avg_envstep_per_sec: 436.2952338690222
avg_train_sample_per_sec: 436.2952338690222
avg_episode_per_sec: 0.9409674346564101
collect_time: 3.188208103179932
reward_mean: 529.6666870117188
reward_std: 412.49188232421875
reward_max: 1113.0
reward_min: 234.0
total_envstep_count: 46535
total_train_sample_count: 46505
total_episode_count: 123
total_duration: 100.59724920562338
[2024-11-19 20:16:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1568
train_sample_count: 1568
avg_envstep_per_episode: 261.3333333333333
avg_sample_per_episode: 261.3333333333333
avg_envstep_per_sec: 435.9025893505429
avg_train_sample_per_sec: 435.9025893505429
avg_episode_per_sec: 1.6679946021066692
collect_time: 3.5971339430127824
reward_mean: 514.0
reward_std: 213.0586700439453
reward_max: 802.0
reward_min: 229.0
total_envstep_count: 47545
total_train_sample_count: 47497
total_episode_count: 129
total_duration: 104.19438314863616
[2024-11-19 20:16:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1155
train_sample_count: 1155
avg_envstep_per_episode: 385.0
avg_sample_per_episode: 385.0
avg_envstep_per_sec: 435.12204526679017
avg_train_sample_per_sec: 435.12204526679017
avg_episode_per_sec: 1.1301871305630913
collect_time: 2.6544276773929596
reward_mean: 619.0
reward_std: 11.224971771240234
reward_max: 631.0
reward_min: 604.0
total_envstep_count: 48535
total_train_sample_count: 48508
total_episode_count: 132
total_duration: 106.84881082602912
[2024-11-19 20:16:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 240
train_sample_count: 240
avg_envstep_per_episode: 80.0
avg_sample_per_episode: 80.0
avg_envstep_per_sec: 427.811835467196
avg_train_sample_per_sec: 427.811835467196
avg_episode_per_sec: 5.3476479433399495
collect_time: 0.5609942972660065
reward_mean: 362.3333435058594
reward_std: 178.72946166992188
reward_max: 615.0
reward_min: 230.0
total_envstep_count: 49502
total_train_sample_count: 49480
total_episode_count: 135
total_duration: 107.40980512329513
[2024-11-19 20:16:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 447
train_sample_count: 447
avg_envstep_per_episode: 447.0
avg_sample_per_episode: 447.0
avg_envstep_per_sec: 429.168069537709
avg_train_sample_per_sec: 429.168069537709
avg_episode_per_sec: 0.9601075381156801
collect_time: 1.0415499934128352
reward_mean: 986.0
reward_std: 0.0
reward_max: 986.0
reward_min: 986.0
total_envstep_count: 50461
total_train_sample_count: 50443
total_episode_count: 136
total_duration: 108.45135511670796
[2024-11-19 20:16:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2047
train_sample_count: 2047
avg_envstep_per_episode: 409.4
avg_sample_per_episode: 409.4
avg_envstep_per_sec: 433.05460726941527
avg_train_sample_per_sec: 433.05460726941527
avg_episode_per_sec: 1.0577787182936378
collect_time: 4.726886553423745
reward_mean: 567.4000244140625
reward_std: 312.6797790527344
reward_max: 995.0
reward_min: 193.0
total_envstep_count: 51481
total_train_sample_count: 51446
total_episode_count: 141
total_duration: 113.1782416701317
[2024-11-19 20:17:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1665
train_sample_count: 1665
avg_envstep_per_episode: 416.25
avg_sample_per_episode: 416.25
avg_envstep_per_sec: 434.44011059318854
avg_train_sample_per_sec: 434.44011059318854
avg_episode_per_sec: 1.0436999653890415
collect_time: 3.832519050155368
reward_mean: 622.25
reward_std: 231.75674438476562
reward_max: 805.0
reward_min: 236.0
total_envstep_count: 52486
total_train_sample_count: 52451
total_episode_count: 145
total_duration: 117.01076072028707
[2024-11-19 20:17:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1912
train_sample_count: 1912
avg_envstep_per_episode: 239.0
avg_sample_per_episode: 239.0
avg_envstep_per_sec: 438.24586266763794
avg_train_sample_per_sec: 438.24586266763794
avg_episode_per_sec: 1.8336646973541335
collect_time: 4.362847805023193
reward_mean: 522.625
reward_std: 301.9411926269531
reward_max: 926.0
reward_min: 222.0
total_envstep_count: 53486
total_train_sample_count: 53451
total_episode_count: 153
total_duration: 121.37360852531026
[2024-11-19 20:17:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 208
train_sample_count: 208
avg_envstep_per_episode: 69.33333333333333
avg_sample_per_episode: 69.33333333333333
avg_envstep_per_sec: 433.2144099977937
avg_train_sample_per_sec: 433.2144099977937
avg_episode_per_sec: 6.248284759583563
collect_time: 0.4801317666258131
reward_mean: 357.0
reward_std: 176.10792541503906
reward_max: 606.0
reward_min: 228.0
total_envstep_count: 54475
total_train_sample_count: 54439
total_episode_count: 156
total_duration: 121.85374029193608
[2024-11-19 20:17:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1206
train_sample_count: 1206
avg_envstep_per_episode: 301.5
avg_sample_per_episode: 301.5
avg_envstep_per_sec: 429.6711456691885
avg_train_sample_per_sec: 429.6711456691885
avg_episode_per_sec: 1.4251115942593315
collect_time: 2.8067977385861536
reward_mean: 840.25
reward_std: 478.2945556640625
reward_max: 1557.0
reward_min: 247.0
total_envstep_count: 55441
total_train_sample_count: 55417
total_episode_count: 160
total_duration: 124.66053803052223
[2024-11-19 20:17:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 230
train_sample_count: 230
avg_envstep_per_episode: 115.0
avg_sample_per_episode: 115.0
avg_envstep_per_sec: 424.41875042414273
avg_train_sample_per_sec: 424.41875042414273
avg_episode_per_sec: 3.690597829775154
collect_time: 0.541917622089386
reward_mean: 494.5
reward_std: 250.5
reward_max: 745.0
reward_min: 244.0
total_envstep_count: 56447
total_train_sample_count: 56391
total_episode_count: 162
total_duration: 125.20245565261162
[2024-11-19 20:17:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 178
train_sample_count: 178
avg_envstep_per_episode: 89.0
avg_sample_per_episode: 89.0
avg_envstep_per_sec: 431.0548038266496
avg_train_sample_per_sec: 431.0548038266496
avg_episode_per_sec: 4.843312402546625
collect_time: 0.41294053196907043
reward_mean: 410.0
reward_std: 191.0
reward_max: 601.0
reward_min: 219.0
total_envstep_count: 57406
total_train_sample_count: 57361
total_episode_count: 164
total_duration: 125.61539618458069
[2024-11-19 20:17:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1382
train_sample_count: 1382
avg_envstep_per_episode: 460.6666666666667
avg_sample_per_episode: 460.6666666666667
avg_envstep_per_sec: 430.92373376709236
avg_train_sample_per_sec: 430.92373376709236
avg_episode_per_sec: 0.9354350226492598
collect_time: 3.207064015524728
reward_mean: 704.3333129882812
reward_std: 337.7428283691406
reward_max: 1007.0
reward_min: 233.0
total_envstep_count: 58404
total_train_sample_count: 58371
total_episode_count: 167
total_duration: 128.8224602001054
[2024-11-19 20:18:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 793
train_sample_count: 793
avg_envstep_per_episode: 793.0
avg_sample_per_episode: 793.0
avg_envstep_per_sec: 434.41372639016254
avg_train_sample_per_sec: 434.41372639016254
avg_episode_per_sec: 0.5478104998614912
collect_time: 1.8254487642220087
reward_mean: 646.0
reward_std: 0.0
reward_max: 646.0
reward_min: 646.0
total_envstep_count: 59379
total_train_sample_count: 59332
total_episode_count: 168
total_duration: 130.64790896432743
[2024-11-19 20:18:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2604
train_sample_count: 2604
avg_envstep_per_episode: 520.8
avg_sample_per_episode: 520.8
avg_envstep_per_sec: 426.87204218551705
avg_train_sample_per_sec: 426.87204218551705
avg_episode_per_sec: 0.8196467783900097
collect_time: 6.100188681057522
reward_mean: 904.5999755859375
reward_std: 195.71469116210938
reward_max: 1217.0
reward_min: 623.0
total_envstep_count: 60337
total_train_sample_count: 60304
total_episode_count: 173
total_duration: 136.74809764538495
[2024-11-19 20:18:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 421
train_sample_count: 421
avg_envstep_per_episode: 105.25
avg_sample_per_episode: 105.25
avg_envstep_per_sec: 408.7171614478547
avg_train_sample_per_sec: 408.7171614478547
avg_episode_per_sec: 3.8832984460603774
collect_time: 1.03005217228617
reward_mean: 427.75
reward_std: 335.591552734375
reward_max: 1009.0
reward_min: 231.0
total_envstep_count: 61333
total_train_sample_count: 61301
total_episode_count: 177
total_duration: 137.7781498176711
[2024-11-19 20:18:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1253
train_sample_count: 1253
avg_envstep_per_episode: 250.6
avg_sample_per_episode: 250.6
avg_envstep_per_sec: 416.48192721258033
avg_train_sample_per_sec: 416.48192721258033
avg_episode_per_sec: 1.661939055118038
collect_time: 3.00853390778814
reward_mean: 713.0
reward_std: 165.67437744140625
reward_max: 1030.0
reward_min: 576.0
total_envstep_count: 62321
total_train_sample_count: 62290
total_episode_count: 182
total_duration: 140.78668372545926
[2024-11-19 20:18:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 293
train_sample_count: 293
avg_envstep_per_episode: 58.6
avg_sample_per_episode: 58.6
avg_envstep_per_sec: 420.5709217990785
avg_train_sample_per_sec: 420.5709217990785
avg_episode_per_sec: 7.1769781876975856
collect_time: 0.6966720351151057
reward_mean: 397.20001220703125
reward_std: 197.6060791015625
reward_max: 647.0
reward_min: 225.0
total_envstep_count: 63317
total_train_sample_count: 63279
total_episode_count: 187
total_duration: 141.48335576057437
[2024-11-19 20:18:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 197
train_sample_count: 197
avg_envstep_per_episode: 98.5
avg_sample_per_episode: 98.5
avg_envstep_per_sec: 426.52762717563115
avg_train_sample_per_sec: 426.52762717563115
avg_episode_per_sec: 4.330229717519098
collect_time: 0.46186926109450205
reward_mean: 426.5
reward_std: 197.5
reward_max: 624.0
reward_min: 229.0
total_envstep_count: 64299
total_train_sample_count: 64244
total_episode_count: 189
total_duration: 141.94522502166888
[2024-11-19 20:18:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1549
train_sample_count: 1549
avg_envstep_per_episode: 309.8
avg_sample_per_episode: 309.8
avg_envstep_per_sec: 418.34424919525145
avg_train_sample_per_sec: 418.34424919525145
avg_episode_per_sec: 1.3503687837161118
collect_time: 3.7026922277041843
reward_mean: 700.5999755859375
reward_std: 293.00823974609375
reward_max: 1025.0
reward_min: 194.0
total_envstep_count: 65254
total_train_sample_count: 65217
total_episode_count: 194
total_duration: 145.64791724937305
[2024-11-19 20:19:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 389
train_sample_count: 389
avg_envstep_per_episode: 194.5
avg_sample_per_episode: 194.5
avg_envstep_per_sec: 413.57602106458177
avg_train_sample_per_sec: 413.57602106458177
avg_episode_per_sec: 2.126354864085253
collect_time: 0.9405767747334072
reward_mean: 1023.0
reward_std: 388.0
reward_max: 1411.0
reward_min: 635.0
total_envstep_count: 66220
total_train_sample_count: 66182
total_episode_count: 196
total_duration: 146.58849402410647
[2024-11-19 20:19:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1447
train_sample_count: 1447
avg_envstep_per_episode: 206.71428571428572
avg_sample_per_episode: 206.71428571428572
avg_envstep_per_sec: 412.14686134162923
avg_train_sample_per_sec: 412.14686134162923
avg_episode_per_sec: 1.9937996056609568
collect_time: 3.510884433984757
reward_mean: 498.0
reward_std: 344.5062561035156
reward_max: 1175.0
reward_min: 229.0
total_envstep_count: 67221
total_train_sample_count: 67185
total_episode_count: 203
total_duration: 150.09937845809122
[2024-11-19 20:19:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1148
train_sample_count: 1148
avg_envstep_per_episode: 382.6666666666667
avg_sample_per_episode: 382.6666666666667
avg_envstep_per_sec: 414.3858561700618
avg_train_sample_per_sec: 414.3858561700618
avg_episode_per_sec: 1.0828898680402312
collect_time: 2.7703648252146587
reward_mean: 915.3333129882812
reward_std: 488.516357421875
reward_max: 1284.0
reward_min: 225.0
total_envstep_count: 68227
total_train_sample_count: 68189
total_episode_count: 206
total_duration: 152.8697432833059
[2024-11-19 20:19:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2647
train_sample_count: 2647
avg_envstep_per_episode: 330.875
avg_sample_per_episode: 330.875
avg_envstep_per_sec: 417.8467115765256
avg_train_sample_per_sec: 417.8467115765256
avg_episode_per_sec: 1.2628536806241801
collect_time: 6.334858996527537
reward_mean: 599.25
reward_std: 244.8457489013672
reward_max: 1032.0
reward_min: 235.0
total_envstep_count: 69284
total_train_sample_count: 69252
total_episode_count: 214
total_duration: 159.20460227983344
[2024-11-19 20:19:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 569
train_sample_count: 569
avg_envstep_per_episode: 189.66666666666666
avg_sample_per_episode: 189.66666666666666
avg_envstep_per_sec: 417.5260036741218
avg_train_sample_per_sec: 417.5260036741218
avg_episode_per_sec: 2.2013673304435244
collect_time: 1.3627893711839403
reward_mean: 733.6666870117188
reward_std: 70.47615814208984
reward_max: 784.0
reward_min: 634.0
total_envstep_count: 70282
total_train_sample_count: 70241
total_episode_count: 217
total_duration: 160.56739165101737
[2024-11-19 20:19:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 395
train_sample_count: 395
avg_envstep_per_episode: 98.75
avg_sample_per_episode: 98.75
avg_envstep_per_sec: 419.9050217593145
avg_train_sample_per_sec: 419.9050217593145
avg_episode_per_sec: 4.252202751993058
collect_time: 0.9406889166150774
reward_mean: 419.0
reward_std: 187.8656463623047
reward_max: 634.0
reward_min: 218.0
total_envstep_count: 71262
total_train_sample_count: 71212
total_episode_count: 221
total_duration: 161.50808056763245
[2024-11-19 20:19:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 662
train_sample_count: 662
avg_envstep_per_episode: 220.66666666666666
avg_sample_per_episode: 220.66666666666666
avg_envstep_per_sec: 421.7608928749965
avg_train_sample_per_sec: 421.7608928749965
avg_episode_per_sec: 1.9113031399169027
collect_time: 1.5696097271783012
reward_mean: 777.3333129882812
reward_std: 532.7565307617188
reward_max: 1503.0
reward_min: 239.0
total_envstep_count: 72227
total_train_sample_count: 72186
total_episode_count: 224
total_duration: 163.07769029481074
[2024-11-19 20:19:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 990
train_sample_count: 990
avg_envstep_per_episode: 247.5
avg_sample_per_episode: 247.5
avg_envstep_per_sec: 418.62779748382405
avg_train_sample_per_sec: 418.62779748382405
avg_episode_per_sec: 1.691425444379087
collect_time: 2.364869236946106
reward_mean: 759.75
reward_std: 309.803466796875
reward_max: 1008.0
reward_min: 243.0
total_envstep_count: 73215
total_train_sample_count: 73176
total_episode_count: 228
total_duration: 165.44255953175684
[2024-11-19 20:19:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1885
train_sample_count: 1885
avg_envstep_per_episode: 377.0
avg_sample_per_episode: 377.0
avg_envstep_per_sec: 415.0849944961321
avg_train_sample_per_sec: 415.0849944961321
avg_episode_per_sec: 1.1010212055600321
collect_time: 4.5412386017186295
reward_mean: 633.7999877929688
reward_std: 378.26519775390625
reward_max: 1156.0
reward_min: 205.0
total_envstep_count: 74212
total_train_sample_count: 74173
total_episode_count: 233
total_duration: 169.98379813347546
[2024-11-19 20:19:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 480
train_sample_count: 480
avg_envstep_per_episode: 480.0
avg_sample_per_episode: 480.0
avg_envstep_per_sec: 413.647527543838
avg_train_sample_per_sec: 413.647527543838
avg_episode_per_sec: 0.8617656823829959
collect_time: 1.160408241408212
reward_mean: 1282.0
reward_std: 0.0
reward_max: 1282.0
reward_min: 1282.0
total_envstep_count: 75171
total_train_sample_count: 75133
total_episode_count: 234
total_duration: 171.14420637488368
[2024-11-19 20:20:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 666
train_sample_count: 666
avg_envstep_per_episode: 222.0
avg_sample_per_episode: 222.0
avg_envstep_per_sec: 406.0011583810928
avg_train_sample_per_sec: 406.0011583810928
avg_episode_per_sec: 1.8288340467616793
collect_time: 1.6403894083840505
reward_mean: 823.0
reward_std: 166.7653045654297
reward_max: 1039.0
reward_min: 633.0
total_envstep_count: 76137
total_train_sample_count: 76099
total_episode_count: 237
total_duration: 172.78459578326772
[2024-11-19 20:20:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 78
train_sample_count: 78
avg_envstep_per_episode: 78.0
avg_sample_per_episode: 78.0
avg_envstep_per_sec: 407.26537033472454
avg_train_sample_per_sec: 407.26537033472454
avg_episode_per_sec: 5.221350901727238
collect_time: 0.1915213167667389
reward_mean: 606.0
reward_std: 0.0
reward_max: 606.0
reward_min: 606.0
total_envstep_count: 77105
total_train_sample_count: 77065
total_episode_count: 238
total_duration: 172.97611710003446
[2024-11-19 20:20:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1834
train_sample_count: 1834
avg_envstep_per_episode: 229.25
avg_sample_per_episode: 229.25
avg_envstep_per_sec: 409.0779531731921
avg_train_sample_per_sec: 409.0779531731921
avg_episode_per_sec: 1.7844185525548184
collect_time: 4.48325309583119
reward_mean: 558.0
reward_std: 286.62518310546875
reward_max: 984.0
reward_min: 219.0
total_envstep_count: 78156
total_train_sample_count: 78119
total_episode_count: 246
total_duration: 177.45937019586566
[2024-11-19 20:20:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1118
train_sample_count: 1118
avg_envstep_per_episode: 186.33333333333334
avg_sample_per_episode: 186.33333333333334
avg_envstep_per_sec: 407.01524217820594
avg_train_sample_per_sec: 407.01524217820594
avg_episode_per_sec: 2.184339403460855
collect_time: 2.746825878109251
reward_mean: 568.1666870117188
reward_std: 263.43841552734375
reward_max: 935.0
reward_min: 226.0
total_envstep_count: 79143
total_train_sample_count: 79093
total_episode_count: 252
total_duration: 180.20619607397492
[2024-11-19 20:21:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 837
train_sample_count: 837
avg_envstep_per_episode: 837.0
avg_sample_per_episode: 837.0
avg_envstep_per_sec: 409.4982476763666
avg_train_sample_per_sec: 409.4982476763666
avg_episode_per_sec: 0.48924521825133405
collect_time: 2.043964790446418
reward_mean: 896.0
reward_std: 0.0
reward_max: 896.0
reward_min: 896.0
total_envstep_count: 80111
total_train_sample_count: 80086
total_episode_count: 253
total_duration: 182.25016086442133
[2024-11-19 20:21:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1105
train_sample_count: 1105
avg_envstep_per_episode: 157.85714285714286
avg_sample_per_episode: 157.85714285714286
avg_envstep_per_sec: 411.45786983422835
avg_train_sample_per_sec: 411.45786983422835
avg_episode_per_sec: 2.606520442388777
collect_time: 2.685572645493916
reward_mean: 614.7142944335938
reward_std: 371.9883728027344
reward_max: 1292.0
reward_min: 205.0
total_envstep_count: 81098
total_train_sample_count: 81059
total_episode_count: 260
total_duration: 184.93573350991525
[2024-11-19 20:21:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 566
train_sample_count: 566
avg_envstep_per_episode: 188.66666666666666
avg_sample_per_episode: 188.66666666666666
avg_envstep_per_sec: 414.6773531588604
avg_train_sample_per_sec: 414.6773531588604
avg_episode_per_sec: 2.197936500842016
collect_time: 1.36491659283638
reward_mean: 359.3333435058594
reward_std: 211.6999969482422
reward_max: 658.0
reward_min: 192.0
total_envstep_count: 82079
total_train_sample_count: 82057
total_episode_count: 263
total_duration: 186.30065010275163
[2024-11-19 20:21:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 558
train_sample_count: 558
avg_envstep_per_episode: 139.5
avg_sample_per_episode: 139.5
avg_envstep_per_sec: 410.74999387934815
avg_train_sample_per_sec: 410.74999387934815
avg_episode_per_sec: 2.9444444005688037
collect_time: 1.3584905862808228
reward_mean: 568.0
reward_std: 212.789794921875
reward_max: 796.0
reward_min: 219.0
total_envstep_count: 83083
total_train_sample_count: 83035
total_episode_count: 267
total_duration: 187.65914068903245
[2024-11-19 20:21:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2070
train_sample_count: 2070
avg_envstep_per_episode: 690.0
avg_sample_per_episode: 690.0
avg_envstep_per_sec: 410.7196040978494
avg_train_sample_per_sec: 410.7196040978494
avg_episode_per_sec: 0.5952458030403615
collect_time: 5.039934737341745
reward_mean: 932.3333129882812
reward_std: 111.2634506225586
reward_max: 1013.0
reward_min: 775.0
total_envstep_count: 84057
total_train_sample_count: 84025
total_episode_count: 270
total_duration: 192.6990754263742
[2024-11-19 20:21:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1516
train_sample_count: 1516
avg_envstep_per_episode: 758.0
avg_sample_per_episode: 758.0
avg_envstep_per_sec: 411.6465295345592
avg_train_sample_per_sec: 411.6465295345592
avg_episode_per_sec: 0.5430693001775188
collect_time: 3.6827712399618964
reward_mean: 957.5
reward_std: 353.5
reward_max: 1311.0
reward_min: 604.0
total_envstep_count: 85031
total_train_sample_count: 85001
total_episode_count: 272
total_duration: 196.38184666633612
[2024-11-19 20:21:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 117
train_sample_count: 117
avg_envstep_per_episode: 39.0
avg_sample_per_episode: 39.0
avg_envstep_per_sec: 398.7864396635518
avg_train_sample_per_sec: 398.7864396635518
avg_episode_per_sec: 10.225293324706456
collect_time: 0.2933901165212904
reward_mean: 237.0
reward_std: 17.72004508972168
reward_max: 251.0
reward_min: 212.0
total_envstep_count: 86036
total_train_sample_count: 85994
total_episode_count: 275
total_duration: 196.6752367828574
[2024-11-19 20:21:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 490
train_sample_count: 490
avg_envstep_per_episode: 245.0
avg_sample_per_episode: 245.0
avg_envstep_per_sec: 406.3590525046053
avg_train_sample_per_sec: 406.3590525046053
avg_episode_per_sec: 1.6586083775698175
collect_time: 1.205830156803131
reward_mean: 1001.0
reward_std: 382.0
reward_max: 1383.0
reward_min: 619.0
total_envstep_count: 87010
total_train_sample_count: 86964
total_episode_count: 277
total_duration: 197.88106693966054
[2024-11-19 20:21:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1601
train_sample_count: 1601
avg_envstep_per_episode: 400.25
avg_sample_per_episode: 400.25
avg_envstep_per_sec: 402.87641758212635
avg_train_sample_per_sec: 402.87641758212635
avg_episode_per_sec: 1.0065619427411026
collect_time: 3.973923342568534
reward_mean: 749.75
reward_std: 149.06605529785156
reward_max: 997.0
reward_min: 598.0
total_envstep_count: 87984
total_train_sample_count: 87941
total_episode_count: 281
total_duration: 201.85499028222907
[2024-11-19 20:21:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1280
train_sample_count: 1280
avg_envstep_per_episode: 320.0
avg_sample_per_episode: 320.0
avg_envstep_per_sec: 402.0969523358721
avg_train_sample_per_sec: 402.0969523358721
avg_episode_per_sec: 1.2565529760496004
collect_time: 3.1833118668624336
reward_mean: 639.5
reward_std: 273.65533447265625
reward_max: 1003.0
reward_min: 233.0
total_envstep_count: 88956
total_train_sample_count: 88921
total_episode_count: 285
total_duration: 205.0383021490915
[2024-11-19 20:22:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2037
train_sample_count: 2037
avg_envstep_per_episode: 339.5
avg_sample_per_episode: 339.5
avg_envstep_per_sec: 401.48961118712424
avg_train_sample_per_sec: 401.48961118712424
avg_episode_per_sec: 1.1825909018766545
collect_time: 5.073605750288282
reward_mean: 876.3333129882812
reward_std: 324.1551513671875
reward_max: 1536.0
reward_min: 595.0
total_envstep_count: 89991
total_train_sample_count: 89962
total_episode_count: 291
total_duration: 210.1119078993798
[2024-11-19 20:22:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 778
train_sample_count: 778
avg_envstep_per_episode: 129.66666666666666
avg_sample_per_episode: 129.66666666666666
avg_envstep_per_sec: 407.6779180940149
avg_train_sample_per_sec: 407.6779180940149
avg_episode_per_sec: 3.144045640827878
collect_time: 1.908369243144989
reward_mean: 674.5
reward_std: 443.41015625
reward_max: 1556.0
reward_min: 235.0
total_envstep_count: 91017
total_train_sample_count: 90980
total_episode_count: 297
total_duration: 212.02027714252478
[2024-11-19 20:22:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 608
train_sample_count: 608
avg_envstep_per_episode: 121.6
avg_sample_per_episode: 121.6
avg_envstep_per_sec: 405.67825506805
avg_train_sample_per_sec: 405.67825506805
avg_episode_per_sec: 3.3361698607569905
collect_time: 1.4987246479306902
reward_mean: 530.5999755859375
reward_std: 149.90609741210938
reward_max: 634.0
reward_min: 233.0
total_envstep_count: 92006
total_train_sample_count: 91972
total_episode_count: 302
total_duration: 213.51900179045546
[2024-11-19 20:22:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 552
train_sample_count: 552
avg_envstep_per_episode: 92.0
avg_sample_per_episode: 92.0
avg_envstep_per_sec: 401.0545481876376
avg_train_sample_per_sec: 401.0545481876376
avg_episode_per_sec: 4.35928856725693
collect_time: 1.376371375152043
reward_mean: 450.0
reward_std: 214.780517578125
reward_max: 744.0
reward_min: 221.0
total_envstep_count: 93017
total_train_sample_count: 92968
total_episode_count: 308
total_duration: 214.8953731656075
[2024-11-19 20:22:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 2010
train_sample_count: 2010
avg_envstep_per_episode: 223.33333333333334
avg_sample_per_episode: 223.33333333333334
avg_envstep_per_sec: 407.9718361042291
avg_train_sample_per_sec: 407.9718361042291
avg_episode_per_sec: 1.826739564645802
collect_time: 4.926810681819916
reward_mean: 651.888916015625
reward_std: 435.5352783203125
reward_max: 1370.0
reward_min: 229.0
total_envstep_count: 94026
total_train_sample_count: 93982
total_episode_count: 317
total_duration: 219.82218384742743
[2024-11-19 20:22:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 134
train_sample_count: 134
avg_envstep_per_episode: 134.0
avg_sample_per_episode: 134.0
avg_envstep_per_sec: 408.4472671386006
avg_train_sample_per_sec: 408.4472671386006
avg_episode_per_sec: 3.0481139338701535
collect_time: 0.3280717262199947
reward_mean: 730.0
reward_std: 0.0
reward_max: 730.0
reward_min: 730.0
total_envstep_count: 94985
total_train_sample_count: 94944
total_episode_count: 318
total_duration: 220.15025557364743
[2024-11-19 20:22:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 550
train_sample_count: 550
avg_envstep_per_episode: 275.0
avg_sample_per_episode: 275.0
avg_envstep_per_sec: 401.8204529631823
avg_train_sample_per_sec: 401.8204529631823
avg_episode_per_sec: 1.461165283502481
collect_time: 1.3687705440180642
reward_mean: 816.0
reward_std: 184.0
reward_max: 1000.0
reward_min: 632.0
total_envstep_count: 95959
total_train_sample_count: 95926
total_episode_count: 320
total_duration: 221.5190261176655
[2024-11-19 20:22:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 322
train_sample_count: 322
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 408.9333560632407
avg_train_sample_per_sec: 408.9333560632407
avg_episode_per_sec: 2.539958733312054
collect_time: 0.7874143677098411
reward_mean: 694.5
reward_std: 74.5
reward_max: 769.0
reward_min: 620.0
total_envstep_count: 96926
total_train_sample_count: 96896
total_episode_count: 322
total_duration: 222.30644048537533
[2024-11-19 20:22:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 3432
train_sample_count: 3432
avg_envstep_per_episode: 381.3333333333333
avg_sample_per_episode: 381.3333333333333
avg_envstep_per_sec: 406.52092520498803
avg_train_sample_per_sec: 406.52092520498803
avg_episode_per_sec: 1.0660513772858078
collect_time: 8.442369844232287
reward_mean: 1074.3333740234375
reward_std: 307.2056884765625
reward_max: 1611.0
reward_min: 622.0
total_envstep_count: 97926
total_train_sample_count: 97880
total_episode_count: 331
total_duration: 230.7488103296076
[2024-11-19 20:23:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 675
train_sample_count: 675
avg_envstep_per_episode: 96.42857142857143
avg_sample_per_episode: 96.42857142857143
avg_envstep_per_sec: 381.98800911656537
avg_train_sample_per_sec: 381.98800911656537
avg_episode_per_sec: 3.9613571315791964
collect_time: 1.7670711747237613
reward_mean: 489.71429443359375
reward_std: 226.5843963623047
reward_max: 779.0
reward_min: 226.0
total_envstep_count: 98913
total_train_sample_count: 98879
total_episode_count: 338
total_duration: 232.51588150433136
[2024-11-19 20:23:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 994
train_sample_count: 994
avg_envstep_per_episode: 142.0
avg_sample_per_episode: 142.0
avg_envstep_per_sec: 384.9717072486462
avg_train_sample_per_sec: 384.9717072486462
avg_episode_per_sec: 2.7110683609059594
collect_time: 2.582007927553994
reward_mean: 577.0
reward_std: 253.9161834716797
reward_max: 1013.0
reward_min: 229.0
total_envstep_count: 99883
total_train_sample_count: 99849
total_episode_count: 345
total_duration: 235.09788943188536
[2024-11-19 20:23:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1164
train_sample_count: 1164
avg_envstep_per_episode: 105.81818181818181
avg_sample_per_episode: 105.81818181818181
avg_envstep_per_sec: 389.6193526136124
avg_train_sample_per_sec: 389.6193526136124
avg_episode_per_sec: 3.6819698271045844
collect_time: 2.9875312717187974
reward_mean: 551.6363525390625
reward_std: 315.0195617675781
reward_max: 1037.0
reward_min: 211.0
total_envstep_count: 100913
total_train_sample_count: 100869
total_episode_count: 356
total_duration: 238.08542070360417
[2024-11-19 20:24:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 463
train_sample_count: 463
avg_envstep_per_episode: 92.6
avg_sample_per_episode: 92.6
avg_envstep_per_sec: 390.45679600697173
avg_train_sample_per_sec: 390.45679600697173
avg_episode_per_sec: 4.21659606918976
collect_time: 1.1857906040691195
reward_mean: 389.6000061035156
reward_std: 193.88201904296875
reward_max: 637.0
reward_min: 215.0
total_envstep_count: 101916
total_train_sample_count: 101872
total_episode_count: 361
total_duration: 239.2712113076733
[2024-11-19 20:24:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1009
train_sample_count: 1009
avg_envstep_per_episode: 144.14285714285714
avg_sample_per_episode: 144.14285714285714
avg_envstep_per_sec: 393.9505668790668
avg_train_sample_per_sec: 393.9505668790668
avg_episode_per_sec: 2.7330564600133473
collect_time: 2.5612350503603625
reward_mean: 610.0
reward_std: 463.9368591308594
reward_max: 1321.0
reward_min: 232.0
total_envstep_count: 102927
total_train_sample_count: 102893
total_episode_count: 368
total_duration: 241.83244635803365
[2024-11-19 20:24:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 896
train_sample_count: 896
avg_envstep_per_episode: 149.33333333333334
avg_sample_per_episode: 149.33333333333334
avg_envstep_per_sec: 396.75370463615747
avg_train_sample_per_sec: 396.75370463615747
avg_episode_per_sec: 2.6568328435456974
collect_time: 2.258327999285289
reward_mean: 685.6666870117188
reward_std: 319.4602966308594
reward_max: 1290.0
reward_min: 230.0
total_envstep_count: 103913
total_train_sample_count: 103873
total_episode_count: 374
total_duration: 244.09077435731894
[2024-11-19 20:24:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1467
train_sample_count: 1467
avg_envstep_per_episode: 183.375
avg_sample_per_episode: 183.375
avg_envstep_per_sec: 391.56400401088183
avg_train_sample_per_sec: 391.56400401088183
avg_episode_per_sec: 2.135318358614216
collect_time: 3.7465139414582938
reward_mean: 569.625
reward_std: 353.800048828125
reward_max: 1033.0
reward_min: 228.0
total_envstep_count: 104908
total_train_sample_count: 104860
total_episode_count: 382
total_duration: 247.83728829877722
[2024-11-19 20:24:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 687
train_sample_count: 687
avg_envstep_per_episode: 171.75
avg_sample_per_episode: 171.75
avg_envstep_per_sec: 391.21253817615053
avg_train_sample_per_sec: 391.21253817615053
avg_episode_per_sec: 2.2778022601231473
collect_time: 1.7560786860329762
reward_mean: 564.25
reward_std: 355.00518798828125
reward_max: 1020.0
reward_min: 201.0
total_envstep_count: 105898
total_train_sample_count: 105883
total_episode_count: 386
total_duration: 249.5933669848102
[2024-11-19 20:24:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1418
train_sample_count: 1418
avg_envstep_per_episode: 141.8
avg_sample_per_episode: 141.8
avg_envstep_per_sec: 386.768851305276
avg_train_sample_per_sec: 386.768851305276
avg_episode_per_sec: 2.727565947145811
collect_time: 3.6662724912166595
reward_mean: 699.2999877929688
reward_std: 309.0838317871094
reward_max: 1333.0
reward_min: 238.0
total_envstep_count: 106915
total_train_sample_count: 106881
total_episode_count: 396
total_duration: 253.25963947602685
[2024-11-19 20:24:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 873
train_sample_count: 873
avg_envstep_per_episode: 124.71428571428571
avg_sample_per_episode: 124.71428571428571
avg_envstep_per_sec: 378.72195662671857
avg_train_sample_per_sec: 378.72195662671857
avg_episode_per_sec: 3.0367167198018667
collect_time: 2.3051211706229617
reward_mean: 506.1428527832031
reward_std: 271.8452453613281
reward_max: 1005.0
reward_min: 223.0
total_envstep_count: 107933
total_train_sample_count: 107898
total_episode_count: 403
total_duration: 255.5647606466498
[2024-11-19 20:24:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 522
train_sample_count: 522
avg_envstep_per_episode: 174.0
avg_sample_per_episode: 174.0
avg_envstep_per_sec: 292.91156514964496
avg_train_sample_per_sec: 292.91156514964496
avg_episode_per_sec: 1.6833997997106034
collect_time: 1.7821078513349806
reward_mean: 646.0
reward_std: 325.0364074707031
reward_max: 1022.0
reward_min: 229.0
total_envstep_count: 108906
total_train_sample_count: 108876
total_episode_count: 406
total_duration: 257.34686849798476
[2024-11-19 20:24:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 650
train_sample_count: 650
avg_envstep_per_episode: 162.5
avg_sample_per_episode: 162.5
avg_envstep_per_sec: 393.0220803142186
avg_train_sample_per_sec: 393.0220803142186
avg_episode_per_sec: 2.4185974173182685
collect_time: 1.653851100376674
reward_mean: 780.25
reward_std: 379.93182373046875
reward_max: 1308.0
reward_min: 234.0
total_envstep_count: 109895
total_train_sample_count: 109850
total_episode_count: 410
total_duration: 259.00071959836146
[2024-11-19 20:25:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1627
train_sample_count: 1627
avg_envstep_per_episode: 325.4
avg_sample_per_episode: 325.4
avg_envstep_per_sec: 387.0413627459297
avg_train_sample_per_sec: 387.0413627459297
avg_episode_per_sec: 1.1894325837305768
collect_time: 4.203685075044632
reward_mean: 1003.2000122070312
reward_std: 181.2483367919922
reward_max: 1295.0
reward_min: 725.0
total_envstep_count: 110874
total_train_sample_count: 110829
total_episode_count: 415
total_duration: 263.2044046734061
[2024-11-19 20:25:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 804
train_sample_count: 804
avg_envstep_per_episode: 114.85714285714286
avg_sample_per_episode: 114.85714285714286
avg_envstep_per_sec: 406.3813673892139
avg_train_sample_per_sec: 406.3813673892139
avg_episode_per_sec: 3.5381462334881806
collect_time: 1.9784371640001024
reward_mean: 448.8571472167969
reward_std: 372.6114196777344
reward_max: 1263.0
reward_min: 210.0
total_envstep_count: 111830
total_train_sample_count: 111801
total_episode_count: 422
total_duration: 265.1828418374062
[2024-11-19 20:25:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1436
train_sample_count: 1436
avg_envstep_per_episode: 205.14285714285714
avg_sample_per_episode: 205.14285714285714
avg_envstep_per_sec: 511.744618591765
avg_train_sample_per_sec: 511.744618591765
avg_episode_per_sec: 2.4945768315754564
collect_time: 2.8060871532985145
reward_mean: 720.0
reward_std: 246.60205078125
reward_max: 1042.0
reward_min: 230.0
total_envstep_count: 112824
total_train_sample_count: 112793
total_episode_count: 429
total_duration: 267.9889289907047
