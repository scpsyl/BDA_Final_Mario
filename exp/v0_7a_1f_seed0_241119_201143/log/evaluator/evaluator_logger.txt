[2024-11-19 20:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 250.0, current episode: 1
[2024-11-19 20:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 250.0, current episode: 2
[2024-11-19 20:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 250.0, current episode: 3
[2024-11-19 20:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 250.0, current episode: 4
[2024-11-19 20:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 250.0, current episode: 5
[2024-11-19 20:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 250.0, current episode: 6
[2024-11-19 20:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 250.0, current episode: 7
[2024-11-19 20:12:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 250.0, current episode: 8
[2024-11-19 20:12:09][interaction_serial_evaluator.py:279][INFO] 
+-------+------------+---------------------+---------------+---------------+
| Name  | train_iter | ckpt_name           | episode_count | envstep_count |
+-------+------------+---------------------+---------------+---------------+
| Value | 0.000000   | iteration_0.pth.tar | 8.000000      | 240.000000    |
+-------+------------+---------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.000000               | 0.829694      | 289.263342          | 9.642111             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 250.000000  | 0.000000   | 250.000000 | 250.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 20:13:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 252.0, current episode: 1
[2024-11-19 20:13:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 252.0, current episode: 2
[2024-11-19 20:13:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 252.0, current episode: 3
[2024-11-19 20:13:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 252.0, current episode: 4
[2024-11-19 20:13:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 252.0, current episode: 5
[2024-11-19 20:13:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 252.0, current episode: 6
[2024-11-19 20:13:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 252.0, current episode: 7
[2024-11-19 20:13:58][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 252.0, current episode: 8
[2024-11-19 20:13:58][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 2000.000000 | iteration_2000.pth.tar | 8.000000      | 216.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 27.000000               | 0.495344      | 436.060873          | 16.150403            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 252.000000  | 0.000000   | 252.000000 | 252.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 20:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 252.0, current episode: 1
[2024-11-19 20:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 252.0, current episode: 2
[2024-11-19 20:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 252.0, current episode: 3
[2024-11-19 20:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 252.0, current episode: 4
[2024-11-19 20:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 252.0, current episode: 5
[2024-11-19 20:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 252.0, current episode: 6
[2024-11-19 20:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 252.0, current episode: 7
[2024-11-19 20:15:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 252.0, current episode: 8
[2024-11-19 20:15:50][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 4000.000000 | iteration_4000.pth.tar | 8.000000      | 216.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 27.000000               | 0.495443      | 435.973789          | 16.147177            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 252.000000  | 0.000000   | 252.000000 | 252.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 20:18:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 20:18:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 20:18:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 20:18:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 20:18:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 20:18:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 20:18:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 20:18:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 20:18:18][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 6000.000000 | iteration_6000.pth.tar | 8.000000      | 16040.000000  |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 34.683811     | 462.463595          | 0.230655             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 20:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -415.0, current episode: 1
[2024-11-19 20:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -415.0, current episode: 2
[2024-11-19 20:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -415.0, current episode: 3
[2024-11-19 20:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -415.0, current episode: 4
[2024-11-19 20:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -415.0, current episode: 5
[2024-11-19 20:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -415.0, current episode: 6
[2024-11-19 20:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -415.0, current episode: 7
[2024-11-19 20:20:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -415.0, current episode: 8
[2024-11-19 20:20:55][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 8000.000000 | iteration_8000.pth.tar | 8.000000      | 16040.000000  |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 36.829547     | 435.519881          | 0.217217             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | -415.000000 | 0.000000   | -415.000000 | -415.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 20:23:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -415.0, current episode: 1
[2024-11-19 20:23:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -415.0, current episode: 2
[2024-11-19 20:23:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -415.0, current episode: 3
[2024-11-19 20:23:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -415.0, current episode: 4
[2024-11-19 20:23:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -415.0, current episode: 5
[2024-11-19 20:23:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -415.0, current episode: 6
[2024-11-19 20:23:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -415.0, current episode: 7
[2024-11-19 20:23:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -415.0, current episode: 8
[2024-11-19 20:23:39][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 10000.000000 | iteration_10000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 38.724624     | 414.206731          | 0.206587             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | -415.000000 | 0.000000   | -415.000000 | -415.000000 |
+-------+-------------+------------+-------------+-------------+


