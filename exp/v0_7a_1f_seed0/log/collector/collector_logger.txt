[2024-11-15 01:30:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 235
train_sample_count: 235
avg_envstep_per_episode: 58.75
avg_sample_per_episode: 58.75
avg_envstep_per_sec: 869.317825635765
avg_train_sample_per_sec: 869.317825635765
avg_episode_per_sec: 14.796899159757702
collect_time: 0.27032690814563204
reward_mean: 325.0
reward_std: 176.28244018554688
reward_max: 630.0
reward_min: 210.0
total_envstep_count: 1149
total_train_sample_count: 1135
total_episode_count: 4
total_duration: 0.27032690814563204
[2024-11-15 01:30:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 773
train_sample_count: 773
avg_envstep_per_episode: 193.25
avg_sample_per_episode: 193.25
avg_envstep_per_sec: 880.2714337872955
avg_train_sample_per_sec: 880.2714337872955
avg_episode_per_sec: 4.555091507308127
collect_time: 0.8781382313796451
reward_mean: 642.75
reward_std: 49.89175796508789
reward_max: 727.0
reward_min: 597.0
total_envstep_count: 2154
total_train_sample_count: 2124
total_episode_count: 8
total_duration: 1.1484651395252772
[2024-11-15 01:30:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 327
train_sample_count: 327
avg_envstep_per_episode: 109.0
avg_sample_per_episode: 109.0
avg_envstep_per_sec: 869.9647378262343
avg_train_sample_per_sec: 869.9647378262343
avg_episode_per_sec: 7.981327869965453
collect_time: 0.3758773037365505
reward_mean: 385.6666564941406
reward_std: 224.3885498046875
reward_max: 703.0
reward_min: 227.0
total_envstep_count: 3160
total_train_sample_count: 3135
total_episode_count: 11
total_duration: 1.5243424432618276
[2024-11-15 01:30:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 586
train_sample_count: 586
avg_envstep_per_episode: 195.33333333333334
avg_sample_per_episode: 195.33333333333334
avg_envstep_per_sec: 875.5118786696175
avg_train_sample_per_sec: 875.5118786696175
avg_episode_per_sec: 4.4821427235645945
collect_time: 0.6693227291107178
reward_mean: 509.6666564941406
reward_std: 210.09573364257812
reward_max: 690.0
reward_min: 215.0
total_envstep_count: 4149
total_train_sample_count: 4117
total_episode_count: 14
total_duration: 2.1936651723725453
[2024-11-15 01:31:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 254
train_sample_count: 254
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 861.6551653139045
avg_train_sample_per_sec: 861.6551653139045
avg_episode_per_sec: 3.392343170527183
collect_time: 0.2947814975466047
reward_mean: 774.0
reward_std: 0.0
reward_max: 774.0
reward_min: 774.0
total_envstep_count: 5492
total_train_sample_count: 5463
total_episode_count: 15
total_duration: 2.48844666991915
[2024-11-15 01:31:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1310
train_sample_count: 1310
avg_envstep_per_episode: 262.0
avg_sample_per_episode: 262.0
avg_envstep_per_sec: 866.3872357606589
avg_train_sample_per_sec: 866.3872357606589
avg_episode_per_sec: 3.306821510536866
collect_time: 1.512025969369071
reward_mean: 541.7999877929688
reward_std: 285.0981750488281
reward_max: 961.0
reward_min: 213.0
total_envstep_count: 6511
total_train_sample_count: 6473
total_episode_count: 20
total_duration: 4.000472639288221
[2024-11-15 01:31:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 904
train_sample_count: 904
avg_envstep_per_episode: 301.3333333333333
avg_sample_per_episode: 301.3333333333333
avg_envstep_per_sec: 871.4551792447697
avg_train_sample_per_sec: 871.4551792447697
avg_episode_per_sec: 2.891997276254767
collect_time: 1.0373453753335136
reward_mean: 734.3333129882812
reward_std: 151.2841339111328
reward_max: 948.0
reward_min: 618.0
total_envstep_count: 7476
total_train_sample_count: 7449
total_episode_count: 23
total_duration: 5.037818014621735
[2024-11-15 01:31:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1446
train_sample_count: 1446
avg_envstep_per_episode: 241.0
avg_sample_per_episode: 241.0
avg_envstep_per_sec: 871.4343970296911
avg_train_sample_per_sec: 871.4343970296911
avg_episode_per_sec: 3.61591036111905
collect_time: 1.6593331694602969
reward_mean: 498.1666564941406
reward_std: 188.47760009765625
reward_max: 706.0
reward_min: 235.0
total_envstep_count: 8488
total_train_sample_count: 8439
total_episode_count: 29
total_duration: 6.697151184082031
[2024-11-15 01:31:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 171
train_sample_count: 171
avg_envstep_per_episode: 85.5
avg_sample_per_episode: 85.5
avg_envstep_per_sec: 823.7685616452854
avg_train_sample_per_sec: 823.7685616452854
avg_episode_per_sec: 9.634720019243105
collect_time: 0.20758257593427384
reward_mean: 416.0
reward_std: 179.0
reward_max: 595.0
reward_min: 237.0
total_envstep_count: 9447
total_train_sample_count: 9414
total_episode_count: 31
total_duration: 6.904733760016305
[2024-11-15 01:31:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2114
train_sample_count: 2114
avg_envstep_per_episode: 422.8
avg_sample_per_episode: 422.8
avg_envstep_per_sec: 851.0029947482171
avg_train_sample_per_sec: 851.0029947482171
avg_episode_per_sec: 2.0127790793477227
collect_time: 2.4841275683471133
reward_mean: 546.5999755859375
reward_std: 195.55624389648438
reward_max: 757.0
reward_min: 177.0
total_envstep_count: 10427
total_train_sample_count: 10388
total_episode_count: 36
total_duration: 9.388861328363419
[2024-11-15 01:31:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 146
train_sample_count: 146
avg_envstep_per_episode: 73.0
avg_sample_per_episode: 73.0
avg_envstep_per_sec: 843.6902455949227
avg_train_sample_per_sec: 843.6902455949227
avg_episode_per_sec: 11.55740062458798
collect_time: 0.1730492923940931
reward_mean: 428.0
reward_std: 190.0
reward_max: 618.0
reward_min: 238.0
total_envstep_count: 11417
total_train_sample_count: 11374
total_episode_count: 38
total_duration: 9.561910620757512
[2024-11-15 01:31:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 346
train_sample_count: 346
avg_envstep_per_episode: 115.33333333333333
avg_sample_per_episode: 115.33333333333333
avg_envstep_per_sec: 853.7674851136932
avg_train_sample_per_sec: 853.7674851136932
avg_episode_per_sec: 7.402608252430866
collect_time: 0.40526256390980314
reward_mean: 384.6666564941406
reward_std: 217.32362365722656
reward_max: 692.0
reward_min: 229.0
total_envstep_count: 12382
total_train_sample_count: 12356
total_episode_count: 41
total_duration: 9.967173184667315
[2024-11-15 01:31:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 811
train_sample_count: 811
avg_envstep_per_episode: 811.0
avg_sample_per_episode: 811.0
avg_envstep_per_sec: 849.6765561913913
avg_train_sample_per_sec: 849.6765561913913
avg_episode_per_sec: 1.047689958312443
collect_time: 0.9544808481420789
reward_mean: 1303.0
reward_std: 0.0
reward_max: 1303.0
reward_min: 1303.0
total_envstep_count: 14429
total_train_sample_count: 14391
total_episode_count: 42
total_duration: 10.921654032809395
[2024-11-15 01:31:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1143
train_sample_count: 1143
avg_envstep_per_episode: 381.0
avg_sample_per_episode: 381.0
avg_envstep_per_sec: 854.7647581002838
avg_train_sample_per_sec: 854.7647581002838
avg_episode_per_sec: 2.243477055381322
collect_time: 1.337210020848683
reward_mean: 815.6666870117188
reward_std: 442.78387451171875
reward_max: 1293.0
reward_min: 226.0
total_envstep_count: 15418
total_train_sample_count: 15390
total_episode_count: 45
total_duration: 12.258864053658078
[2024-11-15 01:31:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 711
train_sample_count: 711
avg_envstep_per_episode: 355.5
avg_sample_per_episode: 355.5
avg_envstep_per_sec: 842.7140026812974
avg_train_sample_per_sec: 842.7140026812974
avg_episode_per_sec: 2.37050352371673
collect_time: 0.8437026057924544
reward_mean: 733.0
reward_std: 498.0
reward_max: 1231.0
reward_min: 235.0
total_envstep_count: 16408
total_train_sample_count: 16377
total_episode_count: 47
total_duration: 13.102566659450533
[2024-11-15 01:31:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 830
train_sample_count: 830
avg_envstep_per_episode: 830.0
avg_sample_per_episode: 830.0
avg_envstep_per_sec: 854.7577119192536
avg_train_sample_per_sec: 854.7577119192536
avg_episode_per_sec: 1.0298285685774138
collect_time: 0.9710354038647243
reward_mean: 678.0
reward_std: 0.0
reward_max: 678.0
reward_min: 678.0
total_envstep_count: 17367
total_train_sample_count: 17339
total_episode_count: 48
total_duration: 14.073602063315256
[2024-11-15 01:31:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2317
train_sample_count: 2317
avg_envstep_per_episode: 1158.5
avg_sample_per_episode: 1158.5
avg_envstep_per_sec: 858.4206290752643
avg_train_sample_per_sec: 858.4206290752643
avg_episode_per_sec: 0.7409759422315617
collect_time: 2.6991429626941676
reward_mean: 725.5
reward_std: 285.5
reward_max: 1011.0
reward_min: 440.0
total_envstep_count: 18341
total_train_sample_count: 18300
total_episode_count: 50
total_duration: 16.772745026009424
[2024-11-15 01:31:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 528
train_sample_count: 528
avg_envstep_per_episode: 528.0
avg_sample_per_episode: 528.0
avg_envstep_per_sec: 844.0564745830319
avg_train_sample_per_sec: 844.0564745830319
avg_episode_per_sec: 1.5985918079224088
collect_time: 0.6255505595888411
reward_mean: 738.0
reward_std: 0.0
reward_max: 738.0
reward_min: 738.0
total_envstep_count: 20164
total_train_sample_count: 20124
total_episode_count: 51
total_duration: 17.398295585598266
[2024-11-15 01:31:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 410
train_sample_count: 410
avg_envstep_per_episode: 410.0
avg_sample_per_episode: 410.0
avg_envstep_per_sec: 850.9867383482393
avg_train_sample_per_sec: 850.9867383482393
avg_episode_per_sec: 2.0755774106054616
collect_time: 0.4817936420440673
reward_mean: 652.0
reward_std: 0.0
reward_max: 652.0
reward_min: 652.0
total_envstep_count: 21123
total_train_sample_count: 21086
total_episode_count: 52
total_duration: 17.880089227642333
[2024-11-15 01:31:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1894
train_sample_count: 1894
avg_envstep_per_episode: 1894.0
avg_sample_per_episode: 1894.0
avg_envstep_per_sec: 853.0461849872542
avg_train_sample_per_sec: 853.0461849872542
avg_episode_per_sec: 0.4503939730661321
collect_time: 2.220278378043856
reward_mean: 700.0
reward_std: 0.0
reward_max: 700.0
reward_min: 700.0
total_envstep_count: 22083
total_train_sample_count: 22056
total_episode_count: 53
total_duration: 20.100367605686188
[2024-11-15 01:31:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1321
train_sample_count: 1321
avg_envstep_per_episode: 660.5
avg_sample_per_episode: 660.5
avg_envstep_per_sec: 847.0519536125254
avg_train_sample_per_sec: 847.0519536125254
avg_episode_per_sec: 1.2824405050908787
collect_time: 1.5595265371458868
reward_mean: 827.0
reward_std: 47.0
reward_max: 874.0
reward_min: 780.0
total_envstep_count: 23082
total_train_sample_count: 23041
total_episode_count: 55
total_duration: 21.659894142832073
[2024-11-15 01:32:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 98
train_sample_count: 98
avg_envstep_per_episode: 98.0
avg_sample_per_episode: 98.0
avg_envstep_per_sec: 832.4130269808419
avg_train_sample_per_sec: 832.4130269808419
avg_episode_per_sec: 8.494010479396346
collect_time: 0.11773001721927098
reward_mean: 623.0
reward_std: 0.0
reward_max: 623.0
reward_min: 623.0
total_envstep_count: 24041
total_train_sample_count: 24003
total_episode_count: 56
total_duration: 21.777624160051342
[2024-11-15 01:32:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1719
train_sample_count: 1719
avg_envstep_per_episode: 343.8
avg_sample_per_episode: 343.8
avg_envstep_per_sec: 852.7773550151227
avg_train_sample_per_sec: 852.7773550151227
avg_episode_per_sec: 2.480446058799077
collect_time: 2.015766471624374
reward_mean: 691.7999877929688
reward_std: 298.35845947265625
reward_max: 1160.0
reward_min: 223.0
total_envstep_count: 25028
total_train_sample_count: 24978
total_episode_count: 61
total_duration: 23.793390631675717
[2024-11-15 01:32:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 155
train_sample_count: 155
avg_envstep_per_episode: 155.0
avg_sample_per_episode: 155.0
avg_envstep_per_sec: 847.3821254180315
avg_train_sample_per_sec: 847.3821254180315
avg_episode_per_sec: 5.46698145430988
collect_time: 0.1829162963799068
reward_mean: 636.0
reward_std: 0.0
reward_max: 636.0
reward_min: 636.0
total_envstep_count: 25995
total_train_sample_count: 25949
total_episode_count: 62
total_duration: 23.976306928055624
[2024-11-15 01:32:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 4202
train_sample_count: 4202
avg_envstep_per_episode: 525.25
avg_sample_per_episode: 525.25
avg_envstep_per_sec: 851.497169689398
avg_train_sample_per_sec: 851.497169689398
avg_episode_per_sec: 1.621127405405803
collect_time: 4.934837307248796
reward_mean: 580.5
reward_std: 279.9160461425781
reward_max: 1145.0
reward_min: 219.0
total_envstep_count: 27019
total_train_sample_count: 26971
total_episode_count: 70
total_duration: 28.91114423530442
[2024-11-15 01:32:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 414
train_sample_count: 414
avg_envstep_per_episode: 82.8
avg_sample_per_episode: 82.8
avg_envstep_per_sec: 816.6545866091507
avg_train_sample_per_sec: 816.6545866091507
avg_episode_per_sec: 9.862978099144332
collect_time: 0.5069462742124285
reward_mean: 310.0
reward_std: 155.28167724609375
reward_max: 620.0
reward_min: 220.0
total_envstep_count: 28030
total_train_sample_count: 27997
total_episode_count: 75
total_duration: 29.418090509516848
[2024-11-15 01:32:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2038
train_sample_count: 2038
avg_envstep_per_episode: 291.14285714285717
avg_sample_per_episode: 291.14285714285717
avg_envstep_per_sec: 825.5909930963583
avg_train_sample_per_sec: 825.5909930963583
avg_episode_per_sec: 2.835690359015951
collect_time: 2.4685346824782237
reward_mean: 579.1428833007812
reward_std: 427.39556884765625
reward_max: 1543.0
reward_min: 223.0
total_envstep_count: 28985
total_train_sample_count: 28967
total_episode_count: 82
total_duration: 31.886625191995073
[2024-11-15 01:32:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 99
train_sample_count: 99
avg_envstep_per_episode: 49.5
avg_sample_per_episode: 49.5
avg_envstep_per_sec: 832.0708080399468
avg_train_sample_per_sec: 832.0708080399468
avg_episode_per_sec: 16.809511273534277
collect_time: 0.11898025870323181
reward_mean: 224.0
reward_std: 7.0
reward_max: 231.0
reward_min: 217.0
total_envstep_count: 29991
total_train_sample_count: 29942
total_episode_count: 84
total_duration: 32.005605450698305
[2024-11-15 01:32:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1685
train_sample_count: 1685
avg_envstep_per_episode: 561.6666666666666
avg_sample_per_episode: 561.6666666666666
avg_envstep_per_sec: 845.4574829063683
avg_train_sample_per_sec: 845.4574829063683
avg_episode_per_sec: 1.5052655482012494
collect_time: 1.9930038281849451
reward_mean: 830.6666870117188
reward_std: 208.0261688232422
reward_max: 1117.0
reward_min: 629.0
total_envstep_count: 30948
total_train_sample_count: 30907
total_episode_count: 87
total_duration: 33.99860927888325
[2024-11-15 01:32:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 234
train_sample_count: 234
avg_envstep_per_episode: 234.0
avg_sample_per_episode: 234.0
avg_envstep_per_sec: 847.9796092985642
avg_train_sample_per_sec: 847.9796092985642
avg_episode_per_sec: 3.6238444841818986
collect_time: 0.27595003162111553
reward_mean: 620.0
reward_std: 0.0
reward_max: 620.0
reward_min: 620.0
total_envstep_count: 32388
total_train_sample_count: 32353
total_episode_count: 88
total_duration: 34.274559310504365
[2024-11-15 01:32:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 35
train_sample_count: 35
avg_envstep_per_episode: 35.0
avg_sample_per_episode: 35.0
avg_envstep_per_sec: 837.3708779592881
avg_train_sample_per_sec: 837.3708779592881
avg_episode_per_sec: 23.924882227408233
collect_time: 0.041797488927841187
reward_mean: 235.0
reward_std: 0.0
reward_max: 235.0
reward_min: 235.0
total_envstep_count: 33355
total_train_sample_count: 33324
total_episode_count: 89
total_duration: 34.31635679943221
[2024-11-15 01:32:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1710
train_sample_count: 1710
avg_envstep_per_episode: 342.0
avg_sample_per_episode: 342.0
avg_envstep_per_sec: 781.1400210752669
avg_train_sample_per_sec: 781.1400210752669
avg_episode_per_sec: 2.2840351493428854
collect_time: 2.189108167375837
reward_mean: 640.0
reward_std: 384.918701171875
reward_max: 1211.0
reward_min: 231.0
total_envstep_count: 34350
total_train_sample_count: 34314
total_episode_count: 94
total_duration: 36.50546496680804
[2024-11-15 01:32:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 594
train_sample_count: 594
avg_envstep_per_episode: 594.0
avg_sample_per_episode: 594.0
avg_envstep_per_sec: 839.4774868647494
avg_train_sample_per_sec: 839.4774868647494
avg_episode_per_sec: 1.413261762398568
collect_time: 0.7075830016817366
reward_mean: 952.0
reward_std: 0.0
reward_max: 952.0
reward_min: 952.0
total_envstep_count: 35413
total_train_sample_count: 35376
total_episode_count: 95
total_duration: 37.213047968489775
[2024-11-15 01:32:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 997
train_sample_count: 997
avg_envstep_per_episode: 332.3333333333333
avg_sample_per_episode: 332.3333333333333
avg_envstep_per_sec: 828.5703105387138
avg_train_sample_per_sec: 828.5703105387138
avg_episode_per_sec: 2.493190503125518
collect_time: 1.203277485711234
reward_mean: 348.0
reward_std: 179.72386169433594
reward_max: 602.0
reward_min: 213.0
total_envstep_count: 36394
total_train_sample_count: 36349
total_episode_count: 98
total_duration: 38.41632545420101
[2024-11-15 01:32:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1676
train_sample_count: 1676
avg_envstep_per_episode: 335.2
avg_sample_per_episode: 335.2
avg_envstep_per_sec: 842.5842546570603
avg_train_sample_per_sec: 842.5842546570603
avg_episode_per_sec: 2.513676177377865
collect_time: 1.9891185845647539
reward_mean: 577.7999877929688
reward_std: 291.6864013671875
reward_max: 912.0
reward_min: 220.0
total_envstep_count: 37374
total_train_sample_count: 37341
total_episode_count: 103
total_duration: 40.405444038765765
[2024-11-15 01:32:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 36
train_sample_count: 36
avg_envstep_per_episode: 36.0
avg_sample_per_episode: 36.0
avg_envstep_per_sec: 855.2702803248275
avg_train_sample_per_sec: 855.2702803248275
avg_episode_per_sec: 23.757507786800762
collect_time: 0.04209195716040475
reward_mean: 238.0
reward_std: 0.0
reward_max: 238.0
reward_min: 238.0
total_envstep_count: 38333
total_train_sample_count: 38301
total_episode_count: 104
total_duration: 40.44753599592617
[2024-11-15 01:33:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 649
train_sample_count: 649
avg_envstep_per_episode: 324.5
avg_sample_per_episode: 324.5
avg_envstep_per_sec: 843.0997143999692
avg_train_sample_per_sec: 843.0997143999692
avg_episode_per_sec: 2.5981501214174707
collect_time: 0.7697784602642058
reward_mean: 608.5
reward_std: 12.5
reward_max: 621.0
reward_min: 596.0
total_envstep_count: 39323
total_train_sample_count: 39274
total_episode_count: 106
total_duration: 41.21731445619037
[2024-11-15 01:33:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 833
train_sample_count: 833
avg_envstep_per_episode: 166.6
avg_sample_per_episode: 166.6
avg_envstep_per_sec: 817.7115961853935
avg_train_sample_per_sec: 817.7115961853935
avg_episode_per_sec: 4.908232870260465
collect_time: 1.0186965720994132
reward_mean: 592.2000122070312
reward_std: 181.96636962890625
reward_max: 736.0
reward_min: 237.0
total_envstep_count: 40326
total_train_sample_count: 40287
total_episode_count: 111
total_duration: 42.23601102828979
[2024-11-15 01:33:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 3034
train_sample_count: 3034
avg_envstep_per_episode: 1011.3333333333334
avg_sample_per_episode: 1011.3333333333334
avg_envstep_per_sec: 833.7029606927498
avg_train_sample_per_sec: 833.7029606927498
avg_episode_per_sec: 0.8243602116276366
collect_time: 3.639185828822
reward_mean: 595.6666870117188
reward_std: 340.99493408203125
reward_max: 1043.0
reward_min: 216.0
total_envstep_count: 41293
total_train_sample_count: 41269
total_episode_count: 114
total_duration: 45.87519685711179
[2024-11-15 01:33:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 171
train_sample_count: 171
avg_envstep_per_episode: 171.0
avg_sample_per_episode: 171.0
avg_envstep_per_sec: 835.2255974628056
avg_train_sample_per_sec: 835.2255974628056
avg_episode_per_sec: 4.884360219080734
collect_time: 0.20473510452679225
reward_mean: 626.0
reward_std: 0.0
reward_max: 626.0
reward_min: 626.0
total_envstep_count: 42276
total_train_sample_count: 42244
total_episode_count: 115
total_duration: 46.07993196163858
[2024-11-15 01:33:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1089
train_sample_count: 1089
avg_envstep_per_episode: 363.0
avg_sample_per_episode: 363.0
avg_envstep_per_sec: 817.7250087081642
avg_train_sample_per_sec: 817.7250087081642
avg_episode_per_sec: 2.252685974402656
collect_time: 1.331743542637144
reward_mean: 613.3333129882812
reward_std: 312.7878112792969
reward_max: 1001.0
reward_min: 235.0
total_envstep_count: 43266
total_train_sample_count: 43225
total_episode_count: 118
total_duration: 47.41167550427572
[2024-11-15 01:33:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1974
train_sample_count: 1974
avg_envstep_per_episode: 282.0
avg_sample_per_episode: 282.0
avg_envstep_per_sec: 829.6349834002376
avg_train_sample_per_sec: 829.6349834002376
avg_episode_per_sec: 2.941968026241977
collect_time: 2.3793596455029076
reward_mean: 557.1428833007812
reward_std: 212.97044372558594
reward_max: 740.0
reward_min: 211.0
total_envstep_count: 44315
total_train_sample_count: 44287
total_episode_count: 125
total_duration: 49.79103514977863
[2024-11-15 01:33:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 118
train_sample_count: 118
avg_envstep_per_episode: 118.0
avg_sample_per_episode: 118.0
avg_envstep_per_sec: 840.1461931617533
avg_train_sample_per_sec: 840.1461931617533
avg_episode_per_sec: 7.119882992896215
collect_time: 0.14045174632753643
reward_mean: 621.0
reward_std: 0.0
reward_max: 621.0
reward_min: 621.0
total_envstep_count: 45298
total_train_sample_count: 45257
total_episode_count: 126
total_duration: 49.931486896106165
[2024-11-15 01:33:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1023
train_sample_count: 1023
avg_envstep_per_episode: 255.75
avg_sample_per_episode: 255.75
avg_envstep_per_sec: 836.273324671844
avg_train_sample_per_sec: 836.273324671844
avg_episode_per_sec: 3.269885922470553
collect_time: 1.2232842658247267
reward_mean: 665.0
reward_std: 42.08919143676758
reward_max: 716.0
reward_min: 615.0
total_envstep_count: 46270
total_train_sample_count: 46232
total_episode_count: 130
total_duration: 51.15477116193089
[2024-11-15 01:33:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 896
train_sample_count: 896
avg_envstep_per_episode: 224.0
avg_sample_per_episode: 224.0
avg_envstep_per_sec: 835.9015890933719
avg_train_sample_per_sec: 835.9015890933719
avg_episode_per_sec: 3.731703522738267
collect_time: 1.0718965147222792
reward_mean: 751.75
reward_std: 164.71546936035156
reward_max: 998.0
reward_min: 574.0
total_envstep_count: 47267
total_train_sample_count: 47224
total_episode_count: 134
total_duration: 52.226667676653165
[2024-11-15 01:33:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 444
train_sample_count: 444
avg_envstep_per_episode: 111.0
avg_sample_per_episode: 111.0
avg_envstep_per_sec: 836.5037595642266
avg_train_sample_per_sec: 836.5037595642266
avg_episode_per_sec: 7.536069905984023
collect_time: 0.5307806389672416
reward_mean: 515.5
reward_std: 155.7152862548828
reward_max: 637.0
reward_min: 248.0
total_envstep_count: 48239
total_train_sample_count: 48208
total_episode_count: 138
total_duration: 52.75744831562041
[2024-11-15 01:33:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2362
train_sample_count: 2362
avg_envstep_per_episode: 393.6666666666667
avg_sample_per_episode: 393.6666666666667
avg_envstep_per_sec: 836.6596675327118
avg_train_sample_per_sec: 836.6596675327118
avg_episode_per_sec: 2.12529974817793
collect_time: 2.8231311866215307
reward_mean: 385.5
reward_std: 163.51426696777344
reward_max: 591.0
reward_min: 207.0
total_envstep_count: 49250
total_train_sample_count: 49214
total_episode_count: 144
total_duration: 55.58057950224194
[2024-11-15 01:33:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1341
train_sample_count: 1341
avg_envstep_per_episode: 335.25
avg_sample_per_episode: 335.25
avg_envstep_per_sec: 834.0254846099463
avg_train_sample_per_sec: 834.0254846099463
avg_episode_per_sec: 2.4877717661743364
collect_time: 1.6078645374093736
reward_mean: 612.0
reward_std: 267.9953308105469
reward_max: 958.0
reward_min: 205.0
total_envstep_count: 50239
total_train_sample_count: 50195
total_episode_count: 148
total_duration: 57.188444039651316
[2024-11-15 01:33:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1381
train_sample_count: 1381
avg_envstep_per_episode: 690.5
avg_sample_per_episode: 690.5
avg_envstep_per_sec: 833.7791138138904
avg_train_sample_per_sec: 833.7791138138904
avg_episode_per_sec: 1.2075005268847072
collect_time: 1.6563139770712174
reward_mean: 589.5
reward_std: 356.5
reward_max: 946.0
reward_min: 233.0
total_envstep_count: 51205
total_train_sample_count: 51168
total_episode_count: 150
total_duration: 58.84475801672253
[2024-11-15 01:33:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 347
train_sample_count: 347
avg_envstep_per_episode: 173.5
avg_sample_per_episode: 173.5
avg_envstep_per_sec: 818.2938071566601
avg_train_sample_per_sec: 818.2938071566601
avg_episode_per_sec: 4.716390819346744
collect_time: 0.42405306867190773
reward_mean: 947.5
reward_std: 367.5
reward_max: 1315.0
reward_min: 580.0
total_envstep_count: 52179
total_train_sample_count: 52139
total_episode_count: 152
total_duration: 59.26881108539444
[2024-11-15 01:33:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 930
train_sample_count: 930
avg_envstep_per_episode: 465.0
avg_sample_per_episode: 465.0
avg_envstep_per_sec: 831.0103941584832
avg_train_sample_per_sec: 831.0103941584832
avg_episode_per_sec: 1.7871191272225446
collect_time: 1.119119576045445
reward_mean: 1267.0
reward_std: 24.0
reward_max: 1291.0
reward_min: 1243.0
total_envstep_count: 53145
total_train_sample_count: 53105
total_episode_count: 154
total_duration: 60.38793066143988
[2024-11-15 01:33:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 216
train_sample_count: 216
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 819.7743971759622
avg_train_sample_per_sec: 819.7743971759622
avg_episode_per_sec: 3.795251838777603
collect_time: 0.2634871261460441
reward_mean: 1027.0
reward_std: 0.0
reward_max: 1027.0
reward_min: 1027.0
total_envstep_count: 54104
total_train_sample_count: 54065
total_episode_count: 155
total_duration: 60.65141778758593
[2024-11-15 01:34:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1091
train_sample_count: 1091
avg_envstep_per_episode: 363.6666666666667
avg_sample_per_episode: 363.6666666666667
avg_envstep_per_sec: 828.0901789979586
avg_train_sample_per_sec: 828.0901789979586
avg_episode_per_sec: 2.27705823739127
collect_time: 1.3174893600600106
reward_mean: 861.3333129882812
reward_std: 191.3501739501953
reward_max: 1036.0
reward_min: 595.0
total_envstep_count: 55070
total_train_sample_count: 55036
total_episode_count: 158
total_duration: 61.968907147645936
[2024-11-15 01:34:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 3038
train_sample_count: 3038
avg_envstep_per_episode: 303.8
avg_sample_per_episode: 303.8
avg_envstep_per_sec: 830.1582028802223
avg_train_sample_per_sec: 830.1582028802223
avg_episode_per_sec: 2.7325813129697907
collect_time: 3.659543433359691
reward_mean: 640.7999877929688
reward_std: 492.1994934082031
reward_max: 1714.0
reward_min: 212.0
total_envstep_count: 56084
total_train_sample_count: 56046
total_episode_count: 168
total_duration: 65.62845058100562
[2024-11-15 01:34:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 406
train_sample_count: 406
avg_envstep_per_episode: 135.33333333333334
avg_sample_per_episode: 135.33333333333334
avg_envstep_per_sec: 814.4570711761414
avg_train_sample_per_sec: 814.4570711761414
avg_episode_per_sec: 6.018155698345873
collect_time: 0.49849158951214384
reward_mean: 504.0
reward_std: 204.83651733398438
reward_max: 711.0
reward_min: 225.0
total_envstep_count: 57074
total_train_sample_count: 57040
total_episode_count: 171
total_duration: 66.12694217051776
[2024-11-15 01:34:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 601
train_sample_count: 601
avg_envstep_per_episode: 150.25
avg_sample_per_episode: 150.25
avg_envstep_per_sec: 821.7682547024518
avg_train_sample_per_sec: 821.7682547024518
avg_episode_per_sec: 5.469339465573722
collect_time: 0.7313497407095773
reward_mean: 429.25
reward_std: 224.20010375976562
reward_max: 672.0
reward_min: 199.0
total_envstep_count: 58054
total_train_sample_count: 58013
total_episode_count: 175
total_duration: 66.85829191122734
[2024-11-15 01:34:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 359
train_sample_count: 359
avg_envstep_per_episode: 89.75
avg_sample_per_episode: 89.75
avg_envstep_per_sec: 781.347491672486
avg_train_sample_per_sec: 781.347491672486
avg_episode_per_sec: 8.705821634233827
collect_time: 0.4594626639570509
reward_mean: 318.5
reward_std: 181.7821502685547
reward_max: 633.0
reward_min: 203.0
total_envstep_count: 59058
total_train_sample_count: 59032
total_episode_count: 179
total_duration: 67.3177545751844
[2024-11-15 01:34:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 427
train_sample_count: 427
avg_envstep_per_episode: 427.0
avg_sample_per_episode: 427.0
avg_envstep_per_sec: 804.8345932946738
avg_train_sample_per_sec: 804.8345932946738
avg_episode_per_sec: 1.8848585323060276
collect_time: 0.530543795653752
reward_mean: 1281.0
reward_std: 0.0
reward_max: 1281.0
reward_min: 1281.0
total_envstep_count: 60121
total_train_sample_count: 60095
total_episode_count: 180
total_duration: 67.84829837083815
[2024-11-15 01:34:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1171
train_sample_count: 1171
avg_envstep_per_episode: 585.5
avg_sample_per_episode: 585.5
avg_envstep_per_sec: 815.1354629396241
avg_train_sample_per_sec: 815.1354629396241
avg_episode_per_sec: 1.392204035763662
collect_time: 1.4365710403238023
reward_mean: 981.5
reward_std: 273.5
reward_max: 1255.0
reward_min: 708.0
total_envstep_count: 61096
total_train_sample_count: 61062
total_episode_count: 182
total_duration: 69.28486941116195
[2024-11-15 01:34:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 484
train_sample_count: 484
avg_envstep_per_episode: 242.0
avg_sample_per_episode: 242.0
avg_envstep_per_sec: 820.4241583309348
avg_train_sample_per_sec: 820.4241583309348
avg_episode_per_sec: 3.390182472441879
collect_time: 0.5899387470313481
reward_mean: 948.0
reward_std: 341.0
reward_max: 1289.0
reward_min: 607.0
total_envstep_count: 62094
total_train_sample_count: 62050
total_episode_count: 184
total_duration: 69.8748081581933
[2024-11-15 01:34:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 621
train_sample_count: 621
avg_envstep_per_episode: 310.5
avg_sample_per_episode: 310.5
avg_envstep_per_sec: 811.6147373663794
avg_train_sample_per_sec: 811.6147373663794
avg_episode_per_sec: 2.613896094577711
collect_time: 0.7651413551398686
reward_mean: 669.0
reward_std: 82.0
reward_max: 751.0
reward_min: 587.0
total_envstep_count: 63084
total_train_sample_count: 63055
total_episode_count: 186
total_duration: 70.63994951333318
[2024-11-15 01:34:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1408
train_sample_count: 1408
avg_envstep_per_episode: 704.0
avg_sample_per_episode: 704.0
avg_envstep_per_sec: 821.4440606282022
avg_train_sample_per_sec: 821.4440606282022
avg_episode_per_sec: 1.1668239497559691
collect_time: 1.7140546355928692
reward_mean: 367.0
reward_std: 143.0
reward_max: 510.0
reward_min: 224.0
total_envstep_count: 64066
total_train_sample_count: 64031
total_episode_count: 188
total_duration: 72.35400414892605
[2024-11-15 01:34:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1075
train_sample_count: 1075
avg_envstep_per_episode: 358.3333333333333
avg_sample_per_episode: 358.3333333333333
avg_envstep_per_sec: 824.9818211126387
avg_train_sample_per_sec: 824.9818211126387
avg_episode_per_sec: 2.3022748496166665
collect_time: 1.3030590159552438
reward_mean: 717.3333129882812
reward_std: 158.56509399414062
reward_max: 940.0
reward_min: 583.0
total_envstep_count: 65063
total_train_sample_count: 65022
total_episode_count: 191
total_duration: 73.6570631648813
[2024-11-15 01:34:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 676
train_sample_count: 676
avg_envstep_per_episode: 676.0
avg_sample_per_episode: 676.0
avg_envstep_per_sec: 820.4379838387542
avg_train_sample_per_sec: 820.4379838387542
avg_episode_per_sec: 1.2136656565662045
collect_time: 0.823950150183269
reward_mean: 708.0
reward_std: 0.0
reward_max: 708.0
reward_min: 708.0
total_envstep_count: 66022
total_train_sample_count: 65986
total_episode_count: 192
total_duration: 74.48101331506456
[2024-11-15 01:34:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 638
train_sample_count: 638
avg_envstep_per_episode: 638.0
avg_sample_per_episode: 638.0
avg_envstep_per_sec: 815.1473406812339
avg_train_sample_per_sec: 815.1473406812339
avg_episode_per_sec: 1.2776604085912757
collect_time: 0.7826805881091526
reward_mean: 1040.0
reward_std: 0.0
reward_max: 1040.0
reward_min: 1040.0
total_envstep_count: 66981
total_train_sample_count: 66948
total_episode_count: 193
total_duration: 75.26369390317372
[2024-11-15 01:34:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 174
train_sample_count: 174
avg_envstep_per_episode: 174.0
avg_sample_per_episode: 174.0
avg_envstep_per_sec: 821.8667812111632
avg_train_sample_per_sec: 821.8667812111632
avg_episode_per_sec: 4.723372305811283
collect_time: 0.2117131437574114
reward_mean: 612.0
reward_std: 0.0
reward_max: 612.0
reward_min: 612.0
total_envstep_count: 67956
total_train_sample_count: 67914
total_episode_count: 194
total_duration: 75.47540704693112
[2024-11-15 01:34:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1564
train_sample_count: 1564
avg_envstep_per_episode: 782.0
avg_sample_per_episode: 782.0
avg_envstep_per_sec: 811.5216453520155
avg_train_sample_per_sec: 811.5216453520155
avg_episode_per_sec: 1.0377514646445212
collect_time: 1.9272437265941074
reward_mean: 830.5
reward_std: 124.5
reward_max: 955.0
reward_min: 706.0
total_envstep_count: 68930
total_train_sample_count: 68890
total_episode_count: 196
total_duration: 77.40265077352524
[2024-11-15 01:34:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 896
train_sample_count: 896
avg_envstep_per_episode: 224.0
avg_sample_per_episode: 224.0
avg_envstep_per_sec: 816.0754041655315
avg_train_sample_per_sec: 816.0754041655315
avg_episode_per_sec: 3.643193768596123
collect_time: 1.0979377584797994
reward_mean: 419.5
reward_std: 195.73260498046875
reward_max: 643.0
reward_min: 214.0
total_envstep_count: 69895
total_train_sample_count: 69858
total_episode_count: 200
total_duration: 78.50058853200504
[2024-11-15 01:34:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 2763
train_sample_count: 2763
avg_envstep_per_episode: 690.75
avg_sample_per_episode: 690.75
avg_envstep_per_sec: 815.9628873533649
avg_train_sample_per_sec: 815.9628873533649
avg_episode_per_sec: 1.1812709190783421
collect_time: 3.3861834193978995
reward_mean: 770.5
reward_std: 377.3714904785156
reward_max: 1217.0
reward_min: 224.0
total_envstep_count: 70884
total_train_sample_count: 70845
total_episode_count: 204
total_duration: 81.88677195140293
[2024-11-15 01:35:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2003
train_sample_count: 2003
avg_envstep_per_episode: 333.8333333333333
avg_sample_per_episode: 333.8333333333333
avg_envstep_per_sec: 811.7825597883951
avg_train_sample_per_sec: 811.7825597883951
avg_episode_per_sec: 2.4317001291714284
collect_time: 2.46740950005395
reward_mean: 585.8333129882812
reward_std: 307.6060485839844
reward_max: 1129.0
reward_min: 219.0
total_envstep_count: 71878
total_train_sample_count: 71828
total_episode_count: 210
total_duration: 84.35418145145688
[2024-11-15 01:35:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 964
train_sample_count: 964
avg_envstep_per_episode: 192.8
avg_sample_per_episode: 192.8
avg_envstep_per_sec: 807.1803239645428
avg_train_sample_per_sec: 807.1803239645428
avg_episode_per_sec: 4.18661993757543
collect_time: 1.1942808457783292
reward_mean: 633.2000122070312
reward_std: 363.68414306640625
reward_max: 1111.0
reward_min: 232.0
total_envstep_count: 72850
total_train_sample_count: 72816
total_episode_count: 215
total_duration: 85.5484622972352
[2024-11-15 01:35:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 717
train_sample_count: 717
avg_envstep_per_episode: 358.5
avg_sample_per_episode: 358.5
avg_envstep_per_sec: 798.8140050255221
avg_train_sample_per_sec: 798.8140050255221
avg_episode_per_sec: 2.2282120084393924
collect_time: 0.897580657686506
reward_mean: 786.0
reward_std: 174.0
reward_max: 960.0
reward_min: 612.0
total_envstep_count: 73824
total_train_sample_count: 73785
total_episode_count: 217
total_duration: 86.44604295492171
[2024-11-15 01:35:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 237
train_sample_count: 237
avg_envstep_per_episode: 79.0
avg_sample_per_episode: 79.0
avg_envstep_per_sec: 798.3459233803188
avg_train_sample_per_sec: 798.3459233803188
avg_episode_per_sec: 10.105644599750871
collect_time: 0.2968637943267822
reward_mean: 477.6666564941406
reward_std: 175.86422729492188
reward_max: 606.0
reward_min: 229.0
total_envstep_count: 74781
total_train_sample_count: 74754
total_episode_count: 220
total_duration: 86.74290674924849
[2024-11-15 01:35:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 521
train_sample_count: 521
avg_envstep_per_episode: 260.5
avg_sample_per_episode: 260.5
avg_envstep_per_sec: 794.4461415524947
avg_train_sample_per_sec: 794.4461415524947
avg_episode_per_sec: 3.049697280431842
collect_time: 0.6558027948651995
reward_mean: 748.0
reward_std: 536.0
reward_max: 1284.0
reward_min: 212.0
total_envstep_count: 75763
total_train_sample_count: 75731
total_episode_count: 222
total_duration: 87.39870954411369
[2024-11-15 01:35:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1469
train_sample_count: 1469
avg_envstep_per_episode: 489.6666666666667
avg_sample_per_episode: 489.6666666666667
avg_envstep_per_sec: 779.403669333591
avg_train_sample_per_sec: 779.403669333591
avg_episode_per_sec: 1.5917025241666254
collect_time: 1.8847742932183404
reward_mean: 875.0
reward_std: 143.52700805664062
reward_max: 1005.0
reward_min: 675.0
total_envstep_count: 76745
total_train_sample_count: 76708
total_episode_count: 225
total_duration: 89.28348383733203
[2024-11-15 01:35:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 927
train_sample_count: 927
avg_envstep_per_episode: 231.75
avg_sample_per_episode: 231.75
avg_envstep_per_sec: 770.4525752712932
avg_train_sample_per_sec: 770.4525752712932
avg_episode_per_sec: 3.3244987066722467
collect_time: 1.2031889174665722
reward_mean: 612.75
reward_std: 411.5576477050781
reward_max: 1238.0
reward_min: 236.0
total_envstep_count: 77733
total_train_sample_count: 77695
total_episode_count: 229
total_duration: 90.4866727547986
[2024-11-15 01:35:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2000
train_sample_count: 2000
avg_envstep_per_episode: 400.0
avg_sample_per_episode: 400.0
avg_envstep_per_sec: 784.6257778859812
avg_train_sample_per_sec: 784.6257778859812
avg_episode_per_sec: 1.961564444714953
collect_time: 2.54898584314755
reward_mean: 800.4000244140625
reward_std: 173.3569793701172
reward_max: 1033.0
reward_min: 630.0
total_envstep_count: 78721
total_train_sample_count: 78675
total_episode_count: 234
total_duration: 93.03565859794615
[2024-11-15 01:35:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 31
train_sample_count: 31
avg_envstep_per_episode: 31.0
avg_sample_per_episode: 31.0
avg_envstep_per_sec: 742.6315000167266
avg_train_sample_per_sec: 742.6315000167266
avg_episode_per_sec: 23.955854839249245
collect_time: 0.04174344880240304
reward_mean: 248.0
reward_std: 0.0
reward_max: 248.0
reward_min: 248.0
total_envstep_count: 79688
total_train_sample_count: 79642
total_episode_count: 235
total_duration: 93.07740204674856
[2024-11-15 01:35:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2277
train_sample_count: 2277
avg_envstep_per_episode: 379.5
avg_sample_per_episode: 379.5
avg_envstep_per_sec: 782.5856531491
avg_train_sample_per_sec: 782.5856531491
avg_episode_per_sec: 2.0621492836603426
collect_time: 2.909585667507989
reward_mean: 781.3333129882812
reward_std: 121.98589324951172
reward_max: 985.0
reward_min: 622.0
total_envstep_count: 80682
total_train_sample_count: 80635
total_episode_count: 241
total_duration: 95.98698771425654
[2024-11-15 01:35:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 986
train_sample_count: 986
avg_envstep_per_episode: 140.85714285714286
avg_sample_per_episode: 140.85714285714286
avg_envstep_per_sec: 773.3094853900016
avg_train_sample_per_sec: 773.3094853900016
avg_episode_per_sec: 5.49002677254565
collect_time: 1.2750393194811682
reward_mean: 489.5714416503906
reward_std: 224.9513397216797
reward_max: 775.0
reward_min: 236.0
total_envstep_count: 81661
total_train_sample_count: 81621
total_episode_count: 248
total_duration: 97.26202703373771
[2024-11-15 01:35:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 743
train_sample_count: 743
avg_envstep_per_episode: 185.75
avg_sample_per_episode: 185.75
avg_envstep_per_sec: 772.263343159055
avg_train_sample_per_sec: 772.263343159055
avg_episode_per_sec: 4.157541551327348
collect_time: 0.9621070410524096
reward_mean: 909.5
reward_std: 587.086669921875
reward_max: 1847.0
reward_min: 227.0
total_envstep_count: 82658
total_train_sample_count: 82616
total_episode_count: 252
total_duration: 98.22413407479011
[2024-11-15 01:35:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 364
train_sample_count: 364
avg_envstep_per_episode: 91.0
avg_sample_per_episode: 91.0
avg_envstep_per_sec: 757.6306212008561
avg_train_sample_per_sec: 757.6306212008561
avg_episode_per_sec: 8.32561122198743
collect_time: 0.4804452061653137
reward_mean: 421.5
reward_std: 193.50257873535156
reward_max: 616.0
reward_min: 227.0
total_envstep_count: 83638
total_train_sample_count: 83592
total_episode_count: 256
total_duration: 98.70457928095543
[2024-11-15 01:35:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1834
train_sample_count: 1834
avg_envstep_per_episode: 229.25
avg_sample_per_episode: 229.25
avg_envstep_per_sec: 768.5094799281477
avg_train_sample_per_sec: 768.5094799281477
avg_episode_per_sec: 3.3522769026309605
collect_time: 2.3864377055849344
reward_mean: 624.875
reward_std: 356.7969970703125
reward_max: 1333.0
reward_min: 230.0
total_envstep_count: 84610
total_train_sample_count: 84574
total_episode_count: 264
total_duration: 101.09101698654037
[2024-11-15 01:35:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 627
train_sample_count: 627
avg_envstep_per_episode: 156.75
avg_sample_per_episode: 156.75
avg_envstep_per_sec: 766.7216756321976
avg_train_sample_per_sec: 766.7216756321976
avg_episode_per_sec: 4.891366351720559
collect_time: 0.8177674114704132
reward_mean: 597.0
reward_std: 10.440306663513184
reward_max: 608.0
reward_min: 580.0
total_envstep_count: 85622
total_train_sample_count: 85573
total_episode_count: 268
total_duration: 101.90878439801078
[2024-11-15 01:35:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1090
train_sample_count: 1090
avg_envstep_per_episode: 136.25
avg_sample_per_episode: 136.25
avg_envstep_per_sec: 758.0778396041213
avg_train_sample_per_sec: 758.0778396041213
avg_episode_per_sec: 5.56387405214034
collect_time: 1.4378470693315781
reward_mean: 447.125
reward_std: 221.81829833984375
reward_max: 739.0
reward_min: 214.0
total_envstep_count: 86638
total_train_sample_count: 86591
total_episode_count: 276
total_duration: 103.34663146734236
[2024-11-15 01:35:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1294
train_sample_count: 1294
avg_envstep_per_episode: 323.5
avg_sample_per_episode: 323.5
avg_envstep_per_sec: 754.7938815354536
avg_train_sample_per_sec: 754.7938815354536
avg_episode_per_sec: 2.3332113803259773
collect_time: 1.7143753170967102
reward_mean: 768.5
reward_std: 132.57733154296875
reward_max: 962.0
reward_min: 588.0
total_envstep_count: 87626
total_train_sample_count: 87585
total_episode_count: 280
total_duration: 105.06100678443907
[2024-11-15 01:36:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 747
train_sample_count: 747
avg_envstep_per_episode: 186.75
avg_sample_per_episode: 186.75
avg_envstep_per_sec: 749.3342291148675
avg_train_sample_per_sec: 749.3342291148675
avg_episode_per_sec: 4.012499218821246
collect_time: 0.9968849292823246
reward_mean: 617.25
reward_std: 259.9849853515625
reward_max: 981.0
reward_min: 246.0
total_envstep_count: 88615
total_train_sample_count: 88572
total_episode_count: 284
total_duration: 106.0578917137214
[2024-11-15 01:36:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 987
train_sample_count: 987
avg_envstep_per_episode: 246.75
avg_sample_per_episode: 246.75
avg_envstep_per_sec: 751.4516800825952
avg_train_sample_per_sec: 751.4516800825952
avg_episode_per_sec: 3.0453968797673565
collect_time: 1.3134577061448778
reward_mean: 982.5
reward_std: 347.2358703613281
reward_max: 1375.0
reward_min: 623.0
total_envstep_count: 89612
total_train_sample_count: 89571
total_episode_count: 288
total_duration: 107.37134941986628
[2024-11-15 01:36:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 674
train_sample_count: 674
avg_envstep_per_episode: 134.8
avg_sample_per_episode: 134.8
avg_envstep_per_sec: 742.7522101103875
avg_train_sample_per_sec: 742.7522101103875
avg_episode_per_sec: 5.510031232272905
collect_time: 0.907435872725078
reward_mean: 544.0
reward_std: 283.859130859375
reward_max: 1002.0
reward_min: 237.0
total_envstep_count: 90599
total_train_sample_count: 90569
total_episode_count: 293
total_duration: 108.27878529259135
[2024-11-15 01:36:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1270
train_sample_count: 1270
avg_envstep_per_episode: 181.42857142857142
avg_sample_per_episode: 181.42857142857142
avg_envstep_per_sec: 743.5552744165665
avg_train_sample_per_sec: 743.5552744165665
avg_episode_per_sec: 4.098336158201548
collect_time: 1.7080102094582148
reward_mean: 627.5714111328125
reward_std: 387.28167724609375
reward_max: 1264.0
reward_min: 209.0
total_envstep_count: 91617
total_train_sample_count: 91575
total_episode_count: 300
total_duration: 109.98679550204956
[2024-11-15 01:36:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 921
train_sample_count: 921
avg_envstep_per_episode: 184.2
avg_sample_per_episode: 184.2
avg_envstep_per_sec: 732.0352021462064
avg_train_sample_per_sec: 732.0352021462064
avg_episode_per_sec: 3.9741324763637698
collect_time: 1.2581362170832495
reward_mean: 568.7999877929688
reward_std: 297.4232177734375
reward_max: 969.0
reward_min: 228.0
total_envstep_count: 92588
total_train_sample_count: 92556
total_episode_count: 305
total_duration: 111.24493171913281
[2024-11-15 01:36:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 752
train_sample_count: 752
avg_envstep_per_episode: 125.33333333333333
avg_sample_per_episode: 125.33333333333333
avg_envstep_per_sec: 715.4559093831696
avg_train_sample_per_sec: 715.4559093831696
avg_episode_per_sec: 5.708424808908267
collect_time: 1.0510780470711842
reward_mean: 473.0
reward_std: 266.6902160644531
reward_max: 811.0
reward_min: 209.0
total_envstep_count: 93590
total_train_sample_count: 93560
total_episode_count: 311
total_duration: 112.296009766204
[2024-11-15 01:36:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1506
train_sample_count: 1506
avg_envstep_per_episode: 376.5
avg_sample_per_episode: 376.5
avg_envstep_per_sec: 731.8390326799125
avg_train_sample_per_sec: 731.8390326799125
avg_episode_per_sec: 1.943795571526992
collect_time: 2.0578295673642835
reward_mean: 1003.25
reward_std: 62.63136291503906
reward_max: 1046.0
reward_min: 895.0
total_envstep_count: 94578
total_train_sample_count: 94538
total_episode_count: 315
total_duration: 114.35383933356827
[2024-11-15 01:36:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 393
train_sample_count: 393
avg_envstep_per_episode: 196.5
avg_sample_per_episode: 196.5
avg_envstep_per_sec: 740.5987988239187
avg_train_sample_per_sec: 740.5987988239187
avg_episode_per_sec: 3.768950630147169
collect_time: 0.5306516843182699
reward_mean: 620.0
reward_std: 379.0
reward_max: 999.0
reward_min: 241.0
total_envstep_count: 95536
total_train_sample_count: 95507
total_episode_count: 317
total_duration: 114.88449101788655
[2024-11-15 01:36:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 934
train_sample_count: 934
avg_envstep_per_episode: 233.5
avg_sample_per_episode: 233.5
avg_envstep_per_sec: 726.4556158777083
avg_train_sample_per_sec: 726.4556158777083
avg_episode_per_sec: 3.1111589545083866
collect_time: 1.2856945140021188
reward_mean: 649.0
reward_std: 65.44845581054688
reward_max: 755.0
reward_min: 576.0
total_envstep_count: 96540
total_train_sample_count: 96489
total_episode_count: 321
total_duration: 116.17018553188866
[2024-11-15 01:36:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 821
train_sample_count: 821
avg_envstep_per_episode: 164.2
avg_sample_per_episode: 164.2
avg_envstep_per_sec: 731.8088708778322
avg_train_sample_per_sec: 731.8088708778322
avg_episode_per_sec: 4.456814073555616
collect_time: 1.1218776277133395
reward_mean: 431.6000061035156
reward_std: 239.1999969482422
reward_max: 761.0
reward_min: 228.0
total_envstep_count: 97519
total_train_sample_count: 97478
total_episode_count: 326
total_duration: 117.29206315960201
[2024-11-15 01:36:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 972
train_sample_count: 972
avg_envstep_per_episode: 138.85714285714286
avg_sample_per_episode: 138.85714285714286
avg_envstep_per_sec: 724.5584786656826
avg_train_sample_per_sec: 724.5584786656826
avg_episode_per_sec: 5.218013735246686
collect_time: 1.3415066259247916
reward_mean: 509.1428527832031
reward_std: 441.0382080078125
reward_max: 1363.0
reward_min: 216.0
total_envstep_count: 98545
total_train_sample_count: 98498
total_episode_count: 333
total_duration: 118.6335697855268
[2024-11-15 01:36:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 762
train_sample_count: 762
avg_envstep_per_episode: 152.4
avg_sample_per_episode: 152.4
avg_envstep_per_sec: 716.0847817739788
avg_train_sample_per_sec: 716.0847817739788
avg_episode_per_sec: 4.698719040511671
collect_time: 1.0641198073114668
reward_mean: 515.2000122070312
reward_std: 240.18443298339844
reward_max: 788.0
reward_min: 217.0
total_envstep_count: 99540
total_train_sample_count: 99512
total_episode_count: 338
total_duration: 119.69768959283827
[2024-11-15 01:36:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1186
train_sample_count: 1186
avg_envstep_per_episode: 197.66666666666666
avg_sample_per_episode: 197.66666666666666
avg_envstep_per_sec: 714.7417204436449
avg_train_sample_per_sec: 714.7417204436449
avg_episode_per_sec: 3.6158940325985407
collect_time: 1.6593406626156397
reward_mean: 673.0
reward_std: 383.2997131347656
reward_max: 1327.0
reward_min: 249.0
total_envstep_count: 100590
total_train_sample_count: 100554
total_episode_count: 344
total_duration: 121.3570302554539
[2024-11-15 01:36:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 864
train_sample_count: 864
avg_envstep_per_episode: 172.8
avg_sample_per_episode: 172.8
avg_envstep_per_sec: 702.5117416291416
avg_train_sample_per_sec: 702.5117416291416
avg_episode_per_sec: 4.065461467761237
collect_time: 1.2298726822648731
reward_mean: 921.5999755859375
reward_std: 697.3256225585938
reward_max: 1841.0
reward_min: 225.0
total_envstep_count: 101563
total_train_sample_count: 101526
total_episode_count: 349
total_duration: 122.58690293771878
[2024-11-15 01:36:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1660
train_sample_count: 1660
avg_envstep_per_episode: 830.0
avg_sample_per_episode: 830.0
avg_envstep_per_sec: 712.8990789307876
avg_train_sample_per_sec: 712.8990789307876
avg_episode_per_sec: 0.8589145529286598
collect_time: 2.3285203320639476
reward_mean: 916.5
reward_std: 175.5
reward_max: 1092.0
reward_min: 741.0
total_envstep_count: 102809
total_train_sample_count: 102778
total_episode_count: 351
total_duration: 124.91542326978272
[2024-11-15 01:36:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1968
train_sample_count: 1968
avg_envstep_per_episode: 393.6
avg_sample_per_episode: 393.6
avg_envstep_per_sec: 707.5813954280801
avg_train_sample_per_sec: 707.5813954280801
avg_episode_per_sec: 1.7977169599290652
collect_time: 2.7813054621219635
reward_mean: 907.0
reward_std: 101.9372329711914
reward_max: 1011.0
reward_min: 780.0
total_envstep_count: 103796
total_train_sample_count: 103750
total_episode_count: 356
total_duration: 127.69672873190468
[2024-11-15 01:37:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1042
train_sample_count: 1042
avg_envstep_per_episode: 260.5
avg_sample_per_episode: 260.5
avg_envstep_per_sec: 708.9118246923057
avg_train_sample_per_sec: 708.9118246923057
avg_episode_per_sec: 2.7213505746345708
collect_time: 1.469858399459294
reward_mean: 865.25
reward_std: 254.00430297851562
reward_max: 1281.0
reward_min: 591.0
total_envstep_count: 104778
total_train_sample_count: 104756
total_episode_count: 360
total_duration: 129.16658713136397
[2024-11-15 01:37:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 573
train_sample_count: 573
avg_envstep_per_episode: 95.5
avg_sample_per_episode: 95.5
avg_envstep_per_sec: 706.2297187454511
avg_train_sample_per_sec: 706.2297187454511
avg_episode_per_sec: 7.395075588957603
collect_time: 0.8113507330417632
reward_mean: 452.1666564941406
reward_std: 236.91448974609375
reward_max: 802.0
reward_min: 209.0
total_envstep_count: 105772
total_train_sample_count: 105737
total_episode_count: 366
total_duration: 129.97793786440573
[2024-11-15 01:37:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1528
train_sample_count: 1528
avg_envstep_per_episode: 254.66666666666666
avg_sample_per_episode: 254.66666666666666
avg_envstep_per_sec: 706.6324880178088
avg_train_sample_per_sec: 706.6324880178088
avg_episode_per_sec: 2.77473490059349
collect_time: 2.162368736096791
reward_mean: 900.5
reward_std: 239.2904510498047
reward_max: 1320.0
reward_min: 634.0
total_envstep_count: 106782
total_train_sample_count: 106749
total_episode_count: 372
total_duration: 132.14030660050253
[2024-11-15 01:37:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 767
train_sample_count: 767
avg_envstep_per_episode: 153.4
avg_sample_per_episode: 153.4
avg_envstep_per_sec: 685.2418855012038
avg_train_sample_per_sec: 685.2418855012038
avg_episode_per_sec: 4.467026632993506
collect_time: 1.11931278024401
reward_mean: 748.4000244140625
reward_std: 377.9881591796875
reward_max: 1299.0
reward_min: 227.0
total_envstep_count: 107762
total_train_sample_count: 107720
total_episode_count: 377
total_duration: 133.25961938074653
[2024-11-15 01:37:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 438
train_sample_count: 438
avg_envstep_per_episode: 219.0
avg_sample_per_episode: 219.0
avg_envstep_per_sec: 701.2600255265796
avg_train_sample_per_sec: 701.2600255265796
avg_episode_per_sec: 3.202100573180729
collect_time: 0.6245900009359633
reward_mean: 712.0
reward_std: 87.0
reward_max: 799.0
reward_min: 625.0
total_envstep_count: 108728
total_train_sample_count: 108698
total_episode_count: 379
total_duration: 133.8842093816825
[2024-11-15 01:37:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 538
train_sample_count: 538
avg_envstep_per_episode: 179.33333333333334
avg_sample_per_episode: 179.33333333333334
avg_envstep_per_sec: 700.6702068093421
avg_train_sample_per_sec: 700.6702068093421
avg_episode_per_sec: 3.907082937598562
collect_time: 0.7678362727165222
reward_mean: 581.0
reward_std: 494.9774475097656
reward_max: 1281.0
reward_min: 229.0
total_envstep_count: 109725
total_train_sample_count: 109680
total_episode_count: 382
total_duration: 134.65204565439902
[2024-11-15 01:37:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1195
train_sample_count: 1195
avg_envstep_per_episode: 239.0
avg_sample_per_episode: 239.0
avg_envstep_per_sec: 708.0544290605378
avg_train_sample_per_sec: 708.0544290605378
avg_episode_per_sec: 2.9625708328892797
collect_time: 1.6877233598913466
reward_mean: 950.5999755859375
reward_std: 506.1768798828125
reward_max: 1668.0
reward_min: 222.0
total_envstep_count: 110697
total_train_sample_count: 110671
total_episode_count: 387
total_duration: 136.33976901429037
[2024-11-15 01:37:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 644
train_sample_count: 644
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 715.2530468455974
avg_train_sample_per_sec: 715.2530468455974
avg_episode_per_sec: 4.442565508357748
collect_time: 0.9003806454794747
reward_mean: 517.5
reward_std: 317.3141174316406
reward_max: 997.0
reward_min: 213.0
total_envstep_count: 111709
total_train_sample_count: 111663
total_episode_count: 391
total_duration: 137.24014965976986
[2024-11-15 01:37:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1262
train_sample_count: 1262
avg_envstep_per_episode: 252.4
avg_sample_per_episode: 252.4
avg_envstep_per_sec: 714.376444834129
avg_train_sample_per_sec: 714.376444834129
avg_episode_per_sec: 2.830334567488625
collect_time: 1.7665756046772003
reward_mean: 751.5999755859375
reward_std: 260.2580261230469
reward_max: 1267.0
reward_min: 578.0
total_envstep_count: 112704
total_train_sample_count: 112673
total_episode_count: 396
total_duration: 139.00672526444706
[2024-11-15 01:37:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1201
train_sample_count: 1201
avg_envstep_per_episode: 240.2
avg_sample_per_episode: 240.2
avg_envstep_per_sec: 716.0510482475898
avg_train_sample_per_sec: 716.0510482475898
avg_episode_per_sec: 2.9810618161848037
collect_time: 1.6772547193935938
reward_mean: 663.4000244140625
reward_std: 54.271907806396484
reward_max: 744.0
reward_min: 602.0
total_envstep_count: 113715
total_train_sample_count: 113670
total_episode_count: 401
total_duration: 140.68397998384066
[2024-11-15 01:37:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 328
train_sample_count: 328
avg_envstep_per_episode: 109.33333333333333
avg_sample_per_episode: 109.33333333333333
avg_envstep_per_sec: 703.5478367748782
avg_train_sample_per_sec: 703.5478367748782
avg_episode_per_sec: 6.434888750989739
collect_time: 0.4662085260663714
reward_mean: 632.3333129882812
reward_std: 332.7745361328125
reward_max: 1044.0
reward_min: 229.0
total_envstep_count: 114696
total_train_sample_count: 114646
total_episode_count: 404
total_duration: 141.15018850990703
[2024-11-15 01:37:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 2585
train_sample_count: 2585
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 704.1160853727151
avg_train_sample_per_sec: 704.1160853727151
avg_episode_per_sec: 2.99623866116049
collect_time: 3.671269629682813
reward_mean: 731.1818237304688
reward_std: 431.7488098144531
reward_max: 1318.0
reward_min: 245.0
total_envstep_count: 115688
total_train_sample_count: 115647
total_episode_count: 415
total_duration: 144.82145813958985
[2024-11-15 01:37:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 348
train_sample_count: 348
avg_envstep_per_episode: 174.0
avg_sample_per_episode: 174.0
avg_envstep_per_sec: 710.1796879473859
avg_train_sample_per_sec: 710.1796879473859
avg_episode_per_sec: 4.081492459467735
collect_time: 0.4900168308189938
reward_mean: 616.5
reward_std: 393.5
reward_max: 1010.0
reward_min: 223.0
total_envstep_count: 116654
total_train_sample_count: 116631
total_episode_count: 417
total_duration: 145.31147497040885
[2024-11-15 01:37:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1075
train_sample_count: 1075
avg_envstep_per_episode: 179.16666666666666
avg_sample_per_episode: 179.16666666666666
avg_envstep_per_sec: 711.6303325842123
avg_train_sample_per_sec: 711.6303325842123
avg_episode_per_sec: 3.971890228376999
collect_time: 1.5106157660484316
reward_mean: 762.6666870117188
reward_std: 336.9370422363281
reward_max: 1307.0
reward_min: 240.0
total_envstep_count: 117641
total_train_sample_count: 117610
total_episode_count: 423
total_duration: 146.82209073645728
[2024-11-15 01:38:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 605
train_sample_count: 605
avg_envstep_per_episode: 121.0
avg_sample_per_episode: 121.0
avg_envstep_per_sec: 716.7135372901711
avg_train_sample_per_sec: 716.7135372901711
avg_episode_per_sec: 5.923252374298934
collect_time: 0.8441308396203178
reward_mean: 442.20001220703125
reward_std: 267.4385070800781
reward_max: 780.0
reward_min: 214.0
total_envstep_count: 118661
total_train_sample_count: 118635
total_episode_count: 428
total_duration: 147.6662215760776
[2024-11-15 01:38:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 2045
train_sample_count: 2045
avg_envstep_per_episode: 227.22222222222223
avg_sample_per_episode: 227.22222222222223
avg_envstep_per_sec: 705.7241838183439
avg_train_sample_per_sec: 705.7241838183439
avg_episode_per_sec: 3.1058766036015135
collect_time: 2.897732636758259
reward_mean: 738.5555419921875
reward_std: 347.5895080566406
reward_max: 1370.0
reward_min: 234.0
total_envstep_count: 119676
total_train_sample_count: 119636
total_episode_count: 437
total_duration: 150.56395421283585
[2024-11-15 01:38:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 582
train_sample_count: 582
avg_envstep_per_episode: 83.14285714285714
avg_sample_per_episode: 83.14285714285714
avg_envstep_per_sec: 712.7138918707224
avg_train_sample_per_sec: 712.7138918707224
avg_episode_per_sec: 8.572160211503533
collect_time: 0.8165969635759082
reward_mean: 407.28570556640625
reward_std: 201.84060668945312
reward_max: 703.0
reward_min: 226.0
total_envstep_count: 120685
total_train_sample_count: 120638
total_episode_count: 444
total_duration: 151.38055117641176
[2024-11-15 01:38:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1150
train_sample_count: 1150
avg_envstep_per_episode: 164.28571428571428
avg_sample_per_episode: 164.28571428571428
avg_envstep_per_sec: 701.1934277659556
avg_train_sample_per_sec: 701.1934277659556
avg_episode_per_sec: 4.268133908140599
collect_time: 1.6400610080787112
reward_mean: 594.5714111328125
reward_std: 262.4025573730469
reward_max: 1009.0
reward_min: 222.0
total_envstep_count: 121662
total_train_sample_count: 121632
total_episode_count: 451
total_duration: 153.02061218449046
[2024-11-15 01:38:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1141
train_sample_count: 1141
avg_envstep_per_episode: 126.77777777777777
avg_sample_per_episode: 126.77777777777777
avg_envstep_per_sec: 671.179685814298
avg_train_sample_per_sec: 671.179685814298
avg_episode_per_sec: 5.294143008175882
collect_time: 1.699991856302534
reward_mean: 556.0
reward_std: 258.1282958984375
reward_max: 814.0
reward_min: 181.0
total_envstep_count: 122653
total_train_sample_count: 122617
total_episode_count: 460
total_duration: 154.720604040793
[2024-11-15 01:38:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 742
train_sample_count: 742
avg_envstep_per_episode: 123.66666666666667
avg_sample_per_episode: 123.66666666666667
avg_envstep_per_sec: 698.3557479073627
avg_train_sample_per_sec: 698.3557479073627
avg_episode_per_sec: 5.6470815194665445
collect_time: 1.0624957297529494
reward_mean: 621.1666870117188
reward_std: 223.83580017089844
reward_max: 1015.0
reward_min: 240.0
total_envstep_count: 123655
total_train_sample_count: 123599
total_episode_count: 466
total_duration: 155.78309977054596
[2024-11-15 01:38:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 285
train_sample_count: 285
avg_envstep_per_episode: 142.5
avg_sample_per_episode: 142.5
avg_envstep_per_sec: 707.6518138393167
avg_train_sample_per_sec: 707.6518138393167
avg_episode_per_sec: 4.965977640977661
collect_time: 0.40274043594087877
reward_mean: 680.0
reward_std: 85.0
reward_max: 765.0
reward_min: 595.0
total_envstep_count: 124629
total_train_sample_count: 124592
total_episode_count: 468
total_duration: 156.18584020648683
[2024-11-15 01:38:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1398
train_sample_count: 1398
avg_envstep_per_episode: 279.6
avg_sample_per_episode: 279.6
avg_envstep_per_sec: 705.8990223857154
avg_train_sample_per_sec: 705.8990223857154
avg_episode_per_sec: 2.5246746151134314
collect_time: 1.9804532315049852
reward_mean: 790.0
reward_std: 265.8142395019531
reward_max: 1296.0
reward_min: 565.0
total_envstep_count: 125648
total_train_sample_count: 125594
total_episode_count: 473
total_duration: 158.1662934379918
[2024-11-15 01:38:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 971
train_sample_count: 971
avg_envstep_per_episode: 242.75
avg_sample_per_episode: 242.75
avg_envstep_per_sec: 710.3365673608125
avg_train_sample_per_sec: 710.3365673608125
avg_episode_per_sec: 2.9262062507139546
collect_time: 1.3669576432023731
reward_mean: 930.5
reward_std: 372.5550231933594
reward_max: 1492.0
reward_min: 586.0
total_envstep_count: 126636
total_train_sample_count: 126589
total_episode_count: 477
total_duration: 159.53325108119418
[2024-11-15 01:38:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1027
train_sample_count: 1027
avg_envstep_per_episode: 256.75
avg_sample_per_episode: 256.75
avg_envstep_per_sec: 714.2312728519439
avg_train_sample_per_sec: 714.2312728519439
avg_episode_per_sec: 2.7818160578459357
collect_time: 1.4379095946039473
reward_mean: 993.25
reward_std: 317.16351318359375
reward_max: 1337.0
reward_min: 626.0
total_envstep_count: 127626
total_train_sample_count: 127580
total_episode_count: 481
total_duration: 160.97116067579813
[2024-11-15 01:38:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1146
train_sample_count: 1146
avg_envstep_per_episode: 191.0
avg_sample_per_episode: 191.0
avg_envstep_per_sec: 702.8979658755752
avg_train_sample_per_sec: 702.8979658755752
avg_episode_per_sec: 3.6800940621757863
collect_time: 1.630393109151295
reward_mean: 809.0
reward_std: 378.980224609375
reward_max: 1303.0
reward_min: 238.0
total_envstep_count: 128598
total_train_sample_count: 128570
total_episode_count: 487
total_duration: 162.60155378494943
