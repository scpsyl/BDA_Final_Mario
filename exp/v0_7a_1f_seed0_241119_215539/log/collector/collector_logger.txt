[2024-11-19 21:56:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 235
train_sample_count: 235
avg_envstep_per_episode: 58.75
avg_sample_per_episode: 58.75
avg_envstep_per_sec: 768.9366998128194
avg_train_sample_per_sec: 768.9366998128194
avg_episode_per_sec: 13.088284252133096
collect_time: 0.30561683433396475
reward_mean: 325.0
reward_std: 176.28244018554688
reward_max: 630.0
reward_min: 210.0
total_envstep_count: 1149
total_train_sample_count: 1135
total_episode_count: 4
total_duration: 0.30561683433396475
[2024-11-19 21:56:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 773
train_sample_count: 773
avg_envstep_per_episode: 193.25
avg_sample_per_episode: 193.25
avg_envstep_per_sec: 715.5654312691213
avg_train_sample_per_sec: 715.5654312691213
avg_episode_per_sec: 3.702796539555608
collect_time: 1.0802645938737052
reward_mean: 642.75
reward_std: 49.89175796508789
reward_max: 727.0
reward_min: 597.0
total_envstep_count: 2154
total_train_sample_count: 2124
total_episode_count: 8
total_duration: 1.38588142820767
[2024-11-19 21:56:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 327
train_sample_count: 327
avg_envstep_per_episode: 109.0
avg_sample_per_episode: 109.0
avg_envstep_per_sec: 523.7301317414292
avg_train_sample_per_sec: 523.7301317414292
avg_episode_per_sec: 4.804863593958066
collect_time: 0.6243673605578286
reward_mean: 385.6666564941406
reward_std: 224.3885498046875
reward_max: 703.0
reward_min: 227.0
total_envstep_count: 3160
total_train_sample_count: 3135
total_episode_count: 11
total_duration: 2.0102487887654985
[2024-11-19 21:56:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 586
train_sample_count: 586
avg_envstep_per_episode: 195.33333333333334
avg_sample_per_episode: 195.33333333333334
avg_envstep_per_sec: 491.02821346265836
avg_train_sample_per_sec: 491.02821346265836
avg_episode_per_sec: 2.5137963146552473
collect_time: 1.193414113351277
reward_mean: 509.6666564941406
reward_std: 210.09573364257812
reward_max: 690.0
reward_min: 215.0
total_envstep_count: 4150
total_train_sample_count: 4117
total_episode_count: 14
total_duration: 3.2036629021167755
[2024-11-19 21:56:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 596
train_sample_count: 596
avg_envstep_per_episode: 198.66666666666666
avg_sample_per_episode: 198.66666666666666
avg_envstep_per_sec: 414.51100657348735
avg_train_sample_per_sec: 414.51100657348735
avg_episode_per_sec: 2.0864647981886946
collect_time: 1.4378387800284793
reward_mean: 454.6666564941406
reward_std: 163.92750549316406
reward_max: 578.0
reward_min: 223.0
total_envstep_count: 5155
total_train_sample_count: 5097
total_episode_count: 17
total_duration: 4.641501682145255
[2024-11-19 21:56:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1037
train_sample_count: 1037
avg_envstep_per_episode: 259.25
avg_sample_per_episode: 259.25
avg_envstep_per_sec: 414.66743622882655
avg_train_sample_per_sec: 414.66743622882655
avg_episode_per_sec: 1.5994886643349144
collect_time: 2.50079921739442
reward_mean: 461.75
reward_std: 245.28286743164062
reward_max: 759.0
reward_min: 201.0
total_envstep_count: 6152
total_train_sample_count: 6122
total_episode_count: 21
total_duration: 7.142300899539675
[2024-11-19 21:56:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 51
train_sample_count: 51
avg_envstep_per_episode: 51.0
avg_sample_per_episode: 51.0
avg_envstep_per_sec: 431.11694484885754
avg_train_sample_per_sec: 431.11694484885754
avg_episode_per_sec: 8.453273428408972
collect_time: 0.11829736828804016
reward_mean: 227.0
reward_std: 0.0
reward_max: 227.0
reward_min: 227.0
total_envstep_count: 7112
total_train_sample_count: 7085
total_episode_count: 22
total_duration: 7.2605982678277154
[2024-11-19 21:56:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1639
train_sample_count: 1639
avg_envstep_per_episode: 546.3333333333334
avg_sample_per_episode: 546.3333333333334
avg_envstep_per_sec: 447.90931706370134
avg_train_sample_per_sec: 447.90931706370134
avg_episode_per_sec: 0.8198462179323392
collect_time: 3.6592228327478677
reward_mean: 723.0
reward_std: 112.93656158447266
reward_max: 871.0
reward_min: 597.0
total_envstep_count: 8125
total_train_sample_count: 8064
total_episode_count: 25
total_duration: 10.919821100575582
[2024-11-19 21:56:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 47
train_sample_count: 47
avg_envstep_per_episode: 47.0
avg_sample_per_episode: 47.0
avg_envstep_per_sec: 426.15047894508825
avg_train_sample_per_sec: 426.15047894508825
avg_episode_per_sec: 9.06703146691677
collect_time: 0.11028968010629926
reward_mean: 235.0
reward_std: 0.0
reward_max: 235.0
reward_min: 235.0
total_envstep_count: 9092
total_train_sample_count: 9059
total_episode_count: 26
total_duration: 11.030110780681882
[2024-11-19 21:56:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 813
train_sample_count: 813
avg_envstep_per_episode: 406.5
avg_sample_per_episode: 406.5
avg_envstep_per_sec: 434.02831824924306
avg_train_sample_per_sec: 434.02831824924306
avg_episode_per_sec: 1.067720340096539
collect_time: 1.8731496674673895
reward_mean: 1133.5
reward_std: 432.5
reward_max: 1566.0
reward_min: 701.0
total_envstep_count: 10082
total_train_sample_count: 10052
total_episode_count: 28
total_duration: 12.903260448149272
[2024-11-19 21:56:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 469
train_sample_count: 469
avg_envstep_per_episode: 156.33333333333334
avg_sample_per_episode: 156.33333333333334
avg_envstep_per_sec: 441.3515345260422
avg_train_sample_per_sec: 441.3515345260422
avg_episode_per_sec: 2.823144144089822
collect_time: 1.0626449968133653
reward_mean: 641.3333129882812
reward_std: 40.82754898071289
reward_max: 699.0
reward_min: 610.0
total_envstep_count: 11056
total_train_sample_count: 11025
total_episode_count: 31
total_duration: 13.965905444962637
[2024-11-19 21:57:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1320
train_sample_count: 1320
avg_envstep_per_episode: 330.0
avg_sample_per_episode: 330.0
avg_envstep_per_sec: 429.11138861329516
avg_train_sample_per_sec: 429.11138861329516
avg_episode_per_sec: 1.3003375412524096
collect_time: 3.076124370098115
reward_mean: 391.75
reward_std: 177.91061401367188
reward_max: 612.0
reward_min: 196.0
total_envstep_count: 12060
total_train_sample_count: 12021
total_episode_count: 35
total_duration: 17.04202981506075
[2024-11-19 21:57:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 2680
train_sample_count: 2680
avg_envstep_per_episode: 670.0
avg_sample_per_episode: 670.0
avg_envstep_per_sec: 439.82457342168317
avg_train_sample_per_sec: 439.82457342168317
avg_episode_per_sec: 0.656454587196542
collect_time: 6.093338485274995
reward_mean: 787.5
reward_std: 202.777587890625
reward_max: 1070.0
reward_min: 590.0
total_envstep_count: 13032
total_train_sample_count: 12997
total_episode_count: 39
total_duration: 23.135368300335745
[2024-11-19 21:57:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 101
train_sample_count: 101
avg_envstep_per_episode: 101.0
avg_sample_per_episode: 101.0
avg_envstep_per_sec: 437.5401206108782
avg_train_sample_per_sec: 437.5401206108782
avg_episode_per_sec: 4.332080402087903
collect_time: 0.23083597421646118
reward_mean: 610.0
reward_std: 0.0
reward_max: 610.0
reward_min: 610.0
total_envstep_count: 13991
total_train_sample_count: 13962
total_episode_count: 40
total_duration: 23.366204274552206
[2024-11-19 21:57:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1337
train_sample_count: 1337
avg_envstep_per_episode: 445.6666666666667
avg_sample_per_episode: 445.6666666666667
avg_envstep_per_sec: 425.89882255527294
avg_train_sample_per_sec: 425.89882255527294
avg_episode_per_sec: 0.9556443288450402
collect_time: 3.139243240867342
reward_mean: 666.0
reward_std: 365.8606262207031
reward_max: 1131.0
reward_min: 237.0
total_envstep_count: 15021
total_train_sample_count: 14975
total_episode_count: 43
total_duration: 26.505447515419547
[2024-11-19 21:57:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 673
train_sample_count: 673
avg_envstep_per_episode: 168.25
avg_sample_per_episode: 168.25
avg_envstep_per_sec: 410.657837447763
avg_train_sample_per_sec: 410.657837447763
avg_episode_per_sec: 2.4407598065245946
collect_time: 1.6388339357716697
reward_mean: 582.25
reward_std: 429.4556884765625
reward_max: 1272.0
reward_min: 203.0
total_envstep_count: 16001
total_train_sample_count: 15972
total_episode_count: 47
total_duration: 28.144281451191215
[2024-11-19 21:57:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 40
train_sample_count: 40
avg_envstep_per_episode: 40.0
avg_sample_per_episode: 40.0
avg_envstep_per_sec: 395.7853692664935
avg_train_sample_per_sec: 395.7853692664935
avg_episode_per_sec: 9.894634231662337
collect_time: 0.10106487785066877
reward_mean: 237.0
reward_std: 0.0
reward_max: 237.0
reward_min: 237.0
total_envstep_count: 16960
total_train_sample_count: 16936
total_episode_count: 48
total_duration: 28.245346329041883
[2024-11-19 21:57:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2204
train_sample_count: 2204
avg_envstep_per_episode: 440.8
avg_sample_per_episode: 440.8
avg_envstep_per_sec: 432.79756552096336
avg_train_sample_per_sec: 432.79756552096336
avg_episode_per_sec: 0.9818456568079931
collect_time: 5.092450086559568
reward_mean: 761.7999877929688
reward_std: 378.1075744628906
reward_max: 1266.0
reward_min: 226.0
total_envstep_count: 17964
total_train_sample_count: 17928
total_episode_count: 53
total_duration: 33.33779641560145
[2024-11-19 21:57:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 261
train_sample_count: 261
avg_envstep_per_episode: 261.0
avg_sample_per_episode: 261.0
avg_envstep_per_sec: 467.1428264969515
avg_train_sample_per_sec: 467.1428264969515
avg_episode_per_sec: 1.7898192586090096
collect_time: 0.5587156329836165
reward_mean: 1021.0
reward_std: 0.0
reward_max: 1021.0
reward_min: 1021.0
total_envstep_count: 19227
total_train_sample_count: 19185
total_episode_count: 54
total_duration: 33.896512048585066
[2024-11-19 21:57:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1087
train_sample_count: 1087
avg_envstep_per_episode: 1087.0
avg_sample_per_episode: 1087.0
avg_envstep_per_sec: 442.0632688479839
avg_train_sample_per_sec: 442.0632688479839
avg_episode_per_sec: 0.4066819400625427
collect_time: 2.4589240423270633
reward_mean: 847.0
reward_std: 0.0
reward_max: 847.0
reward_min: 847.0
total_envstep_count: 20186
total_train_sample_count: 20152
total_episode_count: 55
total_duration: 36.35543609091213
[2024-11-19 21:57:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 926
train_sample_count: 926
avg_envstep_per_episode: 926.0
avg_sample_per_episode: 926.0
avg_envstep_per_sec: 451.6639937115032
avg_train_sample_per_sec: 451.6639937115032
avg_episode_per_sec: 0.4877580925610186
collect_time: 2.050196634871619
reward_mean: 1527.0
reward_std: 0.0
reward_max: 1527.0
reward_min: 1527.0
total_envstep_count: 21145
total_train_sample_count: 21114
total_episode_count: 56
total_duration: 38.40563272578375
[2024-11-19 21:57:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1804
train_sample_count: 1804
avg_envstep_per_episode: 451.0
avg_sample_per_episode: 451.0
avg_envstep_per_sec: 526.7863831318762
avg_train_sample_per_sec: 526.7863831318762
avg_episode_per_sec: 1.168040760824559
collect_time: 3.424538024834224
reward_mean: 710.25
reward_std: 138.2142791748047
reward_max: 942.0
reward_min: 577.0
total_envstep_count: 22149
total_train_sample_count: 22102
total_episode_count: 60
total_duration: 41.830170750617974
[2024-11-19 21:57:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1164
train_sample_count: 1164
avg_envstep_per_episode: 194.0
avg_sample_per_episode: 194.0
avg_envstep_per_sec: 650.7860466178129
avg_train_sample_per_sec: 650.7860466178129
avg_episode_per_sec: 3.354567250607283
collect_time: 1.788606264761516
reward_mean: 471.0
reward_std: 271.9031677246094
reward_max: 938.0
reward_min: 199.0
total_envstep_count: 23120
total_train_sample_count: 23086
total_episode_count: 66
total_duration: 43.61877701537949
[2024-11-19 21:57:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2194
train_sample_count: 2194
avg_envstep_per_episode: 731.3333333333334
avg_sample_per_episode: 731.3333333333334
avg_envstep_per_sec: 524.553894718688
avg_train_sample_per_sec: 524.553894718688
avg_episode_per_sec: 0.7172569207639308
collect_time: 4.182601677519935
reward_mean: 789.6666870117188
reward_std: 154.47618103027344
reward_max: 1002.0
reward_min: 639.0
total_envstep_count: 24109
total_train_sample_count: 24068
total_episode_count: 69
total_duration: 47.801378692899426
[2024-11-19 21:58:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 427
train_sample_count: 427
avg_envstep_per_episode: 71.16666666666667
avg_sample_per_episode: 71.16666666666667
avg_envstep_per_sec: 787.7398876288048
avg_train_sample_per_sec: 787.7398876288048
avg_episode_per_sec: 11.068944556845032
collect_time: 0.542057101215635
reward_mean: 358.0
reward_std: 181.61956787109375
reward_max: 646.0
reward_min: 216.0
total_envstep_count: 25087
total_train_sample_count: 25047
total_episode_count: 75
total_duration: 48.34343579411506
[2024-11-19 21:58:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 278
train_sample_count: 278
avg_envstep_per_episode: 139.0
avg_sample_per_episode: 139.0
avg_envstep_per_sec: 737.503831241779
avg_train_sample_per_sec: 737.503831241779
avg_episode_per_sec: 5.30578295857395
collect_time: 0.37694719433784485
reward_mean: 517.0
reward_std: 279.0
reward_max: 796.0
reward_min: 238.0
total_envstep_count: 26070
total_train_sample_count: 26021
total_episode_count: 77
total_duration: 48.720382988452904
[2024-11-19 21:58:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 202
train_sample_count: 202
avg_envstep_per_episode: 202.0
avg_sample_per_episode: 202.0
avg_envstep_per_sec: 721.7379205712914
avg_train_sample_per_sec: 721.7379205712914
avg_episode_per_sec: 3.572960002828175
collect_time: 0.27987998723983765
reward_mean: 624.0
reward_std: 0.0
reward_max: 624.0
reward_min: 624.0
total_envstep_count: 27037
total_train_sample_count: 26991
total_episode_count: 78
total_duration: 49.00026297569274
[2024-11-19 21:58:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1509
train_sample_count: 1509
avg_envstep_per_episode: 503.0
avg_sample_per_episode: 503.0
avg_envstep_per_sec: 719.421603643707
avg_train_sample_per_sec: 719.421603643707
avg_episode_per_sec: 1.4302616374626385
collect_time: 2.0975183291094646
reward_mean: 603.3333129882812
reward_std: 281.862060546875
reward_max: 856.0
reward_min: 210.0
total_envstep_count: 28002
total_train_sample_count: 27972
total_episode_count: 81
total_duration: 51.097781304802204
[2024-11-19 21:58:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 217
train_sample_count: 217
avg_envstep_per_episode: 72.33333333333333
avg_sample_per_episode: 72.33333333333333
avg_envstep_per_sec: 823.9097400722698
avg_train_sample_per_sec: 823.9097400722698
avg_episode_per_sec: 11.390457236022163
collect_time: 0.2633783646992275
reward_mean: 359.0
reward_std: 190.2647247314453
reward_max: 628.0
reward_min: 219.0
total_envstep_count: 28991
total_train_sample_count: 28945
total_episode_count: 84
total_duration: 51.36115966950143
[2024-11-19 21:58:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 37
train_sample_count: 37
avg_envstep_per_episode: 37.0
avg_sample_per_episode: 37.0
avg_envstep_per_sec: 868.5843257400899
avg_train_sample_per_sec: 868.5843257400899
avg_episode_per_sec: 23.475252047029453
collect_time: 0.04259805168424334
reward_mean: 232.0
reward_std: 0.0
reward_max: 232.0
reward_min: 232.0
total_envstep_count: 29950
total_train_sample_count: 29906
total_episode_count: 85
total_duration: 51.40375772118568
[2024-11-19 21:58:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1992
train_sample_count: 1992
avg_envstep_per_episode: 996.0
avg_sample_per_episode: 996.0
avg_envstep_per_sec: 786.3414538410702
avg_train_sample_per_sec: 786.3414538410702
avg_episode_per_sec: 0.7894994516476609
collect_time: 2.533250651189259
reward_mean: 762.0
reward_std: 43.0
reward_max: 805.0
reward_min: 719.0
total_envstep_count: 30932
total_train_sample_count: 30878
total_episode_count: 87
total_duration: 53.93700837237493
[2024-11-19 21:58:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1044
train_sample_count: 1044
avg_envstep_per_episode: 1044.0
avg_sample_per_episode: 1044.0
avg_envstep_per_sec: 805.476893674715
avg_train_sample_per_sec: 805.476893674715
avg_episode_per_sec: 0.7715295916424474
collect_time: 1.2961265657629286
reward_mean: 555.0
reward_std: 0.0
reward_max: 555.0
reward_min: 555.0
total_envstep_count: 31891
total_train_sample_count: 31838
total_episode_count: 88
total_duration: 55.23313493813786
[2024-11-19 21:58:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2572
train_sample_count: 2572
avg_envstep_per_episode: 428.6666666666667
avg_sample_per_episode: 428.6666666666667
avg_envstep_per_sec: 831.860239128295
avg_train_sample_per_sec: 831.860239128295
avg_episode_per_sec: 1.940575985524794
collect_time: 3.091865531035832
reward_mean: 628.6666870117188
reward_std: 320.8284606933594
reward_max: 1113.0
reward_min: 237.0
total_envstep_count: 32877
total_train_sample_count: 32838
total_episode_count: 94
total_duration: 58.32500046917369
[2024-11-19 21:58:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 40
train_sample_count: 40
avg_envstep_per_episode: 40.0
avg_sample_per_episode: 40.0
avg_envstep_per_sec: 865.8374340904494
avg_train_sample_per_sec: 865.8374340904494
avg_episode_per_sec: 21.645935852261236
collect_time: 0.046198048761912754
reward_mean: 247.0
reward_std: 0.0
reward_max: 247.0
reward_min: 247.0
total_envstep_count: 33836
total_train_sample_count: 33802
total_episode_count: 95
total_duration: 58.3711985179356
[2024-11-19 21:58:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1685
train_sample_count: 1685
avg_envstep_per_episode: 240.71428571428572
avg_sample_per_episode: 240.71428571428572
avg_envstep_per_sec: 889.9667541617112
avg_train_sample_per_sec: 889.9667541617112
avg_episode_per_sec: 3.697191263579809
collect_time: 1.8933291520391193
reward_mean: 558.1428833007812
reward_std: 210.13223266601562
reward_max: 759.0
reward_min: 234.0
total_envstep_count: 34837
total_train_sample_count: 34791
total_episode_count: 102
total_duration: 60.264527669974726
[2024-11-19 21:58:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1120
train_sample_count: 1120
avg_envstep_per_episode: 280.0
avg_sample_per_episode: 280.0
avg_envstep_per_sec: 898.2403626216636
avg_train_sample_per_sec: 898.2403626216636
avg_episode_per_sec: 3.20800129507737
collect_time: 1.246882289648056
reward_mean: 474.75
reward_std: 286.0990905761719
reward_max: 900.0
reward_min: 196.0
total_envstep_count: 35833
total_train_sample_count: 35791
total_episode_count: 106
total_duration: 61.51140995962278
[2024-11-19 21:58:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 55
train_sample_count: 55
avg_envstep_per_episode: 55.0
avg_sample_per_episode: 55.0
avg_envstep_per_sec: 880.4609804900065
avg_train_sample_per_sec: 880.4609804900065
avg_episode_per_sec: 16.00838146345466
collect_time: 0.06246727705001831
reward_mean: 197.0
reward_std: 0.0
reward_max: 197.0
reward_min: 197.0
total_envstep_count: 36792
total_train_sample_count: 36758
total_episode_count: 107
total_duration: 61.5738772366728
[2024-11-19 21:58:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 687
train_sample_count: 687
avg_envstep_per_episode: 229.0
avg_sample_per_episode: 229.0
avg_envstep_per_sec: 869.682982484483
avg_train_sample_per_sec: 869.682982484483
avg_episode_per_sec: 3.7977422815916286
collect_time: 0.7899430181298938
reward_mean: 680.0
reward_std: 73.57988739013672
reward_max: 784.0
reward_min: 625.0
total_envstep_count: 37781
total_train_sample_count: 37733
total_episode_count: 110
total_duration: 62.3638202548027
[2024-11-19 21:58:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 93
train_sample_count: 93
avg_envstep_per_episode: 93.0
avg_sample_per_episode: 93.0
avg_envstep_per_sec: 876.9706648749284
avg_train_sample_per_sec: 876.9706648749284
avg_episode_per_sec: 9.429792095429338
collect_time: 0.10604687673704964
reward_mean: 600.0
reward_std: 0.0
reward_max: 600.0
reward_min: 600.0
total_envstep_count: 38756
total_train_sample_count: 38714
total_episode_count: 111
total_duration: 62.46986713153974
[2024-11-19 21:59:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1181
train_sample_count: 1181
avg_envstep_per_episode: 590.5
avg_sample_per_episode: 590.5
avg_envstep_per_sec: 885.6919747586438
avg_train_sample_per_sec: 885.6919747586438
avg_episode_per_sec: 1.4999017354083721
collect_time: 1.33342068535941
reward_mean: 802.0
reward_std: 132.0
reward_max: 934.0
reward_min: 670.0
total_envstep_count: 39723
total_train_sample_count: 39691
total_episode_count: 113
total_duration: 63.80328781689915
[2024-11-19 21:59:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 442
train_sample_count: 442
avg_envstep_per_episode: 442.0
avg_sample_per_episode: 442.0
avg_envstep_per_sec: 895.8084413886411
avg_train_sample_per_sec: 895.8084413886411
avg_episode_per_sec: 2.026715930743532
collect_time: 0.49340905887740005
reward_mean: 1289.0
reward_std: 0.0
reward_max: 1289.0
reward_min: 1289.0
total_envstep_count: 40690
total_train_sample_count: 40661
total_episode_count: 114
total_duration: 64.29669687577655
[2024-11-19 21:59:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 215
train_sample_count: 215
avg_envstep_per_episode: 107.5
avg_sample_per_episode: 107.5
avg_envstep_per_sec: 861.0878078370973
avg_train_sample_per_sec: 861.0878078370973
avg_episode_per_sec: 8.010119142670673
collect_time: 0.24968417627470835
reward_mean: 425.0
reward_std: 187.0
reward_max: 612.0
reward_min: 238.0
total_envstep_count: 41664
total_train_sample_count: 41632
total_episode_count: 116
total_duration: 64.54638105205126
[2024-11-19 21:59:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 3571
train_sample_count: 3571
avg_envstep_per_episode: 595.1666666666666
avg_sample_per_episode: 595.1666666666666
avg_envstep_per_sec: 874.6970410173789
avg_train_sample_per_sec: 874.6970410173789
avg_episode_per_sec: 1.469667388995876
collect_time: 4.082556396722794
reward_mean: 644.6666870117188
reward_std: 551.9434204101562
reward_max: 1769.0
reward_min: 200.0
total_envstep_count: 42650
total_train_sample_count: 42611
total_episode_count: 122
total_duration: 68.62893744877405
[2024-11-19 21:59:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 453
train_sample_count: 453
avg_envstep_per_episode: 113.25
avg_sample_per_episode: 113.25
avg_envstep_per_sec: 872.0971984209139
avg_train_sample_per_sec: 872.0971984209139
avg_episode_per_sec: 7.700637513650453
collect_time: 0.5194375131811415
reward_mean: 505.5
reward_std: 153.37127685546875
reward_max: 636.0
reward_min: 244.0
total_envstep_count: 43638
total_train_sample_count: 43604
total_episode_count: 126
total_duration: 69.1483749619552
[2024-11-19 21:59:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 195
train_sample_count: 195
avg_envstep_per_episode: 97.5
avg_sample_per_episode: 97.5
avg_envstep_per_sec: 873.2010963543171
avg_train_sample_per_sec: 873.2010963543171
avg_episode_per_sec: 8.955908680557098
collect_time: 0.22331625648907252
reward_mean: 436.5
reward_std: 199.5
reward_max: 636.0
reward_min: 237.0
total_envstep_count: 44620
total_train_sample_count: 44579
total_episode_count: 128
total_duration: 69.37169121844427
[2024-11-19 21:59:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 936
train_sample_count: 936
avg_envstep_per_episode: 468.0
avg_sample_per_episode: 468.0
avg_envstep_per_sec: 878.8447872262818
avg_train_sample_per_sec: 878.8447872262818
avg_episode_per_sec: 1.8778734769792347
collect_time: 1.0650344789028168
reward_mean: 445.5
reward_std: 219.5
reward_max: 665.0
reward_min: 226.0
total_envstep_count: 45586
total_train_sample_count: 45551
total_episode_count: 130
total_duration: 70.43672569734709
[2024-11-19 21:59:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 254
train_sample_count: 254
avg_envstep_per_episode: 127.0
avg_sample_per_episode: 127.0
avg_envstep_per_sec: 886.884669588977
avg_train_sample_per_sec: 886.884669588977
avg_episode_per_sec: 6.983343855031315
collect_time: 0.28639574987547733
reward_mean: 511.5
reward_std: 290.5
reward_max: 802.0
reward_min: 221.0
total_envstep_count: 46552
total_train_sample_count: 46513
total_episode_count: 132
total_duration: 70.72312144722257
[2024-11-19 21:59:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1164
train_sample_count: 1164
avg_envstep_per_episode: 1164.0
avg_sample_per_episode: 1164.0
avg_envstep_per_sec: 874.1875302730522
avg_train_sample_per_sec: 874.1875302730522
avg_episode_per_sec: 0.7510202150112132
collect_time: 1.331522081579481
reward_mean: 845.0
reward_std: 0.0
reward_max: 845.0
reward_min: 845.0
total_envstep_count: 47511
total_train_sample_count: 47473
total_episode_count: 133
total_duration: 72.05464352880205
[2024-11-19 21:59:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1414
train_sample_count: 1414
avg_envstep_per_episode: 282.8
avg_sample_per_episode: 282.8
avg_envstep_per_sec: 886.0765382340352
avg_train_sample_per_sec: 886.0765382340352
avg_episode_per_sec: 3.133226797150054
collect_time: 1.5957989394664762
reward_mean: 617.7999877929688
reward_std: 371.8652648925781
reward_max: 1245.0
reward_min: 233.0
total_envstep_count: 48516
total_train_sample_count: 48467
total_episode_count: 138
total_duration: 73.65044246826852
[2024-11-19 21:59:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 51
train_sample_count: 51
avg_envstep_per_episode: 51.0
avg_sample_per_episode: 51.0
avg_envstep_per_sec: 829.7503388391506
avg_train_sample_per_sec: 829.7503388391506
avg_episode_per_sec: 16.26961448704217
collect_time: 0.06146427137511117
reward_mean: 209.0
reward_std: 0.0
reward_max: 209.0
reward_min: 209.0
total_envstep_count: 49475
total_train_sample_count: 49430
total_episode_count: 139
total_duration: 73.71190673964364
[2024-11-19 21:59:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 3661
train_sample_count: 3661
avg_envstep_per_episode: 732.2
avg_sample_per_episode: 732.2
avg_envstep_per_sec: 874.1208923944035
avg_train_sample_per_sec: 874.1208923944035
avg_episode_per_sec: 1.1938280420573661
collect_time: 4.188207869018827
reward_mean: 747.2000122070312
reward_std: 327.92401123046875
reward_max: 1198.0
reward_min: 239.0
total_envstep_count: 50454
total_train_sample_count: 50415
total_episode_count: 144
total_duration: 77.90011460866246
[2024-11-19 21:59:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 191
train_sample_count: 191
avg_envstep_per_episode: 191.0
avg_sample_per_episode: 191.0
avg_envstep_per_sec: 886.4022066699391
avg_train_sample_per_sec: 886.4022066699391
avg_episode_per_sec: 4.640849249580833
collect_time: 0.21547780292374746
reward_mean: 762.0
reward_std: 0.0
reward_max: 762.0
reward_min: 762.0
total_envstep_count: 51437
total_train_sample_count: 51386
total_episode_count: 145
total_duration: 78.1155924115862
[2024-11-19 21:59:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 890
train_sample_count: 890
avg_envstep_per_episode: 445.0
avg_sample_per_episode: 445.0
avg_envstep_per_sec: 876.9043964052762
avg_train_sample_per_sec: 876.9043964052762
avg_episode_per_sec: 1.9705716773152275
collect_time: 1.0149339011737277
reward_mean: 851.0
reward_std: 76.0
reward_max: 927.0
reward_min: 775.0
total_envstep_count: 52395
total_train_sample_count: 52360
total_episode_count: 147
total_duration: 79.13052631275994
[2024-11-19 21:59:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 534
train_sample_count: 534
avg_envstep_per_episode: 267.0
avg_sample_per_episode: 267.0
avg_envstep_per_sec: 887.5213293877395
avg_train_sample_per_sec: 887.5213293877395
avg_episode_per_sec: 3.3240499228005222
collect_time: 0.6016756807054793
reward_mean: 800.5
reward_std: 177.5
reward_max: 978.0
reward_min: 623.0
total_envstep_count: 53393
total_train_sample_count: 53350
total_episode_count: 149
total_duration: 79.73220199346542
[2024-11-19 21:59:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 36
train_sample_count: 36
avg_envstep_per_episode: 36.0
avg_sample_per_episode: 36.0
avg_envstep_per_sec: 884.7465841266168
avg_train_sample_per_sec: 884.7465841266168
avg_episode_per_sec: 24.57629400351713
collect_time: 0.040689617395401
reward_mean: 242.0
reward_std: 0.0
reward_max: 242.0
reward_min: 242.0
total_envstep_count: 54353
total_train_sample_count: 54310
total_episode_count: 150
total_duration: 79.77289161086082
[2024-11-19 21:59:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 2523
train_sample_count: 2523
avg_envstep_per_episode: 630.75
avg_sample_per_episode: 630.75
avg_envstep_per_sec: 880.5906697832984
avg_train_sample_per_sec: 880.5906697832984
avg_episode_per_sec: 1.3961009429778808
collect_time: 2.865122339555195
reward_mean: 652.5
reward_std: 257.8812561035156
reward_max: 907.0
reward_min: 223.0
total_envstep_count: 55341
total_train_sample_count: 55297
total_episode_count: 154
total_duration: 82.63801395041602
[2024-11-19 21:59:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2444
train_sample_count: 2444
avg_envstep_per_episode: 814.6666666666666
avg_sample_per_episode: 814.6666666666666
avg_envstep_per_sec: 883.3421651860949
avg_train_sample_per_sec: 883.3421651860949
avg_episode_per_sec: 1.0842988934362867
collect_time: 2.7667647898197174
reward_mean: 1296.3333740234375
reward_std: 305.6951904296875
reward_max: 1707.0
reward_min: 974.0
total_envstep_count: 56322
total_train_sample_count: 56277
total_episode_count: 157
total_duration: 85.40477874023574
[2024-11-19 22:00:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 350
train_sample_count: 350
avg_envstep_per_episode: 175.0
avg_sample_per_episode: 175.0
avg_envstep_per_sec: 854.9329194963552
avg_train_sample_per_sec: 854.9329194963552
avg_episode_per_sec: 4.885330968550601
collect_time: 0.40938884445599144
reward_mean: 606.0
reward_std: 20.0
reward_max: 626.0
reward_min: 586.0
total_envstep_count: 57304
total_train_sample_count: 57251
total_episode_count: 159
total_duration: 85.81416758469173
[2024-11-19 22:00:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 761
train_sample_count: 761
avg_envstep_per_episode: 190.25
avg_sample_per_episode: 190.25
avg_envstep_per_sec: 878.4405535444937
avg_train_sample_per_sec: 878.4405535444937
avg_episode_per_sec: 4.617295945043331
collect_time: 0.8663079099995749
reward_mean: 760.5
reward_std: 414.739990234375
reward_max: 1393.0
reward_min: 242.0
total_envstep_count: 58277
total_train_sample_count: 58240
total_episode_count: 163
total_duration: 86.68047549469131
[2024-11-19 22:00:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1194
train_sample_count: 1194
avg_envstep_per_episode: 238.8
avg_sample_per_episode: 238.8
avg_envstep_per_sec: 880.5957107612511
avg_train_sample_per_sec: 880.5957107612511
avg_episode_per_sec: 3.687586728480951
collect_time: 1.3559003131730216
reward_mean: 555.7999877929688
reward_std: 157.48828125
reward_max: 686.0
reward_min: 246.0
total_envstep_count: 59281
total_train_sample_count: 59242
total_episode_count: 168
total_duration: 88.03637580786433
[2024-11-19 22:00:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1109
train_sample_count: 1109
avg_envstep_per_episode: 1109.0
avg_sample_per_episode: 1109.0
avg_envstep_per_sec: 878.142001750903
avg_train_sample_per_sec: 878.142001750903
avg_episode_per_sec: 0.7918322829133481
collect_time: 1.262893698045186
reward_mean: 1135.0
reward_std: 0.0
reward_max: 1135.0
reward_min: 1135.0
total_envstep_count: 60241
total_train_sample_count: 60207
total_episode_count: 169
total_duration: 89.29926950590952
[2024-11-19 22:00:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 592
train_sample_count: 592
avg_envstep_per_episode: 296.0
avg_sample_per_episode: 296.0
avg_envstep_per_sec: 858.7761802054888
avg_train_sample_per_sec: 858.7761802054888
avg_episode_per_sec: 2.901270879072597
collect_time: 0.6893530743462699
reward_mean: 898.5
reward_std: 124.5
reward_max: 1023.0
reward_min: 774.0
total_envstep_count: 61231
total_train_sample_count: 61183
total_episode_count: 171
total_duration: 89.9886225802558
[2024-11-19 22:00:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1780
train_sample_count: 1780
avg_envstep_per_episode: 593.3333333333334
avg_sample_per_episode: 593.3333333333334
avg_envstep_per_sec: 875.8019817399423
avg_train_sample_per_sec: 875.8019817399423
avg_episode_per_sec: 1.4760707557414758
collect_time: 2.0324228959424153
reward_mean: 692.3333129882812
reward_std: 155.10498046875
reward_max: 911.0
reward_min: 568.0
total_envstep_count: 62212
total_train_sample_count: 62183
total_episode_count: 174
total_duration: 92.02104547619821
[2024-11-19 22:00:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1423
train_sample_count: 1423
avg_envstep_per_episode: 355.75
avg_sample_per_episode: 355.75
avg_envstep_per_sec: 861.8111728485967
avg_train_sample_per_sec: 861.8111728485967
avg_episode_per_sec: 2.4225191084992175
collect_time: 1.6511737661702295
reward_mean: 971.0
reward_std: 326.3334045410156
reward_max: 1317.0
reward_min: 610.0
total_envstep_count: 63209
total_train_sample_count: 63174
total_episode_count: 178
total_duration: 93.67221924236844
[2024-11-19 22:00:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 339
train_sample_count: 339
avg_envstep_per_episode: 339.0
avg_sample_per_episode: 339.0
avg_envstep_per_sec: 869.568381647246
avg_train_sample_per_sec: 869.568381647246
avg_episode_per_sec: 2.565098470935829
collect_time: 0.3898485813822065
reward_mean: 730.0
reward_std: 0.0
reward_max: 730.0
reward_min: 730.0
total_envstep_count: 64168
total_train_sample_count: 64137
total_episode_count: 179
total_duration: 94.06206782375065
[2024-11-19 22:00:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 652
train_sample_count: 652
avg_envstep_per_episode: 652.0
avg_sample_per_episode: 652.0
avg_envstep_per_sec: 864.1318815207413
avg_train_sample_per_sec: 864.1318815207413
avg_episode_per_sec: 1.3253556465042045
collect_time: 0.7545144600527627
reward_mean: 642.0
reward_std: 0.0
reward_max: 642.0
reward_min: 642.0
total_envstep_count: 65135
total_train_sample_count: 65101
total_episode_count: 180
total_duration: 94.81658228380341
[2024-11-19 22:00:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1025
train_sample_count: 1025
avg_envstep_per_episode: 341.6666666666667
avg_sample_per_episode: 341.6666666666667
avg_envstep_per_sec: 867.2086387251369
avg_train_sample_per_sec: 867.2086387251369
avg_episode_per_sec: 2.538171625536986
collect_time: 1.181953170469829
reward_mean: 683.3333129882812
reward_std: 44.813194274902344
reward_max: 743.0
reward_min: 635.0
total_envstep_count: 66108
total_train_sample_count: 66078
total_episode_count: 183
total_duration: 95.99853545427324
[2024-11-19 22:00:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1041
train_sample_count: 1041
avg_envstep_per_episode: 148.71428571428572
avg_sample_per_episode: 148.71428571428572
avg_envstep_per_sec: 868.0102013706779
avg_train_sample_per_sec: 868.0102013706779
avg_episode_per_sec: 5.836764082223579
collect_time: 1.199294660772596
reward_mean: 486.5714416503906
reward_std: 416.12701416015625
reward_max: 1274.0
reward_min: 211.0
total_envstep_count: 67095
total_train_sample_count: 67059
total_episode_count: 190
total_duration: 97.19783011504583
[2024-11-19 22:00:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1488
train_sample_count: 1488
avg_envstep_per_episode: 372.0
avg_sample_per_episode: 372.0
avg_envstep_per_sec: 866.999234777336
avg_train_sample_per_sec: 866.999234777336
avg_episode_per_sec: 2.3306431042401505
collect_time: 1.7162644905703408
reward_mean: 677.5
reward_std: 294.8851623535156
reward_max: 951.0
reward_min: 222.0
total_envstep_count: 68099
total_train_sample_count: 68055
total_episode_count: 194
total_duration: 98.91409460561617
[2024-11-19 22:00:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 448
train_sample_count: 448
avg_envstep_per_episode: 448.0
avg_sample_per_episode: 448.0
avg_envstep_per_sec: 864.2031935128933
avg_train_sample_per_sec: 864.2031935128933
avg_episode_per_sec: 1.9290249855198514
collect_time: 0.5183966032096318
reward_mean: 982.0
reward_std: 0.0
reward_max: 982.0
reward_min: 982.0
total_envstep_count: 69058
total_train_sample_count: 69019
total_episode_count: 195
total_duration: 99.43249120882581
[2024-11-19 22:00:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1762
train_sample_count: 1762
avg_envstep_per_episode: 440.5
avg_sample_per_episode: 440.5
avg_envstep_per_sec: 868.2425167509233
avg_train_sample_per_sec: 868.2425167509233
avg_episode_per_sec: 1.9710386305355805
collect_time: 2.0293869120734076
reward_mean: 983.25
reward_std: 265.8706359863281
reward_max: 1306.0
reward_min: 689.0
total_envstep_count: 70015
total_train_sample_count: 69989
total_episode_count: 199
total_duration: 101.46187812089921
[2024-11-19 22:00:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1387
train_sample_count: 1387
avg_envstep_per_episode: 173.375
avg_sample_per_episode: 173.375
avg_envstep_per_sec: 867.1064394937798
avg_train_sample_per_sec: 867.1064394937798
avg_episode_per_sec: 5.001334906957634
collect_time: 1.5995729437896185
reward_mean: 570.875
reward_std: 319.87396240234375
reward_max: 1233.0
reward_min: 231.0
total_envstep_count: 71040
total_train_sample_count: 71004
total_episode_count: 207
total_duration: 103.06145106468884
[2024-11-19 22:00:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 923
train_sample_count: 923
avg_envstep_per_episode: 184.6
avg_sample_per_episode: 184.6
avg_envstep_per_sec: 865.9628262422137
avg_train_sample_per_sec: 865.9628262422137
avg_episode_per_sec: 4.6910228940531615
collect_time: 1.0658656145845142
reward_mean: 662.7999877929688
reward_std: 321.3673400878906
reward_max: 1243.0
reward_min: 250.0
total_envstep_count: 72020
total_train_sample_count: 71987
total_episode_count: 212
total_duration: 104.12731667927335
[2024-11-19 22:00:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 703
train_sample_count: 703
avg_envstep_per_episode: 140.6
avg_sample_per_episode: 140.6
avg_envstep_per_sec: 856.9189965378516
avg_train_sample_per_sec: 856.9189965378516
avg_episode_per_sec: 6.09472970510563
collect_time: 0.8203809261322021
reward_mean: 571.7999877929688
reward_std: 307.54473876953125
reward_max: 1010.0
reward_min: 228.0
total_envstep_count: 73032
total_train_sample_count: 72990
total_episode_count: 217
total_duration: 104.94769760540555
[2024-11-19 22:00:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1250
train_sample_count: 1250
avg_envstep_per_episode: 250.0
avg_sample_per_episode: 250.0
avg_envstep_per_sec: 862.0633381951225
avg_train_sample_per_sec: 862.0633381951225
avg_episode_per_sec: 3.44825335278049
collect_time: 1.45000946521759
reward_mean: 434.3999938964844
reward_std: 241.81529235839844
reward_max: 734.0
reward_min: 232.0
total_envstep_count: 74052
total_train_sample_count: 74012
total_episode_count: 222
total_duration: 106.39770707062314
[2024-11-19 22:00:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 926
train_sample_count: 926
avg_envstep_per_episode: 154.33333333333334
avg_sample_per_episode: 154.33333333333334
avg_envstep_per_sec: 860.8117315552339
avg_train_sample_per_sec: 860.8117315552339
avg_episode_per_sec: 5.5776138113730065
collect_time: 1.0757288336753845
reward_mean: 600.8333129882812
reward_std: 178.75347900390625
reward_max: 767.0
reward_min: 221.0
total_envstep_count: 75007
total_train_sample_count: 74986
total_episode_count: 228
total_duration: 107.47343590429853
[2024-11-19 22:01:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1184
train_sample_count: 1184
avg_envstep_per_episode: 169.14285714285714
avg_sample_per_episode: 169.14285714285714
avg_envstep_per_sec: 856.0544201125755
avg_train_sample_per_sec: 856.0544201125755
avg_episode_per_sec: 5.06113255134124
collect_time: 1.3830896403108321
reward_mean: 479.28570556640625
reward_std: 218.893798828125
reward_max: 805.0
reward_min: 225.0
total_envstep_count: 76017
total_train_sample_count: 75978
total_episode_count: 235
total_duration: 108.85652554460935
[2024-11-19 22:01:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1543
train_sample_count: 1543
avg_envstep_per_episode: 220.42857142857142
avg_sample_per_episode: 220.42857142857142
avg_envstep_per_sec: 856.4909011704262
avg_train_sample_per_sec: 856.4909011704262
avg_episode_per_sec: 3.885571165387546
collect_time: 1.8015369432313104
reward_mean: 731.0
reward_std: 449.2072448730469
reward_max: 1633.0
reward_min: 226.0
total_envstep_count: 76988
total_train_sample_count: 76957
total_episode_count: 242
total_duration: 110.65806248784067
[2024-11-19 22:01:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 154
train_sample_count: 154
avg_envstep_per_episode: 77.0
avg_sample_per_episode: 77.0
avg_envstep_per_sec: 852.456633215482
avg_train_sample_per_sec: 852.456633215482
avg_episode_per_sec: 11.070865366434832
collect_time: 0.18065435120037623
reward_mean: 653.5
reward_std: 403.5
reward_max: 1057.0
reward_min: 250.0
total_envstep_count: 77962
total_train_sample_count: 77927
total_episode_count: 244
total_duration: 110.83871683904104
[2024-11-19 22:01:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 502
train_sample_count: 502
avg_envstep_per_episode: 251.0
avg_sample_per_episode: 251.0
avg_envstep_per_sec: 840.6259710059359
avg_train_sample_per_sec: 840.6259710059359
avg_episode_per_sec: 3.3491074542069157
collect_time: 0.5971740313938686
reward_mean: 822.0
reward_std: 188.0
reward_max: 1010.0
reward_min: 634.0
total_envstep_count: 78928
total_train_sample_count: 78897
total_episode_count: 246
total_duration: 111.4358908704349
[2024-11-19 22:01:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1720
train_sample_count: 1720
avg_envstep_per_episode: 286.6666666666667
avg_sample_per_episode: 286.6666666666667
avg_envstep_per_sec: 858.1171574851194
avg_train_sample_per_sec: 858.1171574851194
avg_episode_per_sec: 2.9934319447155326
collect_time: 2.00438831107957
reward_mean: 784.8333129882812
reward_std: 344.24090576171875
reward_max: 1268.0
reward_min: 212.0
total_envstep_count: 79954
total_train_sample_count: 79921
total_episode_count: 252
total_duration: 113.44027918151447
[2024-11-19 22:01:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 189
train_sample_count: 189
avg_envstep_per_episode: 94.5
avg_sample_per_episode: 94.5
avg_envstep_per_sec: 846.6800631752734
avg_train_sample_per_sec: 846.6800631752734
avg_episode_per_sec: 8.95957738809813
collect_time: 0.2232248144490378
reward_mean: 407.5
reward_std: 171.5
reward_max: 579.0
reward_min: 236.0
total_envstep_count: 80936
total_train_sample_count: 80902
total_episode_count: 254
total_duration: 113.66350399596351
[2024-11-19 22:01:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1666
train_sample_count: 1666
avg_envstep_per_episode: 208.25
avg_sample_per_episode: 208.25
avg_envstep_per_sec: 848.5993599454824
avg_train_sample_per_sec: 848.5993599454824
avg_episode_per_sec: 4.074906890494514
collect_time: 1.9632350419248852
reward_mean: 709.875
reward_std: 508.3852844238281
reward_max: 1837.0
reward_min: 225.0
total_envstep_count: 81921
total_train_sample_count: 81896
total_episode_count: 262
total_duration: 115.6267390378884
[2024-11-19 22:01:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 746
train_sample_count: 746
avg_envstep_per_episode: 373.0
avg_sample_per_episode: 373.0
avg_envstep_per_sec: 852.586532960456
avg_train_sample_per_sec: 852.586532960456
avg_episode_per_sec: 2.285754780054842
collect_time: 0.874984498534884
reward_mean: 729.5
reward_std: 491.5
reward_max: 1221.0
reward_min: 238.0
total_envstep_count: 82911
total_train_sample_count: 82870
total_episode_count: 264
total_duration: 116.50172353642328
[2024-11-19 22:01:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 943
train_sample_count: 943
avg_envstep_per_episode: 157.16666666666666
avg_sample_per_episode: 157.16666666666666
avg_envstep_per_sec: 853.4709464699122
avg_train_sample_per_sec: 853.4709464699122
avg_episode_per_sec: 5.430355969055645
collect_time: 1.1048999428749084
reward_mean: 511.1666564941406
reward_std: 198.1055450439453
reward_max: 768.0
reward_min: 240.0
total_envstep_count: 83897
total_train_sample_count: 83849
total_episode_count: 270
total_duration: 117.6066234792982
[2024-11-19 22:01:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1292
train_sample_count: 1292
avg_envstep_per_episode: 215.33333333333334
avg_sample_per_episode: 215.33333333333334
avg_envstep_per_sec: 848.7595521244571
avg_train_sample_per_sec: 848.7595521244571
avg_episode_per_sec: 3.941607827203361
collect_time: 1.5222214545522414
reward_mean: 522.8333129882812
reward_std: 305.5669250488281
reward_max: 1035.0
reward_min: 239.0
total_envstep_count: 84860
total_train_sample_count: 84829
total_episode_count: 276
total_duration: 119.12884493385043
[2024-11-19 22:01:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 656
train_sample_count: 656
avg_envstep_per_episode: 164.0
avg_sample_per_episode: 164.0
avg_envstep_per_sec: 846.7039670941421
avg_train_sample_per_sec: 846.7039670941421
avg_episode_per_sec: 5.162829067647207
collect_time: 0.7747690166745866
reward_mean: 345.0
reward_std: 216.20013427734375
reward_max: 719.0
reward_min: 211.0
total_envstep_count: 85832
total_train_sample_count: 85797
total_episode_count: 280
total_duration: 119.90361395052501
[2024-11-19 22:01:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 519
train_sample_count: 519
avg_envstep_per_episode: 259.5
avg_sample_per_episode: 259.5
avg_envstep_per_sec: 845.970280212027
avg_train_sample_per_sec: 845.970280212027
avg_episode_per_sec: 3.2600010798151327
collect_time: 0.6134967293058122
reward_mean: 872.0
reward_std: 150.0
reward_max: 1022.0
reward_min: 722.0
total_envstep_count: 86799
total_train_sample_count: 86772
total_episode_count: 282
total_duration: 120.51711067983082
[2024-11-19 22:01:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1859
train_sample_count: 1859
avg_envstep_per_episode: 265.57142857142856
avg_sample_per_episode: 265.57142857142856
avg_envstep_per_sec: 847.4337124266951
avg_train_sample_per_sec: 847.4337124266951
avg_episode_per_sec: 3.190982241520638
collect_time: 2.1936819042478293
reward_mean: 652.7142944335938
reward_std: 435.1527404785156
reward_max: 1325.0
reward_min: 218.0
total_envstep_count: 87803
total_train_sample_count: 87767
total_episode_count: 289
total_duration: 122.71079258407865
[2024-11-19 22:01:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 132
train_sample_count: 132
avg_envstep_per_episode: 44.0
avg_sample_per_episode: 44.0
avg_envstep_per_sec: 853.3709460346001
avg_train_sample_per_sec: 853.3709460346001
avg_episode_per_sec: 19.394794228059094
collect_time: 0.15468068208013264
reward_mean: 234.6666717529297
reward_std: 6.018489837646484
reward_max: 243.0
reward_min: 229.0
total_envstep_count: 88776
total_train_sample_count: 88739
total_episode_count: 292
total_duration: 122.86547326615877
[2024-11-19 22:01:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2016
train_sample_count: 2016
avg_envstep_per_episode: 336.0
avg_sample_per_episode: 336.0
avg_envstep_per_sec: 845.3890491536703
avg_train_sample_per_sec: 845.3890491536703
avg_episode_per_sec: 2.516038836766876
collect_time: 2.384700868810926
reward_mean: 814.6666870117188
reward_std: 253.0037384033203
reward_max: 1331.0
reward_min: 616.0
total_envstep_count: 89826
total_train_sample_count: 89771
total_episode_count: 298
total_duration: 125.2501741349697
[2024-11-19 22:01:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 922
train_sample_count: 922
avg_envstep_per_episode: 307.3333333333333
avg_sample_per_episode: 307.3333333333333
avg_envstep_per_sec: 843.7340603378798
avg_train_sample_per_sec: 843.7340603378798
avg_episode_per_sec: 2.745338591121084
collect_time: 1.0927613845893314
reward_mean: 850.6666870117188
reward_std: 275.63421630859375
reward_max: 1232.0
reward_min: 590.0
total_envstep_count: 90784
total_train_sample_count: 90753
total_episode_count: 301
total_duration: 126.34293551955903
[2024-11-19 22:01:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1336
train_sample_count: 1336
avg_envstep_per_episode: 222.66666666666666
avg_sample_per_episode: 222.66666666666666
avg_envstep_per_sec: 842.5058065088781
avg_train_sample_per_sec: 842.5058065088781
avg_episode_per_sec: 3.7837087118662187
collect_time: 1.5857457476002828
reward_mean: 834.6666870117188
reward_std: 385.0829772949219
reward_max: 1339.0
reward_min: 246.0
total_envstep_count: 91740
total_train_sample_count: 91729
total_episode_count: 307
total_duration: 127.92868126715932
[2024-11-19 22:01:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 851
train_sample_count: 851
avg_envstep_per_episode: 121.57142857142857
avg_sample_per_episode: 121.57142857142857
avg_envstep_per_sec: 840.929883485899
avg_train_sample_per_sec: 840.929883485899
avg_episode_per_sec: 6.91716707920246
collect_time: 1.0119749775954654
reward_mean: 640.0
reward_std: 455.6094970703125
reward_max: 1308.0
reward_min: 193.0
total_envstep_count: 92789
total_train_sample_count: 92748
total_episode_count: 314
total_duration: 128.9406562447548
[2024-11-19 22:01:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 323
train_sample_count: 323
avg_envstep_per_episode: 107.66666666666667
avg_sample_per_episode: 107.66666666666667
avg_envstep_per_sec: 836.3981788957423
avg_train_sample_per_sec: 836.3981788957423
avg_episode_per_sec: 7.768404138350547
collect_time: 0.38617970262254986
reward_mean: 429.0
reward_std: 254.55975341796875
reward_max: 789.0
reward_min: 248.0
total_envstep_count: 93762
total_train_sample_count: 93731
total_episode_count: 317
total_duration: 129.32683594737733
[2024-11-19 22:02:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 707
train_sample_count: 707
avg_envstep_per_episode: 235.66666666666666
avg_sample_per_episode: 235.66666666666666
avg_envstep_per_sec: 846.519613076021
avg_train_sample_per_sec: 846.519613076021
avg_episode_per_sec: 3.592020989007161
collect_time: 0.8351844293730599
reward_mean: 917.0
reward_std: 316.6196594238281
reward_max: 1349.0
reward_min: 599.0
total_envstep_count: 94721
total_train_sample_count: 94702
total_episode_count: 320
total_duration: 130.1620203767504
[2024-11-19 22:02:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 795
train_sample_count: 795
avg_envstep_per_episode: 198.75
avg_sample_per_episode: 198.75
avg_envstep_per_sec: 839.973670777114
avg_train_sample_per_sec: 839.973670777114
avg_episode_per_sec: 4.226282620262209
collect_time: 0.9464582375117712
reward_mean: 699.0
reward_std: 474.2298889160156
reward_max: 1307.0
reward_min: 231.0
total_envstep_count: 95702
total_train_sample_count: 95677
total_episode_count: 324
total_duration: 131.10847861426217
[2024-11-19 22:02:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1197
train_sample_count: 1197
avg_envstep_per_episode: 399.0
avg_sample_per_episode: 399.0
avg_envstep_per_sec: 827.4148184808225
avg_train_sample_per_sec: 827.4148184808225
avg_episode_per_sec: 2.0737213495759965
collect_time: 1.4466745981148312
reward_mean: 907.3333129882812
reward_std: 280.38702392578125
reward_max: 1290.0
reward_min: 626.0
total_envstep_count: 96708
total_train_sample_count: 96646
total_episode_count: 327
total_duration: 132.555153212377
[2024-11-19 22:02:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 821
train_sample_count: 821
avg_envstep_per_episode: 821.0
avg_sample_per_episode: 821.0
avg_envstep_per_sec: 839.4673615461118
avg_train_sample_per_sec: 839.4673615461118
avg_episode_per_sec: 1.022493741225471
collect_time: 0.9780010964189256
reward_mean: 918.0
reward_std: 0.0
reward_max: 918.0
reward_min: 918.0
total_envstep_count: 97667
total_train_sample_count: 97611
total_episode_count: 328
total_duration: 133.53315430879593
[2024-11-19 22:02:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1274
train_sample_count: 1274
avg_envstep_per_episode: 254.8
avg_sample_per_episode: 254.8
avg_envstep_per_sec: 827.0655039493581
avg_train_sample_per_sec: 827.0655039493581
avg_episode_per_sec: 3.245939968404074
collect_time: 1.5403858508382524
reward_mean: 1017.7999877929688
reward_std: 827.148193359375
reward_max: 2598.0
reward_min: 235.0
total_envstep_count: 98622
total_train_sample_count: 98585
total_episode_count: 333
total_duration: 135.07354015963418
[2024-11-19 22:02:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1106
train_sample_count: 1106
avg_envstep_per_episode: 122.88888888888889
avg_sample_per_episode: 122.88888888888889
avg_envstep_per_sec: 824.3813251958422
avg_train_sample_per_sec: 824.3813251958422
avg_episode_per_sec: 6.708347130888408
collect_time: 1.341612147433417
reward_mean: 467.5555419921875
reward_std: 372.62493896484375
reward_max: 1361.0
reward_min: 230.0
total_envstep_count: 99623
total_train_sample_count: 99571
total_episode_count: 342
total_duration: 136.4151523070676
[2024-11-19 22:02:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 186
train_sample_count: 186
avg_envstep_per_episode: 62.0
avg_sample_per_episode: 62.0
avg_envstep_per_sec: 837.9013482545477
avg_train_sample_per_sec: 837.9013482545477
avg_episode_per_sec: 13.51453787507335
collect_time: 0.22198317306382315
reward_mean: 353.3333435058594
reward_std: 173.00738525390625
reward_max: 598.0
reward_min: 230.0
total_envstep_count: 100612
total_train_sample_count: 100573
total_episode_count: 345
total_duration: 136.6371354801314
[2024-11-19 22:02:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1102
train_sample_count: 1102
avg_envstep_per_episode: 220.4
avg_sample_per_episode: 220.4
avg_envstep_per_sec: 820.3799158432515
avg_train_sample_per_sec: 820.3799158432515
avg_episode_per_sec: 3.7222319230637546
collect_time: 1.3432800812380652
reward_mean: 501.3999938964844
reward_std: 394.1971740722656
reward_max: 1231.0
reward_min: 213.0
total_envstep_count: 101591
total_train_sample_count: 101567
total_episode_count: 350
total_duration: 137.98041556136948
[2024-11-19 22:02:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 520
train_sample_count: 520
avg_envstep_per_episode: 130.0
avg_sample_per_episode: 130.0
avg_envstep_per_sec: 824.1897247625793
avg_train_sample_per_sec: 824.1897247625793
avg_episode_per_sec: 6.339920959712148
collect_time: 0.63092269216265
reward_mean: 494.0
reward_std: 467.73443603515625
reward_max: 1304.0
reward_min: 210.0
total_envstep_count: 102595
total_train_sample_count: 102543
total_episode_count: 354
total_duration: 138.61133825353213
[2024-11-19 22:02:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2385
train_sample_count: 2385
avg_envstep_per_episode: 340.7142857142857
avg_sample_per_episode: 340.7142857142857
avg_envstep_per_sec: 824.9094054189178
avg_train_sample_per_sec: 824.9094054189178
avg_episode_per_sec: 2.4211177517536373
collect_time: 2.891226581164769
reward_mean: 619.5714111328125
reward_std: 292.77093505859375
reward_max: 1144.0
reward_min: 229.0
total_envstep_count: 103580
total_train_sample_count: 103548
total_episode_count: 361
total_duration: 141.5025648346969
[2024-11-19 22:02:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1720
train_sample_count: 1720
avg_envstep_per_episode: 143.33333333333334
avg_sample_per_episode: 143.33333333333334
avg_envstep_per_sec: 828.1274786111844
avg_train_sample_per_sec: 828.1274786111844
avg_episode_per_sec: 5.7776335717059375
collect_time: 2.076974915606635
reward_mean: 615.3333129882812
reward_std: 393.8172607421875
reward_max: 1298.0
reward_min: 216.0
total_envstep_count: 104600
total_train_sample_count: 104560
total_episode_count: 373
total_duration: 143.57953975030352
[2024-11-19 22:02:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 689
train_sample_count: 689
avg_envstep_per_episode: 114.83333333333333
avg_sample_per_episode: 114.83333333333333
avg_envstep_per_sec: 825.6644463648648
avg_train_sample_per_sec: 825.6644463648648
avg_episode_per_sec: 7.190111289098968
collect_time: 0.8344794341496059
reward_mean: 550.3333129882812
reward_std: 272.70721435546875
reward_max: 1005.0
reward_min: 189.0
total_envstep_count: 105587
total_train_sample_count: 105537
total_episode_count: 379
total_duration: 144.41401918445314
[2024-11-19 22:02:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 878
train_sample_count: 878
avg_envstep_per_episode: 146.33333333333334
avg_sample_per_episode: 146.33333333333334
avg_envstep_per_sec: 827.588956940265
avg_train_sample_per_sec: 827.588956940265
avg_episode_per_sec: 5.65550540050295
collect_time: 1.06091314128467
reward_mean: 600.3333129882812
reward_std: 289.2021484375
reward_max: 1017.0
reward_min: 218.0
total_envstep_count: 106557
total_train_sample_count: 106523
total_episode_count: 385
total_duration: 145.4749323257378
[2024-11-19 22:02:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 669
train_sample_count: 669
avg_envstep_per_episode: 111.5
avg_sample_per_episode: 111.5
avg_envstep_per_sec: 817.805980750364
avg_train_sample_per_sec: 817.805980750364
avg_episode_per_sec: 7.334582786998781
collect_time: 0.8180424400738306
reward_mean: 504.8333435058594
reward_std: 320.14080810546875
reward_max: 1114.0
reward_min: 226.0
total_envstep_count: 107559
total_train_sample_count: 107528
total_episode_count: 391
total_duration: 146.29297476581164
[2024-11-19 22:02:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1256
train_sample_count: 1256
avg_envstep_per_episode: 209.33333333333334
avg_sample_per_episode: 209.33333333333334
avg_envstep_per_sec: 823.4063032955937
avg_train_sample_per_sec: 823.4063032955937
avg_episode_per_sec: 3.933469601730543
collect_time: 1.5253708830901553
reward_mean: 747.8333129882812
reward_std: 344.711181640625
reward_max: 1295.0
reward_min: 247.0
total_envstep_count: 108561
total_train_sample_count: 108508
total_episode_count: 397
total_duration: 147.81834564890178
[2024-11-19 22:02:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1727
train_sample_count: 1727
avg_envstep_per_episode: 172.7
avg_sample_per_episode: 172.7
avg_envstep_per_sec: 731.9452635235353
avg_train_sample_per_sec: 731.9452635235353
avg_episode_per_sec: 4.2382470383528394
collect_time: 2.3594660503523692
reward_mean: 791.2000122070312
reward_std: 256.98980712890625
reward_max: 1403.0
reward_min: 598.0
total_envstep_count: 109544
total_train_sample_count: 109515
total_episode_count: 407
total_duration: 150.17781169925416
[2024-11-19 22:02:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 374
train_sample_count: 374
avg_envstep_per_episode: 53.42857142857143
avg_sample_per_episode: 53.42857142857143
avg_envstep_per_sec: 822.9139066988812
avg_train_sample_per_sec: 822.9139066988812
avg_episode_per_sec: 15.402131943561947
collect_time: 0.45448253694034757
reward_mean: 347.0
reward_std: 173.5511474609375
reward_max: 635.0
reward_min: 228.0
total_envstep_count: 110569
total_train_sample_count: 110537
total_episode_count: 414
total_duration: 150.63229423619453
[2024-11-19 22:02:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1249
train_sample_count: 1249
avg_envstep_per_episode: 156.125
avg_sample_per_episode: 156.125
avg_envstep_per_sec: 823.0834183769472
avg_train_sample_per_sec: 823.0834183769472
avg_episode_per_sec: 5.271951438763473
collect_time: 1.517464660462879
reward_mean: 685.375
reward_std: 342.61346435546875
reward_max: 1302.0
reward_min: 217.0
total_envstep_count: 111601
total_train_sample_count: 111558
total_episode_count: 422
total_duration: 152.1497588966574
[2024-11-19 22:03:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 466
train_sample_count: 466
avg_envstep_per_episode: 116.5
avg_sample_per_episode: 116.5
avg_envstep_per_sec: 793.697335191477
avg_train_sample_per_sec: 793.697335191477
avg_episode_per_sec: 6.812852662587786
collect_time: 0.5871255695819855
reward_mean: 616.5
reward_std: 294.5696105957031
reward_max: 1038.0
reward_min: 205.0
total_envstep_count: 112573
total_train_sample_count: 112528
total_episode_count: 426
total_duration: 152.7368844662394
[2024-11-19 22:03:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 947
train_sample_count: 947
avg_envstep_per_episode: 236.75
avg_sample_per_episode: 236.75
avg_envstep_per_sec: 810.4412691099707
avg_train_sample_per_sec: 810.4412691099707
avg_episode_per_sec: 3.4231943785004044
collect_time: 1.168499231338501
reward_mean: 770.5
reward_std: 370.073974609375
reward_max: 1280.0
reward_min: 234.0
total_envstep_count: 113593
total_train_sample_count: 113547
total_episode_count: 430
total_duration: 153.9053836975779
[2024-11-19 22:03:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 756
train_sample_count: 756
avg_envstep_per_episode: 252.0
avg_sample_per_episode: 252.0
avg_envstep_per_sec: 807.3296128984581
avg_train_sample_per_sec: 807.3296128984581
avg_episode_per_sec: 3.2036889400732464
collect_time: 0.9364205002784729
reward_mean: 811.3333129882812
reward_std: 221.9554443359375
reward_max: 1124.0
reward_min: 631.0
total_envstep_count: 114558
total_train_sample_count: 114531
total_episode_count: 433
total_duration: 154.84180419785636
[2024-11-19 22:03:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1102
train_sample_count: 1102
avg_envstep_per_episode: 367.3333333333333
avg_sample_per_episode: 367.3333333333333
avg_envstep_per_sec: 813.2940440449885
avg_train_sample_per_sec: 813.2940440449885
avg_episode_per_sec: 2.2140491217195692
collect_time: 1.3549834872995103
reward_mean: 1095.6666259765625
reward_std: 294.6289367675781
reward_max: 1495.0
reward_min: 793.0
total_envstep_count: 115548
total_train_sample_count: 115501
total_episode_count: 436
total_duration: 156.19678768515587
[2024-11-19 22:03:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1043
train_sample_count: 1043
avg_envstep_per_episode: 208.6
avg_sample_per_episode: 208.6
avg_envstep_per_sec: 810.0504557323732
avg_train_sample_per_sec: 810.0504557323732
avg_episode_per_sec: 3.8832715998675607
collect_time: 1.2875741166727883
reward_mean: 783.0
reward_std: 370.24749755859375
reward_max: 1313.0
reward_min: 215.0
total_envstep_count: 116512
total_train_sample_count: 116472
total_episode_count: 441
total_duration: 157.48436180182867
[2024-11-19 22:03:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 910
train_sample_count: 910
avg_envstep_per_episode: 227.5
avg_sample_per_episode: 227.5
avg_envstep_per_sec: 802.9010609499894
avg_train_sample_per_sec: 802.9010609499894
avg_episode_per_sec: 3.529235432747206
collect_time: 1.1333899583135332
reward_mean: 805.25
reward_std: 254.3170928955078
reward_max: 1240.0
reward_min: 623.0
total_envstep_count: 117493
total_train_sample_count: 117454
total_episode_count: 445
total_duration: 158.6177517601422
[2024-11-19 22:03:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1142
train_sample_count: 1142
avg_envstep_per_episode: 380.6666666666667
avg_sample_per_episode: 380.6666666666667
avg_envstep_per_sec: 813.3506234000188
avg_train_sample_per_sec: 813.3506234000188
avg_episode_per_sec: 2.1366478723292963
collect_time: 1.404068512575967
reward_mean: 810.0
reward_std: 133.02630615234375
reward_max: 982.0
reward_min: 658.0
total_envstep_count: 118459
total_train_sample_count: 118428
total_episode_count: 448
total_duration: 160.02182027271817
[2024-11-19 22:03:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 564
train_sample_count: 564
avg_envstep_per_episode: 112.8
avg_sample_per_episode: 112.8
avg_envstep_per_sec: 803.4775261570582
avg_train_sample_per_sec: 803.4775261570582
avg_episode_per_sec: 7.123027714158318
collect_time: 0.7019486938204084
reward_mean: 460.0
reward_std: 312.6294860839844
reward_max: 1015.0
reward_min: 224.0
total_envstep_count: 119463
total_train_sample_count: 119412
total_episode_count: 453
total_duration: 160.7237689665386
[2024-11-19 22:03:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1197
train_sample_count: 1197
avg_envstep_per_episode: 239.4
avg_sample_per_episode: 239.4
avg_envstep_per_sec: 808.4073991009953
avg_train_sample_per_sec: 808.4073991009953
avg_episode_per_sec: 3.376806178366731
collect_time: 1.480689070054463
reward_mean: 791.0
reward_std: 239.3056640625
reward_max: 1261.0
reward_min: 610.0
total_envstep_count: 120450
total_train_sample_count: 120405
total_episode_count: 458
total_duration: 162.20445803659305
[2024-11-19 22:03:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1366
train_sample_count: 1366
avg_envstep_per_episode: 170.75
avg_sample_per_episode: 170.75
avg_envstep_per_sec: 816.67959390304
avg_train_sample_per_sec: 816.67959390304
avg_episode_per_sec: 4.78289659679672
collect_time: 1.6726265847682953
reward_mean: 742.0
reward_std: 350.6754150390625
reward_max: 1515.0
reward_min: 250.0
total_envstep_count: 121451
total_train_sample_count: 121411
total_episode_count: 466
total_duration: 163.87708462136135
[2024-11-19 22:03:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1245
train_sample_count: 1245
avg_envstep_per_episode: 138.33333333333334
avg_sample_per_episode: 138.33333333333334
avg_envstep_per_sec: 797.8379674528396
avg_train_sample_per_sec: 797.8379674528396
avg_episode_per_sec: 5.767503379177153
collect_time: 1.5604672261646815
reward_mean: 671.4444580078125
reward_std: 686.2372436523438
reward_max: 2543.0
reward_min: 240.0
total_envstep_count: 122507
total_train_sample_count: 122464
total_episode_count: 475
total_duration: 165.43755184752604
[2024-11-19 22:03:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 872
train_sample_count: 872
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 806.3825886081441
avg_train_sample_per_sec: 806.3825886081441
avg_episode_per_sec: 3.699002700037359
collect_time: 1.0813725548131126
reward_mean: 744.25
reward_std: 155.13925170898438
reward_max: 996.0
reward_min: 598.0
total_envstep_count: 123495
total_train_sample_count: 123456
total_episode_count: 479
total_duration: 166.51892440233914
[2024-11-19 22:04:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 892
train_sample_count: 892
avg_envstep_per_episode: 148.66666666666666
avg_sample_per_episode: 148.66666666666666
avg_envstep_per_sec: 805.7445846579215
avg_train_sample_per_sec: 805.7445846579215
avg_episode_per_sec: 5.419806623259562
collect_time: 1.1070505678653717
reward_mean: 708.0
reward_std: 361.114013671875
reward_max: 1431.0
reward_min: 229.0
total_envstep_count: 124513
total_train_sample_count: 124468
total_episode_count: 485
total_duration: 167.6259749702045
[2024-11-19 22:04:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1143
train_sample_count: 1143
avg_envstep_per_episode: 163.28571428571428
avg_sample_per_episode: 163.28571428571428
avg_envstep_per_sec: 807.1983683366077
avg_train_sample_per_sec: 807.1983683366077
avg_episode_per_sec: 4.943472072052716
collect_time: 1.4160088087831224
reward_mean: 893.5714111328125
reward_std: 499.26544189453125
reward_max: 1669.0
reward_min: 204.0
total_envstep_count: 125522
total_train_sample_count: 125491
total_episode_count: 492
total_duration: 169.04198377898763
[2024-11-19 22:04:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 877
train_sample_count: 877
avg_envstep_per_episode: 175.4
avg_sample_per_episode: 175.4
avg_envstep_per_sec: 807.6167312199295
avg_train_sample_per_sec: 807.6167312199295
avg_episode_per_sec: 4.60442834218888
collect_time: 1.085911133459636
reward_mean: 883.4000244140625
reward_std: 272.012939453125
reward_max: 1338.0
reward_min: 615.0
total_envstep_count: 126533
total_train_sample_count: 126488
total_episode_count: 497
total_duration: 170.12789491244726
[2024-11-19 22:04:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 1616
train_sample_count: 1616
avg_envstep_per_episode: 115.42857142857143
avg_sample_per_episode: 115.42857142857143
avg_envstep_per_sec: 792.000574078126
avg_train_sample_per_sec: 792.000574078126
avg_episode_per_sec: 6.8613911120629725
collect_time: 2.040402561426163
reward_mean: 526.1428833007812
reward_std: 449.4561767578125
reward_max: 1624.0
reward_min: 222.0
total_envstep_count: 127609
total_train_sample_count: 127552
total_episode_count: 511
total_duration: 172.16829747387342
[2024-11-19 22:04:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 770
train_sample_count: 770
avg_envstep_per_episode: 192.5
avg_sample_per_episode: 192.5
avg_envstep_per_sec: 803.3107913800653
avg_train_sample_per_sec: 803.3107913800653
avg_episode_per_sec: 4.173043072104235
collect_time: 0.9585331210068293
reward_mean: 820.25
reward_std: 201.570556640625
reward_max: 1023.0
reward_min: 603.0
total_envstep_count: 128565
total_train_sample_count: 128526
total_episode_count: 515
total_duration: 173.12683059488026
[2024-11-19 22:04:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1102
train_sample_count: 1102
avg_envstep_per_episode: 220.4
avg_sample_per_episode: 220.4
avg_envstep_per_sec: 802.9582906233836
avg_train_sample_per_sec: 802.9582906233836
avg_episode_per_sec: 3.643186436585225
collect_time: 1.3724249601364136
reward_mean: 1006.4000244140625
reward_std: 232.14358520507812
reward_max: 1407.0
reward_min: 754.0
total_envstep_count: 129536
total_train_sample_count: 129496
total_episode_count: 520
total_duration: 174.49925555501667
[2024-11-19 22:04:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 923
train_sample_count: 923
avg_envstep_per_episode: 184.6
avg_sample_per_episode: 184.6
avg_envstep_per_sec: 795.9714649934915
avg_train_sample_per_sec: 795.9714649934915
avg_episode_per_sec: 4.311871424666801
collect_time: 1.159589307648795
reward_mean: 774.7999877929688
reward_std: 263.7979431152344
reward_max: 1290.0
reward_min: 584.0
total_envstep_count: 130524
total_train_sample_count: 130479
total_episode_count: 525
total_duration: 175.65884486266546
[2024-11-19 22:04:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1242
train_sample_count: 1242
avg_envstep_per_episode: 112.9090909090909
avg_sample_per_episode: 112.9090909090909
avg_envstep_per_sec: 803.977781676802
avg_train_sample_per_sec: 803.977781676802
avg_episode_per_sec: 7.120576166219664
collect_time: 1.544818810054234
reward_mean: 525.6363525390625
reward_std: 304.9981384277344
reward_max: 1038.0
reward_min: 214.0
total_envstep_count: 131539
total_train_sample_count: 131481
total_episode_count: 536
total_duration: 177.2036636727197
[2024-11-19 22:04:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 348
train_sample_count: 348
avg_envstep_per_episode: 87.0
avg_sample_per_episode: 87.0
avg_envstep_per_sec: 814.454448755328
avg_train_sample_per_sec: 814.454448755328
avg_episode_per_sec: 9.361545387992276
collect_time: 0.4272798810686384
reward_mean: 412.25
reward_std: 357.2886657714844
reward_max: 1030.0
reward_min: 176.0
total_envstep_count: 132497
total_train_sample_count: 132453
total_episode_count: 540
total_duration: 177.63094355378834
[2024-11-19 22:04:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1193
train_sample_count: 1193
avg_envstep_per_episode: 132.55555555555554
avg_sample_per_episode: 132.55555555555554
avg_envstep_per_sec: 810.0794184037346
avg_train_sample_per_sec: 810.0794184037346
avg_episode_per_sec: 6.111244564655165
collect_time: 1.4726951122283938
reward_mean: 633.3333129882812
reward_std: 348.3465881347656
reward_max: 1327.0
reward_min: 246.0
total_envstep_count: 133520
total_train_sample_count: 133478
total_episode_count: 549
total_duration: 179.10363866601674
[2024-11-19 22:04:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1030
train_sample_count: 1030
avg_envstep_per_episode: 257.5
avg_sample_per_episode: 257.5
avg_envstep_per_sec: 805.7038193473737
avg_train_sample_per_sec: 805.7038193473737
avg_episode_per_sec: 3.128946871251937
collect_time: 1.278385400772095
reward_mean: 894.5
reward_std: 415.94140625
reward_max: 1294.0
reward_min: 199.0
total_envstep_count: 134508
total_train_sample_count: 134460
total_episode_count: 553
total_duration: 180.38202406678883
[2024-11-19 22:04:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 708
train_sample_count: 708
avg_envstep_per_episode: 177.0
avg_sample_per_episode: 177.0
avg_envstep_per_sec: 804.8615270753189
avg_train_sample_per_sec: 804.8615270753189
avg_episode_per_sec: 4.547240265962254
collect_time: 0.8796544202736446
reward_mean: 713.5
reward_std: 166.2505645751953
reward_max: 1001.0
reward_min: 606.0
total_envstep_count: 135472
total_train_sample_count: 135444
total_episode_count: 557
total_duration: 181.26167848706248
[2024-11-19 22:04:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1517
train_sample_count: 1517
avg_envstep_per_episode: 189.625
avg_sample_per_episode: 189.625
avg_envstep_per_sec: 808.0719406828871
avg_train_sample_per_sec: 808.0719406828871
avg_episode_per_sec: 4.2614209132914285
collect_time: 1.8773081004619596
reward_mean: 744.75
reward_std: 402.6778259277344
reward_max: 1324.0
reward_min: 202.0
total_envstep_count: 136489
total_train_sample_count: 136469
total_episode_count: 565
total_duration: 183.13898658752444
[2024-11-19 22:04:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1024
train_sample_count: 1024
avg_envstep_per_episode: 102.4
avg_sample_per_episode: 102.4
avg_envstep_per_sec: 806.0154213854202
avg_train_sample_per_sec: 806.0154213854202
avg_episode_per_sec: 7.871244349466993
collect_time: 1.2704471562589918
reward_mean: 461.79998779296875
reward_std: 404.3856506347656
reward_max: 1393.0
reward_min: 193.0
total_envstep_count: 137497
total_train_sample_count: 137457
total_episode_count: 575
total_duration: 184.40943374378344
[2024-11-19 22:05:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 852
train_sample_count: 852
avg_envstep_per_episode: 142.0
avg_sample_per_episode: 142.0
avg_envstep_per_sec: 801.0813809813486
avg_train_sample_per_sec: 801.0813809813486
avg_episode_per_sec: 5.64141817592499
collect_time: 1.063562354871205
reward_mean: 641.6666870117188
reward_std: 431.9798278808594
reward_max: 1531.0
reward_min: 233.0
total_envstep_count: 138492
total_train_sample_count: 138453
total_episode_count: 581
total_duration: 185.47299609865465
[2024-11-19 22:05:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 934
train_sample_count: 934
avg_envstep_per_episode: 116.75
avg_sample_per_episode: 116.75
avg_envstep_per_sec: 790.0752798371983
avg_train_sample_per_sec: 790.0752798371983
avg_episode_per_sec: 6.767240084258658
collect_time: 1.1821658313274384
reward_mean: 646.25
reward_std: 393.3096008300781
reward_max: 1411.0
reward_min: 223.0
total_envstep_count: 139510
total_train_sample_count: 139459
total_episode_count: 589
total_duration: 186.65516192998209
[2024-11-19 22:05:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 719
train_sample_count: 719
avg_envstep_per_episode: 143.8
avg_sample_per_episode: 143.8
avg_envstep_per_sec: 788.5036003630134
avg_train_sample_per_sec: 788.5036003630134
avg_episode_per_sec: 5.483335190285212
collect_time: 0.9118537945406778
reward_mean: 739.5999755859375
reward_std: 479.279296875
reward_max: 1305.0
reward_min: 231.0
total_envstep_count: 140506
total_train_sample_count: 140454
total_episode_count: 594
total_duration: 187.56701572452278
[2024-11-19 22:05:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1529
train_sample_count: 1529
avg_envstep_per_episode: 169.88888888888889
avg_sample_per_episode: 169.88888888888889
avg_envstep_per_sec: 795.1681120156026
avg_train_sample_per_sec: 795.1681120156026
avg_episode_per_sec: 4.680518644957765
collect_time: 1.9228638282844
reward_mean: 647.3333129882812
reward_std: 333.02252197265625
reward_max: 1127.0
reward_min: 183.0
total_envstep_count: 141499
total_train_sample_count: 141455
total_episode_count: 603
total_duration: 189.48987955280717
[2024-11-19 22:05:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 427
train_sample_count: 427
avg_envstep_per_episode: 142.33333333333334
avg_sample_per_episode: 142.33333333333334
avg_envstep_per_sec: 783.5820304447591
avg_train_sample_per_sec: 783.5820304447591
avg_episode_per_sec: 5.505260167059197
collect_time: 0.544933374438967
reward_mean: 493.6666564941406
reward_std: 191.3919677734375
reward_max: 630.0
reward_min: 223.0
total_envstep_count: 142480
total_train_sample_count: 142434
total_episode_count: 606
total_duration: 190.03481292724612
[2024-11-19 22:05:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1091
train_sample_count: 1091
avg_envstep_per_episode: 136.375
avg_sample_per_episode: 136.375
avg_envstep_per_sec: 781.290767772266
avg_train_sample_per_sec: 781.290767772266
avg_episode_per_sec: 5.728988214645397
collect_time: 1.3964071316378455
reward_mean: 536.125
reward_std: 319.5436096191406
reward_max: 1043.0
reward_min: 243.0
total_envstep_count: 143459
total_train_sample_count: 143417
total_episode_count: 614
total_duration: 191.43122005888398
[2024-11-19 22:05:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1023
train_sample_count: 1023
avg_envstep_per_episode: 146.14285714285714
avg_sample_per_episode: 146.14285714285714
avg_envstep_per_sec: 655.3278273021526
avg_train_sample_per_sec: 655.3278273021526
avg_episode_per_sec: 4.484159131099774
collect_time: 1.5610507556370323
reward_mean: 619.1428833007812
reward_std: 366.97662353515625
reward_max: 1031.0
reward_min: 207.0
total_envstep_count: 144469
total_train_sample_count: 144440
total_episode_count: 621
total_duration: 192.99227081452102
[2024-11-19 22:05:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1226
train_sample_count: 1226
avg_envstep_per_episode: 204.33333333333334
avg_sample_per_episode: 204.33333333333334
avg_envstep_per_sec: 802.8653557062194
avg_train_sample_per_sec: 802.8653557062194
avg_episode_per_sec: 3.929194236735168
collect_time: 1.52703064254352
reward_mean: 814.8333129882812
reward_std: 381.4539794921875
reward_max: 1418.0
reward_min: 228.0
total_envstep_count: 145520
total_train_sample_count: 145474
total_episode_count: 627
total_duration: 194.51930145706453
[2024-11-19 22:05:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1128
train_sample_count: 1128
avg_envstep_per_episode: 112.8
avg_sample_per_episode: 112.8
avg_envstep_per_sec: 799.482852282645
avg_train_sample_per_sec: 799.482852282645
avg_episode_per_sec: 7.087613938675931
collect_time: 1.4109120624405997
reward_mean: 509.6000061035156
reward_std: 357.4734191894531
reward_max: 1050.0
reward_min: 205.0
total_envstep_count: 146566
total_train_sample_count: 146530
total_episode_count: 637
total_duration: 195.93021351950512
[2024-11-19 22:05:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 649
train_sample_count: 649
avg_envstep_per_episode: 162.25
avg_sample_per_episode: 162.25
avg_envstep_per_sec: 808.1864734763066
avg_train_sample_per_sec: 808.1864734763066
avg_episode_per_sec: 4.981118480593569
collect_time: 0.8030324947266352
reward_mean: 775.0
reward_std: 167.60816955566406
reward_max: 1042.0
reward_min: 579.0
total_envstep_count: 147546
total_train_sample_count: 147503
total_episode_count: 641
total_duration: 196.73324601423175
[2024-11-19 22:05:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1147
train_sample_count: 1147
avg_envstep_per_episode: 163.85714285714286
avg_sample_per_episode: 163.85714285714286
avg_envstep_per_sec: 811.9136735431631
avg_train_sample_per_sec: 811.9136735431631
avg_episode_per_sec: 4.955009341588616
collect_time: 1.412711766504106
reward_mean: 722.7142944335938
reward_std: 502.2815856933594
reward_max: 1651.0
reward_min: 230.0
total_envstep_count: 148523
total_train_sample_count: 148482
total_episode_count: 648
total_duration: 198.14595778073587
[2024-11-19 22:05:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1062
train_sample_count: 1062
avg_envstep_per_episode: 212.4
avg_sample_per_episode: 212.4
avg_envstep_per_sec: 806.0438766786799
avg_train_sample_per_sec: 806.0438766786799
avg_episode_per_sec: 3.7949335060201506
collect_time: 1.3175461419991086
reward_mean: 1059.4000244140625
reward_std: 524.1055297851562
reward_max: 1889.0
reward_min: 234.0
total_envstep_count: 149519
total_train_sample_count: 149460
total_episode_count: 653
total_duration: 199.463503922735
[2024-11-19 22:05:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1019
train_sample_count: 1019
avg_envstep_per_episode: 145.57142857142858
avg_sample_per_episode: 145.57142857142858
avg_envstep_per_sec: 799.1860526429405
avg_train_sample_per_sec: 799.1860526429405
avg_episode_per_sec: 5.489992510795469
collect_time: 1.2750472767012462
reward_mean: 788.5714111328125
reward_std: 414.320068359375
reward_max: 1306.0
reward_min: 246.0
total_envstep_count: 150531
total_train_sample_count: 150491
total_episode_count: 660
total_duration: 200.73855119943624
[2024-11-19 22:05:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 905
train_sample_count: 905
avg_envstep_per_episode: 181.0
avg_sample_per_episode: 181.0
avg_envstep_per_sec: 802.6614496477669
avg_train_sample_per_sec: 802.6614496477669
avg_episode_per_sec: 4.4345936444628
collect_time: 1.1274990226541246
reward_mean: 916.4000244140625
reward_std: 566.8119506835938
reward_max: 1421.0
reward_min: 213.0
total_envstep_count: 151519
total_train_sample_count: 151480
total_episode_count: 665
total_duration: 201.86605022209037
[2024-11-19 22:06:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1288
train_sample_count: 1288
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 797.4180167567331
avg_train_sample_per_sec: 797.4180167567331
avg_episode_per_sec: 4.952906936377224
collect_time: 1.615213066339493
reward_mean: 747.75
reward_std: 273.7662048339844
reward_max: 1117.0
reward_min: 247.0
total_envstep_count: 152551
total_train_sample_count: 152504
total_episode_count: 673
total_duration: 203.48126328842986
[2024-11-19 22:06:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 617
train_sample_count: 617
avg_envstep_per_episode: 205.66666666666666
avg_sample_per_episode: 205.66666666666666
avg_envstep_per_sec: 801.4386528953014
avg_train_sample_per_sec: 801.4386528953014
avg_episode_per_sec: 3.8967843738831514
collect_time: 0.7698655383927481
reward_mean: 970.0
reward_std: 296.8141784667969
reward_max: 1296.0
reward_min: 578.0
total_envstep_count: 153532
total_train_sample_count: 153493
total_episode_count: 676
total_duration: 204.2511288268226
[2024-11-19 22:06:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1241
train_sample_count: 1241
avg_envstep_per_episode: 155.125
avg_sample_per_episode: 155.125
avg_envstep_per_sec: 803.1635015204973
avg_train_sample_per_sec: 803.1635015204973
avg_episode_per_sec: 5.177524586755824
collect_time: 1.545139934335436
reward_mean: 727.75
reward_std: 408.83056640625
reward_max: 1300.0
reward_min: 207.0
total_envstep_count: 154532
total_train_sample_count: 154494
total_episode_count: 684
total_duration: 205.79626876115802
[2024-11-19 22:06:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 397
train_sample_count: 397
avg_envstep_per_episode: 198.5
avg_sample_per_episode: 198.5
avg_envstep_per_sec: 806.379266204849
avg_train_sample_per_sec: 806.379266204849
avg_episode_per_sec: 4.062364061485385
collect_time: 0.4923241663546789
reward_mean: 818.0
reward_std: 184.0
reward_max: 1002.0
reward_min: 634.0
total_envstep_count: 155507
total_train_sample_count: 155479
total_episode_count: 686
total_duration: 206.2885929275127
[2024-11-19 22:06:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 934
train_sample_count: 934
avg_envstep_per_episode: 155.66666666666666
avg_sample_per_episode: 155.66666666666666
avg_envstep_per_sec: 811.3856865498516
avg_train_sample_per_sec: 811.3856865498516
avg_episode_per_sec: 5.212327750855578
collect_time: 1.1511171758174896
reward_mean: 747.1666870117188
reward_std: 352.2259826660156
reward_max: 1315.0
reward_min: 181.0
total_envstep_count: 156494
total_train_sample_count: 156461
total_episode_count: 692
total_duration: 207.43971010333019
[2024-11-19 22:06:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1782
train_sample_count: 1782
avg_envstep_per_episode: 297.0
avg_sample_per_episode: 297.0
avg_envstep_per_sec: 805.3393785215325
avg_train_sample_per_sec: 805.3393785215325
avg_episode_per_sec: 2.711580399062399
collect_time: 2.212731734627769
reward_mean: 1237.6666259765625
reward_std: 678.62646484375
reward_max: 2289.0
reward_min: 237.0
total_envstep_count: 157489
total_train_sample_count: 157451
total_episode_count: 698
total_duration: 209.65244183795795
[2024-11-19 22:06:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 871
train_sample_count: 871
avg_envstep_per_episode: 145.16666666666666
avg_sample_per_episode: 145.16666666666666
avg_envstep_per_sec: 799.8459523134165
avg_train_sample_per_sec: 799.8459523134165
avg_episode_per_sec: 5.509845825350745
collect_time: 1.0889596896512168
reward_mean: 840.1666870117188
reward_std: 264.79388427734375
reward_max: 1335.0
reward_min: 615.0
total_envstep_count: 158468
total_train_sample_count: 158430
total_episode_count: 704
total_duration: 210.74140152760916
[2024-11-19 22:06:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 678
train_sample_count: 678
avg_envstep_per_episode: 169.5
avg_sample_per_episode: 169.5
avg_envstep_per_sec: 801.9938555682648
avg_train_sample_per_sec: 801.9938555682648
avg_episode_per_sec: 4.7315271714941876
collect_time: 0.8453930105481829
reward_mean: 920.0
reward_std: 318.8753662109375
reward_max: 1315.0
reward_min: 594.0
total_envstep_count: 159456
total_train_sample_count: 159408
total_episode_count: 708
total_duration: 211.58679453815733
[2024-11-19 22:06:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1172
train_sample_count: 1172
avg_envstep_per_episode: 167.42857142857142
avg_sample_per_episode: 167.42857142857142
avg_envstep_per_sec: 803.7552137060703
avg_train_sample_per_sec: 803.7552137060703
avg_episode_per_sec: 4.800585747391206
collect_time: 1.4581553936004639
reward_mean: 808.4285888671875
reward_std: 498.0880126953125
reward_max: 1909.0
reward_min: 229.0
total_envstep_count: 160466
total_train_sample_count: 160424
total_episode_count: 715
total_duration: 213.0449499317578
[2024-11-19 22:06:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1194
train_sample_count: 1194
avg_envstep_per_episode: 149.25
avg_sample_per_episode: 149.25
avg_envstep_per_sec: 805.9804083161476
avg_train_sample_per_sec: 805.9804083161476
avg_episode_per_sec: 5.400203740811709
collect_time: 1.481425587620054
reward_mean: 658.875
reward_std: 208.04232788085938
reward_max: 1024.0
reward_min: 222.0
total_envstep_count: 161468
total_train_sample_count: 161450
total_episode_count: 723
total_duration: 214.52637551937786
[2024-11-19 22:06:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 920
train_sample_count: 920
avg_envstep_per_episode: 153.33333333333334
avg_sample_per_episode: 153.33333333333334
avg_envstep_per_sec: 804.2243465814532
avg_train_sample_per_sec: 804.2243465814532
avg_episode_per_sec: 5.244941390748608
collect_time: 1.14395939878055
reward_mean: 653.6666870117188
reward_std: 305.62701416015625
reward_max: 1271.0
reward_min: 244.0
total_envstep_count: 162479
total_train_sample_count: 162430
total_episode_count: 729
total_duration: 215.6703349181584
[2024-11-19 22:06:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 775
train_sample_count: 775
avg_envstep_per_episode: 110.71428571428571
avg_sample_per_episode: 110.71428571428571
avg_envstep_per_sec: 806.9252245089915
avg_train_sample_per_sec: 806.9252245089915
avg_episode_per_sec: 7.288356866532827
collect_time: 0.9604359567165374
reward_mean: 514.4285888671875
reward_std: 266.3278503417969
reward_max: 1014.0
reward_min: 245.0
total_envstep_count: 163458
total_train_sample_count: 163421
total_episode_count: 736
total_duration: 216.63077087487494
[2024-11-19 22:06:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1099
train_sample_count: 1099
avg_envstep_per_episode: 183.16666666666666
avg_sample_per_episode: 183.16666666666666
avg_envstep_per_sec: 800.969370715745
avg_train_sample_per_sec: 800.969370715745
avg_episode_per_sec: 4.372899203179681
collect_time: 1.3720874232905254
reward_mean: 742.1666870117188
reward_std: 434.1180419921875
reward_max: 1296.0
reward_min: 231.0
total_envstep_count: 164478
total_train_sample_count: 164424
total_episode_count: 742
total_duration: 218.00285829816548
[2024-11-19 22:06:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 545
train_sample_count: 545
avg_envstep_per_episode: 181.66666666666666
avg_sample_per_episode: 181.66666666666666
avg_envstep_per_sec: 799.8323914273544
avg_train_sample_per_sec: 799.8323914273544
avg_episode_per_sec: 4.402747108774428
collect_time: 0.6813927590847015
reward_mean: 650.3333129882812
reward_std: 40.28509521484375
reward_max: 706.0
reward_min: 612.0
total_envstep_count: 165435
total_train_sample_count: 165389
total_episode_count: 745
total_duration: 218.68425105725018
[2024-11-19 22:06:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1357
train_sample_count: 1357
avg_envstep_per_episode: 193.85714285714286
avg_sample_per_episode: 193.85714285714286
avg_envstep_per_sec: 803.3697710376784
avg_train_sample_per_sec: 803.3697710376784
avg_episode_per_sec: 4.144132938293109
collect_time: 1.6891350022384102
reward_mean: 647.8571166992188
reward_std: 329.1163330078125
reward_max: 1294.0
reward_min: 238.0
total_envstep_count: 166413
total_train_sample_count: 166374
total_episode_count: 752
total_duration: 220.37338605948858
[2024-11-19 22:06:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 678
train_sample_count: 678
avg_envstep_per_episode: 96.85714285714286
avg_sample_per_episode: 96.85714285714286
avg_envstep_per_sec: 803.5372775746537
avg_train_sample_per_sec: 803.5372775746537
avg_episode_per_sec: 8.296107585579021
collect_time: 0.8437691926956177
reward_mean: 518.5714111328125
reward_std: 271.92584228515625
reward_max: 1019.0
reward_min: 238.0
total_envstep_count: 167407
total_train_sample_count: 167364
total_episode_count: 759
total_duration: 221.2171552521842
[2024-11-19 22:06:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 818
train_sample_count: 818
avg_envstep_per_episode: 163.6
avg_sample_per_episode: 163.6
avg_envstep_per_sec: 798.6073062601124
avg_train_sample_per_sec: 798.6073062601124
avg_episode_per_sec: 4.881462752201176
collect_time: 1.0242831408977509
reward_mean: 597.4000244140625
reward_std: 331.59710693359375
reward_max: 1122.0
reward_min: 235.0
total_envstep_count: 168403
total_train_sample_count: 168350
total_episode_count: 764
total_duration: 222.24143839308195
[2024-11-19 22:07:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1737
train_sample_count: 1737
avg_envstep_per_episode: 248.14285714285714
avg_sample_per_episode: 248.14285714285714
avg_envstep_per_sec: 803.7538511016201
avg_train_sample_per_sec: 803.7538511016201
avg_episode_per_sec: 3.239077120156212
collect_time: 2.161109396389552
reward_mean: 835.2857055664062
reward_std: 243.08653259277344
reward_max: 1292.0
reward_min: 579.0
total_envstep_count: 169406
total_train_sample_count: 169379
total_episode_count: 771
total_duration: 224.4025477894715
[2024-11-19 22:07:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 818
train_sample_count: 818
avg_envstep_per_episode: 116.85714285714286
avg_sample_per_episode: 116.85714285714286
avg_envstep_per_sec: 812.6002588408517
avg_train_sample_per_sec: 812.6002588408517
avg_episode_per_sec: 6.953791946070858
collect_time: 1.0066450153078352
reward_mean: 595.2857055664062
reward_std: 157.32742309570312
reward_max: 744.0
reward_min: 233.0
total_envstep_count: 170408
total_train_sample_count: 170389
total_episode_count: 778
total_duration: 225.40919280477934
[2024-11-19 22:07:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1117
train_sample_count: 1117
avg_envstep_per_episode: 159.57142857142858
avg_sample_per_episode: 159.57142857142858
avg_envstep_per_sec: 802.4128780398756
avg_train_sample_per_sec: 802.4128780398756
avg_episode_per_sec: 5.028549817617842
collect_time: 1.3920514370713915
reward_mean: 675.2857055664062
reward_std: 440.9259033203125
reward_max: 1320.0
reward_min: 238.0
total_envstep_count: 171418
total_train_sample_count: 171374
total_episode_count: 785
total_duration: 226.80124424185072
[2024-11-19 22:07:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1049
train_sample_count: 1049
avg_envstep_per_episode: 149.85714285714286
avg_sample_per_episode: 149.85714285714286
avg_envstep_per_sec: 810.0050991455781
avg_train_sample_per_sec: 810.0050991455781
avg_episode_per_sec: 5.405181786481456
collect_time: 1.295053575720106
reward_mean: 568.0
reward_std: 255.102783203125
reward_max: 1020.0
reward_min: 218.0
total_envstep_count: 172428
total_train_sample_count: 172375
total_episode_count: 792
total_duration: 228.09629781757084
[2024-11-19 22:07:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 544
train_sample_count: 544
avg_envstep_per_episode: 136.0
avg_sample_per_episode: 136.0
avg_envstep_per_sec: 812.0711888501313
avg_train_sample_per_sec: 812.0711888501313
avg_episode_per_sec: 5.971111682721554
collect_time: 0.6698920088154929
reward_mean: 529.75
reward_std: 195.88819885253906
reward_max: 700.0
reward_min: 198.0
total_envstep_count: 173385
total_train_sample_count: 173351
total_episode_count: 796
total_duration: 228.76618982638632
[2024-11-19 22:07:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 909
train_sample_count: 909
avg_envstep_per_episode: 151.5
avg_sample_per_episode: 151.5
avg_envstep_per_sec: 809.6321290187149
avg_train_sample_per_sec: 809.6321290187149
avg_episode_per_sec: 5.344106462169735
collect_time: 1.1227321241583141
reward_mean: 634.0
reward_std: 224.33680725097656
reward_max: 1013.0
reward_min: 250.0
total_envstep_count: 174349
total_train_sample_count: 174320
total_episode_count: 802
total_duration: 229.88892195054464
[2024-11-19 22:07:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1130
train_sample_count: 1130
avg_envstep_per_episode: 226.0
avg_sample_per_episode: 226.0
avg_envstep_per_sec: 807.6376755144994
avg_train_sample_per_sec: 807.6376755144994
avg_episode_per_sec: 3.573618033249997
collect_time: 1.399142256804875
reward_mean: 845.5999755859375
reward_std: 308.61602783203125
reward_max: 1389.0
reward_min: 610.0
total_envstep_count: 175328
total_train_sample_count: 175306
total_episode_count: 807
total_duration: 231.28806420734952
[2024-11-19 22:07:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 981
train_sample_count: 981
avg_envstep_per_episode: 245.25
avg_sample_per_episode: 245.25
avg_envstep_per_sec: 815.911171490986
avg_train_sample_per_sec: 815.911171490986
avg_episode_per_sec: 3.3268549296268546
collect_time: 1.202336766890117
reward_mean: 868.5
reward_std: 145.05258178710938
reward_max: 1029.0
reward_min: 716.0
total_envstep_count: 176332
total_train_sample_count: 176299
total_episode_count: 811
total_duration: 232.49040097423963
[2024-11-19 22:07:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1405
train_sample_count: 1405
avg_envstep_per_episode: 156.11111111111111
avg_sample_per_episode: 156.11111111111111
avg_envstep_per_sec: 802.5733204753117
avg_train_sample_per_sec: 802.5733204753117
avg_episode_per_sec: 5.141039063542921
collect_time: 1.7506188707692283
reward_mean: 711.0
reward_std: 331.008544921875
reward_max: 1290.0
reward_min: 246.0
total_envstep_count: 177341
total_train_sample_count: 177296
total_episode_count: 820
total_duration: 234.24101984500885
[2024-11-19 22:07:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1048
train_sample_count: 1048
avg_envstep_per_episode: 131.0
avg_sample_per_episode: 131.0
avg_envstep_per_sec: 797.9210052175647
avg_train_sample_per_sec: 797.9210052175647
avg_episode_per_sec: 6.091000039828739
collect_time: 1.3134132240499767
reward_mean: 636.875
reward_std: 370.2044677734375
reward_max: 1307.0
reward_min: 237.0
total_envstep_count: 178333
total_train_sample_count: 178296
total_episode_count: 828
total_duration: 235.55443306905883
[2024-11-19 22:07:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1102
train_sample_count: 1102
avg_envstep_per_episode: 110.2
avg_sample_per_episode: 110.2
avg_envstep_per_sec: 795.7751293262346
avg_train_sample_per_sec: 795.7751293262346
avg_episode_per_sec: 7.221189921290695
collect_time: 1.384813321488244
reward_mean: 684.2000122070312
reward_std: 349.9267883300781
reward_max: 1307.0
reward_min: 246.0
total_envstep_count: 179332
total_train_sample_count: 179290
total_episode_count: 838
total_duration: 236.93924639054708
[2024-11-19 22:07:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1127
train_sample_count: 1127
avg_envstep_per_episode: 102.45454545454545
avg_sample_per_episode: 102.45454545454545
avg_envstep_per_sec: 801.1327218175511
avg_train_sample_per_sec: 801.1327218175511
avg_episode_per_sec: 7.819396574971662
collect_time: 1.406758167913982
reward_mean: 517.9091186523438
reward_std: 247.0963897705078
reward_max: 1039.0
reward_min: 208.0
total_envstep_count: 180345
total_train_sample_count: 180309
total_episode_count: 849
total_duration: 238.34600455846106
[2024-11-19 22:07:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 968
train_sample_count: 968
avg_envstep_per_episode: 121.0
avg_sample_per_episode: 121.0
avg_envstep_per_sec: 803.602943232204
avg_train_sample_per_sec: 803.602943232204
avg_episode_per_sec: 6.641346638282678
collect_time: 1.2045749809060777
reward_mean: 582.0
reward_std: 233.65626525878906
reward_max: 1004.0
reward_min: 242.0
total_envstep_count: 181345
total_train_sample_count: 181301
total_episode_count: 857
total_duration: 239.55057953936713
[2024-11-19 22:07:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 737
train_sample_count: 737
avg_envstep_per_episode: 105.28571428571429
avg_sample_per_episode: 105.28571428571429
avg_envstep_per_sec: 586.3872768077288
avg_train_sample_per_sec: 586.3872768077288
avg_episode_per_sec: 5.5694856684587535
collect_time: 1.2568485523973192
reward_mean: 550.1428833007812
reward_std: 199.74085998535156
reward_max: 761.0
reward_min: 240.0
total_envstep_count: 182338
total_train_sample_count: 182314
total_episode_count: 864
total_duration: 240.80742809176445
[2024-11-19 22:07:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 961
train_sample_count: 961
avg_envstep_per_episode: 120.125
avg_sample_per_episode: 120.125
avg_envstep_per_sec: 787.2348715758188
avg_train_sample_per_sec: 787.2348715758188
avg_episode_per_sec: 6.553464071390791
collect_time: 1.2207284442016055
reward_mean: 531.875
reward_std: 380.530029296875
reward_max: 1034.0
reward_min: 223.0
total_envstep_count: 183362
total_train_sample_count: 183311
total_episode_count: 872
total_duration: 242.02815653596605
[2024-11-19 22:07:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 890
train_sample_count: 890
avg_envstep_per_episode: 127.14285714285714
avg_sample_per_episode: 127.14285714285714
avg_envstep_per_sec: 807.8247407529276
avg_train_sample_per_sec: 807.8247407529276
avg_episode_per_sec: 6.353677736258981
collect_time: 1.1017241179943085
reward_mean: 567.0
reward_std: 336.46905517578125
reward_max: 1034.0
reward_min: 197.0
total_envstep_count: 184316
total_train_sample_count: 184285
total_episode_count: 879
total_duration: 243.12988065396036
[2024-11-19 22:07:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1168
train_sample_count: 1168
avg_envstep_per_episode: 146.0
avg_sample_per_episode: 146.0
avg_envstep_per_sec: 797.1395979410107
avg_train_sample_per_sec: 797.1395979410107
avg_episode_per_sec: 5.459860259869937
collect_time: 1.4652389656929743
reward_mean: 697.25
reward_std: 442.3289794921875
reward_max: 1332.0
reward_min: 228.0
total_envstep_count: 185357
total_train_sample_count: 185309
total_episode_count: 887
total_duration: 244.59511961965333
[2024-11-19 22:07:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 687
train_sample_count: 687
avg_envstep_per_episode: 98.14285714285714
avg_sample_per_episode: 98.14285714285714
avg_envstep_per_sec: 794.8197818945534
avg_train_sample_per_sec: 794.8197818945534
avg_episode_per_sec: 8.098600397761098
collect_time: 0.8643468817075094
reward_mean: 481.28570556640625
reward_std: 218.9296875
reward_max: 732.0
reward_min: 230.0
total_envstep_count: 186319
total_train_sample_count: 186284
total_episode_count: 894
total_duration: 245.45946650136085
[2024-11-19 22:08:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1033
train_sample_count: 1033
avg_envstep_per_episode: 147.57142857142858
avg_sample_per_episode: 147.57142857142858
avg_envstep_per_sec: 791.5673441162645
avg_train_sample_per_sec: 791.5673441162645
avg_episode_per_sec: 5.363960705531317
collect_time: 1.305005831377847
reward_mean: 744.1428833007812
reward_std: 514.1051635742188
reward_max: 1679.0
reward_min: 179.0
total_envstep_count: 187312
total_train_sample_count: 187269
total_episode_count: 901
total_duration: 246.7644723327387
[2024-11-19 22:08:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1060
train_sample_count: 1060
avg_envstep_per_episode: 176.66666666666666
avg_sample_per_episode: 176.66666666666666
avg_envstep_per_sec: 781.5686165381968
avg_train_sample_per_sec: 781.5686165381968
avg_episode_per_sec: 4.423973301159605
collect_time: 1.3562468829609098
reward_mean: 706.3333129882812
reward_std: 141.5481719970703
reward_max: 1001.0
reward_min: 602.0
total_envstep_count: 188315
total_train_sample_count: 188293
total_episode_count: 907
total_duration: 248.1207192156996
[2024-11-19 22:08:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1185
train_sample_count: 1185
avg_envstep_per_episode: 148.125
avg_sample_per_episode: 148.125
avg_envstep_per_sec: 776.9145834215907
avg_train_sample_per_sec: 776.9145834215907
avg_episode_per_sec: 5.2449929682470255
collect_time: 1.525264199290957
reward_mean: 657.875
reward_std: 410.7552185058594
reward_max: 1306.0
reward_min: 221.0
total_envstep_count: 189357
total_train_sample_count: 189310
total_episode_count: 915
total_duration: 249.64598341499055
[2024-11-19 22:08:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 714
train_sample_count: 714
avg_envstep_per_episode: 142.8
avg_sample_per_episode: 142.8
avg_envstep_per_sec: 779.963175294346
avg_train_sample_per_sec: 779.963175294346
avg_episode_per_sec: 5.461926997859566
collect_time: 0.9154278337955475
reward_mean: 606.5999755859375
reward_std: 248.11497497558594
reward_max: 1009.0
reward_min: 225.0
total_envstep_count: 190320
total_train_sample_count: 190300
total_episode_count: 920
total_duration: 250.5614112487861
[2024-11-19 22:08:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 787
train_sample_count: 787
avg_envstep_per_episode: 112.42857142857143
avg_sample_per_episode: 112.42857142857143
avg_envstep_per_sec: 784.7074468309554
avg_train_sample_per_sec: 784.7074468309554
avg_episode_per_sec: 6.97960880281663
collect_time: 1.0029215386935642
reward_mean: 462.5714416503906
reward_std: 191.43954467773438
reward_max: 637.0
reward_min: 233.0
total_envstep_count: 191322
total_train_sample_count: 191279
total_episode_count: 927
total_duration: 251.56433278747966
[2024-11-19 22:08:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1371
train_sample_count: 1371
avg_envstep_per_episode: 171.375
avg_sample_per_episode: 171.375
avg_envstep_per_sec: 778.2994745250069
avg_train_sample_per_sec: 778.2994745250069
avg_episode_per_sec: 4.541499486652119
collect_time: 1.7615327324186052
reward_mean: 608.5
reward_std: 425.038818359375
reward_max: 1259.0
reward_min: 202.0
total_envstep_count: 192316
total_train_sample_count: 192278
total_episode_count: 935
total_duration: 253.32586551989826
[2024-11-19 22:08:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 888
train_sample_count: 888
avg_envstep_per_episode: 222.0
avg_sample_per_episode: 222.0
avg_envstep_per_sec: 782.9070144209276
avg_train_sample_per_sec: 782.9070144209276
avg_episode_per_sec: 3.5266081730672414
collect_time: 1.1342343134539468
reward_mean: 741.75
reward_std: 171.2138671875
reward_max: 1025.0
reward_min: 602.0
total_envstep_count: 193297
total_train_sample_count: 193250
total_episode_count: 939
total_duration: 254.46009983335222
[2024-11-19 22:08:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 798
train_sample_count: 798
avg_envstep_per_episode: 159.6
avg_sample_per_episode: 159.6
avg_envstep_per_sec: 800.5003188547234
avg_train_sample_per_sec: 800.5003188547234
avg_episode_per_sec: 5.015666158237615
collect_time: 0.9968765548297337
reward_mean: 680.4000244140625
reward_std: 426.5946960449219
reward_max: 1324.0
reward_min: 249.0
total_envstep_count: 194293
total_train_sample_count: 194264
total_episode_count: 944
total_duration: 255.45697638818194
[2024-11-19 22:08:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1297
train_sample_count: 1297
avg_envstep_per_episode: 216.16666666666666
avg_sample_per_episode: 216.16666666666666
avg_envstep_per_sec: 807.4344211362805
avg_train_sample_per_sec: 807.4344211362805
avg_episode_per_sec: 3.735240190298908
collect_time: 1.6063224034649985
reward_mean: 903.1666870117188
reward_std: 329.150146484375
reward_max: 1298.0
reward_min: 238.0
total_envstep_count: 195280
total_train_sample_count: 195249
total_episode_count: 950
total_duration: 257.06329879164696
[2024-11-19 22:08:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1085
train_sample_count: 1085
avg_envstep_per_episode: 180.83333333333334
avg_sample_per_episode: 180.83333333333334
avg_envstep_per_sec: 809.2859356356264
avg_train_sample_per_sec: 809.2859356356264
avg_episode_per_sec: 4.475313929782266
collect_time: 1.3406880710806166
reward_mean: 777.5
reward_std: 306.17791748046875
reward_max: 1120.0
reward_min: 252.0
total_envstep_count: 196234
total_train_sample_count: 196214
total_episode_count: 956
total_duration: 258.40398686272755
[2024-11-19 22:08:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 944
train_sample_count: 944
avg_envstep_per_episode: 157.33333333333334
avg_sample_per_episode: 157.33333333333334
avg_envstep_per_sec: 808.244874338792
avg_train_sample_per_sec: 808.244874338792
avg_episode_per_sec: 5.137149625034695
collect_time: 1.1679628661700656
reward_mean: 802.6666870117188
reward_std: 509.15509033203125
reward_max: 1554.0
reward_min: 233.0
total_envstep_count: 197260
total_train_sample_count: 197230
total_episode_count: 962
total_duration: 259.5719497288976
[2024-11-19 22:09:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1131
train_sample_count: 1131
avg_envstep_per_episode: 141.375
avg_sample_per_episode: 141.375
avg_envstep_per_sec: 804.1395922277665
avg_train_sample_per_sec: 804.1395922277665
avg_episode_per_sec: 5.687990042283052
collect_time: 1.4064722231456213
reward_mean: 555.625
reward_std: 405.3559875488281
reward_max: 1296.0
reward_min: 171.0
total_envstep_count: 198245
total_train_sample_count: 198205
total_episode_count: 970
total_duration: 260.9784219520432
[2024-11-19 22:09:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1166
train_sample_count: 1166
avg_envstep_per_episode: 116.6
avg_sample_per_episode: 116.6
avg_envstep_per_sec: 802.559453794883
avg_train_sample_per_sec: 802.559453794883
avg_episode_per_sec: 6.883014183489562
collect_time: 1.4528518659727914
reward_mean: 615.7000122070312
reward_std: 299.3038635253906
reward_max: 1111.0
reward_min: 235.0
total_envstep_count: 199269
total_train_sample_count: 199239
total_episode_count: 980
total_duration: 262.431273818016
[2024-11-19 22:09:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 714
train_sample_count: 714
avg_envstep_per_episode: 89.25
avg_sample_per_episode: 89.25
avg_envstep_per_sec: 803.7689634983849
avg_train_sample_per_sec: 803.7689634983849
avg_episode_per_sec: 9.005814717068738
collect_time: 0.8883149666445596
reward_mean: 543.375
reward_std: 262.4928283691406
reward_max: 1028.0
reward_min: 244.0
total_envstep_count: 200331
total_train_sample_count: 200289
total_episode_count: 988
total_duration: 263.31958878466054
[2024-11-19 22:09:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 670
train_sample_count: 670
avg_envstep_per_episode: 167.5
avg_sample_per_episode: 167.5
avg_envstep_per_sec: 801.859469239701
avg_train_sample_per_sec: 801.859469239701
avg_episode_per_sec: 4.787220711878812
collect_time: 0.8355578822749001
reward_mean: 611.25
reward_std: 270.81854248046875
reward_max: 1004.0
reward_min: 239.0
total_envstep_count: 201295
total_train_sample_count: 201259
total_episode_count: 992
total_duration: 264.1551466669354
[2024-11-19 22:09:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1565
train_sample_count: 1565
avg_envstep_per_episode: 173.88888888888889
avg_sample_per_episode: 173.88888888888889
avg_envstep_per_sec: 805.8655437931385
avg_train_sample_per_sec: 805.8655437931385
avg_episode_per_sec: 4.634370539385461
collect_time: 1.942011309521539
reward_mean: 671.111083984375
reward_std: 469.48681640625
reward_max: 1668.0
reward_min: 225.0
total_envstep_count: 202344
total_train_sample_count: 202320
total_episode_count: 1001
total_duration: 266.09715797645697
[2024-11-19 22:09:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 585
train_sample_count: 585
avg_envstep_per_episode: 146.25
avg_sample_per_episode: 146.25
avg_envstep_per_sec: 801.1078865745069
avg_train_sample_per_sec: 801.1078865745069
avg_episode_per_sec: 5.477660762902611
collect_time: 0.7302387229033879
reward_mean: 679.5
reward_std: 559.9537963867188
reward_max: 1612.0
reward_min: 239.0
total_envstep_count: 203334
total_train_sample_count: 203301
total_episode_count: 1005
total_duration: 266.82739669936035
[2024-11-19 22:09:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1303
train_sample_count: 1303
avg_envstep_per_episode: 162.875
avg_sample_per_episode: 162.875
avg_envstep_per_sec: 797.8692170731482
avg_train_sample_per_sec: 797.8692170731482
avg_episode_per_sec: 4.898659813188937
collect_time: 1.6330997262682234
reward_mean: 724.375
reward_std: 359.61712646484375
reward_max: 1305.0
reward_min: 232.0
total_envstep_count: 204359
total_train_sample_count: 204340
total_episode_count: 1013
total_duration: 268.46049642562855
[2024-11-19 22:09:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1181
train_sample_count: 1181
avg_envstep_per_episode: 168.71428571428572
avg_sample_per_episode: 168.71428571428572
avg_envstep_per_sec: 799.3441505802497
avg_train_sample_per_sec: 799.3441505802497
avg_episode_per_sec: 4.7378569467076606
collect_time: 1.4774612401212965
reward_mean: 956.1428833007812
reward_std: 429.011962890625
reward_max: 1814.0
reward_min: 630.0
total_envstep_count: 205378
total_train_sample_count: 205329
total_episode_count: 1020
total_duration: 269.9379576657498
[2024-11-19 22:09:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 983
train_sample_count: 983
avg_envstep_per_episode: 109.22222222222223
avg_sample_per_episode: 109.22222222222223
avg_envstep_per_sec: 809.104710238593
avg_train_sample_per_sec: 809.104710238593
avg_episode_per_sec: 7.40787628906138
collect_time: 1.21492309655462
reward_mean: 549.6666870117188
reward_std: 385.0085144042969
reward_max: 1307.0
reward_min: 232.0
total_envstep_count: 206373
total_train_sample_count: 206348
total_episode_count: 1029
total_duration: 271.15288076230445
[2024-11-19 22:09:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 706
train_sample_count: 706
avg_envstep_per_episode: 88.25
avg_sample_per_episode: 88.25
avg_envstep_per_sec: 795.2780654365748
avg_train_sample_per_sec: 795.2780654365748
avg_episode_per_sec: 9.011649466703398
collect_time: 0.8877398116247996
reward_mean: 464.75
reward_std: 221.01060485839844
reward_max: 742.0
reward_min: 247.0
total_envstep_count: 207405
total_train_sample_count: 207366
total_episode_count: 1037
total_duration: 272.04062057392923
[2024-11-19 22:09:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 990
train_sample_count: 990
avg_envstep_per_episode: 123.75
avg_sample_per_episode: 123.75
avg_envstep_per_sec: 804.7512805271298
avg_train_sample_per_sec: 804.7512805271298
avg_episode_per_sec: 6.503040650724281
collect_time: 1.2301937554563793
reward_mean: 555.375
reward_std: 339.8392639160156
reward_max: 1039.0
reward_min: 230.0
total_envstep_count: 208443
total_train_sample_count: 208404
total_episode_count: 1045
total_duration: 273.2708143293856
[2024-11-19 22:09:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 865
train_sample_count: 865
avg_envstep_per_episode: 173.0
avg_sample_per_episode: 173.0
avg_envstep_per_sec: 812.2931721592624
avg_train_sample_per_sec: 812.2931721592624
avg_episode_per_sec: 4.695336255255852
collect_time: 1.0648864592824665
reward_mean: 746.5999755859375
reward_std: 299.1278076171875
reward_max: 1036.0
reward_min: 230.0
total_envstep_count: 209415
total_train_sample_count: 209377
total_episode_count: 1050
total_duration: 274.3357007886681
[2024-11-19 22:09:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 1798
train_sample_count: 1798
avg_envstep_per_episode: 119.86666666666666
avg_sample_per_episode: 119.86666666666666
avg_envstep_per_sec: 807.159785409557
avg_train_sample_per_sec: 807.159785409557
avg_episode_per_sec: 6.733813560146471
collect_time: 2.227563900606973
reward_mean: 671.7333374023438
reward_std: 491.5626525878906
reward_max: 1661.0
reward_min: 236.0
total_envstep_count: 210450
total_train_sample_count: 210407
total_episode_count: 1065
total_duration: 276.56326468927506
[2024-11-19 22:09:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 455
train_sample_count: 455
avg_envstep_per_episode: 65.0
avg_sample_per_episode: 65.0
avg_envstep_per_sec: 803.4489333138428
avg_train_sample_per_sec: 803.4489333138428
avg_episode_per_sec: 12.360752820212966
collect_time: 0.566308549472264
reward_mean: 401.5714416503906
reward_std: 179.0944366455078
reward_max: 625.0
reward_min: 238.0
total_envstep_count: 211451
total_train_sample_count: 211414
total_episode_count: 1072
total_duration: 277.1295732387473
[2024-11-19 22:09:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1194
train_sample_count: 1194
avg_envstep_per_episode: 132.66666666666666
avg_sample_per_episode: 132.66666666666666
avg_envstep_per_sec: 807.6326081064085
avg_train_sample_per_sec: 807.6326081064085
avg_episode_per_sec: 6.087682975676446
collect_time: 1.478394988037291
reward_mean: 763.7777709960938
reward_std: 483.0285949707031
reward_max: 1426.0
reward_min: 203.0
total_envstep_count: 212450
total_train_sample_count: 212416
total_episode_count: 1081
total_duration: 278.6079682267846
[2024-11-19 22:09:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1006
train_sample_count: 1006
avg_envstep_per_episode: 143.71428571428572
avg_sample_per_episode: 143.71428571428572
avg_envstep_per_sec: 806.1532295636212
avg_train_sample_per_sec: 806.1532295636212
avg_episode_per_sec: 5.609416110283647
collect_time: 1.2479017178217569
reward_mean: 861.5714111328125
reward_std: 394.0133361816406
reward_max: 1409.0
reward_min: 228.0
total_envstep_count: 213500
total_train_sample_count: 213446
total_episode_count: 1088
total_duration: 279.85586994460635
[2024-11-19 22:09:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 843
train_sample_count: 843
avg_envstep_per_episode: 168.6
avg_sample_per_episode: 168.6
avg_envstep_per_sec: 807.1235720493926
avg_train_sample_per_sec: 807.1235720493926
avg_episode_per_sec: 4.7872097986322215
collect_time: 1.0444497338363101
reward_mean: 1009.5999755859375
reward_std: 341.0932922363281
reward_max: 1421.0
reward_min: 622.0
total_envstep_count: 214457
total_train_sample_count: 214433
total_episode_count: 1093
total_duration: 280.90031967844266
[2024-11-19 22:10:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 919
train_sample_count: 919
avg_envstep_per_episode: 153.16666666666666
avg_sample_per_episode: 153.16666666666666
avg_envstep_per_sec: 801.9157837982525
avg_train_sample_per_sec: 801.9157837982525
avg_episode_per_sec: 5.235576390412966
collect_time: 1.1460056262356892
reward_mean: 710.5
reward_std: 527.2528686523438
reward_max: 1471.0
reward_min: 202.0
total_envstep_count: 215452
total_train_sample_count: 215424
total_episode_count: 1099
total_duration: 282.04632530467836
[2024-11-19 22:10:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 787
train_sample_count: 787
avg_envstep_per_episode: 196.75
avg_sample_per_episode: 196.75
avg_envstep_per_sec: 804.8162613393463
avg_train_sample_per_sec: 804.8162613393463
avg_episode_per_sec: 4.090552789526537
collect_time: 0.9778629456247603
reward_mean: 893.5
reward_std: 479.40093994140625
reward_max: 1402.0
reward_min: 247.0
total_envstep_count: 216464
total_train_sample_count: 216415
total_episode_count: 1103
total_duration: 283.0241882503031
[2024-11-19 22:10:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1099
train_sample_count: 1099
avg_envstep_per_episode: 157.0
avg_sample_per_episode: 157.0
avg_envstep_per_sec: 794.1915367606088
avg_train_sample_per_sec: 794.1915367606088
avg_episode_per_sec: 5.0585448201312655
collect_time: 1.3837971687316897
reward_mean: 659.2857055664062
reward_std: 299.0058288574219
reward_max: 1054.0
reward_min: 248.0
total_envstep_count: 217443
total_train_sample_count: 217406
total_episode_count: 1110
total_duration: 284.4079854190348
[2024-11-19 22:10:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1085
train_sample_count: 1085
avg_envstep_per_episode: 180.83333333333334
avg_sample_per_episode: 180.83333333333334
avg_envstep_per_sec: 797.7968340277815
avg_train_sample_per_sec: 797.7968340277815
avg_episode_per_sec: 4.41177972734257
collect_time: 1.3599953694002969
reward_mean: 859.5
reward_std: 347.3474426269531
reward_max: 1426.0
reward_min: 589.0
total_envstep_count: 218430
total_train_sample_count: 218395
total_episode_count: 1116
total_duration: 285.76798078843507
[2024-11-19 22:10:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 991
train_sample_count: 991
avg_envstep_per_episode: 165.16666666666666
avg_sample_per_episode: 165.16666666666666
avg_envstep_per_sec: 797.2023652378716
avg_train_sample_per_sec: 797.2023652378716
avg_episode_per_sec: 4.826654078130403
collect_time: 1.2430971648011888
reward_mean: 647.8333129882812
reward_std: 333.0587463378906
reward_max: 1038.0
reward_min: 216.0
total_envstep_count: 219425
total_train_sample_count: 219386
total_episode_count: 1122
total_duration: 287.0110779532363
[2024-11-19 22:10:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1044
train_sample_count: 1044
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 796.2747349189592
avg_train_sample_per_sec: 796.2747349189592
avg_episode_per_sec: 6.864437369991028
collect_time: 1.3111052683421545
reward_mean: 626.2222290039062
reward_std: 374.2636413574219
reward_max: 1414.0
reward_min: 215.0
total_envstep_count: 220416
total_train_sample_count: 220382
total_episode_count: 1131
total_duration: 288.3221832215784
[2024-11-19 22:10:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 718
train_sample_count: 718
avg_envstep_per_episode: 143.6
avg_sample_per_episode: 143.6
avg_envstep_per_sec: 802.7458979955745
avg_train_sample_per_sec: 802.7458979955745
avg_episode_per_sec: 5.590152493005394
collect_time: 0.894429983127685
reward_mean: 841.7999877929688
reward_std: 484.2884826660156
reward_max: 1673.0
reward_min: 245.0
total_envstep_count: 221371
total_train_sample_count: 221352
total_episode_count: 1136
total_duration: 289.2166132047061
[2024-11-19 22:10:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1368
train_sample_count: 1368
avg_envstep_per_episode: 195.42857142857142
avg_sample_per_episode: 195.42857142857142
avg_envstep_per_sec: 795.2874214435204
avg_train_sample_per_sec: 795.2874214435204
avg_episode_per_sec: 4.069453179901055
collect_time: 1.720132826339631
reward_mean: 795.5714111328125
reward_std: 486.35931396484375
reward_max: 1737.0
reward_min: 228.0
total_envstep_count: 222381
total_train_sample_count: 222336
total_episode_count: 1143
total_duration: 290.93674603104574
[2024-11-19 22:10:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1370
train_sample_count: 1370
avg_envstep_per_episode: 195.71428571428572
avg_sample_per_episode: 195.71428571428572
avg_envstep_per_sec: 798.5326488545202
avg_train_sample_per_sec: 798.5326488545202
avg_episode_per_sec: 4.080093826263972
collect_time: 1.7156468204089574
reward_mean: 1002.5714111328125
reward_std: 223.43093872070312
reward_max: 1315.0
reward_min: 755.0
total_envstep_count: 223384
total_train_sample_count: 223346
total_episode_count: 1150
total_duration: 292.6523928514547
[2024-11-19 22:10:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 379
train_sample_count: 379
avg_envstep_per_episode: 75.8
avg_sample_per_episode: 75.8
avg_envstep_per_sec: 797.2195341125549
avg_train_sample_per_sec: 797.2195341125549
avg_episode_per_sec: 10.517408101748746
collect_time: 0.4754022998469216
reward_mean: 329.20001220703125
reward_std: 212.17672729492188
reward_max: 748.0
reward_min: 159.0
total_envstep_count: 224387
total_train_sample_count: 224349
total_episode_count: 1155
total_duration: 293.1277951513016
[2024-11-19 22:10:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1391
train_sample_count: 1391
avg_envstep_per_episode: 198.71428571428572
avg_sample_per_episode: 198.71428571428572
avg_envstep_per_sec: 800.9990526440976
avg_train_sample_per_sec: 800.9990526440976
avg_episode_per_sec: 4.030908244794165
collect_time: 1.7365813297884805
reward_mean: 908.8571166992188
reward_std: 285.4722595214844
reward_max: 1324.0
reward_min: 592.0
total_envstep_count: 225382
total_train_sample_count: 225332
total_episode_count: 1162
total_duration: 294.86437648109006
[2024-11-19 22:10:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 940
train_sample_count: 940
avg_envstep_per_episode: 104.44444444444444
avg_sample_per_episode: 104.44444444444444
avg_envstep_per_sec: 803.1985669587261
avg_train_sample_per_sec: 803.1985669587261
avg_episode_per_sec: 7.690199045349505
collect_time: 1.1703208131449563
reward_mean: 589.888916015625
reward_std: 308.8114929199219
reward_max: 1040.0
reward_min: 177.0
total_envstep_count: 226381
total_train_sample_count: 226332
total_episode_count: 1171
total_duration: 296.034697294235
[2024-11-19 22:10:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 929
train_sample_count: 929
avg_envstep_per_episode: 154.83333333333334
avg_sample_per_episode: 154.83333333333334
avg_envstep_per_sec: 811.162000163166
avg_train_sample_per_sec: 811.162000163166
avg_episode_per_sec: 5.238936491904194
collect_time: 1.1452706115586415
reward_mean: 755.3333129882812
reward_std: 293.7565002441406
reward_max: 1029.0
reward_min: 247.0
total_envstep_count: 227344
total_train_sample_count: 227309
total_episode_count: 1177
total_duration: 297.17996790579366
[2024-11-19 22:10:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 997
train_sample_count: 997
avg_envstep_per_episode: 99.7
avg_sample_per_episode: 99.7
avg_envstep_per_sec: 798.8669631962839
avg_train_sample_per_sec: 798.8669631962839
avg_episode_per_sec: 8.012707755228524
collect_time: 1.2480175622871943
reward_mean: 570.2000122070312
reward_std: 427.0156555175781
reward_max: 1316.0
reward_min: 172.0
total_envstep_count: 228351
total_train_sample_count: 228318
total_episode_count: 1187
total_duration: 298.42798546808086
[2024-11-19 22:10:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 442
train_sample_count: 442
avg_envstep_per_episode: 73.66666666666667
avg_sample_per_episode: 73.66666666666667
avg_envstep_per_sec: 818.9886195216237
avg_train_sample_per_sec: 818.9886195216237
avg_episode_per_sec: 11.117492572691724
collect_time: 0.5396900389875685
reward_mean: 385.1666564941406
reward_std: 216.33724975585938
reward_max: 748.0
reward_min: 230.0
total_envstep_count: 229338
total_train_sample_count: 229312
total_episode_count: 1193
total_duration: 298.9676755070684
[2024-11-19 22:10:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1435
train_sample_count: 1435
avg_envstep_per_episode: 159.44444444444446
avg_sample_per_episode: 159.44444444444446
avg_envstep_per_sec: 806.8805319138057
avg_train_sample_per_sec: 806.8805319138057
avg_episode_per_sec: 5.060574764616203
collect_time: 1.7784541121550972
reward_mean: 661.0
reward_std: 363.5592346191406
reward_max: 1289.0
reward_min: 235.0
total_envstep_count: 230401
total_train_sample_count: 230351
total_episode_count: 1202
total_duration: 300.7461296192235
[2024-11-19 22:10:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1177
train_sample_count: 1177
avg_envstep_per_episode: 147.125
avg_sample_per_episode: 147.125
avg_envstep_per_sec: 799.5346004046426
avg_train_sample_per_sec: 799.5346004046426
avg_episode_per_sec: 5.434389807338267
collect_time: 1.472106397151947
reward_mean: 812.75
reward_std: 417.263916015625
reward_max: 1390.0
reward_min: 239.0
total_envstep_count: 231387
total_train_sample_count: 231348
total_episode_count: 1210
total_duration: 302.21823601637544
[2024-11-19 22:11:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 528
train_sample_count: 528
avg_envstep_per_episode: 132.0
avg_sample_per_episode: 132.0
avg_envstep_per_sec: 796.1052983026286
avg_train_sample_per_sec: 796.1052983026286
avg_episode_per_sec: 6.031100744716884
collect_time: 0.6632288481507982
reward_mean: 664.75
reward_std: 288.114013671875
reward_max: 1047.0
reward_min: 240.0
total_envstep_count: 232360
total_train_sample_count: 232332
total_episode_count: 1214
total_duration: 302.88146486452627
[2024-11-19 22:11:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1156
train_sample_count: 1156
avg_envstep_per_episode: 192.66666666666666
avg_sample_per_episode: 192.66666666666666
avg_envstep_per_sec: 807.2614906856747
avg_train_sample_per_sec: 807.2614906856747
avg_episode_per_sec: 4.18993853297063
collect_time: 1.4320019142968314
reward_mean: 769.3333129882812
reward_std: 420.28271484375
reward_max: 1323.0
reward_min: 223.0
total_envstep_count: 233362
total_train_sample_count: 233320
total_episode_count: 1220
total_duration: 304.3134667788231
[2024-11-19 22:11:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1020
train_sample_count: 1020
avg_envstep_per_episode: 170.0
avg_sample_per_episode: 170.0
avg_envstep_per_sec: 796.9577811771477
avg_train_sample_per_sec: 796.9577811771477
avg_episode_per_sec: 4.6879869481008685
collect_time: 1.2798670445169724
reward_mean: 800.6666870117188
reward_std: 444.24005126953125
reward_max: 1640.0
reward_min: 235.0
total_envstep_count: 234364
total_train_sample_count: 234328
total_episode_count: 1226
total_duration: 305.59333382334006
[2024-11-19 22:11:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1333
train_sample_count: 1333
avg_envstep_per_episode: 121.18181818181819
avg_sample_per_episode: 121.18181818181819
avg_envstep_per_sec: 795.7053987675868
avg_train_sample_per_sec: 795.7053987675868
avg_episode_per_sec: 6.566211092605742
collect_time: 1.6752431264945442
reward_mean: 585.9091186523438
reward_std: 369.34918212890625
reward_max: 1315.0
reward_min: 232.0
total_envstep_count: 235379
total_train_sample_count: 235349
total_episode_count: 1237
total_duration: 307.2685769498346
[2024-11-19 22:11:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 644
train_sample_count: 644
avg_envstep_per_episode: 92.0
avg_sample_per_episode: 92.0
avg_envstep_per_sec: 805.9375193394576
avg_train_sample_per_sec: 805.9375193394576
avg_episode_per_sec: 8.760190427602799
collect_time: 0.7990693875721523
reward_mean: 558.5714111328125
reward_std: 417.3059387207031
reward_max: 1309.0
reward_min: 219.0
total_envstep_count: 236382
total_train_sample_count: 236341
total_episode_count: 1244
total_duration: 308.06764633740676
[2024-11-19 22:11:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1254
train_sample_count: 1254
avg_envstep_per_episode: 125.4
avg_sample_per_episode: 125.4
avg_envstep_per_sec: 798.5887702701639
avg_train_sample_per_sec: 798.5887702701639
avg_episode_per_sec: 6.368331501356969
collect_time: 1.5702700146606992
reward_mean: 624.7999877929688
reward_std: 492.725830078125
reward_max: 1408.0
reward_min: 227.0
total_envstep_count: 237429
total_train_sample_count: 237391
total_episode_count: 1254
total_duration: 309.63791635206746
[2024-11-19 22:11:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 765
train_sample_count: 765
avg_envstep_per_episode: 127.5
avg_sample_per_episode: 127.5
avg_envstep_per_sec: 805.3610946550909
avg_train_sample_per_sec: 805.3610946550909
avg_episode_per_sec: 6.316557605137968
collect_time: 0.9498844742774963
reward_mean: 547.5
reward_std: 222.41009521484375
reward_max: 794.0
reward_min: 245.0
total_envstep_count: 238409
total_train_sample_count: 238372
total_episode_count: 1260
total_duration: 310.58780082634496
[2024-11-19 22:11:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1208
train_sample_count: 1208
avg_envstep_per_episode: 241.6
avg_sample_per_episode: 241.6
avg_envstep_per_sec: 797.3828866583507
avg_train_sample_per_sec: 797.3828866583507
avg_episode_per_sec: 3.300425855373968
collect_time: 1.5149560144969398
reward_mean: 1329.5999755859375
reward_std: 260.73785400390625
reward_max: 1693.0
reward_min: 1038.0
total_envstep_count: 239420
total_train_sample_count: 239376
total_episode_count: 1265
total_duration: 312.1027568408419
[2024-11-19 22:11:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 770
train_sample_count: 770
avg_envstep_per_episode: 154.0
avg_sample_per_episode: 154.0
avg_envstep_per_sec: 806.1949402084292
avg_train_sample_per_sec: 806.1949402084292
avg_episode_per_sec: 5.2350320792755145
collect_time: 0.9551039849008832
reward_mean: 662.5999755859375
reward_std: 421.73004150390625
reward_max: 1383.0
reward_min: 240.0
total_envstep_count: 240408
total_train_sample_count: 240374
total_episode_count: 1270
total_duration: 313.05786082574275
[2024-11-19 22:11:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1493
train_sample_count: 1493
avg_envstep_per_episode: 149.3
avg_sample_per_episode: 149.3
avg_envstep_per_sec: 802.3204578343757
avg_train_sample_per_sec: 802.3204578343757
avg_episode_per_sec: 5.373881164329375
collect_time: 1.860852462904794
reward_mean: 781.7999877929688
reward_std: 364.8067321777344
reward_max: 1654.0
reward_min: 246.0
total_envstep_count: 241462
total_train_sample_count: 241423
total_episode_count: 1280
total_duration: 314.91871328864755
[2024-11-19 22:11:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1132
train_sample_count: 1132
avg_envstep_per_episode: 102.9090909090909
avg_sample_per_episode: 102.9090909090909
avg_envstep_per_sec: 802.075791339723
avg_train_sample_per_sec: 802.075791339723
avg_episode_per_sec: 7.794022707364799
collect_time: 1.4113379461424689
reward_mean: 649.1818237304688
reward_std: 319.1622009277344
reward_max: 1319.0
reward_min: 247.0
total_envstep_count: 242461
total_train_sample_count: 242423
total_episode_count: 1291
total_duration: 316.33005123479
[2024-11-19 22:11:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 866
train_sample_count: 866
avg_envstep_per_episode: 96.22222222222223
avg_sample_per_episode: 96.22222222222223
avg_envstep_per_sec: 790.0143140097894
avg_train_sample_per_sec: 790.0143140097894
avg_episode_per_sec: 8.210310422734532
collect_time: 1.0961826699120658
reward_mean: 580.2222290039062
reward_std: 196.63433837890625
reward_max: 811.0
reward_min: 235.0
total_envstep_count: 243484
total_train_sample_count: 243445
total_episode_count: 1300
total_duration: 317.4262339047021
[2024-11-19 22:11:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 591
train_sample_count: 591
avg_envstep_per_episode: 147.75
avg_sample_per_episode: 147.75
avg_envstep_per_sec: 796.6874187370104
avg_train_sample_per_sec: 796.6874187370104
avg_episode_per_sec: 5.3921314296921175
collect_time: 0.7418216807501656
reward_mean: 825.0
reward_std: 436.1490478515625
reward_max: 1417.0
reward_min: 251.0
total_envstep_count: 244441
total_train_sample_count: 244420
total_episode_count: 1304
total_duration: 318.16805558545224
[2024-11-19 22:11:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1286
train_sample_count: 1286
avg_envstep_per_episode: 142.88888888888889
avg_sample_per_episode: 142.88888888888889
avg_envstep_per_sec: 798.5454876848474
avg_train_sample_per_sec: 798.5454876848474
avg_episode_per_sec: 5.588576507903286
collect_time: 1.6104279841695512
reward_mean: 774.5555419921875
reward_std: 512.8137817382812
reward_max: 1810.0
reward_min: 181.0
total_envstep_count: 245458
total_train_sample_count: 245418
total_episode_count: 1313
total_duration: 319.7784835696218
[2024-11-19 22:11:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1054
train_sample_count: 1054
avg_envstep_per_episode: 105.4
avg_sample_per_episode: 105.4
avg_envstep_per_sec: 794.6498298702244
avg_train_sample_per_sec: 794.6498298702244
avg_episode_per_sec: 7.539372199907253
collect_time: 1.3263703840119496
reward_mean: 648.5999755859375
reward_std: 407.8000183105469
reward_max: 1325.0
reward_min: 235.0
total_envstep_count: 246489
total_train_sample_count: 246436
total_episode_count: 1323
total_duration: 321.1048539536338
[2024-11-19 22:11:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1026
train_sample_count: 1026
avg_envstep_per_episode: 128.25
avg_sample_per_episode: 128.25
avg_envstep_per_sec: 796.2365538242412
avg_train_sample_per_sec: 796.2365538242412
avg_episode_per_sec: 6.208472154574981
collect_time: 1.2885617911815639
reward_mean: 724.75
reward_std: 476.115478515625
reward_max: 1335.0
reward_min: 172.0
total_envstep_count: 247482
total_train_sample_count: 247438
total_episode_count: 1331
total_duration: 322.39341574481534
[2024-11-19 22:11:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 988
train_sample_count: 988
avg_envstep_per_episode: 164.66666666666666
avg_sample_per_episode: 164.66666666666666
avg_envstep_per_sec: 810.4322238528868
avg_train_sample_per_sec: 810.4322238528868
avg_episode_per_sec: 4.921653181292835
collect_time: 1.2191025614738464
reward_mean: 880.0
reward_std: 393.9991455078125
reward_max: 1340.0
reward_min: 245.0
total_envstep_count: 248461
total_train_sample_count: 248426
total_episode_count: 1337
total_duration: 323.6125183062892
[2024-11-19 22:12:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1153
train_sample_count: 1153
avg_envstep_per_episode: 115.3
avg_sample_per_episode: 115.3
avg_envstep_per_sec: 801.8477687784513
avg_train_sample_per_sec: 801.8477687784513
avg_episode_per_sec: 6.954447257402006
collect_time: 1.4379288000719888
reward_mean: 652.0999755859375
reward_std: 503.013427734375
reward_max: 1822.0
reward_min: 240.0
total_envstep_count: 249467
total_train_sample_count: 249423
total_episode_count: 1347
total_duration: 325.05044710636116
[2024-11-19 22:12:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 789
train_sample_count: 789
avg_envstep_per_episode: 112.71428571428571
avg_sample_per_episode: 112.71428571428571
avg_envstep_per_sec: 789.9979061516846
avg_train_sample_per_sec: 789.9979061516846
avg_episode_per_sec: 7.008853413259559
collect_time: 0.9987368243081229
reward_mean: 689.8571166992188
reward_std: 227.6064453125
reward_max: 1038.0
reward_min: 233.0
total_envstep_count: 250493
total_train_sample_count: 250464
total_episode_count: 1354
total_duration: 326.0491839306693
[2024-11-19 22:12:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1072
train_sample_count: 1072
avg_envstep_per_episode: 97.45454545454545
avg_sample_per_episode: 97.45454545454545
avg_envstep_per_sec: 811.6185329946903
avg_train_sample_per_sec: 811.6185329946903
avg_episode_per_sec: 8.328175245281336
collect_time: 1.3208175471850803
reward_mean: 463.5454406738281
reward_std: 268.45562744140625
reward_max: 1035.0
reward_min: 218.0
total_envstep_count: 251509
total_train_sample_count: 251464
total_episode_count: 1365
total_duration: 327.3700014778544
[2024-11-19 22:12:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1074
train_sample_count: 1074
avg_envstep_per_episode: 82.61538461538461
avg_sample_per_episode: 82.61538461538461
avg_envstep_per_sec: 802.8463085110393
avg_train_sample_per_sec: 802.8463085110393
avg_episode_per_sec: 9.717878967079619
collect_time: 1.3377404723848616
reward_mean: 528.2307739257812
reward_std: 403.16326904296875
reward_max: 1418.0
reward_min: 227.0
total_envstep_count: 252505
total_train_sample_count: 252478
total_episode_count: 1378
total_duration: 328.7077419502392
[2024-11-19 22:12:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1015
train_sample_count: 1015
avg_envstep_per_episode: 92.27272727272727
avg_sample_per_episode: 92.27272727272727
avg_envstep_per_sec: 805.8479867682654
avg_train_sample_per_sec: 805.8479867682654
avg_episode_per_sec: 8.733327935419625
collect_time: 1.2595427632331848
reward_mean: 421.2727355957031
reward_std: 227.50709533691406
reward_max: 797.0
reward_min: 193.0
total_envstep_count: 253521
total_train_sample_count: 253493
total_episode_count: 1389
total_duration: 329.9672847134724
[2024-11-19 22:12:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1076
train_sample_count: 1076
avg_envstep_per_episode: 89.66666666666667
avg_sample_per_episode: 89.66666666666667
avg_envstep_per_sec: 809.0065983409033
avg_train_sample_per_sec: 809.0065983409033
avg_episode_per_sec: 9.022378420158773
collect_time: 1.3300262348992482
reward_mean: 518.4166870117188
reward_std: 229.87803649902344
reward_max: 1035.0
reward_min: 232.0
total_envstep_count: 254551
total_train_sample_count: 254521
total_episode_count: 1401
total_duration: 331.29731094837166
[2024-11-19 22:12:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1170
train_sample_count: 1170
avg_envstep_per_episode: 97.5
avg_sample_per_episode: 97.5
avg_envstep_per_sec: 800.9489241999833
avg_train_sample_per_sec: 800.9489241999833
avg_episode_per_sec: 8.21486076102547
collect_time: 1.4607673031943182
reward_mean: 526.25
reward_std: 332.5319519042969
reward_max: 1334.0
reward_min: 227.0
total_envstep_count: 255589
total_train_sample_count: 255547
total_episode_count: 1413
total_duration: 332.75807825156596
[2024-11-19 22:12:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 705
train_sample_count: 705
avg_envstep_per_episode: 88.125
avg_sample_per_episode: 88.125
avg_envstep_per_sec: 791.9568278892334
avg_train_sample_per_sec: 791.9568278892334
avg_episode_per_sec: 8.986744146260804
collect_time: 0.8902000401701246
reward_mean: 690.75
reward_std: 459.80914306640625
reward_max: 1433.0
reward_min: 249.0
total_envstep_count: 256589
total_train_sample_count: 256552
total_episode_count: 1421
total_duration: 333.64827829173606
[2024-11-19 22:12:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 867
train_sample_count: 867
avg_envstep_per_episode: 144.5
avg_sample_per_episode: 144.5
avg_envstep_per_sec: 798.5853818437002
avg_train_sample_per_sec: 798.5853818437002
avg_episode_per_sec: 5.5265424349045
collect_time: 1.0856697601931435
reward_mean: 706.6666870117188
reward_std: 248.51805114746094
reward_max: 1036.0
reward_min: 235.0
total_envstep_count: 257559
total_train_sample_count: 257527
total_episode_count: 1427
total_duration: 334.7339480519292
[2024-11-19 22:12:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 626
train_sample_count: 626
avg_envstep_per_episode: 125.2
avg_sample_per_episode: 125.2
avg_envstep_per_sec: 809.4670418955776
avg_train_sample_per_sec: 809.4670418955776
avg_episode_per_sec: 6.465391708431132
collect_time: 0.7733483484813145
reward_mean: 571.4000244140625
reward_std: 182.41995239257812
reward_max: 793.0
reward_min: 236.0
total_envstep_count: 258516
total_train_sample_count: 258501
total_episode_count: 1432
total_duration: 335.5072964004105
[2024-11-19 22:12:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 16
envstep_count: 1976
train_sample_count: 1976
avg_envstep_per_episode: 123.5
avg_sample_per_episode: 123.5
avg_envstep_per_sec: 801.6858928397899
avg_train_sample_per_sec: 801.6858928397899
avg_episode_per_sec: 6.491383747690606
collect_time: 2.4648057520389557
reward_mean: 678.375
reward_std: 422.1150207519531
reward_max: 1420.0
reward_min: 162.0
total_envstep_count: 259566
total_train_sample_count: 259517
total_episode_count: 1448
total_duration: 337.97210215244945
[2024-11-19 22:12:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 694
train_sample_count: 694
avg_envstep_per_episode: 69.4
avg_sample_per_episode: 69.4
avg_envstep_per_sec: 793.1817789186769
avg_train_sample_per_sec: 793.1817789186769
avg_episode_per_sec: 11.429132261076036
collect_time: 0.8749570633683886
reward_mean: 472.29998779296875
reward_std: 258.1526794433594
reward_max: 1047.0
reward_min: 240.0
total_envstep_count: 260542
total_train_sample_count: 260523
total_episode_count: 1458
total_duration: 338.84705921581786
[2024-11-19 22:12:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1041
train_sample_count: 1041
avg_envstep_per_episode: 104.1
avg_sample_per_episode: 104.1
avg_envstep_per_sec: 802.4724489355167
avg_train_sample_per_sec: 802.4724489355167
avg_episode_per_sec: 7.7086690579780655
collect_time: 1.2972407979624612
reward_mean: 666.4000244140625
reward_std: 398.8849792480469
reward_max: 1352.0
reward_min: 240.0
total_envstep_count: 261564
total_train_sample_count: 261528
total_episode_count: 1468
total_duration: 340.1443000137803
[2024-11-19 22:12:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 701
train_sample_count: 701
avg_envstep_per_episode: 100.14285714285714
avg_sample_per_episode: 100.14285714285714
avg_envstep_per_sec: 807.4384926836435
avg_train_sample_per_sec: 807.4384926836435
avg_episode_per_sec: 8.062866546056354
collect_time: 0.8681775842394148
reward_mean: 682.7142944335938
reward_std: 425.20068359375
reward_max: 1345.0
reward_min: 237.0
total_envstep_count: 262581
total_train_sample_count: 262541
total_episode_count: 1475
total_duration: 341.0124775980197
[2024-11-19 22:12:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1089
train_sample_count: 1089
avg_envstep_per_episode: 136.125
avg_sample_per_episode: 136.125
avg_envstep_per_sec: 802.250093815757
avg_train_sample_per_sec: 802.250093815757
avg_episode_per_sec: 5.893480946304918
collect_time: 1.357432063136782
reward_mean: 740.5
reward_std: 376.8464660644531
reward_max: 1410.0
reward_min: 235.0
total_envstep_count: 263557
total_train_sample_count: 263522
total_episode_count: 1483
total_duration: 342.3699096611565
[2024-11-19 22:12:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1319
train_sample_count: 1319
avg_envstep_per_episode: 109.91666666666667
avg_sample_per_episode: 109.91666666666667
avg_envstep_per_sec: 806.6431279405857
avg_train_sample_per_sec: 806.6431279405857
avg_episode_per_sec: 7.338678950179704
collect_time: 1.6351716816425323
reward_mean: 620.0
reward_std: 331.0500793457031
reward_max: 1323.0
reward_min: 230.0
total_envstep_count: 264619
total_train_sample_count: 264577
total_episode_count: 1495
total_duration: 344.00508134279903
[2024-11-19 22:12:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 758
train_sample_count: 758
avg_envstep_per_episode: 94.75
avg_sample_per_episode: 94.75
avg_envstep_per_sec: 796.4167373600574
avg_train_sample_per_sec: 796.4167373600574
avg_episode_per_sec: 8.405453692454431
collect_time: 0.9517630210944583
reward_mean: 579.875
reward_std: 312.69970703125
reward_max: 1043.0
reward_min: 228.0
total_envstep_count: 265619
total_train_sample_count: 265587
total_episode_count: 1503
total_duration: 344.9568443638935
[2024-11-19 22:13:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 548
train_sample_count: 548
avg_envstep_per_episode: 137.0
avg_sample_per_episode: 137.0
avg_envstep_per_sec: 813.2562917016421
avg_train_sample_per_sec: 813.2562917016421
avg_episode_per_sec: 5.936177311690819
collect_time: 0.6738343196255822
reward_mean: 580.5
reward_std: 340.0746154785156
reward_max: 1029.0
reward_min: 251.0
total_envstep_count: 266616
total_train_sample_count: 266567
total_episode_count: 1507
total_duration: 345.6306786835191
[2024-11-19 22:13:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1532
train_sample_count: 1532
avg_envstep_per_episode: 170.22222222222223
avg_sample_per_episode: 170.22222222222223
avg_envstep_per_sec: 805.2331281274547
avg_train_sample_per_sec: 805.2331281274547
avg_episode_per_sec: 4.730481823203063
collect_time: 1.9025546099458421
reward_mean: 830.888916015625
reward_std: 436.87054443359375
reward_max: 1545.0
reward_min: 241.0
total_envstep_count: 267601
total_train_sample_count: 267571
total_episode_count: 1516
total_duration: 347.53323329346495
[2024-11-19 22:13:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 848
train_sample_count: 848
avg_envstep_per_episode: 106.0
avg_sample_per_episode: 106.0
avg_envstep_per_sec: 802.996955249938
avg_train_sample_per_sec: 802.996955249938
avg_episode_per_sec: 7.575442974056019
collect_time: 1.0560438547815596
reward_mean: 640.875
reward_std: 344.2181091308594
reward_max: 1059.0
reward_min: 243.0
total_envstep_count: 268611
total_train_sample_count: 268563
total_episode_count: 1524
total_duration: 348.5892771482465
[2024-11-19 22:13:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1391
train_sample_count: 1391
avg_envstep_per_episode: 154.55555555555554
avg_sample_per_episode: 154.55555555555554
avg_envstep_per_sec: 797.8355405518465
avg_train_sample_per_sec: 797.8355405518465
avg_episode_per_sec: 5.162127868415974
collect_time: 1.743467079741614
reward_mean: 961.5555419921875
reward_std: 375.42779541015625
reward_max: 1660.0
reward_min: 609.0
total_envstep_count: 269611
total_train_sample_count: 269570
total_episode_count: 1533
total_duration: 350.3327442279881
[2024-11-19 22:13:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 911
train_sample_count: 911
avg_envstep_per_episode: 75.91666666666667
avg_sample_per_episode: 75.91666666666667
avg_envstep_per_sec: 789.4854694168475
avg_train_sample_per_sec: 789.4854694168475
avg_episode_per_sec: 10.399369520309737
collect_time: 1.1539161077567508
reward_mean: 497.0833435058594
reward_std: 242.14231872558594
reward_max: 1037.0
reward_min: 233.0
total_envstep_count: 270614
total_train_sample_count: 270601
total_episode_count: 1545
total_duration: 351.48666033574483
[2024-11-19 22:13:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 758
train_sample_count: 758
avg_envstep_per_episode: 126.33333333333333
avg_sample_per_episode: 126.33333333333333
avg_envstep_per_sec: 795.1917779622171
avg_train_sample_per_sec: 795.1917779622171
avg_episode_per_sec: 6.294394020809107
collect_time: 0.9532291718891688
reward_mean: 708.0
reward_std: 406.67022705078125
reward_max: 1323.0
reward_min: 220.0
total_envstep_count: 271656
total_train_sample_count: 271623
total_episode_count: 1551
total_duration: 352.439889507634
[2024-11-19 22:13:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1218
train_sample_count: 1218
avg_envstep_per_episode: 152.25
avg_sample_per_episode: 152.25
avg_envstep_per_sec: 802.3898812380037
avg_train_sample_per_sec: 802.3898812380037
avg_episode_per_sec: 5.270212684650271
collect_time: 1.5179653040000372
reward_mean: 789.625
reward_std: 477.8174133300781
reward_max: 1331.0
reward_min: 231.0
total_envstep_count: 272665
total_train_sample_count: 272625
total_episode_count: 1559
total_duration: 353.95785481163404
[2024-11-19 22:13:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 718
train_sample_count: 718
avg_envstep_per_episode: 89.75
avg_sample_per_episode: 89.75
avg_envstep_per_sec: 806.1893509769536
avg_train_sample_per_sec: 806.1893509769536
avg_episode_per_sec: 8.982611152946559
collect_time: 0.8906096305165973
reward_mean: 584.75
reward_std: 415.4587097167969
reward_max: 1424.0
reward_min: 233.0
total_envstep_count: 273659
total_train_sample_count: 273619
total_episode_count: 1567
total_duration: 354.84846444215066
[2024-11-19 22:13:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1150
train_sample_count: 1150
avg_envstep_per_episode: 127.77777777777777
avg_sample_per_episode: 127.77777777777777
avg_envstep_per_sec: 798.997397995646
avg_train_sample_per_sec: 798.997397995646
avg_episode_per_sec: 6.253023114748534
collect_time: 1.4393038111073633
reward_mean: 705.4444580078125
reward_std: 458.18072509765625
reward_max: 1897.0
reward_min: 239.0
total_envstep_count: 274675
total_train_sample_count: 274637
total_episode_count: 1576
total_duration: 356.28776825325804
[2024-11-19 22:13:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 1316
train_sample_count: 1316
avg_envstep_per_episode: 87.73333333333333
avg_sample_per_episode: 87.73333333333333
avg_envstep_per_sec: 795.2157070437856
avg_train_sample_per_sec: 795.2157070437856
avg_episode_per_sec: 9.064008818888134
collect_time: 1.6548968894141063
reward_mean: 540.933349609375
reward_std: 380.7106628417969
reward_max: 1343.0
reward_min: 224.0
total_envstep_count: 275735
total_train_sample_count: 275689
total_episode_count: 1591
total_duration: 357.9426651426721
[2024-11-19 22:13:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 826
train_sample_count: 826
avg_envstep_per_episode: 82.6
avg_sample_per_episode: 82.6
avg_envstep_per_sec: 804.6843044464648
avg_train_sample_per_sec: 804.6843044464648
avg_episode_per_sec: 9.741940731797394
collect_time: 1.0264895132609777
reward_mean: 402.5
reward_std: 292.00592041015625
reward_max: 1043.0
reward_min: 128.0
total_envstep_count: 276728
total_train_sample_count: 276695
total_episode_count: 1601
total_duration: 358.9691546559331
[2024-11-19 22:13:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1022
train_sample_count: 1022
avg_envstep_per_episode: 113.55555555555556
avg_sample_per_episode: 113.55555555555556
avg_envstep_per_sec: 806.8562474964559
avg_train_sample_per_sec: 806.8562474964559
avg_episode_per_sec: 7.10538769810969
collect_time: 1.2666444650718145
reward_mean: 679.3333129882812
reward_std: 322.53717041015625
reward_max: 1325.0
reward_min: 241.0
total_envstep_count: 277720
total_train_sample_count: 277669
total_episode_count: 1610
total_duration: 360.2357991210049
[2024-11-19 22:13:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 950
train_sample_count: 950
avg_envstep_per_episode: 79.16666666666667
avg_sample_per_episode: 79.16666666666667
avg_envstep_per_sec: 795.942537091732
avg_train_sample_per_sec: 795.942537091732
avg_episode_per_sec: 10.05401099484293
collect_time: 1.1935534988130845
reward_mean: 576.1666870117188
reward_std: 501.2870788574219
reward_max: 1912.0
reward_min: 215.0
total_envstep_count: 278773
total_train_sample_count: 278715
total_episode_count: 1622
total_duration: 361.42935261981796
[2024-11-19 22:13:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 953
train_sample_count: 953
avg_envstep_per_episode: 158.83333333333334
avg_sample_per_episode: 158.83333333333334
avg_envstep_per_sec: 803.084741145599
avg_train_sample_per_sec: 803.084741145599
avg_episode_per_sec: 5.0561473734245475
collect_time: 1.1866742713110787
reward_mean: 813.8333129882812
reward_std: 170.697021484375
reward_max: 1030.0
reward_min: 604.0
total_envstep_count: 279745
total_train_sample_count: 279704
total_episode_count: 1628
total_duration: 362.616026891129
[2024-11-19 22:13:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1022
train_sample_count: 1022
avg_envstep_per_episode: 102.2
avg_sample_per_episode: 102.2
avg_envstep_per_sec: 805.3588133621889
avg_train_sample_per_sec: 805.3588133621889
avg_episode_per_sec: 7.880223222722005
collect_time: 1.2689995850835525
reward_mean: 603.0
reward_std: 357.30853271484375
reward_max: 1338.0
reward_min: 247.0
total_envstep_count: 280783
total_train_sample_count: 280726
total_episode_count: 1638
total_duration: 363.8850264762126
[2024-11-19 22:13:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 916
train_sample_count: 916
avg_envstep_per_episode: 101.77777777777777
avg_sample_per_episode: 101.77777777777777
avg_envstep_per_sec: 807.5342274812442
avg_train_sample_per_sec: 807.5342274812442
avg_episode_per_sec: 7.9342882612786
collect_time: 1.1343172448022025
reward_mean: 699.4444580078125
reward_std: 419.0099792480469
reward_max: 1343.0
reward_min: 229.0
total_envstep_count: 281790
total_train_sample_count: 281762
total_episode_count: 1647
total_duration: 365.0193437210148
[2024-11-19 22:13:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1383
train_sample_count: 1383
avg_envstep_per_episode: 125.72727272727273
avg_sample_per_episode: 125.72727272727273
avg_envstep_per_sec: 799.1933408600032
avg_train_sample_per_sec: 799.1933408600032
avg_episode_per_sec: 6.356563087100532
collect_time: 1.7304948994091578
reward_mean: 794.6363525390625
reward_std: 506.99298095703125
reward_max: 1574.0
reward_min: 230.0
total_envstep_count: 282806
total_train_sample_count: 282773
total_episode_count: 1658
total_duration: 366.749838620424
[2024-11-19 22:14:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 838
train_sample_count: 838
avg_envstep_per_episode: 69.83333333333333
avg_sample_per_episode: 69.83333333333333
avg_envstep_per_sec: 791.993736905471
avg_train_sample_per_sec: 791.993736905471
avg_episode_per_sec: 11.341199096498391
collect_time: 1.0580891753946031
reward_mean: 505.8333435058594
reward_std: 338.7409973144531
reward_max: 1050.0
reward_min: 234.0
total_envstep_count: 283834
total_train_sample_count: 283791
total_episode_count: 1670
total_duration: 367.8079277958186
[2024-11-19 22:14:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1062
train_sample_count: 1062
avg_envstep_per_episode: 106.2
avg_sample_per_episode: 106.2
avg_envstep_per_sec: 804.1436036082877
avg_train_sample_per_sec: 804.1436036082877
avg_episode_per_sec: 7.571973668627944
collect_time: 1.3206596374511719
reward_mean: 700.9000244140625
reward_std: 400.65032958984375
reward_max: 1342.0
reward_min: 228.0
total_envstep_count: 284842
total_train_sample_count: 284805
total_episode_count: 1680
total_duration: 369.1285874332698
[2024-11-19 22:14:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 884
train_sample_count: 884
avg_envstep_per_episode: 126.28571428571429
avg_sample_per_episode: 126.28571428571429
avg_envstep_per_sec: 808.1512327308784
avg_train_sample_per_sec: 808.1512327308784
avg_episode_per_sec: 6.3993875894979055
collect_time: 1.0938546700137002
reward_mean: 584.4285888671875
reward_std: 346.607177734375
reward_max: 1049.0
reward_min: 183.0
total_envstep_count: 285828
total_train_sample_count: 285797
total_episode_count: 1687
total_duration: 370.22244210328347
[2024-11-19 22:14:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1024
train_sample_count: 1024
avg_envstep_per_episode: 93.0909090909091
avg_sample_per_episode: 93.0909090909091
avg_envstep_per_sec: 794.2784613477934
avg_train_sample_per_sec: 794.2784613477934
avg_episode_per_sec: 8.5322881590095
collect_time: 1.2892204054764336
reward_mean: 585.1818237304688
reward_std: 332.3620300292969
reward_max: 1329.0
reward_min: 246.0
total_envstep_count: 286850
total_train_sample_count: 286821
total_episode_count: 1698
total_duration: 371.5116625087599
[2024-11-19 22:14:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1076
train_sample_count: 1076
avg_envstep_per_episode: 134.5
avg_sample_per_episode: 134.5
avg_envstep_per_sec: 791.580593402409
avg_train_sample_per_sec: 791.580593402409
avg_episode_per_sec: 5.885357571765123
collect_time: 1.3593056840556008
reward_mean: 748.5
reward_std: 324.7175598144531
reward_max: 1044.0
reward_min: 243.0
total_envstep_count: 287859
total_train_sample_count: 287837
total_episode_count: 1706
total_duration: 372.8709681928155
[2024-11-19 22:14:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 653
train_sample_count: 653
avg_envstep_per_episode: 130.6
avg_sample_per_episode: 130.6
avg_envstep_per_sec: 797.6845329484728
avg_train_sample_per_sec: 797.6845329484728
avg_episode_per_sec: 6.10784481583823
collect_time: 0.8186193576880864
reward_mean: 605.5999755859375
reward_std: 308.0419616699219
reward_max: 1021.0
reward_min: 249.0
total_envstep_count: 288840
total_train_sample_count: 288802
total_episode_count: 1711
total_duration: 373.6895875505036
[2024-11-19 22:14:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1122
train_sample_count: 1122
avg_envstep_per_episode: 140.25
avg_sample_per_episode: 140.25
avg_envstep_per_sec: 808.5483690018933
avg_train_sample_per_sec: 808.5483690018933
avg_episode_per_sec: 5.765050759371788
collect_time: 1.3876720837184358
reward_mean: 917.625
reward_std: 313.1429138183594
reward_max: 1416.0
reward_min: 614.0
total_envstep_count: 289856
total_train_sample_count: 289804
total_episode_count: 1719
total_duration: 375.077259634222
[2024-11-19 22:14:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 985
train_sample_count: 985
avg_envstep_per_episode: 109.44444444444444
avg_sample_per_episode: 109.44444444444444
avg_envstep_per_sec: 807.974374145961
avg_train_sample_per_sec: 807.974374145961
avg_episode_per_sec: 7.382506971892028
collect_time: 1.219098069838115
reward_mean: 568.888916015625
reward_std: 370.55828857421875
reward_max: 1336.0
reward_min: 228.0
total_envstep_count: 290855
total_train_sample_count: 290801
total_episode_count: 1728
total_duration: 376.29635770406014
[2024-11-19 22:14:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1084
train_sample_count: 1084
avg_envstep_per_episode: 120.44444444444444
avg_sample_per_episode: 120.44444444444444
avg_envstep_per_sec: 802.1637054146064
avg_train_sample_per_sec: 802.1637054146064
avg_episode_per_sec: 6.660030764512414
collect_time: 1.3513451090880804
reward_mean: 610.888916015625
reward_std: 312.3038024902344
reward_max: 1124.0
reward_min: 225.0
total_envstep_count: 291849
total_train_sample_count: 291801
total_episode_count: 1737
total_duration: 377.6477028131482
[2024-11-19 22:14:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 997
train_sample_count: 997
avg_envstep_per_episode: 166.16666666666666
avg_sample_per_episode: 166.16666666666666
avg_envstep_per_sec: 801.6280926153618
avg_train_sample_per_sec: 801.6280926153618
avg_episode_per_sec: 4.824241279530763
collect_time: 1.243718888078417
reward_mean: 854.1666870117188
reward_std: 399.5211486816406
reward_max: 1328.0
reward_min: 228.0
total_envstep_count: 292819
total_train_sample_count: 292786
total_episode_count: 1743
total_duration: 378.89142170122665
[2024-11-19 22:14:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1311
train_sample_count: 1311
avg_envstep_per_episode: 100.84615384615384
avg_sample_per_episode: 100.84615384615384
avg_envstep_per_sec: 802.7305429313013
avg_train_sample_per_sec: 802.7305429313013
avg_episode_per_sec: 7.959951989402683
collect_time: 1.6331756796155656
reward_mean: 657.3846435546875
reward_std: 454.1640930175781
reward_max: 1437.0
reward_min: 246.0
total_envstep_count: 293847
total_train_sample_count: 293809
total_episode_count: 1756
total_duration: 380.52459738084224
[2024-11-19 22:14:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 939
train_sample_count: 939
avg_envstep_per_episode: 134.14285714285714
avg_sample_per_episode: 134.14285714285714
avg_envstep_per_sec: 806.5148253722638
avg_train_sample_per_sec: 806.5148253722638
avg_episode_per_sec: 6.012357590634553
collect_time: 1.164268740585872
reward_mean: 858.0
reward_std: 382.251220703125
reward_max: 1565.0
reward_min: 249.0
total_envstep_count: 294882
total_train_sample_count: 294832
total_episode_count: 1763
total_duration: 381.68886612142813
[2024-11-19 22:14:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1027
train_sample_count: 1027
avg_envstep_per_episode: 93.36363636363636
avg_sample_per_episode: 93.36363636363636
avg_envstep_per_sec: 806.813130858086
avg_train_sample_per_sec: 806.813130858086
avg_episode_per_sec: 8.64162068105058
collect_time: 1.2729093773024422
reward_mean: 621.6363525390625
reward_std: 447.6598205566406
reward_max: 1339.0
reward_min: 235.0
total_envstep_count: 295868
total_train_sample_count: 295823
total_episode_count: 1774
total_duration: 382.96177549873056
[2024-11-19 22:14:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 816
train_sample_count: 816
avg_envstep_per_episode: 90.66666666666667
avg_sample_per_episode: 90.66666666666667
avg_envstep_per_sec: 799.5925168306845
avg_train_sample_per_sec: 799.5925168306845
avg_episode_per_sec: 8.819035112103137
collect_time: 1.0205198058060239
reward_mean: 681.6666870117188
reward_std: 452.78472900390625
reward_max: 1420.0
reward_min: 243.0
total_envstep_count: 296892
total_train_sample_count: 296843
total_episode_count: 1783
total_duration: 383.9822953045366
[2024-11-19 22:14:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1033
train_sample_count: 1033
avg_envstep_per_episode: 114.77777777777777
avg_sample_per_episode: 114.77777777777777
avg_envstep_per_sec: 792.4587717016794
avg_train_sample_per_sec: 792.4587717016794
avg_episode_per_sec: 6.904287459162744
collect_time: 1.3035378456115723
reward_mean: 802.6666870117188
reward_std: 365.1145935058594
reward_max: 1327.0
reward_min: 234.0
total_envstep_count: 297861
total_train_sample_count: 297828
total_episode_count: 1792
total_duration: 385.28583315014816
[2024-11-19 22:14:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1050
train_sample_count: 1050
avg_envstep_per_episode: 105.0
avg_sample_per_episode: 105.0
avg_envstep_per_sec: 805.0057308883162
avg_train_sample_per_sec: 805.0057308883162
avg_episode_per_sec: 7.666721246555392
collect_time: 1.3043385403496879
reward_mean: 716.5
reward_std: 373.3869934082031
reward_max: 1345.0
reward_min: 231.0
total_envstep_count: 298869
total_train_sample_count: 298830
total_episode_count: 1802
total_duration: 386.59017169049787
[2024-11-19 22:14:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1150
train_sample_count: 1150
avg_envstep_per_episode: 95.83333333333333
avg_sample_per_episode: 95.83333333333333
avg_envstep_per_sec: 796.1288509498503
avg_train_sample_per_sec: 796.1288509498503
avg_episode_per_sec: 8.30743148817235
collect_time: 1.4444897941180639
reward_mean: 635.75
reward_std: 342.2177734375
reward_max: 1314.0
reward_min: 236.0
total_envstep_count: 299858
total_train_sample_count: 299848
total_episode_count: 1814
total_duration: 388.0346614846159
[2024-11-19 22:15:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 958
train_sample_count: 958
avg_envstep_per_episode: 95.8
avg_sample_per_episode: 95.8
avg_envstep_per_sec: 798.7211751340731
avg_train_sample_per_sec: 798.7211751340731
avg_episode_per_sec: 8.337381786368194
collect_time: 1.1994173058441708
reward_mean: 610.2999877929688
reward_std: 335.52825927734375
reward_max: 1041.0
reward_min: 232.0
total_envstep_count: 300928
total_train_sample_count: 300890
total_episode_count: 1824
total_duration: 389.2340787904601
[2024-11-19 22:15:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 658
train_sample_count: 658
avg_envstep_per_episode: 131.6
avg_sample_per_episode: 131.6
avg_envstep_per_sec: 795.8899647025299
avg_train_sample_per_sec: 795.8899647025299
avg_episode_per_sec: 6.047796084365729
collect_time: 0.8267474515097482
reward_mean: 783.4000244140625
reward_std: 204.7960968017578
reward_max: 1046.0
reward_min: 610.0
total_envstep_count: 301900
total_train_sample_count: 301872
total_episode_count: 1829
total_duration: 390.06082624196983
[2024-11-19 22:15:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1096
train_sample_count: 1096
avg_envstep_per_episode: 137.0
avg_sample_per_episode: 137.0
avg_envstep_per_sec: 800.0919269655019
avg_train_sample_per_sec: 800.0919269655019
avg_episode_per_sec: 5.840087058142349
collect_time: 1.3698425931589946
reward_mean: 667.25
reward_std: 413.9510192871094
reward_max: 1310.0
reward_min: 231.0
total_envstep_count: 302916
total_train_sample_count: 302884
total_episode_count: 1837
total_duration: 391.4306688351288
[2024-11-19 22:15:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 928
train_sample_count: 928
avg_envstep_per_episode: 132.57142857142858
avg_sample_per_episode: 132.57142857142858
avg_envstep_per_sec: 799.4557509506058
avg_train_sample_per_sec: 799.4557509506058
avg_episode_per_sec: 6.030377431739483
collect_time: 1.1607896983623505
reward_mean: 798.2857055664062
reward_std: 351.3466796875
reward_max: 1323.0
reward_min: 241.0
total_envstep_count: 303903
total_train_sample_count: 303860
total_episode_count: 1844
total_duration: 392.59145853349116
[2024-11-19 22:15:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1151
train_sample_count: 1151
avg_envstep_per_episode: 115.1
avg_sample_per_episode: 115.1
avg_envstep_per_sec: 805.0216183549629
avg_train_sample_per_sec: 805.0216183549629
avg_episode_per_sec: 6.994106154256846
collect_time: 1.4297752678394318
reward_mean: 677.9000244140625
reward_std: 454.7224426269531
reward_max: 1691.0
reward_min: 235.0
total_envstep_count: 304926
total_train_sample_count: 304891
total_episode_count: 1854
total_duration: 394.0212338013306
[2024-11-19 22:15:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 910
train_sample_count: 910
avg_envstep_per_episode: 75.83333333333333
avg_sample_per_episode: 75.83333333333333
avg_envstep_per_sec: 802.3937547527948
avg_train_sample_per_sec: 802.3937547527948
avg_episode_per_sec: 10.581016546190702
collect_time: 1.1341065338679723
reward_mean: 484.1666564941406
reward_std: 308.0670471191406
reward_max: 1318.0
reward_min: 223.0
total_envstep_count: 305954
total_train_sample_count: 305921
total_episode_count: 1866
total_duration: 395.15534033519856
[2024-11-19 22:15:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 933
train_sample_count: 933
avg_envstep_per_episode: 155.5
avg_sample_per_episode: 155.5
avg_envstep_per_sec: 795.2151296467327
avg_train_sample_per_sec: 795.2151296467327
avg_episode_per_sec: 5.11392366332304
collect_time: 1.1732674155916487
reward_mean: 742.8333129882812
reward_std: 406.92523193359375
reward_max: 1302.0
reward_min: 239.0
total_envstep_count: 306957
total_train_sample_count: 306914
total_episode_count: 1872
total_duration: 396.3286077507902
[2024-11-19 22:15:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 631
train_sample_count: 631
avg_envstep_per_episode: 210.33333333333334
avg_sample_per_episode: 210.33333333333334
avg_envstep_per_sec: 803.7955642665299
avg_train_sample_per_sec: 803.7955642665299
avg_episode_per_sec: 3.8215320012671787
collect_time: 0.7850254816668374
reward_mean: 758.6666870117188
reward_std: 38.51695251464844
reward_max: 808.0
reward_min: 714.0
total_envstep_count: 307946
total_train_sample_count: 307917
total_episode_count: 1875
total_duration: 397.113633232457
[2024-11-19 22:15:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1813
train_sample_count: 1813
avg_envstep_per_episode: 201.44444444444446
avg_sample_per_episode: 201.44444444444446
avg_envstep_per_sec: 787.0778600888683
avg_train_sample_per_sec: 787.0778600888683
avg_episode_per_sec: 3.907170844346285
collect_time: 2.3034569919109344
reward_mean: 1085.6666259765625
reward_std: 415.4769592285156
reward_max: 1696.0
reward_min: 232.0
total_envstep_count: 309021
total_train_sample_count: 308974
total_episode_count: 1884
total_duration: 399.41709022436794
[2024-11-19 22:15:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 18
envstep_count: 1220
train_sample_count: 1220
avg_envstep_per_episode: 67.77777777777777
avg_sample_per_episode: 67.77777777777777
avg_envstep_per_sec: 793.1418580774177
avg_train_sample_per_sec: 793.1418580774177
avg_episode_per_sec: 11.702092988027475
collect_time: 1.5381863755839211
reward_mean: 486.27777099609375
reward_std: 348.4704284667969
reward_max: 1574.0
reward_min: 229.0
total_envstep_count: 310035
total_train_sample_count: 310002
total_episode_count: 1902
total_duration: 400.95527659995184
[2024-11-19 22:15:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 724
train_sample_count: 724
avg_envstep_per_episode: 60.333333333333336
avg_sample_per_episode: 60.333333333333336
avg_envstep_per_sec: 799.9717209055797
avg_train_sample_per_sec: 799.9717209055797
avg_episode_per_sec: 13.259199794015133
collect_time: 0.9050319918564389
reward_mean: 434.25
reward_std: 248.39254760742188
reward_max: 1042.0
reward_min: 237.0
total_envstep_count: 311034
total_train_sample_count: 311026
total_episode_count: 1914
total_duration: 401.8603085918083
[2024-11-19 22:15:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1178
train_sample_count: 1178
avg_envstep_per_episode: 130.88888888888889
avg_sample_per_episode: 130.88888888888889
avg_envstep_per_sec: 795.1215501888479
avg_train_sample_per_sec: 795.1215501888479
avg_episode_per_sec: 6.074782641510723
collect_time: 1.4815344895635332
reward_mean: 803.888916015625
reward_std: 461.20770263671875
reward_max: 1565.0
reward_min: 240.0
total_envstep_count: 312066
total_train_sample_count: 312024
total_episode_count: 1923
total_duration: 403.34184308137185
[2024-11-19 22:15:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1053
train_sample_count: 1053
avg_envstep_per_episode: 95.72727272727273
avg_sample_per_episode: 95.72727272727273
avg_envstep_per_sec: 795.6968808823684
avg_train_sample_per_sec: 795.6968808823684
avg_episode_per_sec: 8.312123162114009
collect_time: 1.3233682640961237
reward_mean: 631.0
reward_std: 364.7257995605469
reward_max: 1424.0
reward_min: 228.0
total_envstep_count: 313129
total_train_sample_count: 313089
total_episode_count: 1934
total_duration: 404.665211345468
[2024-11-19 22:15:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 761
train_sample_count: 761
avg_envstep_per_episode: 76.1
avg_sample_per_episode: 76.1
avg_envstep_per_sec: 798.3347247075208
avg_train_sample_per_sec: 798.3347247075208
avg_episode_per_sec: 10.490600850295937
collect_time: 0.9532342467989241
reward_mean: 530.2999877929688
reward_std: 341.7142333984375
reward_max: 1333.0
reward_min: 236.0
total_envstep_count: 314163
total_train_sample_count: 314114
total_episode_count: 1944
total_duration: 405.6184455922669
[2024-11-19 22:15:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 842
train_sample_count: 842
avg_envstep_per_episode: 105.25
avg_sample_per_episode: 105.25
avg_envstep_per_sec: 802.9409035532113
avg_train_sample_per_sec: 802.9409035532113
avg_episode_per_sec: 7.628892195279918
collect_time: 1.0486450450760978
reward_mean: 686.25
reward_std: 466.7876281738281
reward_max: 1698.0
reward_min: 242.0
total_envstep_count: 315165
total_train_sample_count: 315124
total_episode_count: 1952
total_duration: 406.667090637343
[2024-11-19 22:15:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1304
train_sample_count: 1304
avg_envstep_per_episode: 144.88888888888889
avg_sample_per_episode: 144.88888888888889
avg_envstep_per_sec: 800.3291909045507
avg_train_sample_per_sec: 800.3291909045507
avg_episode_per_sec: 5.523744415752268
collect_time: 1.629329549414771
reward_mean: 844.5555419921875
reward_std: 441.1497802734375
reward_max: 1321.0
reward_min: 232.0
total_envstep_count: 316174
total_train_sample_count: 316128
total_episode_count: 1961
total_duration: 408.29642018675776
[2024-11-19 22:15:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 872
train_sample_count: 872
avg_envstep_per_episode: 145.33333333333334
avg_sample_per_episode: 145.33333333333334
avg_envstep_per_sec: 803.12696876413
avg_train_sample_per_sec: 803.12696876413
avg_episode_per_sec: 5.526102996083463
collect_time: 1.085756093263626
reward_mean: 798.0
reward_std: 429.8398742675781
reward_max: 1422.0
reward_min: 243.0
total_envstep_count: 317185
total_train_sample_count: 317144
total_episode_count: 1967
total_duration: 409.3821762800214
[2024-11-19 22:16:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 786
train_sample_count: 786
avg_envstep_per_episode: 87.33333333333333
avg_sample_per_episode: 87.33333333333333
avg_envstep_per_sec: 795.5817150225041
avg_train_sample_per_sec: 795.5817150225041
avg_episode_per_sec: 9.10971429415081
collect_time: 0.9879563408238548
reward_mean: 604.5555419921875
reward_std: 449.93310546875
reward_max: 1422.0
reward_min: 234.0
total_envstep_count: 318168
total_train_sample_count: 318134
total_episode_count: 1976
total_duration: 410.37013262084525
[2024-11-19 22:16:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1277
train_sample_count: 1277
avg_envstep_per_episode: 159.625
avg_sample_per_episode: 159.625
avg_envstep_per_sec: 797.2818513021663
avg_train_sample_per_sec: 797.2818513021663
avg_episode_per_sec: 4.994717940812318
collect_time: 1.601692046437945
reward_mean: 958.125
reward_std: 697.7996215820312
reward_max: 2337.0
reward_min: 248.0
total_envstep_count: 319171
total_train_sample_count: 319135
total_episode_count: 1984
total_duration: 411.9718246672832
[2024-11-19 22:16:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 616
train_sample_count: 616
avg_envstep_per_episode: 123.2
avg_sample_per_episode: 123.2
avg_envstep_per_sec: 802.2188316205802
avg_train_sample_per_sec: 802.2188316205802
avg_episode_per_sec: 6.5115164904267875
collect_time: 0.7678702814238412
reward_mean: 707.7999877929688
reward_std: 439.7096252441406
reward_max: 1299.0
reward_min: 249.0
total_envstep_count: 320182
total_train_sample_count: 320147
total_episode_count: 1989
total_duration: 412.73969494870704
[2024-11-19 22:16:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1460
train_sample_count: 1460
avg_envstep_per_episode: 182.5
avg_sample_per_episode: 182.5
avg_envstep_per_sec: 799.944291009912
avg_train_sample_per_sec: 799.944291009912
avg_episode_per_sec: 4.383256389095408
collect_time: 1.8251270949840548
reward_mean: 1037.25
reward_std: 381.8166198730469
reward_max: 1411.0
reward_min: 231.0
total_envstep_count: 321190
total_train_sample_count: 321151
total_episode_count: 1997
total_duration: 414.5648220436911
[2024-11-19 22:16:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 729
train_sample_count: 729
avg_envstep_per_episode: 104.14285714285714
avg_sample_per_episode: 104.14285714285714
avg_envstep_per_sec: 791.3305530297033
avg_train_sample_per_sec: 791.3305530297033
avg_episode_per_sec: 7.598510111396329
collect_time: 0.921233228274754
reward_mean: 628.7142944335938
reward_std: 298.59515380859375
reward_max: 1039.0
reward_min: 248.0
total_envstep_count: 322175
total_train_sample_count: 322144
total_episode_count: 2004
total_duration: 415.4860552719658
[2024-11-19 22:16:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 18
envstep_count: 1568
train_sample_count: 1568
avg_envstep_per_episode: 87.11111111111111
avg_sample_per_episode: 87.11111111111111
avg_envstep_per_sec: 795.630648018498
avg_train_sample_per_sec: 795.630648018498
avg_episode_per_sec: 9.133515092049084
collect_time: 1.97076370034899
reward_mean: 475.3888854980469
reward_std: 352.8468322753906
reward_max: 1322.0
reward_min: 207.0
total_envstep_count: 323224
total_train_sample_count: 323184
total_episode_count: 2022
total_duration: 417.4568189723148
[2024-11-19 22:16:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 944
train_sample_count: 944
avg_envstep_per_episode: 78.66666666666667
avg_sample_per_episode: 78.66666666666667
avg_envstep_per_sec: 797.8025635488414
avg_train_sample_per_sec: 797.8025635488414
avg_episode_per_sec: 10.141558011214086
collect_time: 1.1832501462527683
reward_mean: 478.0833435058594
reward_std: 257.86444091796875
reward_max: 1043.0
reward_min: 238.0
total_envstep_count: 324230
total_train_sample_count: 324188
total_episode_count: 2034
total_duration: 418.64006911856757
[2024-11-19 22:16:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 817
train_sample_count: 817
avg_envstep_per_episode: 116.71428571428571
avg_sample_per_episode: 116.71428571428571
avg_envstep_per_sec: 798.2967081622235
avg_train_sample_per_sec: 798.2967081622235
avg_episode_per_sec: 6.83975147752211
collect_time: 1.02342899782317
reward_mean: 746.0
reward_std: 407.7344970703125
reward_max: 1428.0
reward_min: 246.0
total_envstep_count: 325224
total_train_sample_count: 325197
total_episode_count: 2041
total_duration: 419.6634981163907
[2024-11-19 22:16:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 664
train_sample_count: 664
avg_envstep_per_episode: 132.8
avg_sample_per_episode: 132.8
avg_envstep_per_sec: 802.155028107546
avg_train_sample_per_sec: 802.155028107546
avg_episode_per_sec: 6.040324006833931
collect_time: 0.8277701650347028
reward_mean: 757.5999755859375
reward_std: 484.233642578125
reward_max: 1678.0
reward_min: 236.0
total_envstep_count: 326204
total_train_sample_count: 326173
total_episode_count: 2046
total_duration: 420.4912682814254
[2024-11-19 22:16:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 936
train_sample_count: 936
avg_envstep_per_episode: 133.71428571428572
avg_sample_per_episode: 133.71428571428572
avg_envstep_per_sec: 802.7676901636527
avg_train_sample_per_sec: 802.7676901636527
avg_episode_per_sec: 6.003604520454667
collect_time: 1.1659662084920066
reward_mean: 749.0
reward_std: 373.3336181640625
reward_max: 1303.0
reward_min: 247.0
total_envstep_count: 327190
total_train_sample_count: 327145
total_episode_count: 2053
total_duration: 421.6572344899174
[2024-11-19 22:16:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1542
train_sample_count: 1542
avg_envstep_per_episode: 128.5
avg_sample_per_episode: 128.5
avg_envstep_per_sec: 797.7670674466684
avg_train_sample_per_sec: 797.7670674466684
avg_episode_per_sec: 6.208304026822322
collect_time: 1.9328950302941459
reward_mean: 764.4166870117188
reward_std: 443.43157958984375
reward_max: 1409.0
reward_min: 231.0
total_envstep_count: 328210
total_train_sample_count: 328171
total_episode_count: 2065
total_duration: 423.5901295202116
[2024-11-19 22:16:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 288
train_sample_count: 288
avg_envstep_per_episode: 144.0
avg_sample_per_episode: 144.0
avg_envstep_per_sec: 793.8823536757045
avg_train_sample_per_sec: 793.8823536757045
avg_episode_per_sec: 5.513071900525725
collect_time: 0.3627741549696242
reward_mean: 715.5
reward_std: 93.5
reward_max: 809.0
reward_min: 622.0
total_envstep_count: 329176
total_train_sample_count: 329143
total_episode_count: 2067
total_duration: 423.9529036751812
[2024-11-19 22:17:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1359
train_sample_count: 1359
avg_envstep_per_episode: 169.875
avg_sample_per_episode: 169.875
avg_envstep_per_sec: 804.2075268342336
avg_train_sample_per_sec: 804.2075268342336
avg_episode_per_sec: 4.734113476581213
collect_time: 1.6898623236588066
reward_mean: 663.875
reward_std: 202.35577392578125
reward_max: 1012.0
reward_min: 246.0
total_envstep_count: 330185
total_train_sample_count: 330154
total_episode_count: 2075
total_duration: 425.64276599884
[2024-11-19 22:17:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1104
train_sample_count: 1104
avg_envstep_per_episode: 157.71428571428572
avg_sample_per_episode: 157.71428571428572
avg_envstep_per_sec: 798.1989541455354
avg_train_sample_per_sec: 798.1989541455354
avg_episode_per_sec: 5.0610440933140834
collect_time: 1.3831138142517636
reward_mean: 834.7142944335938
reward_std: 514.4268798828125
reward_max: 1564.0
reward_min: 231.0
total_envstep_count: 331187
total_train_sample_count: 331138
total_episode_count: 2082
total_duration: 427.02587981309176
[2024-11-19 22:17:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 674
train_sample_count: 674
avg_envstep_per_episode: 134.8
avg_sample_per_episode: 134.8
avg_envstep_per_sec: 801.2839659687291
avg_train_sample_per_sec: 801.2839659687291
avg_episode_per_sec: 5.944243070984638
collect_time: 0.8411499900477273
reward_mean: 709.4000244140625
reward_std: 294.9200439453125
reward_max: 1031.0
reward_min: 248.0
total_envstep_count: 332175
total_train_sample_count: 332136
total_episode_count: 2087
total_duration: 427.8670298031395
[2024-11-19 22:17:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1335
train_sample_count: 1335
avg_envstep_per_episode: 121.36363636363636
avg_sample_per_episode: 121.36363636363636
avg_envstep_per_sec: 800.0147769691787
avg_train_sample_per_sec: 800.0147769691787
avg_episode_per_sec: 6.591882057423944
collect_time: 1.668719176735197
reward_mean: 700.3636474609375
reward_std: 467.0279846191406
reward_max: 1553.0
reward_min: 202.0
total_envstep_count: 333182
total_train_sample_count: 333147
total_episode_count: 2098
total_duration: 429.53574897987465
[2024-11-19 22:17:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 993
train_sample_count: 993
avg_envstep_per_episode: 76.38461538461539
avg_sample_per_episode: 76.38461538461539
avg_envstep_per_sec: 798.1347650986281
avg_train_sample_per_sec: 798.1347650986281
avg_episode_per_sec: 10.44889420572222
collect_time: 1.2441507918494088
reward_mean: 430.30767822265625
reward_std: 351.5426025390625
reward_max: 1325.0
reward_min: 188.0
total_envstep_count: 334172
total_train_sample_count: 334140
total_episode_count: 2111
total_duration: 430.77989977172405
[2024-11-19 22:17:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 691
train_sample_count: 691
avg_envstep_per_episode: 138.2
avg_sample_per_episode: 138.2
avg_envstep_per_sec: 797.3219187222916
avg_train_sample_per_sec: 797.3219187222916
avg_episode_per_sec: 5.76933371000211
collect_time: 0.8666512029511587
reward_mean: 555.7999877929688
reward_std: 379.4761657714844
reward_max: 1028.0
reward_min: 83.0
total_envstep_count: 335183
total_train_sample_count: 335131
total_episode_count: 2116
total_duration: 431.6465509746752
[2024-11-19 22:17:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1453
train_sample_count: 1453
avg_envstep_per_episode: 145.3
avg_sample_per_episode: 145.3
avg_envstep_per_sec: 798.1333391063246
avg_train_sample_per_sec: 798.1333391063246
avg_episode_per_sec: 5.493003022066928
collect_time: 1.8204978150980815
reward_mean: 664.0999755859375
reward_std: 328.47479248046875
reward_max: 1041.0
reward_min: 224.0
total_envstep_count: 336181
total_train_sample_count: 336152
total_episode_count: 2126
total_duration: 433.4670487897733
[2024-11-19 22:17:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1161
train_sample_count: 1161
avg_envstep_per_episode: 116.1
avg_sample_per_episode: 116.1
avg_envstep_per_sec: 802.7921923615096
avg_train_sample_per_sec: 802.7921923615096
avg_episode_per_sec: 6.914661432915673
collect_time: 1.446202405861446
reward_mean: 726.5
reward_std: 393.06317138671875
reward_max: 1332.0
reward_min: 226.0
total_envstep_count: 337248
total_train_sample_count: 337205
total_episode_count: 2136
total_duration: 434.91325119563476
[2024-11-19 22:17:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 853
train_sample_count: 853
avg_envstep_per_episode: 85.3
avg_sample_per_episode: 85.3
avg_envstep_per_sec: 797.533126897086
avg_train_sample_per_sec: 797.533126897086
avg_episode_per_sec: 9.349743574408981
collect_time: 1.0695480491433824
reward_mean: 498.8999938964844
reward_std: 286.3108215332031
reward_max: 1129.0
reward_min: 240.0
total_envstep_count: 338242
total_train_sample_count: 338202
total_episode_count: 2146
total_duration: 435.98279924477816
[2024-11-19 22:17:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1115
train_sample_count: 1115
avg_envstep_per_episode: 85.76923076923077
avg_sample_per_episode: 85.76923076923077
avg_envstep_per_sec: 797.9966224224272
avg_train_sample_per_sec: 797.9966224224272
avg_episode_per_sec: 9.303996494611258
collect_time: 1.3972490217004503
reward_mean: 572.8461303710938
reward_std: 374.34124755859375
reward_max: 1426.0
reward_min: 247.0
total_envstep_count: 339224
total_train_sample_count: 339197
total_episode_count: 2159
total_duration: 437.38004826647864
[2024-11-19 22:17:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 741
train_sample_count: 741
avg_envstep_per_episode: 82.33333333333333
avg_sample_per_episode: 82.33333333333333
avg_envstep_per_sec: 799.659162966183
avg_train_sample_per_sec: 799.659162966183
avg_episode_per_sec: 9.712459469224894
collect_time: 0.9266447935785567
reward_mean: 422.77777099609375
reward_std: 295.3117980957031
reward_max: 1020.0
reward_min: 151.0
total_envstep_count: 340296
total_train_sample_count: 340238
total_episode_count: 2168
total_duration: 438.30669306005717
[2024-11-19 22:18:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1113
train_sample_count: 1113
avg_envstep_per_episode: 139.125
avg_sample_per_episode: 139.125
avg_envstep_per_sec: 796.2901921604541
avg_train_sample_per_sec: 796.2901921604541
avg_episode_per_sec: 5.723559332689697
collect_time: 1.397731644766671
reward_mean: 686.25
reward_std: 175.7226104736328
reward_max: 1139.0
reward_min: 578.0
total_envstep_count: 341264
total_train_sample_count: 341219
total_episode_count: 2176
total_duration: 439.70442470482385
[2024-11-19 22:18:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 689
train_sample_count: 689
avg_envstep_per_episode: 137.8
avg_sample_per_episode: 137.8
avg_envstep_per_sec: 790.4313552116911
avg_train_sample_per_sec: 790.4313552116911
avg_episode_per_sec: 5.736076598052911
collect_time: 0.8716759468827928
reward_mean: 893.4000244140625
reward_std: 308.0796203613281
reward_max: 1419.0
reward_min: 605.0
total_envstep_count: 342230
total_train_sample_count: 342208
total_episode_count: 2181
total_duration: 440.57610065170667
[2024-11-19 22:18:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 731
train_sample_count: 731
avg_envstep_per_episode: 182.75
avg_sample_per_episode: 182.75
avg_envstep_per_sec: 811.6157383713345
avg_train_sample_per_sec: 811.6157383713345
avg_episode_per_sec: 4.441125791361611
collect_time: 0.9006725294249398
reward_mean: 823.75
reward_std: 207.06686401367188
reward_max: 1033.0
reward_min: 601.0
total_envstep_count: 343234
total_train_sample_count: 343191
total_episode_count: 2185
total_duration: 441.4767731811316
[2024-11-19 22:18:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1407
train_sample_count: 1407
avg_envstep_per_episode: 140.7
avg_sample_per_episode: 140.7
avg_envstep_per_sec: 802.5459151318435
avg_train_sample_per_sec: 802.5459151318435
avg_episode_per_sec: 5.703951067035135
collect_time: 1.7531707201685225
reward_mean: 598.7000122070312
reward_std: 414.0147705078125
reward_max: 1322.0
reward_min: 228.0
total_envstep_count: 344225
total_train_sample_count: 344178
total_episode_count: 2195
total_duration: 443.2299439013001
[2024-11-19 22:18:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 16
envstep_count: 1396
train_sample_count: 1396
avg_envstep_per_episode: 87.25
avg_sample_per_episode: 87.25
avg_envstep_per_sec: 800.8665285319252
avg_train_sample_per_sec: 800.8665285319252
avg_episode_per_sec: 9.178986000365905
collect_time: 1.7431119297231947
reward_mean: 537.0625
reward_std: 374.2283020019531
reward_max: 1315.0
reward_min: 235.0
total_envstep_count: 345277
total_train_sample_count: 345226
total_episode_count: 2211
total_duration: 444.97305583102326
[2024-11-19 22:18:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 645
train_sample_count: 645
avg_envstep_per_episode: 80.625
avg_sample_per_episode: 80.625
avg_envstep_per_sec: 799.5582711591062
avg_train_sample_per_sec: 799.5582711591062
avg_episode_per_sec: 9.917001812826124
collect_time: 0.806695425794238
reward_mean: 478.375
reward_std: 267.5247497558594
reward_max: 1032.0
reward_min: 239.0
total_envstep_count: 346229
total_train_sample_count: 346195
total_episode_count: 2219
total_duration: 445.7797512568175
[2024-11-19 22:18:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 955
train_sample_count: 955
avg_envstep_per_episode: 106.11111111111111
avg_sample_per_episode: 106.11111111111111
avg_envstep_per_sec: 802.31121457856
avg_train_sample_per_sec: 802.31121457856
avg_episode_per_sec: 7.561048095504754
collect_time: 1.1903111693404969
reward_mean: 563.3333129882812
reward_std: 318.83642578125
reward_max: 1037.0
reward_min: 229.0
total_envstep_count: 347220
total_train_sample_count: 347186
total_episode_count: 2228
total_duration: 446.970062426158
[2024-11-19 22:18:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1123
train_sample_count: 1123
avg_envstep_per_episode: 140.375
avg_sample_per_episode: 140.375
avg_envstep_per_sec: 801.6006289655365
avg_train_sample_per_sec: 801.6006289655365
avg_episode_per_sec: 5.710423002425906
collect_time: 1.400947004556656
reward_mean: 701.75
reward_std: 437.9773864746094
reward_max: 1404.0
reward_min: 230.0
total_envstep_count: 348246
total_train_sample_count: 348213
total_episode_count: 2236
total_duration: 448.37100943071465
[2024-11-19 22:18:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1146
train_sample_count: 1146
avg_envstep_per_episode: 114.6
avg_sample_per_episode: 114.6
avg_envstep_per_sec: 797.9636319930022
avg_train_sample_per_sec: 797.9636319930022
avg_episode_per_sec: 6.963033437984312
collect_time: 1.436155676841736
reward_mean: 714.9000244140625
reward_std: 327.8141174316406
reward_max: 1313.0
reward_min: 231.0
total_envstep_count: 349261
total_train_sample_count: 349227
total_episode_count: 2246
total_duration: 449.8071651075564
[2024-11-19 22:18:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 868
train_sample_count: 868
avg_envstep_per_episode: 86.8
avg_sample_per_episode: 86.8
avg_envstep_per_sec: 799.131969272718
avg_train_sample_per_sec: 799.131969272718
avg_episode_per_sec: 9.206589507750207
collect_time: 1.0861785454409465
reward_mean: 507.3999938964844
reward_std: 330.1376037597656
reward_max: 1305.0
reward_min: 206.0
total_envstep_count: 350277
total_train_sample_count: 350251
total_episode_count: 2256
total_duration: 450.8933436529973
[2024-11-19 22:18:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 839
train_sample_count: 839
avg_envstep_per_episode: 69.91666666666667
avg_sample_per_episode: 69.91666666666667
avg_envstep_per_sec: 793.4413426236891
avg_train_sample_per_sec: 793.4413426236891
avg_episode_per_sec: 11.348386306894243
collect_time: 1.0574190616607664
reward_mean: 383.0
reward_std: 356.4138488769531
reward_max: 1310.0
reward_min: 189.0
total_envstep_count: 351267
total_train_sample_count: 351246
total_episode_count: 2268
total_duration: 451.9507627146581
[2024-11-19 22:18:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1353
train_sample_count: 1353
avg_envstep_per_episode: 135.3
avg_sample_per_episode: 135.3
avg_envstep_per_sec: 800.2166494408275
avg_train_sample_per_sec: 800.2166494408275
avg_episode_per_sec: 5.914387652925554
collect_time: 1.6907921135425568
reward_mean: 721.2000122070312
reward_std: 398.3309631347656
reward_max: 1300.0
reward_min: 235.0
total_envstep_count: 352266
total_train_sample_count: 352227
total_episode_count: 2278
total_duration: 453.64155482820064
[2024-11-19 22:18:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1009
train_sample_count: 1009
avg_envstep_per_episode: 100.9
avg_sample_per_episode: 100.9
avg_envstep_per_sec: 803.4264161620158
avg_train_sample_per_sec: 803.4264161620158
avg_episode_per_sec: 7.962600754826718
collect_time: 1.255871078797749
reward_mean: 633.9000244140625
reward_std: 308.96356201171875
reward_max: 1045.0
reward_min: 232.0
total_envstep_count: 353273
total_train_sample_count: 353260
total_episode_count: 2288
total_duration: 454.89742590699836
[2024-11-19 22:18:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 654
train_sample_count: 654
avg_envstep_per_episode: 65.4
avg_sample_per_episode: 65.4
avg_envstep_per_sec: 802.3321573936704
avg_train_sample_per_sec: 802.3321573936704
avg_episode_per_sec: 12.268075801126459
collect_time: 0.8151237538882664
reward_mean: 433.70001220703125
reward_std: 263.7859191894531
reward_max: 1034.0
reward_min: 232.0
total_envstep_count: 354303
total_train_sample_count: 354262
total_episode_count: 2298
total_duration: 455.7125496608866
[2024-11-19 22:18:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 663
train_sample_count: 663
avg_envstep_per_episode: 165.75
avg_sample_per_episode: 165.75
avg_envstep_per_sec: 797.3857247807806
avg_train_sample_per_sec: 797.3857247807806
avg_episode_per_sec: 4.810773603503955
collect_time: 0.8314671048096248
reward_mean: 679.25
reward_std: 397.5313720703125
reward_max: 1319.0
reward_min: 226.0
total_envstep_count: 355323
total_train_sample_count: 355285
total_episode_count: 2302
total_duration: 456.54401676569626
[2024-11-19 22:18:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1833
train_sample_count: 1833
avg_envstep_per_episode: 152.75
avg_sample_per_episode: 152.75
avg_envstep_per_sec: 795.9450684155679
avg_train_sample_per_sec: 795.9450684155679
avg_episode_per_sec: 5.210769678661656
collect_time: 2.302922742707389
reward_mean: 796.25
reward_std: 321.78228759765625
reward_max: 1317.0
reward_min: 246.0
total_envstep_count: 356336
total_train_sample_count: 356290
total_episode_count: 2314
total_duration: 458.84693950840364
[2024-11-19 22:18:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 765
train_sample_count: 765
avg_envstep_per_episode: 63.75
avg_sample_per_episode: 63.75
avg_envstep_per_sec: 795.830310824152
avg_train_sample_per_sec: 795.830310824152
avg_episode_per_sec: 12.483612718810228
collect_time: 0.9612601952893394
reward_mean: 421.0833435058594
reward_std: 312.83660888671875
reward_max: 1310.0
reward_min: 213.0
total_envstep_count: 357327
total_train_sample_count: 357295
total_episode_count: 2326
total_duration: 459.808199703693
[2024-11-19 22:19:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 871
train_sample_count: 871
avg_envstep_per_episode: 108.875
avg_sample_per_episode: 108.875
avg_envstep_per_sec: 789.2863423375109
avg_train_sample_per_sec: 789.2863423375109
avg_episode_per_sec: 7.249472719517895
collect_time: 1.1035285336630685
reward_mean: 716.875
reward_std: 361.12652587890625
reward_max: 1325.0
reward_min: 247.0
total_envstep_count: 358328
total_train_sample_count: 358286
total_episode_count: 2334
total_duration: 460.91172823735604
[2024-11-19 22:19:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1121
train_sample_count: 1121
avg_envstep_per_episode: 140.125
avg_sample_per_episode: 140.125
avg_envstep_per_sec: 794.6918219530813
avg_train_sample_per_sec: 794.6918219530813
avg_episode_per_sec: 5.671306490298528
collect_time: 1.4106097093650272
reward_mean: 805.625
reward_std: 255.86175537109375
reward_max: 1302.0
reward_min: 599.0
total_envstep_count: 359322
total_train_sample_count: 359287
total_episode_count: 2342
total_duration: 462.32233794672106
[2024-11-19 22:19:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1122
train_sample_count: 1122
avg_envstep_per_episode: 140.25
avg_sample_per_episode: 140.25
avg_envstep_per_sec: 797.3748336255248
avg_train_sample_per_sec: 797.3748336255248
avg_episode_per_sec: 5.685382057936006
collect_time: 1.407117396593094
reward_mean: 821.5
reward_std: 290.6669006347656
reward_max: 1430.0
reward_min: 594.0
total_envstep_count: 360292
total_train_sample_count: 360277
total_episode_count: 2350
total_duration: 463.72945534331416
[2024-11-19 22:19:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 738
train_sample_count: 738
avg_envstep_per_episode: 82.0
avg_sample_per_episode: 82.0
avg_envstep_per_sec: 794.2641080096795
avg_train_sample_per_sec: 794.2641080096795
avg_episode_per_sec: 9.686147658654628
collect_time: 0.9291619658470154
reward_mean: 348.8888854980469
reward_std: 247.6563262939453
reward_max: 741.0
reward_min: 121.0
total_envstep_count: 361332
total_train_sample_count: 361279
total_episode_count: 2359
total_duration: 464.6586173091612
[2024-11-19 22:19:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 791
train_sample_count: 791
avg_envstep_per_episode: 158.2
avg_sample_per_episode: 158.2
avg_envstep_per_sec: 796.9088217615605
avg_train_sample_per_sec: 796.9088217615605
avg_episode_per_sec: 5.037350327190648
collect_time: 0.9925853226866042
reward_mean: 967.5999755859375
reward_std: 452.17767333984375
reward_max: 1337.0
reward_min: 247.0
total_envstep_count: 362296
total_train_sample_count: 362262
total_episode_count: 2364
total_duration: 465.65120263184775
[2024-11-19 22:19:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1041
train_sample_count: 1041
avg_envstep_per_episode: 130.125
avg_sample_per_episode: 130.125
avg_envstep_per_sec: 791.8396921628243
avg_train_sample_per_sec: 791.8396921628243
avg_episode_per_sec: 6.0852233787729055
collect_time: 1.3146600382668634
reward_mean: 754.5
reward_std: 447.53045654296875
reward_max: 1316.0
reward_min: 232.0
total_envstep_count: 363257
total_train_sample_count: 363231
total_episode_count: 2372
total_duration: 466.96586267011463
[2024-11-19 22:19:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 1344
train_sample_count: 1344
avg_envstep_per_episode: 96.0
avg_sample_per_episode: 96.0
avg_envstep_per_sec: 809.6456680889681
avg_train_sample_per_sec: 809.6456680889681
avg_episode_per_sec: 8.433809042593419
collect_time: 1.6599854145731243
reward_mean: 535.3571166992188
reward_std: 310.38446044921875
reward_max: 1282.0
reward_min: 238.0
total_envstep_count: 364303
total_train_sample_count: 364275
total_episode_count: 2386
total_duration: 468.62584808468773
[2024-11-19 22:19:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1079
train_sample_count: 1079
avg_envstep_per_episode: 83.0
avg_sample_per_episode: 83.0
avg_envstep_per_sec: 800.9118637499818
avg_train_sample_per_sec: 800.9118637499818
avg_episode_per_sec: 9.649540527108215
collect_time: 1.3472144050257546
reward_mean: 476.23077392578125
reward_std: 230.56390380859375
reward_max: 785.0
reward_min: 227.0
total_envstep_count: 365324
total_train_sample_count: 365270
total_episode_count: 2399
total_duration: 469.97306248971347
[2024-11-19 22:19:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 958
train_sample_count: 958
avg_envstep_per_episode: 95.8
avg_sample_per_episode: 95.8
avg_envstep_per_sec: 801.4051392546544
avg_train_sample_per_sec: 801.4051392546544
avg_episode_per_sec: 8.36539811330537
collect_time: 1.1954003700188227
reward_mean: 545.7000122070312
reward_std: 323.39605712890625
reward_max: 1310.0
reward_min: 190.0
total_envstep_count: 366308
total_train_sample_count: 366276
total_episode_count: 2409
total_duration: 471.1684628597323
[2024-11-19 22:19:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1019
train_sample_count: 1019
avg_envstep_per_episode: 101.9
avg_sample_per_episode: 101.9
avg_envstep_per_sec: 796.9117874908147
avg_train_sample_per_sec: 796.9117874908147
avg_episode_per_sec: 7.82052784583724
collect_time: 1.2786860678877148
reward_mean: 643.7999877929688
reward_std: 376.8505859375
reward_max: 1337.0
reward_min: 218.0
total_envstep_count: 367301
total_train_sample_count: 367259
total_episode_count: 2419
total_duration: 472.44714892762
[2024-11-19 22:19:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1099
train_sample_count: 1099
avg_envstep_per_episode: 84.53846153846153
avg_sample_per_episode: 84.53846153846153
avg_envstep_per_sec: 802.6068014318322
avg_train_sample_per_sec: 802.6068014318322
avg_episode_per_sec: 9.49398400237836
collect_time: 1.3692881720406669
reward_mean: 515.3846435546875
reward_std: 351.6277770996094
reward_max: 1344.0
reward_min: 218.0
total_envstep_count: 368320
total_train_sample_count: 368274
total_episode_count: 2432
total_duration: 473.8164370996607
[2024-11-19 22:20:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 569
train_sample_count: 569
avg_envstep_per_episode: 113.8
avg_sample_per_episode: 113.8
avg_envstep_per_sec: 795.4803202708284
avg_train_sample_per_sec: 795.4803202708284
avg_episode_per_sec: 6.99016098656264
collect_time: 0.7152911084038871
reward_mean: 634.4000244140625
reward_std: 362.3040771484375
reward_max: 1039.0
reward_min: 222.0
total_envstep_count: 369299
total_train_sample_count: 369263
total_episode_count: 2437
total_duration: 474.5317282080646
[2024-11-19 22:20:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1080
train_sample_count: 1080
avg_envstep_per_episode: 120.0
avg_sample_per_episode: 120.0
avg_envstep_per_sec: 795.9284784113786
avg_train_sample_per_sec: 795.9284784113786
avg_episode_per_sec: 6.632737320094821
collect_time: 1.3569058392729076
reward_mean: 560.5555419921875
reward_std: 334.94183349609375
reward_max: 1129.0
reward_min: 223.0
total_envstep_count: 370298
total_train_sample_count: 370247
total_episode_count: 2446
total_duration: 475.88863404733746
[2024-11-19 22:20:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1027
train_sample_count: 1027
avg_envstep_per_episode: 114.11111111111111
avg_sample_per_episode: 114.11111111111111
avg_envstep_per_sec: 788.9614519536907
avg_train_sample_per_sec: 788.9614519536907
avg_episode_per_sec: 6.91397572306058
collect_time: 1.3017112527574812
reward_mean: 627.5555419921875
reward_std: 414.71624755859375
reward_max: 1319.0
reward_min: 231.0
total_envstep_count: 371313
total_train_sample_count: 371262
total_episode_count: 2455
total_duration: 477.1903453000949
[2024-11-19 22:20:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 945
train_sample_count: 945
avg_envstep_per_episode: 105.0
avg_sample_per_episode: 105.0
avg_envstep_per_sec: 790.0710857844534
avg_train_sample_per_sec: 790.0710857844534
avg_episode_per_sec: 7.524486531280509
collect_time: 1.1960949046271188
reward_mean: 700.888916015625
reward_std: 484.2826232910156
reward_max: 1679.0
reward_min: 234.0
total_envstep_count: 372353
total_train_sample_count: 372315
total_episode_count: 2464
total_duration: 478.386440204722
[2024-11-19 22:20:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 909
train_sample_count: 909
avg_envstep_per_episode: 90.9
avg_sample_per_episode: 90.9
avg_envstep_per_sec: 793.5482236678931
avg_train_sample_per_sec: 793.5482236678931
avg_episode_per_sec: 8.729903450691895
collect_time: 1.145488040787833
reward_mean: 564.7000122070312
reward_std: 388.8107604980469
reward_max: 1421.0
reward_min: 232.0
total_envstep_count: 373385
total_train_sample_count: 373332
total_episode_count: 2474
total_duration: 479.53192824550985
[2024-11-19 22:20:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1399
train_sample_count: 1399
avg_envstep_per_episode: 116.58333333333333
avg_sample_per_episode: 116.58333333333333
avg_envstep_per_sec: 790.3081562789748
avg_train_sample_per_sec: 790.3081562789748
avg_episode_per_sec: 6.778911990956181
collect_time: 1.7701955735683437
reward_mean: 797.6666870117188
reward_std: 642.0306396484375
reward_max: 2339.0
reward_min: 226.0
total_envstep_count: 374407
total_train_sample_count: 374371
total_episode_count: 2486
total_duration: 481.3021238190782
[2024-11-19 22:20:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 745
train_sample_count: 745
avg_envstep_per_episode: 93.125
avg_sample_per_episode: 93.125
avg_envstep_per_sec: 799.3243332083183
avg_train_sample_per_sec: 799.3243332083183
avg_episode_per_sec: 8.583348544518854
collect_time: 0.93203718321664
reward_mean: 491.0
reward_std: 283.45721435546875
reward_max: 1027.0
reward_min: 227.0
total_envstep_count: 375400
total_train_sample_count: 375356
total_episode_count: 2494
total_duration: 482.23416100229485
[2024-11-19 22:20:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1043
train_sample_count: 1043
avg_envstep_per_episode: 149.0
avg_sample_per_episode: 149.0
avg_envstep_per_sec: 801.1126092168765
avg_train_sample_per_sec: 801.1126092168765
avg_episode_per_sec: 5.376594692730714
collect_time: 1.3019393129008159
reward_mean: 876.0
reward_std: 289.6593933105469
reward_max: 1344.0
reward_min: 632.0
total_envstep_count: 376418
total_train_sample_count: 376387
total_episode_count: 2501
total_duration: 483.53610031519565
[2024-11-19 22:20:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1091
train_sample_count: 1091
avg_envstep_per_episode: 155.85714285714286
avg_sample_per_episode: 155.85714285714286
avg_envstep_per_sec: 806.7472267867012
avg_train_sample_per_sec: 806.7472267867012
avg_episode_per_sec: 5.17619668882393
collect_time: 1.3523442830358232
reward_mean: 776.0
reward_std: 292.9300231933594
reward_max: 1139.0
reward_min: 242.0
total_envstep_count: 377429
total_train_sample_count: 377382
total_episode_count: 2508
total_duration: 484.8884445982315
[2024-11-19 22:20:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1083
train_sample_count: 1083
avg_envstep_per_episode: 154.71428571428572
avg_sample_per_episode: 154.71428571428572
avg_envstep_per_sec: 803.6201357171882
avg_train_sample_per_sec: 803.6201357171882
avg_episode_per_sec: 5.194220637137874
collect_time: 1.3476516476699283
reward_mean: 931.7142944335938
reward_std: 333.0159606933594
reward_max: 1416.0
reward_min: 617.0
total_envstep_count: 378400
total_train_sample_count: 378357
total_episode_count: 2515
total_duration: 486.2360962459014
[2024-11-19 22:20:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1097
train_sample_count: 1097
avg_envstep_per_episode: 91.41666666666667
avg_sample_per_episode: 91.41666666666667
avg_envstep_per_sec: 788.9171799749275
avg_train_sample_per_sec: 788.9171799749275
avg_episode_per_sec: 8.62990534156712
collect_time: 1.390513513769422
reward_mean: 591.6666870117188
reward_std: 441.343994140625
reward_max: 1692.0
reward_min: 231.0
total_envstep_count: 379413
total_train_sample_count: 379370
total_episode_count: 2527
total_duration: 487.6266097596708
[2024-11-19 22:20:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 786
train_sample_count: 786
avg_envstep_per_episode: 87.33333333333333
avg_sample_per_episode: 87.33333333333333
avg_envstep_per_sec: 782.6781940037239
avg_train_sample_per_sec: 782.6781940037239
avg_episode_per_sec: 8.961964053477754
collect_time: 1.0042441529887063
reward_mean: 581.7777709960938
reward_std: 223.32476806640625
reward_max: 1033.0
reward_min: 237.0
total_envstep_count: 380408
total_train_sample_count: 380360
total_episode_count: 2536
total_duration: 488.6308539126595
[2024-11-19 22:20:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 742
train_sample_count: 742
avg_envstep_per_episode: 92.75
avg_sample_per_episode: 92.75
avg_envstep_per_sec: 792.7613749945552
avg_train_sample_per_sec: 792.7613749945552
avg_episode_per_sec: 8.547292452771485
collect_time: 0.9359689099448067
reward_mean: 611.375
reward_std: 444.3252868652344
reward_max: 1338.0
reward_min: 244.0
total_envstep_count: 381416
total_train_sample_count: 381366
total_episode_count: 2544
total_duration: 489.5668228226043
[2024-11-19 22:20:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1462
train_sample_count: 1462
avg_envstep_per_episode: 162.44444444444446
avg_sample_per_episode: 162.44444444444446
avg_envstep_per_sec: 798.8209664661555
avg_train_sample_per_sec: 798.8209664661555
avg_episode_per_sec: 4.917502529545416
collect_time: 1.8301973300320757
reward_mean: 715.0
reward_std: 405.57476806640625
reward_max: 1314.0
reward_min: 246.0
total_envstep_count: 382392
total_train_sample_count: 382360
total_episode_count: 2553
total_duration: 491.3970201526364
[2024-11-19 22:20:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 206
train_sample_count: 206
avg_envstep_per_episode: 68.66666666666667
avg_sample_per_episode: 68.66666666666667
avg_envstep_per_sec: 809.2890579241698
avg_train_sample_per_sec: 809.2890579241698
avg_episode_per_sec: 11.785762979478202
collect_time: 0.2545444028718131
reward_mean: 139.0
reward_std: 2.943920373916626
reward_max: 143.0
reward_min: 136.0
total_envstep_count: 383357
total_train_sample_count: 383334
total_episode_count: 2556
total_duration: 491.65156455550823
[2024-11-19 22:20:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1173
train_sample_count: 1173
avg_envstep_per_episode: 234.6
avg_sample_per_episode: 234.6
avg_envstep_per_sec: 793.8907835667444
avg_train_sample_per_sec: 793.8907835667444
avg_episode_per_sec: 3.3840186852802403
collect_time: 1.4775332127298628
reward_mean: 1024.0
reward_std: 372.50665283203125
reward_max: 1556.0
reward_min: 610.0
total_envstep_count: 384330
total_train_sample_count: 384303
total_episode_count: 2561
total_duration: 493.12909776823807
[2024-11-19 22:20:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1348
train_sample_count: 1348
avg_envstep_per_episode: 168.5
avg_sample_per_episode: 168.5
avg_envstep_per_sec: 794.1629747784451
avg_train_sample_per_sec: 794.1629747784451
avg_episode_per_sec: 4.713133381474452
collect_time: 1.697384595870972
reward_mean: 729.625
reward_std: 296.6129455566406
reward_max: 1311.0
reward_min: 249.0
total_envstep_count: 385315
total_train_sample_count: 385279
total_episode_count: 2569
total_duration: 494.82648236410904
[2024-11-19 22:21:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 764
train_sample_count: 764
avg_envstep_per_episode: 191.0
avg_sample_per_episode: 191.0
avg_envstep_per_sec: 789.6549671323672
avg_train_sample_per_sec: 789.6549671323672
avg_episode_per_sec: 4.134319199645901
collect_time: 0.9675111685480391
reward_mean: 999.25
reward_std: 250.20428466796875
reward_max: 1307.0
reward_min: 609.0
total_envstep_count: 386319
total_train_sample_count: 386271
total_episode_count: 2573
total_duration: 495.79399353265705
[2024-11-19 22:21:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1297
train_sample_count: 1297
avg_envstep_per_episode: 129.7
avg_sample_per_episode: 129.7
avg_envstep_per_sec: 786.6266605046684
avg_train_sample_per_sec: 786.6266605046684
avg_episode_per_sec: 6.064970397106156
collect_time: 1.6488126644066403
reward_mean: 772.2999877929688
reward_std: 434.57476806640625
reward_max: 1335.0
reward_min: 238.0
total_envstep_count: 387358
total_train_sample_count: 387304
total_episode_count: 2583
total_duration: 497.4428061970637
[2024-11-19 22:21:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 939
train_sample_count: 939
avg_envstep_per_episode: 117.375
avg_sample_per_episode: 117.375
avg_envstep_per_sec: 794.3492242905362
avg_train_sample_per_sec: 794.3492242905362
avg_episode_per_sec: 6.767618524307017
collect_time: 1.1820997255189076
reward_mean: 727.125
reward_std: 302.58404541015625
reward_max: 1306.0
reward_min: 246.0
total_envstep_count: 388342
total_train_sample_count: 388303
total_episode_count: 2591
total_duration: 498.6249059225826
[2024-11-19 22:21:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 936
train_sample_count: 936
avg_envstep_per_episode: 78.0
avg_sample_per_episode: 78.0
avg_envstep_per_sec: 798.6612083456729
avg_train_sample_per_sec: 798.6612083456729
avg_episode_per_sec: 10.239246260841961
collect_time: 1.1719612649508886
reward_mean: 481.1666564941406
reward_std: 313.5583190917969
reward_max: 1050.0
reward_min: 218.0
total_envstep_count: 389347
total_train_sample_count: 389311
total_episode_count: 2603
total_duration: 499.7968671875335
[2024-11-19 22:21:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 905
train_sample_count: 905
avg_envstep_per_episode: 113.125
avg_sample_per_episode: 113.125
avg_envstep_per_sec: 802.0017339709101
avg_train_sample_per_sec: 802.0017339709101
avg_episode_per_sec: 7.0895180903505866
collect_time: 1.1284264879567278
reward_mean: 608.625
reward_std: 432.8570556640625
reward_max: 1328.0
reward_min: 166.0
total_envstep_count: 390356
total_train_sample_count: 390312
total_episode_count: 2611
total_duration: 500.92529367549025
[2024-11-19 22:21:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1244
train_sample_count: 1244
avg_envstep_per_episode: 177.71428571428572
avg_sample_per_episode: 177.71428571428572
avg_envstep_per_sec: 799.7329800040668
avg_train_sample_per_sec: 799.7329800040668
avg_episode_per_sec: 4.500105192948929
collect_time: 1.5555191934108732
reward_mean: 954.1428833007812
reward_std: 434.2318115234375
reward_max: 1673.0
reward_min: 250.0
total_envstep_count: 391333
total_train_sample_count: 391292
total_episode_count: 2618
total_duration: 502.4808128689011
[2024-11-19 22:21:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 895
train_sample_count: 895
avg_envstep_per_episode: 111.875
avg_sample_per_episode: 111.875
avg_envstep_per_sec: 791.9026507826795
avg_train_sample_per_sec: 791.9026507826795
avg_episode_per_sec: 7.0784594483368
collect_time: 1.1301894230501992
reward_mean: 603.625
reward_std: 316.9266357421875
reward_max: 1122.0
reward_min: 216.0
total_envstep_count: 392334
total_train_sample_count: 392295
total_episode_count: 2626
total_duration: 503.6110022919513
[2024-11-19 22:21:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 915
train_sample_count: 915
avg_envstep_per_episode: 101.66666666666667
avg_sample_per_episode: 101.66666666666667
avg_envstep_per_sec: 801.5999649993055
avg_train_sample_per_sec: 801.5999649993055
avg_episode_per_sec: 7.8845898196653
collect_time: 1.1414671157087597
reward_mean: 535.111083984375
reward_std: 238.97021484375
reward_max: 1025.0
reward_min: 248.0
total_envstep_count: 393337
total_train_sample_count: 393306
total_episode_count: 2635
total_duration: 504.75246940766004
[2024-11-19 22:21:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1468
train_sample_count: 1468
avg_envstep_per_episode: 146.8
avg_sample_per_episode: 146.8
avg_envstep_per_sec: 799.2672650829501
avg_train_sample_per_sec: 799.2672650829501
avg_episode_per_sec: 5.444599898385219
collect_time: 1.8366822515215195
reward_mean: 874.5
reward_std: 610.982666015625
reward_max: 2336.0
reward_min: 234.0
total_envstep_count: 394345
total_train_sample_count: 394306
total_episode_count: 2645
total_duration: 506.58915165918154
[2024-11-19 22:21:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 612
train_sample_count: 612
avg_envstep_per_episode: 68.0
avg_sample_per_episode: 68.0
avg_envstep_per_sec: 802.6534073806527
avg_train_sample_per_sec: 802.6534073806527
avg_episode_per_sec: 11.803726579127245
collect_time: 0.7624710670539312
reward_mean: 399.1111145019531
reward_std: 222.38526916503906
reward_max: 765.0
reward_min: 234.0
total_envstep_count: 395393
total_train_sample_count: 395350
total_episode_count: 2654
total_duration: 507.35162272623546
[2024-11-19 22:21:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 924
train_sample_count: 924
avg_envstep_per_episode: 184.8
avg_sample_per_episode: 184.8
avg_envstep_per_sec: 798.1158594023674
avg_train_sample_per_sec: 798.1158594023674
avg_episode_per_sec: 4.318808762999823
collect_time: 1.1577266497271401
reward_mean: 1058.0
reward_std: 191.6663818359375
reward_max: 1320.0
reward_min: 728.0
total_envstep_count: 396351
total_train_sample_count: 396334
total_episode_count: 2659
total_duration: 508.5093493759626
[2024-11-19 22:21:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1589
train_sample_count: 1589
avg_envstep_per_episode: 132.41666666666666
avg_sample_per_episode: 132.41666666666666
avg_envstep_per_sec: 789.7998371923475
avg_train_sample_per_sec: 789.7998371923475
avg_episode_per_sec: 5.964504749092617
collect_time: 2.0119021620069235
reward_mean: 711.3333129882812
reward_std: 505.00103759765625
reward_max: 1670.0
reward_min: 213.0
total_envstep_count: 397405
total_train_sample_count: 397347
total_episode_count: 2671
total_duration: 510.52125153796953
[2024-11-19 22:21:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 827
train_sample_count: 827
avg_envstep_per_episode: 75.18181818181819
avg_sample_per_episode: 75.18181818181819
avg_envstep_per_sec: 792.9927772507125
avg_train_sample_per_sec: 792.9927772507125
avg_episode_per_sec: 10.547666928364979
collect_time: 1.0428846563611711
reward_mean: 536.4545288085938
reward_std: 257.8510437011719
reward_max: 1065.0
reward_min: 233.0
total_envstep_count: 398402
total_train_sample_count: 398366
total_episode_count: 2682
total_duration: 511.56413619433073
[2024-11-19 22:21:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 810
train_sample_count: 810
avg_envstep_per_episode: 73.63636363636364
avg_sample_per_episode: 73.63636363636364
avg_envstep_per_sec: 798.3106827855634
avg_train_sample_per_sec: 798.3106827855634
avg_episode_per_sec: 10.841256185976786
collect_time: 1.0146425664424894
reward_mean: 452.18182373046875
reward_std: 187.347900390625
reward_max: 640.0
reward_min: 234.0
total_envstep_count: 399394
total_train_sample_count: 399356
total_episode_count: 2693
total_duration: 512.5787787607732
[2024-11-19 22:21:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 988
train_sample_count: 988
avg_envstep_per_episode: 123.5
avg_sample_per_episode: 123.5
avg_envstep_per_sec: 794.5774184387361
avg_train_sample_per_sec: 794.5774184387361
avg_episode_per_sec: 6.433825250516081
collect_time: 1.2434282388005937
reward_mean: 706.375
reward_std: 387.31024169921875
reward_max: 1562.0
reward_min: 240.0
total_envstep_count: 400396
total_train_sample_count: 400356
total_episode_count: 2701
total_duration: 513.8222069995737
[2024-11-19 22:21:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 848
train_sample_count: 848
avg_envstep_per_episode: 77.0909090909091
avg_sample_per_episode: 77.0909090909091
avg_envstep_per_sec: 798.7640501402723
avg_train_sample_per_sec: 798.7640501402723
avg_episode_per_sec: 10.361326122102588
collect_time: 1.0616401675201599
reward_mean: 422.3636474609375
reward_std: 336.9810485839844
reward_max: 1047.0
reward_min: 164.0
total_envstep_count: 401387
total_train_sample_count: 401348
total_episode_count: 2712
total_duration: 514.8838471670939
[2024-11-19 22:21:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1301
train_sample_count: 1301
avg_envstep_per_episode: 118.27272727272727
avg_sample_per_episode: 118.27272727272727
avg_envstep_per_sec: 794.3190799397588
avg_train_sample_per_sec: 794.3190799397588
avg_episode_per_sec: 6.715995295416869
collect_time: 1.637880837633496
reward_mean: 638.9091186523438
reward_std: 277.6064758300781
reward_max: 1333.0
reward_min: 228.0
total_envstep_count: 402408
total_train_sample_count: 402373
total_episode_count: 2723
total_duration: 516.5217280047274
[2024-11-19 22:22:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 856
train_sample_count: 856
avg_envstep_per_episode: 95.11111111111111
avg_sample_per_episode: 95.11111111111111
avg_envstep_per_sec: 787.8261343234951
avg_train_sample_per_sec: 787.8261343234951
avg_episode_per_sec: 8.283218701999365
collect_time: 1.0865341510091509
reward_mean: 605.6666870117188
reward_std: 143.52313232421875
reward_max: 769.0
reward_min: 244.0
total_envstep_count: 403402
total_train_sample_count: 403373
total_episode_count: 2732
total_duration: 517.6082621557365
[2024-11-19 22:22:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1048
train_sample_count: 1048
avg_envstep_per_episode: 116.44444444444444
avg_sample_per_episode: 116.44444444444444
avg_envstep_per_sec: 652.4451721774524
avg_train_sample_per_sec: 652.4451721774524
avg_episode_per_sec: 5.60305968473003
collect_time: 1.6062652383531844
reward_mean: 727.0
reward_std: 306.04974365234375
reward_max: 1405.0
reward_min: 249.0
total_envstep_count: 404395
total_train_sample_count: 404361
total_episode_count: 2741
total_duration: 519.2145273940897
[2024-11-19 22:22:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 906
train_sample_count: 906
avg_envstep_per_episode: 129.42857142857142
avg_sample_per_episode: 129.42857142857142
avg_envstep_per_sec: 791.1093084602489
avg_train_sample_per_sec: 791.1093084602489
avg_episode_per_sec: 6.1123235752999365
collect_time: 1.1452273286524273
reward_mean: 804.5714111328125
reward_std: 293.48101806640625
reward_max: 1042.0
reward_min: 233.0
total_envstep_count: 405404
total_train_sample_count: 405363
total_episode_count: 2748
total_duration: 520.3597547227422
[2024-11-19 22:22:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 755
train_sample_count: 755
avg_envstep_per_episode: 151.0
avg_sample_per_episode: 151.0
avg_envstep_per_sec: 796.6400314632413
avg_train_sample_per_sec: 796.6400314632413
avg_episode_per_sec: 5.2757617977698095
collect_time: 0.9477304305349077
reward_mean: 1045.0
reward_std: 579.9182739257812
reward_max: 1922.0
reward_min: 245.0
total_envstep_count: 406383
total_train_sample_count: 406346
total_episode_count: 2753
total_duration: 521.3074851532771
[2024-11-19 22:22:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1483
train_sample_count: 1483
avg_envstep_per_episode: 123.58333333333333
avg_sample_per_episode: 123.58333333333333
avg_envstep_per_sec: 797.8852941400207
avg_train_sample_per_sec: 797.8852941400207
avg_episode_per_sec: 6.456253222980613
collect_time: 1.8586631573381882
reward_mean: 623.1666870117188
reward_std: 380.532470703125
reward_max: 1420.0
reward_min: 238.0
total_envstep_count: 407405
total_train_sample_count: 407361
total_episode_count: 2765
total_duration: 523.1661483106153
[2024-11-19 22:22:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1009
train_sample_count: 1009
avg_envstep_per_episode: 112.11111111111111
avg_sample_per_episode: 112.11111111111111
avg_envstep_per_sec: 807.6668005827944
avg_train_sample_per_sec: 807.6668005827944
avg_episode_per_sec: 7.204163731660207
collect_time: 1.2492775477114177
reward_mean: 724.888916015625
reward_std: 316.8867492675781
reward_max: 1048.0
reward_min: 234.0
total_envstep_count: 408398
total_train_sample_count: 408382
total_episode_count: 2774
total_duration: 524.4154258583268
[2024-11-19 22:22:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 492
train_sample_count: 492
avg_envstep_per_episode: 82.0
avg_sample_per_episode: 82.0
avg_envstep_per_sec: 803.8009580329123
avg_train_sample_per_sec: 803.8009580329123
avg_episode_per_sec: 9.802450707718442
collect_time: 0.6120918307985578
reward_mean: 421.1666564941406
reward_std: 350.150634765625
reward_max: 1115.0
reward_min: 145.0
total_envstep_count: 409384
total_train_sample_count: 409354
total_episode_count: 2780
total_duration: 525.0275176891254
[2024-11-19 22:22:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1040
train_sample_count: 1040
avg_envstep_per_episode: 115.55555555555556
avg_sample_per_episode: 115.55555555555556
avg_envstep_per_sec: 800.47690172821
avg_train_sample_per_sec: 800.47690172821
avg_episode_per_sec: 6.927203957263356
collect_time: 1.2992254963942937
reward_mean: 652.111083984375
reward_std: 417.28765869140625
reward_max: 1427.0
reward_min: 235.0
total_envstep_count: 410401
total_train_sample_count: 410370
total_episode_count: 2789
total_duration: 526.3267431855197
[2024-11-19 22:22:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1445
train_sample_count: 1445
avg_envstep_per_episode: 111.15384615384616
avg_sample_per_episode: 111.15384615384616
avg_envstep_per_sec: 802.3139576042194
avg_train_sample_per_sec: 802.3139576042194
avg_episode_per_sec: 7.218049445574291
collect_time: 1.8010405855519431
reward_mean: 587.3076782226562
reward_std: 367.888427734375
reward_max: 1319.0
reward_min: 240.0
total_envstep_count: 411406
total_train_sample_count: 411371
total_episode_count: 2802
total_duration: 528.1277837710717
[2024-11-19 22:22:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1041
train_sample_count: 1041
avg_envstep_per_episode: 104.1
avg_sample_per_episode: 104.1
avg_envstep_per_sec: 795.799665474307
avg_train_sample_per_sec: 795.799665474307
avg_episode_per_sec: 7.644569312913611
collect_time: 1.3081181673776534
reward_mean: 595.0
reward_std: 408.1678466796875
reward_max: 1548.0
reward_min: 205.0
total_envstep_count: 412412
total_train_sample_count: 412388
total_episode_count: 2812
total_duration: 529.4359019384493
[2024-11-19 22:22:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 559
train_sample_count: 559
avg_envstep_per_episode: 139.75
avg_sample_per_episode: 139.75
avg_envstep_per_sec: 793.6988471022121
avg_train_sample_per_sec: 793.6988471022121
avg_episode_per_sec: 5.679419299479156
collect_time: 0.7042973566622962
reward_mean: 703.5
reward_std: 298.4765625
reward_max: 1036.0
reward_min: 221.0
total_envstep_count: 413432
total_train_sample_count: 413367
total_episode_count: 2816
total_duration: 530.1401992951116
[2024-11-19 22:22:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1318
train_sample_count: 1318
avg_envstep_per_episode: 188.28571428571428
avg_sample_per_episode: 188.28571428571428
avg_envstep_per_sec: 800.672327203323
avg_train_sample_per_sec: 800.672327203323
avg_episode_per_sec: 4.252432693796101
collect_time: 1.6461165887968883
reward_mean: 902.5714111328125
reward_std: 324.4163513183594
reward_max: 1312.0
reward_min: 240.0
total_envstep_count: 414402
total_train_sample_count: 414361
total_episode_count: 2823
total_duration: 531.7863158839085
[2024-11-19 22:22:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1303
train_sample_count: 1303
avg_envstep_per_episode: 108.58333333333333
avg_sample_per_episode: 108.58333333333333
avg_envstep_per_sec: 805.2320482866273
avg_train_sample_per_sec: 805.2320482866273
avg_episode_per_sec: 7.415797835333483
collect_time: 1.6181670895644593
reward_mean: 446.4166564941406
reward_std: 310.9234924316406
reward_max: 1030.0
reward_min: 100.0
total_envstep_count: 415423
total_train_sample_count: 415388
total_episode_count: 2835
total_duration: 533.404482973473
[2024-11-19 22:22:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 383
train_sample_count: 383
avg_envstep_per_episode: 63.833333333333336
avg_sample_per_episode: 63.833333333333336
avg_envstep_per_sec: 801.0282520868204
avg_train_sample_per_sec: 801.0282520868204
avg_episode_per_sec: 12.548745463501104
collect_time: 0.4781354452882494
reward_mean: 286.1666564941406
reward_std: 143.53445434570312
reward_max: 603.0
reward_min: 175.0
total_envstep_count: 416419
total_train_sample_count: 416383
total_episode_count: 2841
total_duration: 533.8826184187612
[2024-11-19 22:22:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1178
train_sample_count: 1178
avg_envstep_per_episode: 196.33333333333334
avg_sample_per_episode: 196.33333333333334
avg_envstep_per_sec: 804.4053278972958
avg_train_sample_per_sec: 804.4053278972958
avg_episode_per_sec: 4.097140889120352
collect_time: 1.4644358498709542
reward_mean: 999.3333129882812
reward_std: 164.87234497070312
reward_max: 1131.0
reward_min: 638.0
total_envstep_count: 417430
total_train_sample_count: 417381
total_episode_count: 2847
total_duration: 535.3470542686322
[2024-11-19 22:22:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1292
train_sample_count: 1292
avg_envstep_per_episode: 129.2
avg_sample_per_episode: 129.2
avg_envstep_per_sec: 795.9191128204354
avg_train_sample_per_sec: 795.9191128204354
avg_episode_per_sec: 6.160364650312967
collect_time: 1.6232805308841525
reward_mean: 648.7999877929688
reward_std: 412.3980407714844
reward_max: 1398.0
reward_min: 239.0
total_envstep_count: 418452
total_train_sample_count: 418409
total_episode_count: 2857
total_duration: 536.9703347995163
[2024-11-19 22:22:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 984
train_sample_count: 984
avg_envstep_per_episode: 109.33333333333333
avg_sample_per_episode: 109.33333333333333
avg_envstep_per_sec: 797.2731850630277
avg_train_sample_per_sec: 797.2731850630277
avg_episode_per_sec: 7.292132790210619
collect_time: 1.234206816979817
reward_mean: 620.3333129882812
reward_std: 298.480224609375
reward_max: 1323.0
reward_min: 234.0
total_envstep_count: 419486
total_train_sample_count: 419441
total_episode_count: 2866
total_duration: 538.2045416164962
[2024-11-19 22:23:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 489
train_sample_count: 489
avg_envstep_per_episode: 81.5
avg_sample_per_episode: 81.5
avg_envstep_per_sec: 790.1561725470642
avg_train_sample_per_sec: 790.1561725470642
avg_episode_per_sec: 9.695167761313671
collect_time: 0.6188650003501347
reward_mean: 504.5
reward_std: 380.16827392578125
reward_max: 1052.0
reward_min: 226.0
total_envstep_count: 420481
total_train_sample_count: 420446
total_episode_count: 2872
total_duration: 538.8234066168463
[2024-11-19 22:23:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1072
train_sample_count: 1072
avg_envstep_per_episode: 119.11111111111111
avg_sample_per_episode: 119.11111111111111
avg_envstep_per_sec: 795.7023643140568
avg_train_sample_per_sec: 795.7023643140568
avg_episode_per_sec: 6.680337013830701
collect_time: 1.347237419514429
reward_mean: 637.5555419921875
reward_std: 288.388671875
reward_max: 1141.0
reward_min: 236.0
total_envstep_count: 421472
total_train_sample_count: 421434
total_episode_count: 2881
total_duration: 540.1706440363607
[2024-11-19 22:23:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1151
train_sample_count: 1151
avg_envstep_per_episode: 143.875
avg_sample_per_episode: 143.875
avg_envstep_per_sec: 791.644290509544
avg_train_sample_per_sec: 791.644290509544
avg_episode_per_sec: 5.502306102585884
collect_time: 1.453935831785202
reward_mean: 691.375
reward_std: 432.81805419921875
reward_max: 1312.0
reward_min: 218.0
total_envstep_count: 422496
total_train_sample_count: 422465
total_episode_count: 2889
total_duration: 541.6245798681459
[2024-11-19 22:23:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1308
train_sample_count: 1308
avg_envstep_per_episode: 118.9090909090909
avg_sample_per_episode: 118.9090909090909
avg_envstep_per_sec: 798.732288319787
avg_train_sample_per_sec: 798.732288319787
avg_episode_per_sec: 6.717167562322368
collect_time: 1.637594997882843
reward_mean: 700.272705078125
reward_std: 407.7602233886719
reward_max: 1336.0
reward_min: 245.0
total_envstep_count: 423496
total_train_sample_count: 423461
total_episode_count: 2900
total_duration: 543.2621748660288
[2024-11-19 22:23:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 875
train_sample_count: 875
avg_envstep_per_episode: 109.375
avg_sample_per_episode: 109.375
avg_envstep_per_sec: 788.770275274176
avg_train_sample_per_sec: 788.770275274176
avg_episode_per_sec: 7.2116139453638946
collect_time: 1.1093217219625202
reward_mean: 714.75
reward_std: 481.27972412109375
reward_max: 1337.0
reward_min: 242.0
total_envstep_count: 424481
total_train_sample_count: 424456
total_episode_count: 2908
total_duration: 544.3714965879913
[2024-11-19 22:23:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1139
train_sample_count: 1139
avg_envstep_per_episode: 87.61538461538461
avg_sample_per_episode: 87.61538461538461
avg_envstep_per_sec: 770.1513440718404
avg_train_sample_per_sec: 770.1513440718404
avg_episode_per_sec: 8.790138255429259
collect_time: 1.478930094412395
reward_mean: 577.5384521484375
reward_std: 360.35296630859375
reward_max: 1306.0
reward_min: 230.0
total_envstep_count: 425503
total_train_sample_count: 425463
total_episode_count: 2921
total_duration: 545.8504266824036
[2024-11-19 22:23:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1076
train_sample_count: 1076
avg_envstep_per_episode: 107.6
avg_sample_per_episode: 107.6
avg_envstep_per_sec: 785.4029191320247
avg_train_sample_per_sec: 785.4029191320247
avg_episode_per_sec: 7.299283635055993
collect_time: 1.3699974545410702
reward_mean: 682.2999877929688
reward_std: 374.7660827636719
reward_max: 1432.0
reward_min: 237.0
total_envstep_count: 426511
total_train_sample_count: 426479
total_episode_count: 2931
total_duration: 547.2204241369446
[2024-11-19 22:23:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 659
train_sample_count: 659
avg_envstep_per_episode: 94.14285714285714
avg_sample_per_episode: 94.14285714285714
avg_envstep_per_sec: 786.5996138823344
avg_train_sample_per_sec: 786.5996138823344
avg_episode_per_sec: 8.35538284852252
collect_time: 0.837783274196443
reward_mean: 506.1428527832031
reward_std: 172.58572387695312
reward_max: 633.0
reward_min: 224.0
total_envstep_count: 427505
total_train_sample_count: 427450
total_episode_count: 2938
total_duration: 548.0582074111411
[2024-11-19 22:23:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1050
train_sample_count: 1050
avg_envstep_per_episode: 116.66666666666667
avg_sample_per_episode: 116.66666666666667
avg_envstep_per_sec: 776.8462188768056
avg_train_sample_per_sec: 776.8462188768056
avg_episode_per_sec: 6.658681876086905
collect_time: 1.3516188590299516
reward_mean: 778.6666870117188
reward_std: 431.1702575683594
reward_max: 1575.0
reward_min: 222.0
total_envstep_count: 428514
total_train_sample_count: 428476
total_episode_count: 2947
total_duration: 549.409826270171
[2024-11-19 22:23:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 791
train_sample_count: 791
avg_envstep_per_episode: 87.88888888888889
avg_sample_per_episode: 87.88888888888889
avg_envstep_per_sec: 772.7304364433717
avg_train_sample_per_sec: 772.7304364433717
avg_episode_per_sec: 8.792128859659096
collect_time: 1.0236428678035736
reward_mean: 534.5555419921875
reward_std: 381.9878234863281
reward_max: 1419.0
reward_min: 247.0
total_envstep_count: 429513
total_train_sample_count: 429471
total_episode_count: 2956
total_duration: 550.4334691379746
[2024-11-19 22:23:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1422
train_sample_count: 1422
avg_envstep_per_episode: 129.27272727272728
avg_sample_per_episode: 129.27272727272728
avg_envstep_per_sec: 782.5984572013555
avg_train_sample_per_sec: 782.5984572013555
avg_episode_per_sec: 6.053855857394451
collect_time: 1.8170237711497716
reward_mean: 628.0
reward_std: 338.5498352050781
reward_max: 1048.0
reward_min: 197.0
total_envstep_count: 430512
total_train_sample_count: 430473
total_episode_count: 2967
total_duration: 552.2504929091244
[2024-11-19 22:23:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 736
train_sample_count: 736
avg_envstep_per_episode: 105.14285714285714
avg_sample_per_episode: 105.14285714285714
avg_envstep_per_sec: 800.6007920904071
avg_train_sample_per_sec: 800.6007920904071
avg_episode_per_sec: 7.61440970738159
collect_time: 0.9193096075739179
reward_mean: 500.0
reward_std: 329.6444091796875
reward_max: 1118.0
reward_min: 238.0
total_envstep_count: 431483
total_train_sample_count: 431461
total_episode_count: 2974
total_duration: 553.1698025166984
[2024-11-19 22:23:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 883
train_sample_count: 883
avg_envstep_per_episode: 98.11111111111111
avg_sample_per_episode: 98.11111111111111
avg_envstep_per_sec: 801.5052790730447
avg_train_sample_per_sec: 801.5052790730447
avg_episode_per_sec: 8.169362980359459
collect_time: 1.101677085672106
reward_mean: 514.888916015625
reward_std: 273.9425964355469
reward_max: 1038.0
reward_min: 229.0
total_envstep_count: 432499
total_train_sample_count: 432464
total_episode_count: 2983
total_duration: 554.2714796023705
[2024-11-19 22:23:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1337
train_sample_count: 1337
avg_envstep_per_episode: 121.54545454545455
avg_sample_per_episode: 121.54545454545455
avg_envstep_per_sec: 796.1693108692093
avg_train_sample_per_sec: 796.1693108692093
avg_episode_per_sec: 6.550383260704041
collect_time: 1.6792910524777005
reward_mean: 632.0908813476562
reward_std: 422.0089416503906
reward_max: 1415.0
reward_min: 246.0
total_envstep_count: 433505
total_train_sample_count: 433465
total_episode_count: 2994
total_duration: 555.9507706548482
[2024-11-19 22:23:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 918
train_sample_count: 918
avg_envstep_per_episode: 131.14285714285714
avg_sample_per_episode: 131.14285714285714
avg_envstep_per_sec: 804.6525123271259
avg_train_sample_per_sec: 804.6525123271259
avg_episode_per_sec: 6.135694538442136
collect_time: 1.1408651385988509
reward_mean: 638.5714111328125
reward_std: 312.33538818359375
reward_max: 1030.0
reward_min: 187.0
total_envstep_count: 434515
total_train_sample_count: 434479
total_episode_count: 3001
total_duration: 557.091635793447
[2024-11-19 22:23:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 948
train_sample_count: 948
avg_envstep_per_episode: 94.8
avg_sample_per_episode: 94.8
avg_envstep_per_sec: 796.1974715466598
avg_train_sample_per_sec: 796.1974715466598
avg_episode_per_sec: 8.398707505766453
collect_time: 1.190659395286015
reward_mean: 419.70001220703125
reward_std: 231.0580291748047
reward_max: 794.0
reward_min: 223.0
total_envstep_count: 435530
total_train_sample_count: 435475
total_episode_count: 3011
total_duration: 558.2822951887331
[2024-11-19 22:23:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 857
train_sample_count: 857
avg_envstep_per_episode: 107.125
avg_sample_per_episode: 107.125
avg_envstep_per_sec: 789.0147844181633
avg_train_sample_per_sec: 789.0147844181633
avg_episode_per_sec: 7.365365548827662
collect_time: 1.0861646916185106
reward_mean: 551.0
reward_std: 271.38165283203125
reward_max: 1034.0
reward_min: 229.0
total_envstep_count: 436506
total_train_sample_count: 436476
total_episode_count: 3019
total_duration: 559.3684598803516
[2024-11-19 22:24:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1121
train_sample_count: 1121
avg_envstep_per_episode: 101.9090909090909
avg_sample_per_episode: 101.9090909090909
avg_envstep_per_sec: 795.7241905727044
avg_train_sample_per_sec: 795.7241905727044
avg_episode_per_sec: 7.808176713915922
collect_time: 1.408779591321945
reward_mean: 489.3636474609375
reward_std: 265.6019592285156
reward_max: 1011.0
reward_min: 191.0
total_envstep_count: 437504
total_train_sample_count: 437477
total_episode_count: 3030
total_duration: 560.7772394716735
[2024-11-19 22:24:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1030
train_sample_count: 1030
avg_envstep_per_episode: 171.66666666666666
avg_sample_per_episode: 171.66666666666666
avg_envstep_per_sec: 789.1498065202408
avg_train_sample_per_sec: 789.1498065202408
avg_episode_per_sec: 4.596989164195578
collect_time: 1.3052021194071999
reward_mean: 849.6666870117188
reward_std: 386.4654541015625
reward_max: 1302.0
reward_min: 110.0
total_envstep_count: 438523
total_train_sample_count: 438483
total_episode_count: 3036
total_duration: 562.0824415910807
[2024-11-19 22:24:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1170
train_sample_count: 1170
avg_envstep_per_episode: 90.0
avg_sample_per_episode: 90.0
avg_envstep_per_sec: 795.8123472965345
avg_train_sample_per_sec: 795.8123472965345
avg_episode_per_sec: 8.842359414405939
collect_time: 1.470195836964108
reward_mean: 447.4615478515625
reward_std: 239.5378875732422
reward_max: 1021.0
reward_min: 239.0
total_envstep_count: 439521
total_train_sample_count: 439473
total_episode_count: 3049
total_duration: 563.5526374280448
[2024-11-19 22:24:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 908
train_sample_count: 908
avg_envstep_per_episode: 113.5
avg_sample_per_episode: 113.5
avg_envstep_per_sec: 788.9711274563334
avg_train_sample_per_sec: 788.9711274563334
avg_episode_per_sec: 6.951287466575625
collect_time: 1.1508659422397614
reward_mean: 778.25
reward_std: 336.8036193847656
reward_max: 1334.0
reward_min: 245.0
total_envstep_count: 440506
total_train_sample_count: 440477
total_episode_count: 3057
total_duration: 564.7035033702846
[2024-11-19 22:24:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 809
train_sample_count: 809
avg_envstep_per_episode: 89.88888888888889
avg_sample_per_episode: 89.88888888888889
avg_envstep_per_sec: 797.7171281217866
avg_train_sample_per_sec: 797.7171281217866
avg_episode_per_sec: 8.874479793691075
collect_time: 1.0141439508824122
reward_mean: 521.5555419921875
reward_std: 387.93304443359375
reward_max: 1310.0
reward_min: 197.0
total_envstep_count: 441498
total_train_sample_count: 441454
total_episode_count: 3066
total_duration: 565.717647321167
[2024-11-19 22:24:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1229
train_sample_count: 1229
avg_envstep_per_episode: 175.57142857142858
avg_sample_per_episode: 175.57142857142858
avg_envstep_per_sec: 796.8965074966736
avg_train_sample_per_sec: 796.8965074966736
avg_episode_per_sec: 4.538873517068116
collect_time: 1.5422328852471852
reward_mean: 975.2857055664062
reward_std: 205.79859924316406
reward_max: 1301.0
reward_min: 608.0
total_envstep_count: 442493
total_train_sample_count: 442467
total_episode_count: 3073
total_duration: 567.2598802064141
[2024-11-19 22:24:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 689
train_sample_count: 689
avg_envstep_per_episode: 86.125
avg_sample_per_episode: 86.125
avg_envstep_per_sec: 794.2430676300565
avg_train_sample_per_sec: 794.2430676300565
avg_episode_per_sec: 9.22198046595131
collect_time: 0.86749262043408
reward_mean: 639.0
reward_std: 283.6335754394531
reward_max: 1050.0
reward_min: 240.0
total_envstep_count: 443501
total_train_sample_count: 443468
total_episode_count: 3081
total_duration: 568.1273728268482
[2024-11-19 22:24:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 1357
train_sample_count: 1357
avg_envstep_per_episode: 96.92857142857143
avg_sample_per_episode: 96.92857142857143
avg_envstep_per_sec: 797.2079797086378
avg_train_sample_per_sec: 797.2079797086378
avg_episode_per_sec: 8.224695442830457
collect_time: 1.7021906886781966
reward_mean: 590.2857055664062
reward_std: 487.58111572265625
reward_max: 1424.0
reward_min: 194.0
total_envstep_count: 444552
total_train_sample_count: 444501
total_episode_count: 3095
total_duration: 569.8295635155264
[2024-11-19 22:24:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1104
train_sample_count: 1104
avg_envstep_per_episode: 138.0
avg_sample_per_episode: 138.0
avg_envstep_per_sec: 792.1960038817838
avg_train_sample_per_sec: 792.1960038817838
avg_episode_per_sec: 5.740550752766549
collect_time: 1.3935945076601843
reward_mean: 857.625
reward_std: 262.1263732910156
reward_max: 1318.0
reward_min: 583.0
total_envstep_count: 445552
total_train_sample_count: 445509
total_episode_count: 3103
total_duration: 571.2231580231866
[2024-11-19 22:24:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 871
train_sample_count: 871
avg_envstep_per_episode: 96.77777777777777
avg_sample_per_episode: 96.77777777777777
avg_envstep_per_sec: 806.775219194187
avg_train_sample_per_sec: 806.775219194187
avg_episode_per_sec: 8.336368510617318
collect_time: 1.0796067842415402
reward_mean: 580.3333129882812
reward_std: 449.09613037109375
reward_max: 1576.0
reward_min: 156.0
total_envstep_count: 446552
total_train_sample_count: 446500
total_episode_count: 3112
total_duration: 572.302764807428
[2024-11-19 22:24:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 851
train_sample_count: 851
avg_envstep_per_episode: 106.375
avg_sample_per_episode: 106.375
avg_envstep_per_sec: 796.8560616770964
avg_train_sample_per_sec: 796.8560616770964
avg_episode_per_sec: 7.491008805425112
collect_time: 1.0679469491754259
reward_mean: 768.25
reward_std: 429.1531677246094
reward_max: 1430.0
reward_min: 239.0
total_envstep_count: 447553
total_train_sample_count: 447507
total_episode_count: 3120
total_duration: 573.3707117566034
[2024-11-19 22:25:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 432
train_sample_count: 432
avg_envstep_per_episode: 144.0
avg_sample_per_episode: 144.0
avg_envstep_per_sec: 802.6578899968432
avg_train_sample_per_sec: 802.6578899968432
avg_episode_per_sec: 5.574013124978078
collect_time: 0.5382118650845119
reward_mean: 634.0
reward_std: 318.4839172363281
reward_max: 1028.0
reward_min: 248.0
total_envstep_count: 448519
total_train_sample_count: 448491
total_episode_count: 3123
total_duration: 573.9089236216879
[2024-11-19 22:25:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1518
train_sample_count: 1518
avg_envstep_per_episode: 189.75
avg_sample_per_episode: 189.75
avg_envstep_per_sec: 801.4578443640761
avg_train_sample_per_sec: 801.4578443640761
avg_episode_per_sec: 4.223756755541903
collect_time: 1.8940484651497431
reward_mean: 894.875
reward_std: 547.7516479492188
reward_max: 1553.0
reward_min: 224.0
total_envstep_count: 449505
total_train_sample_count: 449481
total_episode_count: 3131
total_duration: 575.8029720868376
[2024-11-19 22:25:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1080
train_sample_count: 1080
avg_envstep_per_episode: 154.28571428571428
avg_sample_per_episode: 154.28571428571428
avg_envstep_per_sec: 800.4999199773063
avg_train_sample_per_sec: 800.4999199773063
avg_episode_per_sec: 5.188425407260318
collect_time: 1.3491569118840354
reward_mean: 873.7142944335938
reward_std: 417.61285400390625
reward_max: 1547.0
reward_min: 246.0
total_envstep_count: 450532
total_train_sample_count: 450489
total_episode_count: 3138
total_duration: 577.1521289987217
[2024-11-19 22:25:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1206
train_sample_count: 1206
avg_envstep_per_episode: 150.75
avg_sample_per_episode: 150.75
avg_envstep_per_sec: 800.789684245509
avg_train_sample_per_sec: 800.789684245509
avg_episode_per_sec: 5.31203770643787
collect_time: 1.5060134061745234
reward_mean: 858.25
reward_std: 406.49530029296875
reward_max: 1675.0
reward_min: 238.0
total_envstep_count: 451534
total_train_sample_count: 451491
total_episode_count: 3146
total_duration: 578.6581424048961
[2024-11-19 22:25:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 825
train_sample_count: 825
avg_envstep_per_episode: 137.5
avg_sample_per_episode: 137.5
avg_envstep_per_sec: 786.0785996068529
avg_train_sample_per_sec: 786.0785996068529
avg_episode_per_sec: 5.716935269868021
collect_time: 1.0495133697986603
reward_mean: 845.3333129882812
reward_std: 418.8132629394531
reward_max: 1574.0
reward_min: 239.0
total_envstep_count: 452507
total_train_sample_count: 452472
total_episode_count: 3152
total_duration: 579.7076557746948
[2024-11-19 22:25:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 773
train_sample_count: 773
avg_envstep_per_episode: 96.625
avg_sample_per_episode: 96.625
avg_envstep_per_sec: 786.6084476610804
avg_train_sample_per_sec: 786.6084476610804
avg_episode_per_sec: 8.140837750696821
collect_time: 0.9826998455183846
reward_mean: 535.625
reward_std: 330.7759704589844
reward_max: 1046.0
reward_min: 233.0
total_envstep_count: 453533
total_train_sample_count: 453497
total_episode_count: 3160
total_duration: 580.6903556202132
[2024-11-19 22:25:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1106
train_sample_count: 1106
avg_envstep_per_episode: 184.33333333333334
avg_sample_per_episode: 184.33333333333334
avg_envstep_per_sec: 798.1292107625663
avg_train_sample_per_sec: 798.1292107625663
avg_episode_per_sec: 4.329814886596201
collect_time: 1.3857405355998447
reward_mean: 763.1666870117188
reward_std: 388.1234436035156
reward_max: 1535.0
reward_min: 248.0
total_envstep_count: 454520
total_train_sample_count: 454495
total_episode_count: 3166
total_duration: 582.076096155813
[2024-11-19 22:25:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 992
train_sample_count: 992
avg_envstep_per_episode: 165.33333333333334
avg_sample_per_episode: 165.33333333333334
avg_envstep_per_sec: 797.0019265425562
avg_train_sample_per_sec: 797.0019265425562
avg_episode_per_sec: 4.820576168604171
collect_time: 1.2446644944804055
reward_mean: 881.5
reward_std: 344.8689270019531
reward_max: 1304.0
reward_min: 246.0
total_envstep_count: 455530
total_train_sample_count: 455499
total_episode_count: 3172
total_duration: 583.3207606502934
[2024-11-19 22:25:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 991
train_sample_count: 991
avg_envstep_per_episode: 165.16666666666666
avg_sample_per_episode: 165.16666666666666
avg_envstep_per_sec: 804.4645508739527
avg_train_sample_per_sec: 804.4645508739527
avg_episode_per_sec: 4.870622911446737
collect_time: 1.2318752876349857
reward_mean: 797.8333129882812
reward_std: 209.7692413330078
reward_max: 1098.0
reward_min: 603.0
total_envstep_count: 456525
total_train_sample_count: 456490
total_episode_count: 3178
total_duration: 584.5526359379285
[2024-11-19 22:25:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 521
train_sample_count: 521
avg_envstep_per_episode: 130.25
avg_sample_per_episode: 130.25
avg_envstep_per_sec: 807.3526454517315
avg_train_sample_per_sec: 807.3526454517315
avg_episode_per_sec: 6.198484801932679
collect_time: 0.6453189977577755
reward_mean: 556.5
reward_std: 187.31590270996094
reward_max: 756.0
reward_min: 250.0
total_envstep_count: 457497
total_train_sample_count: 457467
total_episode_count: 3182
total_duration: 585.1979549356862
[2024-11-19 22:25:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1661
train_sample_count: 1661
avg_envstep_per_episode: 207.625
avg_sample_per_episode: 207.625
avg_envstep_per_sec: 793.6580766026121
avg_train_sample_per_sec: 793.6580766026121
avg_episode_per_sec: 3.822555456243767
collect_time: 2.092840795006071
reward_mean: 978.625
reward_std: 435.78717041015625
reward_max: 1553.0
reward_min: 233.0
total_envstep_count: 458514
total_train_sample_count: 458480
total_episode_count: 3190
total_duration: 587.2907957306923
[2024-11-19 22:26:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1012
train_sample_count: 1012
avg_envstep_per_episode: 112.44444444444444
avg_sample_per_episode: 112.44444444444444
avg_envstep_per_sec: 784.3210759491196
avg_train_sample_per_sec: 784.3210759491196
avg_episode_per_sec: 6.975187434330115
collect_time: 1.2902879076344627
reward_mean: 697.2222290039062
reward_std: 458.41168212890625
reward_max: 1693.0
reward_min: 229.0
total_envstep_count: 459522
total_train_sample_count: 459492
total_episode_count: 3199
total_duration: 588.5810836383267
[2024-11-19 22:26:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 896
train_sample_count: 896
avg_envstep_per_episode: 112.0
avg_sample_per_episode: 112.0
avg_envstep_per_sec: 784.579790429949
avg_train_sample_per_sec: 784.579790429949
avg_episode_per_sec: 7.005176700267402
collect_time: 1.1420125918728965
reward_mean: 666.25
reward_std: 344.66497802734375
reward_max: 1340.0
reward_min: 239.0
total_envstep_count: 460532
total_train_sample_count: 460496
total_episode_count: 3207
total_duration: 589.7230962301996
[2024-11-19 22:26:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1001
train_sample_count: 1001
avg_envstep_per_episode: 111.22222222222223
avg_sample_per_episode: 111.22222222222223
avg_envstep_per_sec: 795.5896601455776
avg_train_sample_per_sec: 795.5896601455776
avg_episode_per_sec: 7.153153787522676
collect_time: 1.2581862864040192
reward_mean: 694.5555419921875
reward_std: 426.3298645019531
reward_max: 1567.0
reward_min: 235.0
total_envstep_count: 461524
total_train_sample_count: 461485
total_episode_count: 3216
total_duration: 590.9812825166036
[2024-11-19 22:26:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 838
train_sample_count: 838
avg_envstep_per_episode: 209.5
avg_sample_per_episode: 209.5
avg_envstep_per_sec: 810.1357704576042
avg_train_sample_per_sec: 810.1357704576042
avg_episode_per_sec: 3.8669965176973946
collect_time: 1.034394518250511
reward_mean: 1294.0
reward_std: 615.0963134765625
reward_max: 2342.0
reward_min: 764.0
total_envstep_count: 462504
total_train_sample_count: 462467
total_episode_count: 3220
total_duration: 592.0156770348542
[2024-11-19 22:26:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1268
train_sample_count: 1268
avg_envstep_per_episode: 140.88888888888889
avg_sample_per_episode: 140.88888888888889
avg_envstep_per_sec: 805.8155904341926
avg_train_sample_per_sec: 805.8155904341926
avg_episode_per_sec: 5.719511288570768
collect_time: 1.5735610170023782
reward_mean: 914.3333129882812
reward_std: 493.3011169433594
reward_max: 1574.0
reward_min: 248.0
total_envstep_count: 463505
total_train_sample_count: 463447
total_episode_count: 3229
total_duration: 593.5892380518566
[2024-11-19 22:26:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 884
train_sample_count: 884
avg_envstep_per_episode: 126.28571428571429
avg_sample_per_episode: 126.28571428571429
avg_envstep_per_sec: 795.9818445985743
avg_train_sample_per_sec: 795.9818445985743
avg_episode_per_sec: 6.3030236563235515
collect_time: 1.1105780942099435
reward_mean: 745.0
reward_std: 396.85333251953125
reward_max: 1318.0
reward_min: 230.0
total_envstep_count: 464522
total_train_sample_count: 464487
total_episode_count: 3236
total_duration: 594.6998161460665
[2024-11-19 22:26:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1052
train_sample_count: 1052
avg_envstep_per_episode: 131.5
avg_sample_per_episode: 131.5
avg_envstep_per_sec: 794.8106639353344
avg_train_sample_per_sec: 794.8106639353344
avg_episode_per_sec: 6.044187558443608
collect_time: 1.3235856635229928
reward_mean: 873.75
reward_std: 446.6689758300781
reward_max: 1417.0
reward_min: 246.0
total_envstep_count: 465507
total_train_sample_count: 465479
total_episode_count: 3244
total_duration: 596.0234018095895
[2024-11-19 22:26:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 771
train_sample_count: 771
avg_envstep_per_episode: 96.375
avg_sample_per_episode: 96.375
avg_envstep_per_sec: 805.4547471811305
avg_train_sample_per_sec: 805.4547471811305
avg_episode_per_sec: 8.357507104343767
collect_time: 0.9572232365608215
reward_mean: 643.75
reward_std: 339.6169738769531
reward_max: 1420.0
reward_min: 247.0
total_envstep_count: 466508
total_train_sample_count: 466466
total_episode_count: 3252
total_duration: 596.9806250461503
[2024-11-19 22:26:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1432
train_sample_count: 1432
avg_envstep_per_episode: 130.1818181818182
avg_sample_per_episode: 130.1818181818182
avg_envstep_per_sec: 803.0846525751414
avg_train_sample_per_sec: 803.0846525751414
avg_episode_per_sec: 6.168946353579996
collect_time: 1.783124600137983
reward_mean: 801.5454711914062
reward_std: 417.43011474609375
reward_max: 1667.0
reward_min: 245.0
total_envstep_count: 467514
total_train_sample_count: 467478
total_episode_count: 3263
total_duration: 598.7637496462883
[2024-11-19 22:26:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 564
train_sample_count: 564
avg_envstep_per_episode: 112.8
avg_sample_per_episode: 112.8
avg_envstep_per_sec: 799.2442726730615
avg_train_sample_per_sec: 799.2442726730615
avg_episode_per_sec: 7.085498871215084
collect_time: 0.7056666144302914
reward_mean: 740.5999755859375
reward_std: 816.3897094726562
reward_max: 2347.0
reward_min: 241.0
total_envstep_count: 468486
total_train_sample_count: 468450
total_episode_count: 3268
total_duration: 599.4694162607185
[2024-11-19 22:26:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1292
train_sample_count: 1292
avg_envstep_per_episode: 184.57142857142858
avg_sample_per_episode: 184.57142857142858
avg_envstep_per_sec: 805.981633029356
avg_train_sample_per_sec: 805.981633029356
avg_episode_per_sec: 4.366773553564622
collect_time: 1.6030141966683527
reward_mean: 1070.7142333984375
reward_std: 416.2604675292969
reward_max: 1689.0
reward_min: 232.0
total_envstep_count: 469490
total_train_sample_count: 469442
total_episode_count: 3275
total_duration: 601.0724304573869
[2024-11-19 22:26:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1019
train_sample_count: 1019
avg_envstep_per_episode: 113.22222222222223
avg_sample_per_episode: 113.22222222222223
avg_envstep_per_sec: 795.6981070977452
avg_train_sample_per_sec: 795.6981070977452
avg_episode_per_sec: 7.027755607340242
collect_time: 1.2806364510740553
reward_mean: 794.888916015625
reward_std: 365.25408935546875
reward_max: 1423.0
reward_min: 233.0
total_envstep_count: 470491
total_train_sample_count: 470437
total_episode_count: 3284
total_duration: 602.353066908461
[2024-11-19 22:26:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1004
train_sample_count: 1004
avg_envstep_per_episode: 111.55555555555556
avg_sample_per_episode: 111.55555555555556
avg_envstep_per_sec: 801.4902244289881
avg_train_sample_per_sec: 801.4902244289881
avg_episode_per_sec: 7.184673326554674
collect_time: 1.252666557119006
reward_mean: 712.5555419921875
reward_std: 355.9126281738281
reward_max: 1309.0
reward_min: 166.0
total_envstep_count: 471427
total_train_sample_count: 471417
total_episode_count: 3293
total_duration: 603.60573346558
[2024-11-19 22:26:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 674
train_sample_count: 674
avg_envstep_per_episode: 67.4
avg_sample_per_episode: 67.4
avg_envstep_per_sec: 808.3543154057851
avg_train_sample_per_sec: 808.3543154057851
avg_episode_per_sec: 11.993387468928562
collect_time: 0.8337927900609515
reward_mean: 480.8999938964844
reward_std: 198.32772827148438
reward_max: 728.0
reward_min: 231.0
total_envstep_count: 472491
total_train_sample_count: 472463
total_episode_count: 3303
total_duration: 604.4395262556409
[2024-11-19 22:26:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 961
train_sample_count: 961
avg_envstep_per_episode: 96.1
avg_sample_per_episode: 96.1
avg_envstep_per_sec: 802.9343916669001
avg_train_sample_per_sec: 802.9343916669001
avg_episode_per_sec: 8.355196583422478
collect_time: 1.1968599302428111
reward_mean: 565.9000244140625
reward_std: 411.83502197265625
reward_max: 1537.0
reward_min: 231.0
total_envstep_count: 473515
total_train_sample_count: 473472
total_episode_count: 3313
total_duration: 605.6363861858837
[2024-11-19 22:26:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1621
train_sample_count: 1621
avg_envstep_per_episode: 124.6923076923077
avg_sample_per_episode: 124.6923076923077
avg_envstep_per_sec: 795.623397757974
avg_train_sample_per_sec: 795.623397757974
avg_episode_per_sec: 6.380693504536497
collect_time: 2.0373960903712676
reward_mean: 736.8461303710938
reward_std: 455.7980041503906
reward_max: 1573.0
reward_min: 233.0
total_envstep_count: 474510
total_train_sample_count: 474469
total_episode_count: 3326
total_duration: 607.673782276255
[2024-11-19 22:26:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 621
train_sample_count: 621
avg_envstep_per_episode: 103.5
avg_sample_per_episode: 103.5
avg_envstep_per_sec: 797.9157321766936
avg_train_sample_per_sec: 797.9157321766936
avg_episode_per_sec: 7.709330745668537
collect_time: 0.7782776738916125
reward_mean: 645.5
reward_std: 231.55255126953125
reward_max: 1041.0
reward_min: 249.0
total_envstep_count: 475514
total_train_sample_count: 475486
total_episode_count: 3332
total_duration: 608.4520599501466
[2024-11-19 22:27:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 837
train_sample_count: 837
avg_envstep_per_episode: 209.25
avg_sample_per_episode: 209.25
avg_envstep_per_sec: 800.7447388367789
avg_train_sample_per_sec: 800.7447388367789
avg_episode_per_sec: 3.826737103162623
collect_time: 1.045276927096503
reward_mean: 895.5
reward_std: 418.7657470703125
reward_max: 1335.0
reward_min: 205.0
total_envstep_count: 476494
total_train_sample_count: 476455
total_episode_count: 3336
total_duration: 609.4973368772431
[2024-11-19 22:27:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 929
train_sample_count: 929
avg_envstep_per_episode: 154.83333333333334
avg_sample_per_episode: 154.83333333333334
avg_envstep_per_sec: 804.6491902312192
avg_train_sample_per_sec: 804.6491902312192
avg_episode_per_sec: 5.1968731338937735
collect_time: 1.1545404025486536
reward_mean: 772.6666870117188
reward_std: 349.05999755859375
reward_max: 1552.0
reward_min: 591.0
total_envstep_count: 477497
total_train_sample_count: 477444
total_episode_count: 3342
total_duration: 610.6518772797917
[2024-11-19 22:27:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 910
train_sample_count: 910
avg_envstep_per_episode: 182.0
avg_sample_per_episode: 182.0
avg_envstep_per_sec: 638.0301732931613
avg_train_sample_per_sec: 638.0301732931613
avg_episode_per_sec: 3.5056602928195675
collect_time: 1.4262648352554863
reward_mean: 833.4000244140625
reward_std: 517.5390625
reward_max: 1421.0
reward_min: 201.0
total_envstep_count: 478460
total_train_sample_count: 478426
total_episode_count: 3347
total_duration: 612.0781421150472
[2024-11-19 22:27:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1225
train_sample_count: 1225
avg_envstep_per_episode: 153.125
avg_sample_per_episode: 153.125
avg_envstep_per_sec: 805.4034822839118
avg_train_sample_per_sec: 805.4034822839118
avg_episode_per_sec: 5.259777843486771
collect_time: 1.5209767861025671
reward_mean: 880.875
reward_std: 404.0697326660156
reward_max: 1844.0
reward_min: 585.0
total_envstep_count: 479445
total_train_sample_count: 479411
total_episode_count: 3355
total_duration: 613.5991189011497
[2024-11-19 22:27:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 999
train_sample_count: 999
avg_envstep_per_episode: 99.9
avg_sample_per_episode: 99.9
avg_envstep_per_sec: 808.4219032431755
avg_train_sample_per_sec: 808.4219032431755
avg_episode_per_sec: 8.09231134377553
collect_time: 1.2357408872672493
reward_mean: 609.0
reward_std: 281.6185302734375
reward_max: 1049.0
reward_min: 236.0
total_envstep_count: 480470
total_train_sample_count: 480446
total_episode_count: 3365
total_duration: 614.834859788417
[2024-11-19 22:27:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 263
train_sample_count: 263
avg_envstep_per_episode: 131.5
avg_sample_per_episode: 131.5
avg_envstep_per_sec: 792.4903738086177
avg_train_sample_per_sec: 792.4903738086177
avg_episode_per_sec: 6.026542766605458
collect_time: 0.3318652297769274
reward_mean: 619.5
reward_std: 1.5
reward_max: 621.0
reward_min: 618.0
total_envstep_count: 481453
total_train_sample_count: 481429
total_episode_count: 3367
total_duration: 615.1667250181939
[2024-11-19 22:27:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 2050
train_sample_count: 2050
avg_envstep_per_episode: 157.69230769230768
avg_sample_per_episode: 157.69230769230768
avg_envstep_per_sec: 804.5866304403743
avg_train_sample_per_sec: 804.5866304403743
avg_episode_per_sec: 5.102256680841398
collect_time: 2.5478922000953133
reward_mean: 673.6153564453125
reward_std: 464.5885925292969
reward_max: 1676.0
reward_min: 231.0
total_envstep_count: 482466
total_train_sample_count: 482447
total_episode_count: 3380
total_duration: 617.7146172182893
[2024-11-19 22:27:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 795
train_sample_count: 795
avg_envstep_per_episode: 88.33333333333333
avg_sample_per_episode: 88.33333333333333
avg_envstep_per_sec: 793.6834839364204
avg_train_sample_per_sec: 793.6834839364204
avg_episode_per_sec: 8.985096044563251
collect_time: 1.001658741916929
reward_mean: 644.6666870117188
reward_std: 332.392333984375
reward_max: 1070.0
reward_min: 238.0
total_envstep_count: 483516
total_train_sample_count: 483482
total_episode_count: 3389
total_duration: 618.7162759602062
[2024-11-19 22:27:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1076
train_sample_count: 1076
avg_envstep_per_episode: 119.55555555555556
avg_sample_per_episode: 119.55555555555556
avg_envstep_per_sec: 795.663933557983
avg_train_sample_per_sec: 795.663933557983
avg_episode_per_sec: 6.6551816003920505
collect_time: 1.352329739502498
reward_mean: 848.888916015625
reward_std: 480.3983459472656
reward_max: 1322.0
reward_min: 228.0
total_envstep_count: 484550
total_train_sample_count: 484510
total_episode_count: 3398
total_duration: 620.0686056997087
[2024-11-19 22:27:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1023
train_sample_count: 1023
avg_envstep_per_episode: 102.3
avg_sample_per_episode: 102.3
avg_envstep_per_sec: 795.8563213618821
avg_train_sample_per_sec: 795.8563213618821
avg_episode_per_sec: 7.779631684866883
collect_time: 1.285407896552767
reward_mean: 720.5999755859375
reward_std: 435.833740234375
reward_max: 1579.0
reward_min: 242.0
total_envstep_count: 485572
total_train_sample_count: 485533
total_episode_count: 3408
total_duration: 621.3540135962614
[2024-11-19 22:27:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 983
train_sample_count: 983
avg_envstep_per_episode: 122.875
avg_sample_per_episode: 122.875
avg_envstep_per_sec: 796.8282460854356
avg_train_sample_per_sec: 796.8282460854356
avg_episode_per_sec: 6.484868737216159
collect_time: 1.2336410071168626
reward_mean: 909.125
reward_std: 548.9254150390625
reward_max: 1858.0
reward_min: 248.0
total_envstep_count: 486581
total_train_sample_count: 486528
total_episode_count: 3416
total_duration: 622.5876546033783
[2024-11-19 22:28:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 967
train_sample_count: 967
avg_envstep_per_episode: 120.875
avg_sample_per_episode: 120.875
avg_envstep_per_sec: 791.2897772152808
avg_train_sample_per_sec: 791.2897772152808
avg_episode_per_sec: 6.546347691543171
collect_time: 1.2220554692404613
reward_mean: 696.75
reward_std: 580.2891235351562
reward_max: 1844.0
reward_min: 229.0
total_envstep_count: 487583
total_train_sample_count: 487543
total_episode_count: 3424
total_duration: 623.8097100726187
[2024-11-19 22:28:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1032
train_sample_count: 1032
avg_envstep_per_episode: 114.66666666666667
avg_sample_per_episode: 114.66666666666667
avg_envstep_per_sec: 799.1629844265382
avg_train_sample_per_sec: 799.1629844265382
avg_episode_per_sec: 6.969444631626786
collect_time: 1.2913511012281689
reward_mean: 672.0
reward_std: 351.2928466796875
reward_max: 1067.0
reward_min: 201.0
total_envstep_count: 488606
total_train_sample_count: 488551
total_episode_count: 3433
total_duration: 625.1010611738469
[2024-11-19 22:28:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1213
train_sample_count: 1213
avg_envstep_per_episode: 101.08333333333333
avg_sample_per_episode: 101.08333333333333
avg_envstep_per_sec: 787.4974649820485
avg_train_sample_per_sec: 787.4974649820485
avg_episode_per_sec: 7.790576735189268
collect_time: 1.5403224187237874
reward_mean: 712.8333129882812
reward_std: 497.3006896972656
reward_max: 1907.0
reward_min: 236.0
total_envstep_count: 489571
total_train_sample_count: 489536
total_episode_count: 3445
total_duration: 626.6413835925707
[2024-11-19 22:28:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 451
train_sample_count: 451
avg_envstep_per_episode: 75.16666666666667
avg_sample_per_episode: 75.16666666666667
avg_envstep_per_sec: 797.0780182542325
avg_train_sample_per_sec: 797.0780182542325
avg_episode_per_sec: 10.604142149723714
collect_time: 0.5658166323389325
reward_mean: 490.0
reward_std: 177.57252502441406
reward_max: 634.0
reward_min: 233.0
total_envstep_count: 490558
total_train_sample_count: 490515
total_episode_count: 3451
total_duration: 627.2072002249097
[2024-11-19 22:28:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1547
train_sample_count: 1547
avg_envstep_per_episode: 119.0
avg_sample_per_episode: 119.0
avg_envstep_per_sec: 777.8864333929268
avg_train_sample_per_sec: 777.8864333929268
avg_episode_per_sec: 6.536860784814511
collect_time: 1.988722175359726
reward_mean: 726.3846435546875
reward_std: 600.672119140625
reward_max: 1841.0
reward_min: 234.0
total_envstep_count: 491573
total_train_sample_count: 491546
total_episode_count: 3464
total_duration: 629.1959224002694
[2024-11-19 22:28:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 706
train_sample_count: 706
avg_envstep_per_episode: 100.85714285714286
avg_sample_per_episode: 100.85714285714286
avg_envstep_per_sec: 786.9288164893763
avg_train_sample_per_sec: 786.9288164893763
avg_episode_per_sec: 7.802410361792684
collect_time: 0.8971586568014962
reward_mean: 731.8571166992188
reward_std: 248.678466796875
reward_max: 1340.0
reward_min: 609.0
total_envstep_count: 492558
total_train_sample_count: 492528
total_episode_count: 3471
total_duration: 630.0930810570709
[2024-11-19 22:28:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1257
train_sample_count: 1257
avg_envstep_per_episode: 104.75
avg_sample_per_episode: 104.75
avg_envstep_per_sec: 797.1155682505288
avg_train_sample_per_sec: 797.1155682505288
avg_episode_per_sec: 7.609695162296218
collect_time: 1.576935704265322
reward_mean: 637.75
reward_std: 334.7456970214844
reward_max: 1142.0
reward_min: 228.0
total_envstep_count: 493604
total_train_sample_count: 493557
total_episode_count: 3483
total_duration: 631.6700167613362
[2024-11-19 22:28:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 483
train_sample_count: 483
avg_envstep_per_episode: 80.5
avg_sample_per_episode: 80.5
avg_envstep_per_sec: 807.3681871944993
avg_train_sample_per_sec: 807.3681871944993
avg_episode_per_sec: 10.029418474465832
collect_time: 0.5982400689806256
reward_mean: 565.8333129882812
reward_std: 274.434814453125
reward_max: 1056.0
reward_min: 245.0
total_envstep_count: 494591
total_train_sample_count: 494556
total_episode_count: 3489
total_duration: 632.2682568303169
[2024-11-19 22:28:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1430
train_sample_count: 1430
avg_envstep_per_episode: 143.0
avg_sample_per_episode: 143.0
avg_envstep_per_sec: 797.0802765861133
avg_train_sample_per_sec: 797.0802765861133
avg_episode_per_sec: 5.573987948154638
collect_time: 1.7940476536750796
reward_mean: 886.5999755859375
reward_std: 317.7323303222656
reward_max: 1433.0
reward_min: 612.0
total_envstep_count: 495590
total_train_sample_count: 495554
total_episode_count: 3499
total_duration: 634.062304483992
[2024-11-19 22:28:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 717
train_sample_count: 717
avg_envstep_per_episode: 102.42857142857143
avg_sample_per_episode: 102.42857142857143
avg_envstep_per_sec: 803.9487028716918
avg_train_sample_per_sec: 803.9487028716918
avg_episode_per_sec: 7.848871576153197
collect_time: 0.8918479468141283
reward_mean: 400.1428527832031
reward_std: 320.3415222167969
reward_max: 1026.0
reward_min: 151.0
total_envstep_count: 496592
total_train_sample_count: 496559
total_episode_count: 3506
total_duration: 634.9541524308061
[2024-11-19 22:28:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1107
train_sample_count: 1107
avg_envstep_per_episode: 138.375
avg_sample_per_episode: 138.375
avg_envstep_per_sec: 800.2017339860483
avg_train_sample_per_sec: 800.2017339860483
avg_episode_per_sec: 5.782849026096104
collect_time: 1.3834011512143272
reward_mean: 726.375
reward_std: 380.76202392578125
reward_max: 1424.0
reward_min: 244.0
total_envstep_count: 497593
total_train_sample_count: 497546
total_episode_count: 3514
total_duration: 636.3375535820204
[2024-11-19 22:28:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 669
train_sample_count: 669
avg_envstep_per_episode: 111.5
avg_sample_per_episode: 111.5
avg_envstep_per_sec: 795.616317823553
avg_train_sample_per_sec: 795.616317823553
avg_episode_per_sec: 7.1355723571619105
collect_time: 0.8408575654029846
reward_mean: 673.3333129882812
reward_std: 349.54095458984375
reward_max: 1386.0
reward_min: 219.0
total_envstep_count: 498581
total_train_sample_count: 498551
total_episode_count: 3520
total_duration: 637.1784111474234
[2024-11-19 22:29:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1250
train_sample_count: 1250
avg_envstep_per_episode: 178.57142857142858
avg_sample_per_episode: 178.57142857142858
avg_envstep_per_sec: 805.5717909238954
avg_train_sample_per_sec: 805.5717909238954
avg_episode_per_sec: 4.511202029173814
collect_time: 1.551692864724568
reward_mean: 825.7142944335938
reward_std: 429.2344665527344
reward_max: 1573.0
reward_min: 185.0
total_envstep_count: 499598
total_train_sample_count: 499561
total_episode_count: 3527
total_duration: 638.730104012148
[2024-11-19 22:29:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1019
train_sample_count: 1019
avg_envstep_per_episode: 169.83333333333334
avg_sample_per_episode: 169.83333333333334
avg_envstep_per_sec: 801.7387799194157
avg_train_sample_per_sec: 801.7387799194157
avg_episode_per_sec: 4.720738645256619
collect_time: 1.2709875404834747
reward_mean: 749.3333129882812
reward_std: 283.1976318359375
reward_max: 1025.0
reward_min: 250.0
total_envstep_count: 500577
total_train_sample_count: 500544
total_episode_count: 3533
total_duration: 640.0010915526315
[2024-11-19 22:29:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1142
train_sample_count: 1142
avg_envstep_per_episode: 126.88888888888889
avg_sample_per_episode: 126.88888888888889
avg_envstep_per_sec: 800.1257696375203
avg_train_sample_per_sec: 800.1257696375203
avg_episode_per_sec: 6.305719725689739
collect_time: 1.4272756150790624
reward_mean: 644.111083984375
reward_std: 376.0140380859375
reward_max: 1431.0
reward_min: 183.0
total_envstep_count: 501592
total_train_sample_count: 501554
total_episode_count: 3542
total_duration: 641.4283671677106
[2024-11-19 22:29:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1048
train_sample_count: 1048
avg_envstep_per_episode: 87.33333333333333
avg_sample_per_episode: 87.33333333333333
avg_envstep_per_sec: 789.7286770344268
avg_train_sample_per_sec: 789.7286770344268
avg_episode_per_sec: 9.04269477520336
collect_time: 1.3270380454404016
reward_mean: 480.8333435058594
reward_std: 354.5282897949219
reward_max: 1310.0
reward_min: 179.0
total_envstep_count: 502629
total_train_sample_count: 502602
total_episode_count: 3554
total_duration: 642.755405213151
[2024-11-19 22:29:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1162
train_sample_count: 1162
avg_envstep_per_episode: 129.11111111111111
avg_sample_per_episode: 129.11111111111111
avg_envstep_per_sec: 795.0099534590531
avg_train_sample_per_sec: 795.0099534590531
avg_episode_per_sec: 6.157564183417795
collect_time: 1.4616169205733707
reward_mean: 654.3333129882812
reward_std: 503.0115966796875
reward_max: 1452.0
reward_min: 150.0
total_envstep_count: 503644
total_train_sample_count: 503608
total_episode_count: 3563
total_duration: 644.2170221337244
[2024-11-19 22:29:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1038
train_sample_count: 1038
avg_envstep_per_episode: 94.36363636363636
avg_sample_per_episode: 94.36363636363636
avg_envstep_per_sec: 788.7272704086209
avg_train_sample_per_sec: 788.7272704086209
avg_episode_per_sec: 8.35838147831872
collect_time: 1.3160442638964882
reward_mean: 570.5454711914062
reward_std: 285.40924072265625
reward_max: 1037.0
reward_min: 242.0
total_envstep_count: 504604
total_train_sample_count: 504586
total_episode_count: 3574
total_duration: 645.5330663976209
[2024-11-19 22:29:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 969
train_sample_count: 969
avg_envstep_per_episode: 88.0909090909091
avg_sample_per_episode: 88.0909090909091
avg_envstep_per_sec: 794.8735526615443
avg_train_sample_per_sec: 794.8735526615443
avg_episode_per_sec: 9.023332383154786
collect_time: 1.219061820279984
reward_mean: 519.0908813476562
reward_std: 297.5061340332031
reward_max: 1046.0
reward_min: 213.0
total_envstep_count: 505652
total_train_sample_count: 505615
total_episode_count: 3585
total_duration: 646.7521282179009
[2024-11-19 22:29:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 803
train_sample_count: 803
avg_envstep_per_episode: 73.0
avg_sample_per_episode: 73.0
avg_envstep_per_sec: 788.243931872076
avg_train_sample_per_sec: 788.243931872076
avg_episode_per_sec: 10.797862080439398
collect_time: 1.018720179796219
reward_mean: 528.727294921875
reward_std: 377.5271301269531
reward_max: 1424.0
reward_min: 239.0
total_envstep_count: 506658
total_train_sample_count: 506622
total_episode_count: 3596
total_duration: 647.7708483976971
[2024-11-19 22:29:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1124
train_sample_count: 1124
avg_envstep_per_episode: 160.57142857142858
avg_sample_per_episode: 160.57142857142858
avg_envstep_per_sec: 790.8111217693344
avg_train_sample_per_sec: 790.8111217693344
avg_episode_per_sec: 4.924980295716495
collect_time: 1.4213254834924425
reward_mean: 1050.4285888671875
reward_std: 448.7343444824219
reward_max: 1582.0
reward_min: 223.0
total_envstep_count: 507655
total_train_sample_count: 507614
total_episode_count: 3603
total_duration: 649.1921738811895
[2024-11-19 22:29:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 912
train_sample_count: 912
avg_envstep_per_episode: 114.0
avg_sample_per_episode: 114.0
avg_envstep_per_sec: 801.1976517446211
avg_train_sample_per_sec: 801.1976517446211
avg_episode_per_sec: 7.028049576707203
collect_time: 1.1382958974157062
reward_mean: 677.5
reward_std: 473.92852783203125
reward_max: 1437.0
reward_min: 164.0
total_envstep_count: 508664
total_train_sample_count: 508622
total_episode_count: 3611
total_duration: 650.3304697786052
[2024-11-19 22:29:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1130
train_sample_count: 1130
avg_envstep_per_episode: 113.0
avg_sample_per_episode: 113.0
avg_envstep_per_sec: 792.8711911452627
avg_train_sample_per_sec: 792.8711911452627
avg_episode_per_sec: 7.016559213674891
collect_time: 1.4251999727317266
reward_mean: 759.9000244140625
reward_std: 312.8576354980469
reward_max: 1429.0
reward_min: 234.0
total_envstep_count: 509682
total_train_sample_count: 509644
total_episode_count: 3621
total_duration: 651.755669751337
[2024-11-19 22:29:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 19
envstep_count: 1278
train_sample_count: 1278
avg_envstep_per_episode: 67.26315789473684
avg_sample_per_episode: 67.26315789473684
avg_envstep_per_sec: 797.1441515156852
avg_train_sample_per_sec: 797.1441515156852
avg_episode_per_sec: 11.851125883253536
collect_time: 1.6032232031935734
reward_mean: 431.47369384765625
reward_std: 239.6039276123047
reward_max: 1041.0
reward_min: 227.0
total_envstep_count: 510704
total_train_sample_count: 510670
total_episode_count: 3640
total_duration: 653.3588929545306
[2024-11-19 22:29:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 508
train_sample_count: 508
avg_envstep_per_episode: 101.6
avg_sample_per_episode: 101.6
avg_envstep_per_sec: 796.419645256749
avg_train_sample_per_sec: 796.419645256749
avg_episode_per_sec: 7.838776035991625
collect_time: 0.6378546825477056
reward_mean: 579.2000122070312
reward_std: 309.0885925292969
reward_max: 1050.0
reward_min: 242.0
total_envstep_count: 511684
total_train_sample_count: 511658
total_episode_count: 3645
total_duration: 653.9967476370783
[2024-11-19 22:29:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1070
train_sample_count: 1070
avg_envstep_per_episode: 118.88888888888889
avg_sample_per_episode: 118.88888888888889
avg_envstep_per_sec: 794.2556509575743
avg_train_sample_per_sec: 794.2556509575743
avg_episode_per_sec: 6.680655008054363
collect_time: 1.3471732920124415
reward_mean: 657.111083984375
reward_std: 265.6829528808594
reward_max: 1029.0
reward_min: 247.0
total_envstep_count: 512693
total_train_sample_count: 512668
total_episode_count: 3654
total_duration: 655.3439209290908
[2024-11-19 22:29:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1148
train_sample_count: 1148
avg_envstep_per_episode: 127.55555555555556
avg_sample_per_episode: 127.55555555555556
avg_envstep_per_sec: 802.5911912136819
avg_train_sample_per_sec: 802.5911912136819
avg_episode_per_sec: 6.292091220316322
collect_time: 1.430367056812559
reward_mean: 807.5555419921875
reward_std: 307.060302734375
reward_max: 1323.0
reward_min: 247.0
total_envstep_count: 513725
total_train_sample_count: 513672
total_episode_count: 3663
total_duration: 656.7742879859034
[2024-11-19 22:29:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 983
train_sample_count: 983
avg_envstep_per_episode: 122.875
avg_sample_per_episode: 122.875
avg_envstep_per_sec: 787.6081738680784
avg_train_sample_per_sec: 787.6081738680784
avg_episode_per_sec: 6.409832544195958
collect_time: 1.2480825270925249
reward_mean: 816.5
reward_std: 356.9656982421875
reward_max: 1325.0
reward_min: 237.0
total_envstep_count: 514704
total_train_sample_count: 514655
total_episode_count: 3671
total_duration: 658.0223705129958
[2024-11-19 22:29:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1170
train_sample_count: 1170
avg_envstep_per_episode: 106.36363636363636
avg_sample_per_episode: 106.36363636363636
avg_envstep_per_sec: 804.7366286161554
avg_train_sample_per_sec: 804.7366286161554
avg_episode_per_sec: 7.565899927160435
collect_time: 1.4538918180125098
reward_mean: 643.8181762695312
reward_std: 286.2433166503906
reward_max: 1341.0
reward_min: 189.0
total_envstep_count: 515694
total_train_sample_count: 515645
total_episode_count: 3682
total_duration: 659.4762623310083
[2024-11-19 22:30:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 754
train_sample_count: 754
avg_envstep_per_episode: 75.4
avg_sample_per_episode: 75.4
avg_envstep_per_sec: 787.5221063160473
avg_train_sample_per_sec: 787.5221063160473
avg_episode_per_sec: 10.444590269443598
collect_time: 0.957433440855571
reward_mean: 477.20001220703125
reward_std: 294.85784912109375
reward_max: 1040.0
reward_min: 145.0
total_envstep_count: 516685
total_train_sample_count: 516639
total_episode_count: 3692
total_duration: 660.4336957718639
[2024-11-19 22:30:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1207
train_sample_count: 1207
avg_envstep_per_episode: 109.72727272727273
avg_sample_per_episode: 109.72727272727273
avg_envstep_per_sec: 792.4006407104812
avg_train_sample_per_sec: 792.4006407104812
avg_episode_per_sec: 7.221546849888395
collect_time: 1.5232193640300207
reward_mean: 721.727294921875
reward_std: 490.5201416015625
reward_max: 1677.0
reward_min: 210.0
total_envstep_count: 517675
total_train_sample_count: 517642
total_episode_count: 3703
total_duration: 661.956915135894
[2024-11-19 22:30:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 832
train_sample_count: 832
avg_envstep_per_episode: 92.44444444444444
avg_sample_per_episode: 92.44444444444444
avg_envstep_per_sec: 792.5483417532674
avg_train_sample_per_sec: 792.5483417532674
avg_episode_per_sec: 8.573239273773327
collect_time: 1.0497782358101437
reward_mean: 587.6666870117188
reward_std: 340.53192138671875
reward_max: 1407.0
reward_min: 233.0
total_envstep_count: 518676
total_train_sample_count: 518630
total_episode_count: 3712
total_duration: 663.006693371704
[2024-11-19 22:30:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 969
train_sample_count: 969
avg_envstep_per_episode: 138.42857142857142
avg_sample_per_episode: 138.42857142857142
avg_envstep_per_sec: 795.5586499983217
avg_train_sample_per_sec: 795.5586499983217
avg_episode_per_sec: 5.747069711030188
collect_time: 1.2180120221206119
reward_mean: 835.8571166992188
reward_std: 387.3280029296875
reward_max: 1345.0
reward_min: 201.0
total_envstep_count: 519670
total_train_sample_count: 519635
total_episode_count: 3719
total_duration: 664.2247053938247
[2024-11-19 22:30:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 750
train_sample_count: 750
avg_envstep_per_episode: 125.0
avg_sample_per_episode: 125.0
avg_envstep_per_sec: 782.6813838205054
avg_train_sample_per_sec: 782.6813838205054
avg_episode_per_sec: 6.261451070564044
collect_time: 0.958244332245418
reward_mean: 751.3333129882812
reward_std: 386.59783935546875
reward_max: 1435.0
reward_min: 211.0
total_envstep_count: 520657
total_train_sample_count: 520613
total_episode_count: 3725
total_duration: 665.1829497260701
[2024-11-19 22:30:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1465
train_sample_count: 1465
avg_envstep_per_episode: 183.125
avg_sample_per_episode: 183.125
avg_envstep_per_sec: 791.8942617617473
avg_train_sample_per_sec: 791.8942617617473
avg_episode_per_sec: 4.324337265593159
collect_time: 1.8499944635799952
reward_mean: 1040.75
reward_std: 518.1017456054688
reward_max: 1679.0
reward_min: 228.0
total_envstep_count: 521667
total_train_sample_count: 521622
total_episode_count: 3733
total_duration: 667.03294418965
[2024-11-19 22:30:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 817
train_sample_count: 817
avg_envstep_per_episode: 90.77777777777777
avg_sample_per_episode: 90.77777777777777
avg_envstep_per_sec: 791.5968517514095
avg_train_sample_per_sec: 791.5968517514095
avg_episode_per_sec: 8.720161157604267
collect_time: 1.0320910172803062
reward_mean: 560.3333129882812
reward_std: 407.3524169921875
reward_max: 1416.0
reward_min: 245.0
total_envstep_count: 522667
total_train_sample_count: 522631
total_episode_count: 3742
total_duration: 668.0650352069304
[2024-11-19 22:30:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 146
train_sample_count: 146
avg_envstep_per_episode: 146.0
avg_sample_per_episode: 146.0
avg_envstep_per_sec: 787.5848458614373
avg_train_sample_per_sec: 787.5848458614373
avg_episode_per_sec: 5.394416752475598
collect_time: 0.1853768527507782
reward_mean: 607.0
reward_std: 0.0
reward_max: 607.0
reward_min: 607.0
total_envstep_count: 523746
total_train_sample_count: 523701
total_episode_count: 3743
total_duration: 668.2504120596811
[2024-11-19 22:30:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 770
train_sample_count: 770
avg_envstep_per_episode: 154.0
avg_sample_per_episode: 154.0
avg_envstep_per_sec: 800.0478868713891
avg_train_sample_per_sec: 800.0478868713891
avg_episode_per_sec: 5.195116148515513
collect_time: 0.9624423895563399
reward_mean: 647.4000244140625
reward_std: 246.39285278320312
reward_max: 1023.0
reward_min: 251.0
total_envstep_count: 524734
total_train_sample_count: 524687
total_episode_count: 3748
total_duration: 669.2128544492375
[2024-11-19 22:30:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1498
train_sample_count: 1498
avg_envstep_per_episode: 299.6
avg_sample_per_episode: 299.6
avg_envstep_per_sec: 802.2948868888483
avg_train_sample_per_sec: 802.2948868888483
avg_episode_per_sec: 2.6778868053699876
collect_time: 1.8671438949448724
reward_mean: 919.7999877929688
reward_std: 359.12078857421875
reward_max: 1317.0
reward_min: 243.0
total_envstep_count: 525714
total_train_sample_count: 525681
total_episode_count: 3753
total_duration: 671.0799983441824
[2024-11-19 22:30:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1240
train_sample_count: 1240
avg_envstep_per_episode: 248.0
avg_sample_per_episode: 248.0
avg_envstep_per_sec: 804.0623212943509
avg_train_sample_per_sec: 804.0623212943509
avg_episode_per_sec: 3.2421867794127053
collect_time: 1.54216901745115
reward_mean: 953.2000122070312
reward_std: 272.2655944824219
reward_max: 1408.0
reward_min: 602.0
total_envstep_count: 526693
total_train_sample_count: 526657
total_episode_count: 3758
total_duration: 672.6221673616335
[2024-11-19 22:31:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1381
train_sample_count: 1381
avg_envstep_per_episode: 138.1
avg_sample_per_episode: 138.1
avg_envstep_per_sec: 795.6467551527218
avg_train_sample_per_sec: 795.6467551527218
avg_episode_per_sec: 5.76138128278582
collect_time: 1.7356948809964312
reward_mean: 740.2000122070312
reward_std: 306.456787109375
reward_max: 1119.0
reward_min: 247.0
total_envstep_count: 527710
total_train_sample_count: 527666
total_episode_count: 3768
total_duration: 674.35786224263
[2024-11-19 22:31:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 888
train_sample_count: 888
avg_envstep_per_episode: 98.66666666666667
avg_sample_per_episode: 98.66666666666667
avg_envstep_per_sec: 787.1894757562151
avg_train_sample_per_sec: 787.1894757562151
avg_episode_per_sec: 7.978271713745423
collect_time: 1.1280638618128642
reward_mean: 642.888916015625
reward_std: 376.6028137207031
reward_max: 1429.0
reward_min: 227.0
total_envstep_count: 528703
total_train_sample_count: 528662
total_episode_count: 3777
total_duration: 675.4859261044428
[2024-11-19 22:31:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 675
train_sample_count: 675
avg_envstep_per_episode: 112.5
avg_sample_per_episode: 112.5
avg_envstep_per_sec: 799.0527367467159
avg_train_sample_per_sec: 799.0527367467159
avg_episode_per_sec: 7.102690993304142
collect_time: 0.8447502510888236
reward_mean: 586.3333129882812
reward_std: 291.06854248046875
reward_max: 1029.0
reward_min: 223.0
total_envstep_count: 529698
total_train_sample_count: 529661
total_episode_count: 3783
total_duration: 676.3306763555316
[2024-11-19 22:31:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1151
train_sample_count: 1151
avg_envstep_per_episode: 127.88888888888889
avg_sample_per_episode: 127.88888888888889
avg_envstep_per_sec: 804.1126348985593
avg_train_sample_per_sec: 804.1126348985593
avg_episode_per_sec: 6.287587935783696
collect_time: 1.4313915116446358
reward_mean: 600.888916015625
reward_std: 325.6417236328125
reward_max: 1021.0
reward_min: 159.0
total_envstep_count: 530738
total_train_sample_count: 530704
total_episode_count: 3792
total_duration: 677.7620678671763
[2024-11-19 22:31:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1278
train_sample_count: 1278
avg_envstep_per_episode: 142.0
avg_sample_per_episode: 142.0
avg_envstep_per_sec: 798.1662479021701
avg_train_sample_per_sec: 798.1662479021701
avg_episode_per_sec: 5.620889069733592
collect_time: 1.6011701864855632
reward_mean: 629.888916015625
reward_std: 452.98724365234375
reward_max: 1428.0
reward_min: 233.0
total_envstep_count: 531770
total_train_sample_count: 531718
total_episode_count: 3801
total_duration: 679.3632380536618
[2024-11-19 22:31:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 744
train_sample_count: 744
avg_envstep_per_episode: 186.0
avg_sample_per_episode: 186.0
avg_envstep_per_sec: 797.8391451035441
avg_train_sample_per_sec: 797.8391451035441
avg_episode_per_sec: 4.289457769373893
collect_time: 0.9325187972613743
reward_mean: 893.0
reward_std: 295.26513671875
reward_max: 1314.0
reward_min: 603.0
total_envstep_count: 532742
total_train_sample_count: 532702
total_episode_count: 3805
total_duration: 680.2957568509232
[2024-11-19 22:31:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1236
train_sample_count: 1236
avg_envstep_per_episode: 123.6
avg_sample_per_episode: 123.6
avg_envstep_per_sec: 792.3598347155958
avg_train_sample_per_sec: 792.3598347155958
avg_episode_per_sec: 6.410678274398023
collect_time: 1.5598973418985094
reward_mean: 851.0999755859375
reward_std: 461.3314208984375
reward_max: 1575.0
reward_min: 247.0
total_envstep_count: 533749
total_train_sample_count: 533710
total_episode_count: 3815
total_duration: 681.8556541928217
[2024-11-19 22:31:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1243
train_sample_count: 1243
avg_envstep_per_episode: 113.0
avg_sample_per_episode: 113.0
avg_envstep_per_sec: 798.9892921732687
avg_train_sample_per_sec: 798.9892921732687
avg_episode_per_sec: 7.070701700648396
collect_time: 1.555715467248644
reward_mean: 664.8181762695312
reward_std: 390.0649719238281
reward_max: 1325.0
reward_min: 226.0
total_envstep_count: 534764
total_train_sample_count: 534725
total_episode_count: 3826
total_duration: 683.4113696600704
[2024-11-19 22:31:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 583
train_sample_count: 583
avg_envstep_per_episode: 97.16666666666667
avg_sample_per_episode: 97.16666666666667
avg_envstep_per_sec: 798.3052780503559
avg_train_sample_per_sec: 798.3052780503559
avg_episode_per_sec: 8.215834765526818
collect_time: 0.7302970630781991
reward_mean: 625.8333129882812
reward_std: 392.7571105957031
reward_max: 1415.0
reward_min: 225.0
total_envstep_count: 535758
total_train_sample_count: 535716
total_episode_count: 3832
total_duration: 684.1416667231485
[2024-11-19 22:31:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1157
train_sample_count: 1157
avg_envstep_per_episode: 144.625
avg_sample_per_episode: 144.625
avg_envstep_per_sec: 787.7583086587334
avg_train_sample_per_sec: 787.7583086587334
avg_episode_per_sec: 5.446902739213368
collect_time: 1.468724591391427
reward_mean: 979.5
reward_std: 481.2901916503906
reward_max: 1858.0
reward_min: 247.0
total_envstep_count: 536766
total_train_sample_count: 536729
total_episode_count: 3840
total_duration: 685.6103913145399
[2024-11-19 22:31:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 361
train_sample_count: 361
avg_envstep_per_episode: 120.33333333333333
avg_sample_per_episode: 120.33333333333333
avg_envstep_per_sec: 808.424751790569
avg_train_sample_per_sec: 808.424751790569
avg_episode_per_sec: 6.718211233716639
collect_time: 0.4465474358626774
reward_mean: 764.6666870117188
reward_std: 191.07821655273438
reward_max: 1034.0
reward_min: 611.0
total_envstep_count: 537763
total_train_sample_count: 537726
total_episode_count: 3843
total_duration: 686.0569387504027
[2024-11-19 22:31:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 831
train_sample_count: 831
avg_envstep_per_episode: 277.0
avg_sample_per_episode: 277.0
avg_envstep_per_sec: 801.5984637193775
avg_train_sample_per_sec: 801.5984637193775
avg_episode_per_sec: 2.893857269745045
collect_time: 1.0366786335195814
reward_mean: 928.0
reward_std: 120.2081527709961
reward_max: 1013.0
reward_min: 758.0
total_envstep_count: 538753
total_train_sample_count: 538713
total_episode_count: 3846
total_duration: 687.0936173839223
[2024-11-19 22:31:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 2098
train_sample_count: 2098
avg_envstep_per_episode: 149.85714285714286
avg_sample_per_episode: 149.85714285714286
avg_envstep_per_sec: 800.8386654379825
avg_train_sample_per_sec: 800.8386654379825
avg_episode_per_sec: 5.344013973370712
collect_time: 2.619753628969193
reward_mean: 632.7857055664062
reward_std: 415.5158996582031
reward_max: 1418.0
reward_min: 229.0
total_envstep_count: 539735
total_train_sample_count: 539719
total_episode_count: 3860
total_duration: 689.7133710128915
[2024-11-19 22:31:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 820
train_sample_count: 820
avg_envstep_per_episode: 82.0
avg_sample_per_episode: 82.0
avg_envstep_per_sec: 797.7326475476375
avg_train_sample_per_sec: 797.7326475476375
avg_episode_per_sec: 9.728446921312653
collect_time: 1.0279133021831512
reward_mean: 586.0999755859375
reward_std: 276.32061767578125
reward_max: 1039.0
reward_min: 234.0
total_envstep_count: 540818
total_train_sample_count: 540779
total_episode_count: 3870
total_duration: 690.7412843150746
[2024-11-19 22:31:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 527
train_sample_count: 527
avg_envstep_per_episode: 105.4
avg_sample_per_episode: 105.4
avg_envstep_per_sec: 790.0539181548708
avg_train_sample_per_sec: 790.0539181548708
avg_episode_per_sec: 7.495767724429514
collect_time: 0.6670430813516889
reward_mean: 604.7999877929688
reward_std: 435.12359619140625
reward_max: 1427.0
reward_min: 230.0
total_envstep_count: 541791
total_train_sample_count: 541762
total_episode_count: 3875
total_duration: 691.4083273964263
[2024-11-19 22:31:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1570
train_sample_count: 1570
avg_envstep_per_episode: 196.25
avg_sample_per_episode: 196.25
avg_envstep_per_sec: 793.6954980993304
avg_train_sample_per_sec: 793.6954980993304
avg_episode_per_sec: 4.044308270569836
collect_time: 1.9780885790075575
reward_mean: 930.75
reward_std: 393.58917236328125
reward_max: 1666.0
reward_min: 231.0
total_envstep_count: 542783
total_train_sample_count: 542744
total_episode_count: 3883
total_duration: 693.3864159754339
[2024-11-19 22:31:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 968
train_sample_count: 968
avg_envstep_per_episode: 107.55555555555556
avg_sample_per_episode: 107.55555555555556
avg_envstep_per_sec: 792.7421259779101
avg_train_sample_per_sec: 792.7421259779101
avg_episode_per_sec: 7.370536295249164
collect_time: 1.2210780382156372
reward_mean: 636.5555419921875
reward_std: 285.4233093261719
reward_max: 1126.0
reward_min: 232.0
total_envstep_count: 543807
total_train_sample_count: 543772
total_episode_count: 3892
total_duration: 694.6074940136496
[2024-11-19 22:32:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 933
train_sample_count: 933
avg_envstep_per_episode: 133.28571428571428
avg_sample_per_episode: 133.28571428571428
avg_envstep_per_sec: 790.8478157763668
avg_train_sample_per_sec: 790.8478157763668
avg_episode_per_sec: 5.933477717507576
collect_time: 1.1797465724604472
reward_mean: 793.2857055664062
reward_std: 322.23358154296875
reward_max: 1566.0
reward_min: 603.0
total_envstep_count: 544848
total_train_sample_count: 544789
total_episode_count: 3899
total_duration: 695.78724058611
[2024-11-19 22:32:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1087
train_sample_count: 1087
avg_envstep_per_episode: 108.7
avg_sample_per_episode: 108.7
avg_envstep_per_sec: 782.2641841795332
avg_train_sample_per_sec: 782.2641841795332
avg_episode_per_sec: 7.196542632746396
collect_time: 1.3895561397075653
reward_mean: 667.0
reward_std: 328.625
reward_max: 1419.0
reward_min: 247.0
total_envstep_count: 545832
total_train_sample_count: 545792
total_episode_count: 3909
total_duration: 697.1767967258176
[2024-11-19 22:32:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1068
train_sample_count: 1068
avg_envstep_per_episode: 118.66666666666667
avg_sample_per_episode: 118.66666666666667
avg_envstep_per_sec: 780.0561992496155
avg_train_sample_per_sec: 780.0561992496155
avg_episode_per_sec: 6.573507297047322
collect_time: 1.3691321228231703
reward_mean: 818.888916015625
reward_std: 381.1958923339844
reward_max: 1692.0
reward_min: 249.0
total_envstep_count: 546823
total_train_sample_count: 546788
total_episode_count: 3918
total_duration: 698.5459288486408
[2024-11-19 22:32:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 922
train_sample_count: 922
avg_envstep_per_episode: 102.44444444444444
avg_sample_per_episode: 102.44444444444444
avg_envstep_per_sec: 786.9947545216139
avg_train_sample_per_sec: 786.9947545216139
avg_episode_per_sec: 7.682161378193628
collect_time: 1.1715452926499503
reward_mean: 689.6666870117188
reward_std: 346.78717041015625
reward_max: 1425.0
reward_min: 244.0
total_envstep_count: 547857
total_train_sample_count: 547818
total_episode_count: 3927
total_duration: 699.7174741412907
[2024-11-19 22:32:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 834
train_sample_count: 834
avg_envstep_per_episode: 166.8
avg_sample_per_episode: 166.8
avg_envstep_per_sec: 789.3406178840779
avg_train_sample_per_sec: 789.3406178840779
avg_episode_per_sec: 4.732257900983681
collect_time: 1.0565780869552068
reward_mean: 1099.4000244140625
reward_std: 277.832763671875
reward_max: 1428.0
reward_min: 634.0
total_envstep_count: 548844
total_train_sample_count: 548796
total_episode_count: 3932
total_duration: 700.774052228246
[2024-11-19 22:32:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1036
train_sample_count: 1036
avg_envstep_per_episode: 172.66666666666666
avg_sample_per_episode: 172.66666666666666
avg_envstep_per_sec: 801.1269553974478
avg_train_sample_per_sec: 801.1269553974478
avg_episode_per_sec: 4.6397314019157205
collect_time: 1.2931783071586065
reward_mean: 1102.1666259765625
reward_std: 314.80755615234375
reward_max: 1426.0
reward_min: 627.0
total_envstep_count: 549822
total_train_sample_count: 549784
total_episode_count: 3938
total_duration: 702.0672305354046
[2024-11-19 22:32:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 994
train_sample_count: 994
avg_envstep_per_episode: 110.44444444444444
avg_sample_per_episode: 110.44444444444444
avg_envstep_per_sec: 798.5409209032881
avg_train_sample_per_sec: 798.5409209032881
avg_episode_per_sec: 7.230249786850697
collect_time: 1.244770272856667
reward_mean: 673.3333129882812
reward_std: 320.667724609375
reward_max: 1320.0
reward_min: 246.0
total_envstep_count: 550797
total_train_sample_count: 550766
total_episode_count: 3947
total_duration: 703.3120008082612
[2024-11-19 22:32:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1209
train_sample_count: 1209
avg_envstep_per_episode: 172.71428571428572
avg_sample_per_episode: 172.71428571428572
avg_envstep_per_sec: 795.6889762275085
avg_train_sample_per_sec: 795.6889762275085
avg_episode_per_sec: 4.606966777165062
collect_time: 1.5194379162220728
reward_mean: 951.7142944335938
reward_std: 249.0919189453125
reward_max: 1337.0
reward_min: 591.0
total_envstep_count: 551791
total_train_sample_count: 551759
total_episode_count: 3954
total_duration: 704.8314387244833
[2024-11-19 22:32:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 853
train_sample_count: 853
avg_envstep_per_episode: 106.625
avg_sample_per_episode: 106.625
avg_envstep_per_sec: 799.1112549845111
avg_train_sample_per_sec: 799.1112549845111
avg_episode_per_sec: 7.49459559188287
collect_time: 1.0674358478614263
reward_mean: 762.625
reward_std: 383.4673767089844
reward_max: 1579.0
reward_min: 238.0
total_envstep_count: 552840
total_train_sample_count: 552804
total_episode_count: 3962
total_duration: 705.8988745723448
[2024-11-19 22:32:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 938
train_sample_count: 938
avg_envstep_per_episode: 117.25
avg_sample_per_episode: 117.25
avg_envstep_per_sec: 793.1110365960186
avg_train_sample_per_sec: 793.1110365960186
avg_episode_per_sec: 6.7642732332283035
collect_time: 1.1826843363898143
reward_mean: 830.25
reward_std: 272.2213134765625
reward_max: 1311.0
reward_min: 615.0
total_envstep_count: 553819
total_train_sample_count: 553790
total_episode_count: 3970
total_duration: 707.0815589087346
[2024-11-19 22:32:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 816
train_sample_count: 816
avg_envstep_per_episode: 136.0
avg_sample_per_episode: 136.0
avg_envstep_per_sec: 791.7837625913277
avg_train_sample_per_sec: 791.7837625913277
avg_episode_per_sec: 5.821939430818586
collect_time: 1.0305844077042172
reward_mean: 863.8333129882812
reward_std: 396.50909423828125
reward_max: 1337.0
reward_min: 244.0
total_envstep_count: 554805
total_train_sample_count: 554774
total_episode_count: 3976
total_duration: 708.1121433164387
[2024-11-19 22:32:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1418
train_sample_count: 1418
avg_envstep_per_episode: 118.16666666666667
avg_sample_per_episode: 118.16666666666667
avg_envstep_per_sec: 797.9691020786765
avg_train_sample_per_sec: 797.9691020786765
avg_episode_per_sec: 6.752912006307559
collect_time: 1.777011160339628
reward_mean: 817.4166870117188
reward_std: 402.3496398925781
reward_max: 1426.0
reward_min: 235.0
total_envstep_count: 555857
total_train_sample_count: 555820
total_episode_count: 3988
total_duration: 709.8891544767783
[2024-11-19 22:32:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 776
train_sample_count: 776
avg_envstep_per_episode: 110.85714285714286
avg_sample_per_episode: 110.85714285714286
avg_envstep_per_sec: 799.7381247596685
avg_train_sample_per_sec: 799.7381247596685
avg_episode_per_sec: 7.21413256870835
collect_time: 0.9703176277024406
reward_mean: 690.7142944335938
reward_std: 182.84397888183594
reward_max: 1138.0
reward_min: 601.0
total_envstep_count: 556844
total_train_sample_count: 556812
total_episode_count: 3995
total_duration: 710.8594721044808
[2024-11-19 22:32:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1191
train_sample_count: 1191
avg_envstep_per_episode: 119.1
avg_sample_per_episode: 119.1
avg_envstep_per_sec: 797.5841121316932
avg_train_sample_per_sec: 797.5841121316932
avg_episode_per_sec: 6.696759967520514
collect_time: 1.4932594341891152
reward_mean: 884.5999755859375
reward_std: 439.95526123046875
reward_max: 1692.0
reward_min: 243.0
total_envstep_count: 557828
total_train_sample_count: 557787
total_episode_count: 4005
total_duration: 712.3527315386699
[2024-11-19 22:32:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 652
train_sample_count: 652
avg_envstep_per_episode: 130.4
avg_sample_per_episode: 130.4
avg_envstep_per_sec: 799.96247981575
avg_train_sample_per_sec: 799.96247981575
avg_episode_per_sec: 6.1346815936790655
collect_time: 0.8150382254804884
reward_mean: 906.4000244140625
reward_std: 448.0074157714844
reward_max: 1568.0
reward_min: 238.0
total_envstep_count: 558784
total_train_sample_count: 558763
total_episode_count: 4010
total_duration: 713.1677697641504
[2024-11-19 22:33:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 978
train_sample_count: 978
avg_envstep_per_episode: 139.71428571428572
avg_sample_per_episode: 139.71428571428572
avg_envstep_per_sec: 794.4833078109632
avg_train_sample_per_sec: 794.4833078109632
avg_episode_per_sec: 5.686485843227753
collect_time: 1.230988732406071
reward_mean: 898.7142944335938
reward_std: 394.6125793457031
reward_max: 1429.0
reward_min: 245.0
total_envstep_count: 559802
total_train_sample_count: 559753
total_episode_count: 4017
total_duration: 714.3987584965565
[2024-11-19 22:33:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1098
train_sample_count: 1098
avg_envstep_per_episode: 156.85714285714286
avg_sample_per_episode: 156.85714285714286
avg_envstep_per_sec: 798.4333243002923
avg_train_sample_per_sec: 798.4333243002923
avg_episode_per_sec: 5.090194235065615
collect_time: 1.3751931020191739
reward_mean: 913.8571166992188
reward_std: 274.84197998046875
reward_max: 1400.0
reward_min: 610.0
total_envstep_count: 560805
total_train_sample_count: 560779
total_episode_count: 4024
total_duration: 715.7739515985756
[2024-11-19 22:33:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1258
train_sample_count: 1258
avg_envstep_per_episode: 157.25
avg_sample_per_episode: 157.25
avg_envstep_per_sec: 797.9807021701159
avg_train_sample_per_sec: 797.9807021701159
avg_episode_per_sec: 5.074599059905347
collect_time: 1.5764792263507843
reward_mean: 1145.0
reward_std: 397.8664855957031
reward_max: 1861.0
reward_min: 606.0
total_envstep_count: 561870
total_train_sample_count: 561833
total_episode_count: 4032
total_duration: 717.3504308249264
[2024-11-19 22:33:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 721
train_sample_count: 721
avg_envstep_per_episode: 144.2
avg_sample_per_episode: 144.2
avg_envstep_per_sec: 795.766620003248
avg_train_sample_per_sec: 795.766620003248
avg_episode_per_sec: 5.5184925104247435
collect_time: 0.9060445385319846
reward_mean: 918.4000244140625
reward_std: 365.3554992675781
reward_max: 1581.0
reward_min: 615.0
total_envstep_count: 562874
total_train_sample_count: 562830
total_episode_count: 4037
total_duration: 718.2564753634584
[2024-11-19 22:33:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 919
train_sample_count: 919
avg_envstep_per_episode: 131.28571428571428
avg_sample_per_episode: 131.28571428571428
avg_envstep_per_sec: 796.2874546300054
avg_train_sample_per_sec: 796.2874546300054
avg_episode_per_sec: 6.065301613068594
collect_time: 1.15410583785602
reward_mean: 821.1428833007812
reward_std: 392.1025390625
reward_max: 1573.0
reward_min: 250.0
total_envstep_count: 563851
total_train_sample_count: 563809
total_episode_count: 4044
total_duration: 719.4105812013145
[2024-11-19 22:33:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1078
train_sample_count: 1078
avg_envstep_per_episode: 119.77777777777777
avg_sample_per_episode: 119.77777777777777
avg_envstep_per_sec: 792.6738205007131
avg_train_sample_per_sec: 792.6738205007131
avg_episode_per_sec: 6.617870486555118
collect_time: 1.3599540846688405
reward_mean: 796.111083984375
reward_std: 501.6143798828125
reward_max: 1687.0
reward_min: 235.0
total_envstep_count: 564843
total_train_sample_count: 564803
total_episode_count: 4053
total_duration: 720.7705352859833
[2024-11-19 22:33:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 901
train_sample_count: 901
avg_envstep_per_episode: 112.625
avg_sample_per_episode: 112.625
avg_envstep_per_sec: 801.6090233378792
avg_train_sample_per_sec: 801.6090233378792
avg_episode_per_sec: 7.117505201668184
collect_time: 1.1239893436431883
reward_mean: 669.625
reward_std: 363.6783752441406
reward_max: 1418.0
reward_min: 243.0
total_envstep_count: 565867
total_train_sample_count: 565824
total_episode_count: 4061
total_duration: 721.8945246296265
[2024-11-19 22:33:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1053
train_sample_count: 1053
avg_envstep_per_episode: 175.5
avg_sample_per_episode: 175.5
avg_envstep_per_sec: 789.798780487727
avg_train_sample_per_sec: 789.798780487727
avg_episode_per_sec: 4.5002779514970195
collect_time: 1.3332509824207852
reward_mean: 1092.5
reward_std: 485.2483215332031
reward_max: 1580.0
reward_min: 250.0
total_envstep_count: 566863
total_train_sample_count: 566817
total_episode_count: 4067
total_duration: 723.2277756120473
[2024-11-19 22:33:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1486
train_sample_count: 1486
avg_envstep_per_episode: 165.11111111111111
avg_sample_per_episode: 165.11111111111111
avg_envstep_per_sec: 800.1552836689215
avg_train_sample_per_sec: 800.1552836689215
avg_episode_per_sec: 4.8461625525035625
collect_time: 1.857139520701908
reward_mean: 765.2222290039062
reward_std: 263.69964599609375
reward_max: 1043.0
reward_min: 248.0
total_envstep_count: 567886
total_train_sample_count: 567847
total_episode_count: 4076
total_duration: 725.0849151327492
[2024-11-19 22:33:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 917
train_sample_count: 917
avg_envstep_per_episode: 114.625
avg_sample_per_episode: 114.625
avg_envstep_per_sec: 789.6677104218545
avg_train_sample_per_sec: 789.6677104218545
avg_episode_per_sec: 6.8891403308340635
collect_time: 1.1612479374522258
reward_mean: 754.75
reward_std: 368.6766052246094
reward_max: 1564.0
reward_min: 240.0
total_envstep_count: 568862
total_train_sample_count: 568824
total_episode_count: 4084
total_duration: 726.2461630702014
[2024-11-19 22:33:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 982
train_sample_count: 982
avg_envstep_per_episode: 89.27272727272727
avg_sample_per_episode: 89.27272727272727
avg_envstep_per_sec: 799.9211554150215
avg_train_sample_per_sec: 799.9211554150215
avg_episode_per_sec: 8.960420274506351
collect_time: 1.227620989084244
reward_mean: 600.0908813476562
reward_std: 321.4202880859375
reward_max: 1423.0
reward_min: 218.0
total_envstep_count: 569860
total_train_sample_count: 569806
total_episode_count: 4095
total_duration: 727.4737840592857
[2024-11-19 22:33:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 982
train_sample_count: 982
avg_envstep_per_episode: 122.75
avg_sample_per_episode: 122.75
avg_envstep_per_sec: 797.4073211428085
avg_train_sample_per_sec: 797.4073211428085
avg_episode_per_sec: 6.496189988943451
collect_time: 1.2314910760947635
reward_mean: 883.25
reward_std: 421.6241760253906
reward_max: 1433.0
reward_min: 242.0
total_envstep_count: 570839
total_train_sample_count: 570800
total_episode_count: 4103
total_duration: 728.7052751353805
[2024-11-19 22:33:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 764
train_sample_count: 764
avg_envstep_per_episode: 127.33333333333333
avg_sample_per_episode: 127.33333333333333
avg_envstep_per_sec: 802.0404723937876
avg_train_sample_per_sec: 802.0404723937876
avg_episode_per_sec: 6.298747165396237
collect_time: 0.9525703830378396
reward_mean: 773.6666870117188
reward_std: 197.20266723632812
reward_max: 1043.0
reward_min: 592.0
total_envstep_count: 571834
total_train_sample_count: 571816
total_episode_count: 4109
total_duration: 729.6578455184183
[2024-11-19 22:34:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1339
train_sample_count: 1339
avg_envstep_per_episode: 133.9
avg_sample_per_episode: 133.9
avg_envstep_per_sec: 798.9750581216528
avg_train_sample_per_sec: 798.9750581216528
avg_episode_per_sec: 5.966953384030266
collect_time: 1.6758971214294434
reward_mean: 911.5
reward_std: 397.8233947753906
reward_max: 1425.0
reward_min: 244.0
total_envstep_count: 572872
total_train_sample_count: 572843
total_episode_count: 4119
total_duration: 731.3337426398477
[2024-11-19 22:34:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 808
train_sample_count: 808
avg_envstep_per_episode: 134.66666666666666
avg_sample_per_episode: 134.66666666666666
avg_envstep_per_sec: 799.311405832666
avg_train_sample_per_sec: 799.311405832666
avg_episode_per_sec: 5.935480736381183
collect_time: 1.010870099067688
reward_mean: 711.8333129882812
reward_std: 78.35265350341797
reward_max: 811.0
reward_min: 602.0
total_envstep_count: 573844
total_train_sample_count: 573819
total_episode_count: 4125
total_duration: 732.3446127389154
[2024-11-19 22:34:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 967
train_sample_count: 967
avg_envstep_per_episode: 138.14285714285714
avg_sample_per_episode: 138.14285714285714
avg_envstep_per_sec: 801.8106790742399
avg_train_sample_per_sec: 801.8106790742399
avg_episode_per_sec: 5.804213809224074
collect_time: 1.2060203552246092
reward_mean: 777.7142944335938
reward_std: 271.71502685546875
reward_max: 1043.0
reward_min: 237.0
total_envstep_count: 574829
total_train_sample_count: 574798
total_episode_count: 4132
total_duration: 733.55063309414
[2024-11-19 22:34:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1172
train_sample_count: 1172
avg_envstep_per_episode: 106.54545454545455
avg_sample_per_episode: 106.54545454545455
avg_envstep_per_sec: 787.6333968462405
avg_train_sample_per_sec: 787.6333968462405
avg_episode_per_sec: 7.392463622277002
collect_time: 1.4880019114131018
reward_mean: 622.727294921875
reward_std: 356.14324951171875
reward_max: 1303.0
reward_min: 231.0
total_envstep_count: 575828
total_train_sample_count: 575790
total_episode_count: 4143
total_duration: 735.0386350055531
[2024-11-19 22:34:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 724
train_sample_count: 724
avg_envstep_per_episode: 120.66666666666667
avg_sample_per_episode: 120.66666666666667
avg_envstep_per_sec: 793.4073801478366
avg_train_sample_per_sec: 793.4073801478366
avg_episode_per_sec: 6.575199282993121
collect_time: 0.91251987076941
reward_mean: 794.0
reward_std: 183.92752075195312
reward_max: 1040.0
reward_min: 608.0
total_envstep_count: 576799
total_train_sample_count: 576778
total_episode_count: 4149
total_duration: 735.9511548763226
[2024-11-19 22:34:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 938
train_sample_count: 938
avg_envstep_per_episode: 117.25
avg_sample_per_episode: 117.25
avg_envstep_per_sec: 792.4890484270941
avg_train_sample_per_sec: 792.4890484270941
avg_episode_per_sec: 6.7589684300818265
collect_time: 1.183612570876167
reward_mean: 811.375
reward_std: 496.70184326171875
reward_max: 1677.0
reward_min: 221.0
total_envstep_count: 577850
total_train_sample_count: 577812
total_episode_count: 4157
total_duration: 737.1347674471988
[2024-11-19 22:34:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 742
train_sample_count: 742
avg_envstep_per_episode: 185.5
avg_sample_per_episode: 185.5
avg_envstep_per_sec: 798.7464141002998
avg_train_sample_per_sec: 798.7464141002998
avg_episode_per_sec: 4.305910588141778
collect_time: 0.9289556571415492
reward_mean: 1031.5
reward_std: 501.7815856933594
reward_max: 1849.0
reward_min: 591.0
total_envstep_count: 578838
total_train_sample_count: 578806
total_episode_count: 4161
total_duration: 738.0637231043403
[2024-11-19 22:34:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1529
train_sample_count: 1529
avg_envstep_per_episode: 191.125
avg_sample_per_episode: 191.125
avg_envstep_per_sec: 795.5125003239017
avg_train_sample_per_sec: 795.5125003239017
avg_episode_per_sec: 4.162262918633887
collect_time: 1.9220313940729414
reward_mean: 1138.75
reward_std: 356.1863098144531
reward_max: 1565.0
reward_min: 621.0
total_envstep_count: 579838
total_train_sample_count: 579807
total_episode_count: 4169
total_duration: 739.9857544984133
[2024-11-19 22:34:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 890
train_sample_count: 890
avg_envstep_per_episode: 111.25
avg_sample_per_episode: 111.25
avg_envstep_per_sec: 798.3493198265551
avg_train_sample_per_sec: 798.3493198265551
avg_episode_per_sec: 7.176173661362293
collect_time: 1.1148002232824052
reward_mean: 777.25
reward_std: 341.29486083984375
reward_max: 1416.0
reward_min: 240.0
total_envstep_count: 580816
total_train_sample_count: 580793
total_episode_count: 4177
total_duration: 741.1005547216956
[2024-11-19 22:34:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1103
train_sample_count: 1103
avg_envstep_per_episode: 91.91666666666667
avg_sample_per_episode: 91.91666666666667
avg_envstep_per_sec: 788.3461760969569
avg_train_sample_per_sec: 788.3461760969569
avg_episode_per_sec: 8.576748969323194
collect_time: 1.3991315407412397
reward_mean: 682.75
reward_std: 394.07000732421875
reward_max: 1312.0
reward_min: 236.0
total_envstep_count: 581831
total_train_sample_count: 581812
total_episode_count: 4189
total_duration: 742.4996862624369
[2024-11-19 22:34:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1023
train_sample_count: 1023
avg_envstep_per_episode: 78.6923076923077
avg_sample_per_episode: 78.6923076923077
avg_envstep_per_sec: 788.6313071212433
avg_train_sample_per_sec: 788.6313071212433
avg_episode_per_sec: 10.021707715128214
collect_time: 1.2971841096878052
reward_mean: 568.7692260742188
reward_std: 319.5918273925781
reward_max: 1309.0
reward_min: 233.0
total_envstep_count: 582866
total_train_sample_count: 582835
total_episode_count: 4202
total_duration: 743.7968703721247
[2024-11-19 22:34:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 817
train_sample_count: 817
avg_envstep_per_episode: 136.16666666666666
avg_sample_per_episode: 136.16666666666666
avg_envstep_per_sec: 791.3232231167012
avg_train_sample_per_sec: 791.3232231167012
avg_episode_per_sec: 5.811431259118981
collect_time: 1.0324479000908988
reward_mean: 915.6666870117188
reward_std: 415.21026611328125
reward_max: 1326.0
reward_min: 158.0
total_envstep_count: 583861
total_train_sample_count: 583820
total_episode_count: 4208
total_duration: 744.8293182722156
[2024-11-19 22:34:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 716
train_sample_count: 716
avg_envstep_per_episode: 119.33333333333333
avg_sample_per_episode: 119.33333333333333
avg_envstep_per_sec: 799.3737351218583
avg_train_sample_per_sec: 799.3737351218583
avg_episode_per_sec: 6.698662584820041
collect_time: 0.8957011827400752
reward_mean: 829.3333129882812
reward_std: 376.8172302246094
reward_max: 1412.0
reward_min: 252.0
total_envstep_count: 584839
total_train_sample_count: 584800
total_episode_count: 4214
total_duration: 745.7250194549556
[2024-11-19 22:34:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1185
train_sample_count: 1185
avg_envstep_per_episode: 148.125
avg_sample_per_episode: 148.125
avg_envstep_per_sec: 798.2462405841507
avg_train_sample_per_sec: 798.2462405841507
avg_episode_per_sec: 5.389004155842367
collect_time: 1.4845043293067386
reward_mean: 934.0
reward_std: 407.3926086425781
reward_max: 1426.0
reward_min: 247.0
total_envstep_count: 585849
total_train_sample_count: 585817
total_episode_count: 4222
total_duration: 747.2095237842624
[2024-11-19 22:34:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1081
train_sample_count: 1081
avg_envstep_per_episode: 180.16666666666666
avg_sample_per_episode: 180.16666666666666
avg_envstep_per_sec: 799.6185324868507
avg_train_sample_per_sec: 799.6185324868507
avg_episode_per_sec: 4.438215721481132
collect_time: 1.3518946298531125
reward_mean: 1070.0
reward_std: 774.1272583007812
reward_max: 2338.0
reward_min: 247.0
total_envstep_count: 586876
total_train_sample_count: 586838
total_episode_count: 4228
total_duration: 748.5614184141155
[2024-11-19 22:34:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 778
train_sample_count: 778
avg_envstep_per_episode: 194.5
avg_sample_per_episode: 194.5
avg_envstep_per_sec: 711.2526459327657
avg_train_sample_per_sec: 711.2526459327657
avg_episode_per_sec: 3.656825943099053
collect_time: 1.0938447884150913
reward_mean: 880.5
reward_std: 313.64111328125
reward_max: 1408.0
reward_min: 598.0
total_envstep_count: 587848
total_train_sample_count: 587808
total_episode_count: 4232
total_duration: 749.6552632025306
[2024-11-19 22:35:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1287
train_sample_count: 1287
avg_envstep_per_episode: 183.85714285714286
avg_sample_per_episode: 183.85714285714286
avg_envstep_per_sec: 732.6355851115375
avg_train_sample_per_sec: 732.6355851115375
avg_episode_per_sec: 3.984808932230585
collect_time: 1.75667142868042
reward_mean: 619.5714111328125
reward_std: 319.010009765625
reward_max: 1267.0
reward_min: 239.0
total_envstep_count: 588858
total_train_sample_count: 588819
total_episode_count: 4239
total_duration: 751.411934631211
[2024-11-19 22:35:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1167
train_sample_count: 1167
avg_envstep_per_episode: 145.875
avg_sample_per_episode: 145.875
avg_envstep_per_sec: 771.9540085930832
avg_train_sample_per_sec: 771.9540085930832
avg_episode_per_sec: 5.291886948367323
collect_time: 1.5117480925151277
reward_mean: 728.25
reward_std: 349.5882263183594
reward_max: 1294.0
reward_min: 251.0
total_envstep_count: 589828
total_train_sample_count: 589794
total_episode_count: 4247
total_duration: 752.9236827237262
[2024-11-19 22:35:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 930
train_sample_count: 930
avg_envstep_per_episode: 93.0
avg_sample_per_episode: 93.0
avg_envstep_per_sec: 788.2011733797016
avg_train_sample_per_sec: 788.2011733797016
avg_episode_per_sec: 8.47528143419034
collect_time: 1.179901821272714
reward_mean: 607.9000244140625
reward_std: 226.54776000976562
reward_max: 1059.0
reward_min: 235.0
total_envstep_count: 590842
total_train_sample_count: 590796
total_episode_count: 4257
total_duration: 754.1035845449989
[2024-11-19 22:35:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 571
train_sample_count: 571
avg_envstep_per_episode: 114.2
avg_sample_per_episode: 114.2
avg_envstep_per_sec: 799.0847282921086
avg_train_sample_per_sec: 799.0847282921086
avg_episode_per_sec: 6.997239302032474
collect_time: 0.7145675293036869
reward_mean: 660.5999755859375
reward_std: 263.20989990234375
reward_max: 1043.0
reward_min: 249.0
total_envstep_count: 591814
total_train_sample_count: 591787
total_episode_count: 4262
total_duration: 754.8181520743026
[2024-11-19 22:35:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1373
train_sample_count: 1373
avg_envstep_per_episode: 124.81818181818181
avg_sample_per_episode: 124.81818181818181
avg_envstep_per_sec: 796.6638823436142
avg_train_sample_per_sec: 796.6638823436142
avg_episode_per_sec: 6.3825948330515345
collect_time: 1.7234369856970653
reward_mean: 720.0908813476562
reward_std: 372.4228820800781
reward_max: 1436.0
reward_min: 241.0
total_envstep_count: 592813
total_train_sample_count: 592800
total_episode_count: 4273
total_duration: 756.5415890599996
[2024-11-19 22:35:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 699
train_sample_count: 699
avg_envstep_per_episode: 139.8
avg_sample_per_episode: 139.8
avg_envstep_per_sec: 800.5582086713216
avg_train_sample_per_sec: 800.5582086713216
avg_episode_per_sec: 5.726453567033774
collect_time: 0.8731407565729958
reward_mean: 953.4000244140625
reward_std: 360.86151123046875
reward_max: 1423.0
reward_min: 602.0
total_envstep_count: 593825
total_train_sample_count: 593775
total_episode_count: 4278
total_duration: 757.4147298165726
[2024-11-19 22:35:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1353
train_sample_count: 1353
avg_envstep_per_episode: 123.0
avg_sample_per_episode: 123.0
avg_envstep_per_sec: 797.3557637021628
avg_train_sample_per_sec: 797.3557637021628
avg_episode_per_sec: 6.48256718457043
collect_time: 1.6968586189406258
reward_mean: 819.9091186523438
reward_std: 465.3216857910156
reward_max: 1576.0
reward_min: 250.0
total_envstep_count: 594873
total_train_sample_count: 594816
total_episode_count: 4289
total_duration: 759.1115884355132
[2024-11-19 22:35:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 925
train_sample_count: 925
avg_envstep_per_episode: 102.77777777777777
avg_sample_per_episode: 102.77777777777777
avg_envstep_per_sec: 792.4040706860857
avg_train_sample_per_sec: 792.4040706860857
avg_episode_per_sec: 7.709877444513266
collect_time: 1.1673337306295122
reward_mean: 669.111083984375
reward_std: 494.6146240234375
reward_max: 1698.0
reward_min: 235.0
total_envstep_count: 595849
total_train_sample_count: 595813
total_episode_count: 4298
total_duration: 760.2789221661427
[2024-11-19 22:35:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 841
train_sample_count: 841
avg_envstep_per_episode: 84.1
avg_sample_per_episode: 84.1
avg_envstep_per_sec: 802.324741184953
avg_train_sample_per_sec: 802.324741184953
avg_episode_per_sec: 9.540127719202772
collect_time: 1.0482039962496077
reward_mean: 619.5
reward_std: 468.968505859375
reward_max: 1329.0
reward_min: 239.0
total_envstep_count: 596855
total_train_sample_count: 596810
total_episode_count: 4308
total_duration: 761.3271261623923
[2024-11-19 22:35:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1007
train_sample_count: 1007
avg_envstep_per_episode: 167.83333333333334
avg_sample_per_episode: 167.83333333333334
avg_envstep_per_sec: 790.520835039192
avg_train_sample_per_sec: 790.520835039192
avg_episode_per_sec: 4.710153932706208
collect_time: 1.273843718426568
reward_mean: 1220.5
reward_std: 291.6371765136719
reward_max: 1441.0
reward_min: 651.0
total_envstep_count: 597834
total_train_sample_count: 597781
total_episode_count: 4314
total_duration: 762.6009698808189
[2024-11-19 22:35:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1260
train_sample_count: 1260
avg_envstep_per_episode: 126.0
avg_sample_per_episode: 126.0
avg_envstep_per_sec: 805.2388199664165
avg_train_sample_per_sec: 805.2388199664165
avg_episode_per_sec: 6.39078428544775
collect_time: 1.5647531747817993
reward_mean: 906.7999877929688
reward_std: 426.45159912109375
reward_max: 1585.0
reward_min: 248.0
total_envstep_count: 598824
total_train_sample_count: 598789
total_episode_count: 4324
total_duration: 764.1657230556007
[2024-11-19 22:36:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 347
train_sample_count: 347
avg_envstep_per_episode: 69.4
avg_sample_per_episode: 69.4
avg_envstep_per_sec: 800.8618898215398
avg_train_sample_per_sec: 800.8618898215398
avg_episode_per_sec: 11.53979668330749
collect_time: 0.4332831970282964
reward_mean: 466.0
reward_std: 180.68093872070312
reward_max: 629.0
reward_min: 241.0
total_envstep_count: 599812
total_train_sample_count: 599760
total_episode_count: 4329
total_duration: 764.599006252629
[2024-11-19 22:36:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 874
train_sample_count: 874
avg_envstep_per_episode: 174.8
avg_sample_per_episode: 174.8
avg_envstep_per_sec: 793.5697091132688
avg_train_sample_per_sec: 793.5697091132688
avg_episode_per_sec: 4.539872477764695
collect_time: 1.1013525213514055
reward_mean: 1036.800048828125
reward_std: 350.1356201171875
reward_max: 1327.0
reward_min: 606.0
total_envstep_count: 600775
total_train_sample_count: 600742
total_episode_count: 4334
total_duration: 765.7003587739804
[2024-11-19 22:36:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1501
train_sample_count: 1501
avg_envstep_per_episode: 136.45454545454547
avg_sample_per_episode: 136.45454545454547
avg_envstep_per_sec: 800.4785142444664
avg_train_sample_per_sec: 800.4785142444664
avg_episode_per_sec: 5.86626492784086
collect_time: 1.8751284054347448
reward_mean: 736.9091186523438
reward_std: 364.89312744140625
reward_max: 1295.0
reward_min: 248.0
total_envstep_count: 601829
total_train_sample_count: 601787
total_episode_count: 4345
total_duration: 767.5754871794152
[2024-11-19 22:36:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1173
train_sample_count: 1173
avg_envstep_per_episode: 117.3
avg_sample_per_episode: 117.3
avg_envstep_per_sec: 795.124282423237
avg_train_sample_per_sec: 795.124282423237
avg_episode_per_sec: 6.778553132337912
collect_time: 1.4752410735402788
reward_mean: 756.5999755859375
reward_std: 533.134521484375
reward_max: 1687.0
reward_min: 228.0
total_envstep_count: 602835
total_train_sample_count: 602792
total_episode_count: 4355
total_duration: 769.0507282529554
[2024-11-19 22:36:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 884
train_sample_count: 884
avg_envstep_per_episode: 126.28571428571429
avg_sample_per_episode: 126.28571428571429
avg_envstep_per_sec: 796.1542857697857
avg_train_sample_per_sec: 796.1542857697857
avg_episode_per_sec: 6.304389140710972
collect_time: 1.1103375511510034
reward_mean: 612.4285888671875
reward_std: 391.9361572265625
reward_max: 1300.0
reward_min: 222.0
total_envstep_count: 603846
total_train_sample_count: 603808
total_episode_count: 4362
total_duration: 770.1610658041064
[2024-11-19 22:36:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 964
train_sample_count: 964
avg_envstep_per_episode: 107.11111111111111
avg_sample_per_episode: 107.11111111111111
avg_envstep_per_sec: 801.767594912512
avg_train_sample_per_sec: 801.767594912512
avg_episode_per_sec: 7.485382110179054
collect_time: 1.2023434298379079
reward_mean: 773.888916015625
reward_std: 488.8581848144531
reward_max: 1569.0
reward_min: 248.0
total_envstep_count: 604846
total_train_sample_count: 604796
total_episode_count: 4371
total_duration: 771.3634092339444
[2024-11-19 22:36:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 869
train_sample_count: 869
avg_envstep_per_episode: 144.83333333333334
avg_sample_per_episode: 144.83333333333334
avg_envstep_per_sec: 798.6981368285392
avg_train_sample_per_sec: 798.6981368285392
avg_episode_per_sec: 5.514601635179787
collect_time: 1.088020567383085
reward_mean: 829.8333129882812
reward_std: 491.3665771484375
reward_max: 1418.0
reward_min: 250.0
total_envstep_count: 605824
total_train_sample_count: 605773
total_episode_count: 4377
total_duration: 772.4514298013274
[2024-11-19 22:36:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 15
envstep_count: 1439
train_sample_count: 1439
avg_envstep_per_episode: 95.93333333333334
avg_sample_per_episode: 95.93333333333334
avg_envstep_per_sec: 797.0885582616462
avg_train_sample_per_sec: 797.0885582616462
avg_episode_per_sec: 8.308775798418827
collect_time: 1.8053201053823744
reward_mean: 614.3333129882812
reward_std: 419.3743591308594
reward_max: 1327.0
reward_min: 234.0
total_envstep_count: 606807
total_train_sample_count: 606768
total_episode_count: 4392
total_duration: 774.2567499067098
[2024-11-19 22:36:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 763
train_sample_count: 763
avg_envstep_per_episode: 127.16666666666667
avg_sample_per_episode: 127.16666666666667
avg_envstep_per_sec: 799.232386222377
avg_train_sample_per_sec: 799.232386222377
avg_episode_per_sec: 6.284920468327997
collect_time: 0.954666018486023
reward_mean: 814.1666870117188
reward_std: 173.26512145996094
reward_max: 1047.0
reward_min: 631.0
total_envstep_count: 607793
total_train_sample_count: 607747
total_episode_count: 4398
total_duration: 775.2114159251959
[2024-11-19 22:36:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 742
train_sample_count: 742
avg_envstep_per_episode: 123.66666666666667
avg_sample_per_episode: 123.66666666666667
avg_envstep_per_sec: 804.5066914465331
avg_train_sample_per_sec: 804.5066914465331
avg_episode_per_sec: 6.505444944311589
collect_time: 0.9223043237413678
reward_mean: 805.6666870117188
reward_std: 414.9922180175781
reward_max: 1577.0
reward_min: 246.0
total_envstep_count: 608789
total_train_sample_count: 608741
total_episode_count: 4404
total_duration: 776.1337202489373
[2024-11-19 22:36:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1271
train_sample_count: 1271
avg_envstep_per_episode: 127.1
avg_sample_per_episode: 127.1
avg_envstep_per_sec: 801.9934688242969
avg_train_sample_per_sec: 801.9934688242969
avg_episode_per_sec: 6.309940746060557
collect_time: 1.5848009359268915
reward_mean: 720.7000122070312
reward_std: 422.58184814453125
reward_max: 1328.0
reward_min: 243.0
total_envstep_count: 609812
total_train_sample_count: 609772
total_episode_count: 4414
total_duration: 777.7185211848641
[2024-11-19 22:36:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 923
train_sample_count: 923
avg_envstep_per_episode: 115.375
avg_sample_per_episode: 115.375
avg_envstep_per_sec: 790.2244856808306
avg_train_sample_per_sec: 790.2244856808306
avg_episode_per_sec: 6.849182974481739
collect_time: 1.1680225261620114
reward_mean: 809.5
reward_std: 435.60504150390625
reward_max: 1338.0
reward_min: 248.0
total_envstep_count: 610798
total_train_sample_count: 610755
total_episode_count: 4422
total_duration: 778.8865437110261
[2024-11-19 22:36:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 601
train_sample_count: 601
avg_envstep_per_episode: 120.2
avg_sample_per_episode: 120.2
avg_envstep_per_sec: 794.5509486312792
avg_train_sample_per_sec: 794.5509486312792
avg_episode_per_sec: 6.6102408371986625
collect_time: 0.7564020923205784
reward_mean: 874.4000244140625
reward_std: 501.3875427246094
reward_max: 1583.0
reward_min: 249.0
total_envstep_count: 611777
total_train_sample_count: 611740
total_episode_count: 4427
total_duration: 779.6429458033467
[2024-11-19 22:36:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 920
train_sample_count: 920
avg_envstep_per_episode: 306.6666666666667
avg_sample_per_episode: 306.6666666666667
avg_envstep_per_sec: 801.5267382971552
avg_train_sample_per_sec: 801.5267382971552
avg_episode_per_sec: 2.6136741466211584
collect_time: 1.147809494109381
reward_mean: 1394.0
reward_std: 693.8126831054688
reward_max: 2286.0
reward_min: 594.0
total_envstep_count: 612752
total_train_sample_count: 612708
total_episode_count: 4430
total_duration: 780.7907552974561
[2024-11-19 22:36:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1732
train_sample_count: 1732
avg_envstep_per_episode: 216.5
avg_sample_per_episode: 216.5
avg_envstep_per_sec: 800.0241304185505
avg_train_sample_per_sec: 800.0241304185505
avg_episode_per_sec: 3.6952615723720577
collect_time: 2.1649346990244727
reward_mean: 959.625
reward_std: 309.8063659667969
reward_max: 1361.0
reward_min: 576.0
total_envstep_count: 613760
total_train_sample_count: 613720
total_episode_count: 4438
total_duration: 782.9556899964806
[2024-11-19 22:36:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 921
train_sample_count: 921
avg_envstep_per_episode: 102.33333333333333
avg_sample_per_episode: 102.33333333333333
avg_envstep_per_sec: 805.0721605579112
avg_train_sample_per_sec: 805.0721605579112
avg_episode_per_sec: 7.867154663432356
collect_time: 1.1439968304974693
reward_mean: 703.888916015625
reward_std: 285.4678039550781
reward_max: 1314.0
reward_min: 248.0
total_envstep_count: 614768
total_train_sample_count: 614725
total_episode_count: 4447
total_duration: 784.0996868269781
[2024-11-19 22:36:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 985
train_sample_count: 985
avg_envstep_per_episode: 140.71428571428572
avg_sample_per_episode: 140.71428571428572
avg_envstep_per_sec: 793.1091430639531
avg_train_sample_per_sec: 793.1091430639531
avg_episode_per_sec: 5.6363086309113415
collect_time: 1.2419476040772028
reward_mean: 969.1428833007812
reward_std: 278.1907958984375
reward_max: 1340.0
reward_min: 626.0
total_envstep_count: 615746
total_train_sample_count: 615710
total_episode_count: 4454
total_duration: 785.3416344310552
[2024-11-19 22:37:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 663
train_sample_count: 663
avg_envstep_per_episode: 132.6
avg_sample_per_episode: 132.6
avg_envstep_per_sec: 796.1145518633477
avg_train_sample_per_sec: 796.1145518633477
avg_episode_per_sec: 6.00388048162404
collect_time: 0.8327947258949279
reward_mean: 867.0
reward_std: 413.76080322265625
reward_max: 1428.0
reward_min: 224.0
total_envstep_count: 616725
total_train_sample_count: 616685
total_episode_count: 4459
total_duration: 786.1744291569502
[2024-11-19 22:37:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 937
train_sample_count: 937
avg_envstep_per_episode: 156.16666666666666
avg_sample_per_episode: 156.16666666666666
avg_envstep_per_sec: 810.918067409611
avg_train_sample_per_sec: 810.918067409611
avg_episode_per_sec: 5.192645042110636
collect_time: 1.1554804827485765
reward_mean: 792.5
reward_std: 284.21630859375
reward_max: 1322.0
reward_min: 581.0
total_envstep_count: 617719
total_train_sample_count: 617670
total_episode_count: 4465
total_duration: 787.3299096396987
[2024-11-19 22:37:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1032
train_sample_count: 1032
avg_envstep_per_episode: 172.0
avg_sample_per_episode: 172.0
avg_envstep_per_sec: 802.2053238338807
avg_train_sample_per_sec: 802.2053238338807
avg_episode_per_sec: 4.663984440894655
collect_time: 1.2864536912668318
reward_mean: 718.6666870117188
reward_std: 270.16888427734375
reward_max: 1032.0
reward_min: 234.0
total_envstep_count: 618715
total_train_sample_count: 618690
total_episode_count: 4471
total_duration: 788.6163633309656
[2024-11-19 22:37:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 907
train_sample_count: 907
avg_envstep_per_episode: 151.16666666666666
avg_sample_per_episode: 151.16666666666666
avg_envstep_per_sec: 798.8359662795121
avg_train_sample_per_sec: 798.8359662795121
avg_episode_per_sec: 5.284471662267997
collect_time: 1.1354020578520638
reward_mean: 857.5
reward_std: 396.283447265625
reward_max: 1322.0
reward_min: 249.0
total_envstep_count: 619710
total_train_sample_count: 619681
total_episode_count: 4477
total_duration: 789.7517653888176
[2024-11-19 22:37:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1533
train_sample_count: 1533
avg_envstep_per_episode: 153.3
avg_sample_per_episode: 153.3
avg_envstep_per_sec: 796.5601338701554
avg_train_sample_per_sec: 796.5601338701554
avg_episode_per_sec: 5.196086978931215
collect_time: 1.9245251360393707
reward_mean: 811.4000244140625
reward_std: 343.78955078125
reward_max: 1297.0
reward_min: 235.0
total_envstep_count: 620718
total_train_sample_count: 620674
total_episode_count: 4487
total_duration: 791.676290524857
[2024-11-19 22:37:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 555
train_sample_count: 555
avg_envstep_per_episode: 185.0
avg_sample_per_episode: 185.0
avg_envstep_per_sec: 795.7377827676527
avg_train_sample_per_sec: 795.7377827676527
avg_episode_per_sec: 4.3012853122575825
collect_time: 0.6974659391811917
reward_mean: 890.0
reward_std: 377.0048828125
reward_max: 1423.0
reward_min: 612.0
total_envstep_count: 621692
total_train_sample_count: 621661
total_episode_count: 4490
total_duration: 792.3737564640381
[2024-11-19 22:37:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1227
train_sample_count: 1227
avg_envstep_per_episode: 204.5
avg_sample_per_episode: 204.5
avg_envstep_per_sec: 799.2409560217937
avg_train_sample_per_sec: 799.2409560217937
avg_episode_per_sec: 3.9082687336029034
collect_time: 1.5352066116673606
reward_mean: 1071.1666259765625
reward_std: 338.934326171875
reward_max: 1417.0
reward_min: 605.0
total_envstep_count: 622672
total_train_sample_count: 622636
total_episode_count: 4496
total_duration: 793.9089630757055
[2024-11-19 22:37:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 485
train_sample_count: 485
avg_envstep_per_episode: 161.66666666666666
avg_sample_per_episode: 161.66666666666666
avg_envstep_per_sec: 803.1569430656014
avg_train_sample_per_sec: 803.1569430656014
avg_episode_per_sec: 4.967981091127431
collect_time: 0.6038670326982226
reward_mean: 1399.0
reward_std: 258.3111877441406
reward_max: 1701.0
reward_min: 1070.0
total_envstep_count: 623653
total_train_sample_count: 623625
total_episode_count: 4499
total_duration: 794.5128301084037
[2024-11-19 22:37:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 962
train_sample_count: 962
avg_envstep_per_episode: 192.4
avg_sample_per_episode: 192.4
avg_envstep_per_sec: 804.0823144718114
avg_train_sample_per_sec: 804.0823144718114
avg_episode_per_sec: 4.179222008689249
collect_time: 1.196394924606596
reward_mean: 1203.0
reward_std: 445.69091796875
reward_max: 1682.0
reward_min: 607.0
total_envstep_count: 624664
total_train_sample_count: 624623
total_episode_count: 4504
total_duration: 795.7092250330103
[2024-11-19 22:37:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1558
train_sample_count: 1558
avg_envstep_per_episode: 155.8
avg_sample_per_episode: 155.8
avg_envstep_per_sec: 706.1032309384191
avg_train_sample_per_sec: 706.1032309384191
avg_episode_per_sec: 4.532113163917965
collect_time: 2.206476237092699
reward_mean: 1057.0999755859375
reward_std: 434.8163757324219
reward_max: 1695.0
reward_min: 622.0
total_envstep_count: 625681
total_train_sample_count: 625653
total_episode_count: 4514
total_duration: 797.915701270103
[2024-11-19 22:37:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 521
train_sample_count: 521
avg_envstep_per_episode: 130.25
avg_sample_per_episode: 130.25
avg_envstep_per_sec: 756.0380682637312
avg_train_sample_per_sec: 756.0380682637312
avg_episode_per_sec: 5.8045149194912184
collect_time: 0.6891187386853355
reward_mean: 895.5
reward_std: 456.5552978515625
reward_max: 1686.0
reward_min: 616.0
total_envstep_count: 626670
total_train_sample_count: 626630
total_episode_count: 4518
total_duration: 798.6048200087884
[2024-11-19 22:37:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1383
train_sample_count: 1383
avg_envstep_per_episode: 153.66666666666666
avg_sample_per_episode: 153.66666666666666
avg_envstep_per_sec: 798.652302910583
avg_train_sample_per_sec: 798.652302910583
avg_episode_per_sec: 5.197303489656723
collect_time: 1.7316672035626002
reward_mean: 938.0
reward_std: 551.8858642578125
reward_max: 1859.0
reward_min: 239.0
total_envstep_count: 627647
total_train_sample_count: 627605
total_episode_count: 4527
total_duration: 800.3364872123509
[2024-11-19 22:37:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 933
train_sample_count: 933
avg_envstep_per_episode: 133.28571428571428
avg_sample_per_episode: 133.28571428571428
avg_envstep_per_sec: 805.2399208494772
avg_train_sample_per_sec: 805.2399208494772
avg_episode_per_sec: 6.041457069610225
collect_time: 1.1586608858335588
reward_mean: 875.4285888671875
reward_std: 329.702392578125
reward_max: 1430.0
reward_min: 614.0
total_envstep_count: 628611
total_train_sample_count: 628586
total_episode_count: 4534
total_duration: 801.4951480981845
[2024-11-19 22:37:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 865
train_sample_count: 865
avg_envstep_per_episode: 123.57142857142857
avg_sample_per_episode: 123.57142857142857
avg_envstep_per_sec: 806.0281304486942
avg_train_sample_per_sec: 806.0281304486942
avg_episode_per_sec: 6.522770997850705
collect_time: 1.0731635377520605
reward_mean: 743.5714111328125
reward_std: 433.5187683105469
reward_max: 1417.0
reward_min: 234.0
total_envstep_count: 629588
total_train_sample_count: 629559
total_episode_count: 4541
total_duration: 802.5683116359365
[2024-11-19 22:37:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1154
train_sample_count: 1154
avg_envstep_per_episode: 128.22222222222223
avg_sample_per_episode: 128.22222222222223
avg_envstep_per_sec: 799.4813528016994
avg_train_sample_per_sec: 799.4813528016994
avg_episode_per_sec: 6.235123202092977
collect_time: 1.4434357924120766
reward_mean: 785.3333129882812
reward_std: 393.45733642578125
reward_max: 1424.0
reward_min: 246.0
total_envstep_count: 630581
total_train_sample_count: 630557
total_episode_count: 4550
total_duration: 804.0117474283486
[2024-11-19 22:37:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1082
train_sample_count: 1082
avg_envstep_per_episode: 135.25
avg_sample_per_episode: 135.25
avg_envstep_per_sec: 790.5577895156391
avg_train_sample_per_sec: 790.5577895156391
avg_episode_per_sec: 5.845159257047239
collect_time: 1.3686538977282388
reward_mean: 896.0
reward_std: 476.07196044921875
reward_max: 1582.0
reward_min: 250.0
total_envstep_count: 631590
total_train_sample_count: 631555
total_episode_count: 4558
total_duration: 805.3804013260768
[2024-11-19 22:37:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1012
train_sample_count: 1012
avg_envstep_per_episode: 112.44444444444444
avg_sample_per_episode: 112.44444444444444
avg_envstep_per_sec: 785.4140346291848
avg_train_sample_per_sec: 785.4140346291848
avg_episode_per_sec: 6.984907422591565
collect_time: 1.2884923815727236
reward_mean: 749.2222290039062
reward_std: 307.406982421875
reward_max: 1318.0
reward_min: 215.0
total_envstep_count: 632622
total_train_sample_count: 632567
total_episode_count: 4567
total_duration: 806.6688937076495
[2024-11-19 22:38:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 867
train_sample_count: 867
avg_envstep_per_episode: 144.5
avg_sample_per_episode: 144.5
avg_envstep_per_sec: 773.2468341394097
avg_train_sample_per_sec: 773.2468341394097
avg_episode_per_sec: 5.351189163594531
collect_time: 1.1212461037295207
reward_mean: 770.0
reward_std: 142.52134704589844
reward_max: 1036.0
reward_min: 610.0
total_envstep_count: 633618
total_train_sample_count: 633578
total_episode_count: 4573
total_duration: 807.790139811379
[2024-11-19 22:38:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1265
train_sample_count: 1265
avg_envstep_per_episode: 105.41666666666667
avg_sample_per_episode: 105.41666666666667
avg_envstep_per_sec: 771.6114365804191
avg_train_sample_per_sec: 771.6114365804191
avg_episode_per_sec: 7.319634181000023
collect_time: 1.639426193067006
reward_mean: 626.6666870117188
reward_std: 278.8453369140625
reward_max: 1421.0
reward_min: 248.0
total_envstep_count: 634646
total_train_sample_count: 634603
total_episode_count: 4585
total_duration: 809.4295660044461
[2024-11-19 22:38:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 790
train_sample_count: 790
avg_envstep_per_episode: 131.66666666666666
avg_sample_per_episode: 131.66666666666666
avg_envstep_per_sec: 787.376139454018
avg_train_sample_per_sec: 787.376139454018
avg_episode_per_sec: 5.9800719452203905
collect_time: 1.0033324105398995
reward_mean: 851.6666870117188
reward_std: 336.918701171875
reward_max: 1334.0
reward_min: 603.0
total_envstep_count: 635648
total_train_sample_count: 635609
total_episode_count: 4591
total_duration: 810.432898414986
[2024-11-19 22:38:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 860
train_sample_count: 860
avg_envstep_per_episode: 143.33333333333334
avg_sample_per_episode: 143.33333333333334
avg_envstep_per_sec: 799.0660212897606
avg_train_sample_per_sec: 799.0660212897606
avg_episode_per_sec: 5.574879218300655
collect_time: 1.076256500823157
reward_mean: 955.6666870117188
reward_std: 490.76153564453125
reward_max: 1848.0
reward_min: 616.0
total_envstep_count: 636634
total_train_sample_count: 636613
total_episode_count: 4597
total_duration: 811.5091549158092
[2024-11-19 22:38:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1041
train_sample_count: 1041
avg_envstep_per_episode: 173.5
avg_sample_per_episode: 173.5
avg_envstep_per_sec: 791.3983048671492
avg_train_sample_per_sec: 791.3983048671492
avg_episode_per_sec: 4.5613735150844334
collect_time: 1.3153932648045676
reward_mean: 1120.5
reward_std: 449.5671081542969
reward_max: 1679.0
reward_min: 605.0
total_envstep_count: 637636
total_train_sample_count: 637594
total_episode_count: 4603
total_duration: 812.8245481806138
[2024-11-19 22:38:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 931
train_sample_count: 931
avg_envstep_per_episode: 133.0
avg_sample_per_episode: 133.0
avg_envstep_per_sec: 798.1162636196733
avg_train_sample_per_sec: 798.1162636196733
avg_episode_per_sec: 6.000874162553935
collect_time: 1.1664967153753552
reward_mean: 841.4285888671875
reward_std: 442.7036437988281
reward_max: 1574.0
reward_min: 249.0
total_envstep_count: 638646
total_train_sample_count: 638597
total_episode_count: 4610
total_duration: 813.9910448959891
[2024-11-19 22:38:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1006
train_sample_count: 1006
avg_envstep_per_episode: 167.66666666666666
avg_sample_per_episode: 167.66666666666666
avg_envstep_per_sec: 800.7299993393622
avg_train_sample_per_sec: 800.7299993393622
avg_episode_per_sec: 4.775725642183074
collect_time: 1.256353578397206
reward_mean: 614.8333129882812
reward_std: 369.9285583496094
reward_max: 1288.0
reward_min: 171.0
total_envstep_count: 639641
total_train_sample_count: 639603
total_episode_count: 4616
total_duration: 815.2473984743864
[2024-11-19 22:38:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 875
train_sample_count: 875
avg_envstep_per_episode: 175.0
avg_sample_per_episode: 175.0
avg_envstep_per_sec: 806.3362910102381
avg_train_sample_per_sec: 806.3362910102381
avg_episode_per_sec: 4.607635948629932
collect_time: 1.0851551762648992
reward_mean: 866.2000122070312
reward_std: 209.41957092285156
reward_max: 1064.0
reward_min: 600.0
total_envstep_count: 640622
total_train_sample_count: 640586
total_episode_count: 4621
total_duration: 816.3325536506513
[2024-11-19 22:38:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1514
train_sample_count: 1514
avg_envstep_per_episode: 137.63636363636363
avg_sample_per_episode: 137.63636363636363
avg_envstep_per_sec: 805.9643293533944
avg_train_sample_per_sec: 805.9643293533944
avg_episode_per_sec: 5.855751402171293
collect_time: 1.8784950460706435
reward_mean: 761.4545288085938
reward_std: 309.36956787109375
reward_max: 1316.0
reward_min: 243.0
total_envstep_count: 641614
total_train_sample_count: 641584
total_episode_count: 4632
total_duration: 818.211048696722
[2024-11-19 22:38:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 745
train_sample_count: 745
avg_envstep_per_episode: 106.42857142857143
avg_sample_per_episode: 106.42857142857143
avg_envstep_per_sec: 808.7622738661953
avg_train_sample_per_sec: 808.7622738661953
avg_episode_per_sec: 7.599108613507876
collect_time: 0.921160672392164
reward_mean: 621.2857055664062
reward_std: 10.443238258361816
reward_max: 634.0
reward_min: 606.0
total_envstep_count: 642625
total_train_sample_count: 642581
total_episode_count: 4639
total_duration: 819.1322093691141
[2024-11-19 22:38:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1312
train_sample_count: 1312
avg_envstep_per_episode: 164.0
avg_sample_per_episode: 164.0
avg_envstep_per_sec: 807.8838214023035
avg_train_sample_per_sec: 807.8838214023035
avg_episode_per_sec: 4.926120862209168
collect_time: 1.6239958831242156
reward_mean: 1114.0
reward_std: 480.33453369140625
reward_max: 1847.0
reward_min: 585.0
total_envstep_count: 643626
total_train_sample_count: 643581
total_episode_count: 4647
total_duration: 820.7562052522383
[2024-11-19 22:38:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 701
train_sample_count: 701
avg_envstep_per_episode: 116.83333333333333
avg_sample_per_episode: 116.83333333333333
avg_envstep_per_sec: 793.274169051565
avg_train_sample_per_sec: 793.274169051565
avg_episode_per_sec: 6.789793173051911
collect_time: 0.8836793473788671
reward_mean: 821.6666870117188
reward_std: 315.5929260253906
reward_max: 1431.0
reward_min: 599.0
total_envstep_count: 644613
total_train_sample_count: 644570
total_episode_count: 4653
total_duration: 821.6398845996172
[2024-11-19 22:38:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 964
train_sample_count: 964
avg_envstep_per_episode: 137.71428571428572
avg_sample_per_episode: 137.71428571428572
avg_envstep_per_sec: 798.0263740583093
avg_train_sample_per_sec: 798.0263740583093
avg_episode_per_sec: 5.794797322000171
collect_time: 1.207980126142502
reward_mean: 986.1428833007812
reward_std: 351.8186950683594
reward_max: 1576.0
reward_min: 635.0
total_envstep_count: 645638
total_train_sample_count: 645606
total_episode_count: 4660
total_duration: 822.8478647257597
[2024-11-19 22:38:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 637
train_sample_count: 637
avg_envstep_per_episode: 212.33333333333334
avg_sample_per_episode: 212.33333333333334
avg_envstep_per_sec: 804.5074565522551
avg_train_sample_per_sec: 804.5074565522551
avg_episode_per_sec: 3.7888891203402912
collect_time: 0.7917888079370772
reward_mean: 1050.0
reward_std: 30.539592742919922
reward_max: 1093.0
reward_min: 1025.0
total_envstep_count: 646598
total_train_sample_count: 646579
total_episode_count: 4663
total_duration: 823.6396535336968
[2024-11-19 22:38:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1162
train_sample_count: 1162
avg_envstep_per_episode: 166.0
avg_sample_per_episode: 166.0
avg_envstep_per_sec: 798.2340387542379
avg_train_sample_per_sec: 798.2340387542379
avg_episode_per_sec: 4.808638787676132
collect_time: 1.455713416848864
reward_mean: 771.2857055664062
reward_std: 320.8874816894531
reward_max: 1435.0
reward_min: 248.0
total_envstep_count: 647607
total_train_sample_count: 647573
total_episode_count: 4670
total_duration: 825.0953669505457
[2024-11-19 22:38:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1117
train_sample_count: 1117
avg_envstep_per_episode: 223.4
avg_sample_per_episode: 223.4
avg_envstep_per_sec: 799.456059188283
avg_train_sample_per_sec: 799.456059188283
avg_episode_per_sec: 3.578585761809682
collect_time: 1.3971999926226477
reward_mean: 1002.0
reward_std: 306.8980407714844
reward_max: 1430.0
reward_min: 615.0
total_envstep_count: 648618
total_train_sample_count: 648570
total_episode_count: 4675
total_duration: 826.4925669431683
[2024-11-19 22:38:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 652
train_sample_count: 652
avg_envstep_per_episode: 81.5
avg_sample_per_episode: 81.5
avg_envstep_per_sec: 795.8359577670261
avg_train_sample_per_sec: 795.8359577670261
avg_episode_per_sec: 9.764858377509523
collect_time: 0.8192643140043532
reward_mean: 475.0
reward_std: 188.64913940429688
reward_max: 637.0
reward_min: 231.0
total_envstep_count: 649602
total_train_sample_count: 649558
total_episode_count: 4683
total_duration: 827.3118312571727
[2024-11-19 22:39:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1428
train_sample_count: 1428
avg_envstep_per_episode: 142.8
avg_sample_per_episode: 142.8
avg_envstep_per_sec: 795.4651425494991
avg_train_sample_per_sec: 795.4651425494991
avg_episode_per_sec: 5.570484191523103
collect_time: 1.7951760845524924
reward_mean: 815.7999877929688
reward_std: 399.0260314941406
reward_max: 1571.0
reward_min: 248.0
total_envstep_count: 650618
total_train_sample_count: 650566
total_episode_count: 4693
total_duration: 829.1070073417252
[2024-11-19 22:39:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1003
train_sample_count: 1003
avg_envstep_per_episode: 143.28571428571428
avg_sample_per_episode: 143.28571428571428
avg_envstep_per_sec: 781.6386990992894
avg_train_sample_per_sec: 781.6386990992894
avg_episode_per_sec: 5.455105576964133
collect_time: 1.283201562506812
reward_mean: 1094.7142333984375
reward_std: 317.55841064453125
reward_max: 1422.0
reward_min: 614.0
total_envstep_count: 651558
total_train_sample_count: 651533
total_episode_count: 4700
total_duration: 830.390208904232
[2024-11-19 22:39:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1067
train_sample_count: 1067
avg_envstep_per_episode: 133.375
avg_sample_per_episode: 133.375
avg_envstep_per_sec: 789.6876434914041
avg_train_sample_per_sec: 789.6876434914041
avg_episode_per_sec: 5.920807073974913
collect_time: 1.3511671466486794
reward_mean: 1003.75
reward_std: 384.0523376464844
reward_max: 1582.0
reward_min: 625.0
total_envstep_count: 652567
total_train_sample_count: 652528
total_episode_count: 4708
total_duration: 831.7413760508807
[2024-11-19 22:39:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 490
train_sample_count: 490
avg_envstep_per_episode: 122.5
avg_sample_per_episode: 122.5
avg_envstep_per_sec: 784.7565811629432
avg_train_sample_per_sec: 784.7565811629432
avg_episode_per_sec: 6.4061761727587205
collect_time: 0.624397439616067
reward_mean: 821.0
reward_std: 344.6788330078125
reward_max: 1418.0
reward_min: 621.0
total_envstep_count: 653523
total_train_sample_count: 653498
total_episode_count: 4712
total_duration: 832.3657734904967
[2024-11-19 22:39:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 1659
train_sample_count: 1659
avg_envstep_per_episode: 118.5
avg_sample_per_episode: 118.5
avg_envstep_per_sec: 788.4827221612966
avg_train_sample_per_sec: 788.4827221612966
avg_episode_per_sec: 6.653862634272545
collect_time: 2.1040410314287463
reward_mean: 729.2142944335938
reward_std: 434.988525390625
reward_max: 1425.0
reward_min: 251.0
total_envstep_count: 654537
total_train_sample_count: 654497
total_episode_count: 4726
total_duration: 834.4698145219255
[2024-11-19 22:39:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 744
train_sample_count: 744
avg_envstep_per_episode: 93.0
avg_sample_per_episode: 93.0
avg_envstep_per_sec: 794.3027059352413
avg_train_sample_per_sec: 794.3027059352413
avg_episode_per_sec: 8.540889311131627
collect_time: 0.9366706098828997
reward_mean: 644.75
reward_std: 397.3807067871094
reward_max: 1428.0
reward_min: 231.0
total_envstep_count: 655546
total_train_sample_count: 655505
total_episode_count: 4734
total_duration: 835.4064851318084
[2024-11-19 22:39:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1032
train_sample_count: 1032
avg_envstep_per_episode: 114.66666666666667
avg_sample_per_episode: 114.66666666666667
avg_envstep_per_sec: 796.079421368152
avg_train_sample_per_sec: 796.079421368152
avg_episode_per_sec: 6.942553093326907
collect_time: 1.2963530676705497
reward_mean: 848.5555419921875
reward_std: 688.0897827148438
reward_max: 1852.0
reward_min: 233.0
total_envstep_count: 656565
total_train_sample_count: 656525
total_episode_count: 4743
total_duration: 836.702838199479
[2024-11-19 22:39:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1091
train_sample_count: 1091
avg_envstep_per_episode: 109.1
avg_sample_per_episode: 109.1
avg_envstep_per_sec: 786.7084862612446
avg_train_sample_per_sec: 786.7084862612446
avg_episode_per_sec: 7.210893549598942
collect_time: 1.3867906842912947
reward_mean: 813.0999755859375
reward_std: 464.6341552734375
reward_max: 1577.0
reward_min: 232.0
total_envstep_count: 657539
total_train_sample_count: 657508
total_episode_count: 4753
total_duration: 838.0896288837703
[2024-11-19 22:39:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1113
train_sample_count: 1113
avg_envstep_per_episode: 123.66666666666667
avg_sample_per_episode: 123.66666666666667
avg_envstep_per_sec: 779.9381309845162
avg_train_sample_per_sec: 779.9381309845162
avg_episode_per_sec: 6.306777339497436
collect_time: 1.427036268370492
reward_mean: 748.6666870117188
reward_std: 249.5845489501953
reward_max: 1052.0
reward_min: 242.0
total_envstep_count: 658540
total_train_sample_count: 658525
total_episode_count: 4762
total_duration: 839.5166651521407
[2024-11-19 22:39:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 598
train_sample_count: 598
avg_envstep_per_episode: 85.42857142857143
avg_sample_per_episode: 85.42857142857143
avg_envstep_per_sec: 782.8451398215147
avg_train_sample_per_sec: 782.8451398215147
avg_episode_per_sec: 9.163739094900674
collect_time: 0.7638803252152033
reward_mean: 563.5714111328125
reward_std: 132.6389923095703
reward_max: 629.0
reward_min: 239.0
total_envstep_count: 659573
total_train_sample_count: 659531
total_episode_count: 4769
total_duration: 840.2805454773559
[2024-11-19 22:39:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1360
train_sample_count: 1360
avg_envstep_per_episode: 123.63636363636364
avg_sample_per_episode: 123.63636363636364
avg_envstep_per_sec: 782.8168912608743
avg_train_sample_per_sec: 782.8168912608743
avg_episode_per_sec: 6.33160720872766
collect_time: 1.737315603664943
reward_mean: 796.0
reward_std: 482.2724609375
reward_max: 1567.0
reward_min: 245.0
total_envstep_count: 660597
total_train_sample_count: 660543
total_episode_count: 4780
total_duration: 842.0178610810208
[2024-11-19 22:40:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 744
train_sample_count: 744
avg_envstep_per_episode: 148.8
avg_sample_per_episode: 148.8
avg_envstep_per_sec: 790.3121292449985
avg_train_sample_per_sec: 790.3121292449985
avg_episode_per_sec: 5.311237427721764
collect_time: 0.9414002043860299
reward_mean: 975.4000244140625
reward_std: 468.6545104980469
reward_max: 1860.0
reward_min: 617.0
total_envstep_count: 661568
total_train_sample_count: 661515
total_episode_count: 4785
total_duration: 842.9592612854068
[2024-11-19 22:40:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 1500
train_sample_count: 1500
avg_envstep_per_episode: 107.14285714285714
avg_sample_per_episode: 107.14285714285714
avg_envstep_per_sec: 681.2656641885092
avg_train_sample_per_sec: 681.2656641885092
avg_episode_per_sec: 6.358479532426085
collect_time: 2.201784236090524
reward_mean: 801.2142944335938
reward_std: 408.9076232910156
reward_max: 1574.0
reward_min: 246.0
total_envstep_count: 662571
total_train_sample_count: 662535
total_episode_count: 4799
total_duration: 845.1610455214973
[2024-11-19 22:40:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 897
train_sample_count: 897
avg_envstep_per_episode: 99.66666666666667
avg_sample_per_episode: 99.66666666666667
avg_envstep_per_sec: 791.4482981263934
avg_train_sample_per_sec: 791.4482981263934
avg_episode_per_sec: 7.940952824010637
collect_time: 1.1333652521882738
reward_mean: 634.3333129882812
reward_std: 345.3159484863281
reward_max: 1324.0
reward_min: 201.0
total_envstep_count: 663574
total_train_sample_count: 663528
total_episode_count: 4808
total_duration: 846.2944107736855
[2024-11-19 22:40:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 679
train_sample_count: 679
avg_envstep_per_episode: 84.875
avg_sample_per_episode: 84.875
avg_envstep_per_sec: 781.4554914527134
avg_train_sample_per_sec: 781.4554914527134
avg_episode_per_sec: 9.207133919914149
collect_time: 0.8688914562974658
reward_mean: 645.375
reward_std: 344.3907470703125
reward_max: 1433.0
reward_min: 249.0
total_envstep_count: 664575
total_train_sample_count: 664531
total_episode_count: 4816
total_duration: 847.163302229983
[2024-11-19 22:40:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1226
train_sample_count: 1226
avg_envstep_per_episode: 153.25
avg_sample_per_episode: 153.25
avg_envstep_per_sec: 785.4279477265657
avg_train_sample_per_sec: 785.4279477265657
avg_episode_per_sec: 5.1251415838601355
collect_time: 1.5609324872493746
reward_mean: 1070.625
reward_std: 476.1698303222656
reward_max: 1577.0
reward_min: 244.0
total_envstep_count: 665568
total_train_sample_count: 665517
total_episode_count: 4824
total_duration: 848.7242347172323
[2024-11-19 22:40:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 887
train_sample_count: 887
avg_envstep_per_episode: 80.63636363636364
avg_sample_per_episode: 80.63636363636364
avg_envstep_per_sec: 789.0038452541753
avg_train_sample_per_sec: 789.0038452541753
avg_episode_per_sec: 9.784715104617732
collect_time: 1.124202379158565
reward_mean: 529.5454711914062
reward_std: 377.2853698730469
reward_max: 1427.0
reward_min: 244.0
total_envstep_count: 666583
total_train_sample_count: 666536
total_episode_count: 4835
total_duration: 849.8484370963909
[2024-11-19 22:40:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1146
train_sample_count: 1146
avg_envstep_per_episode: 127.33333333333333
avg_sample_per_episode: 127.33333333333333
avg_envstep_per_sec: 801.4615656457833
avg_train_sample_per_sec: 801.4615656457833
avg_episode_per_sec: 6.294200777322905
collect_time: 1.4298876566546301
reward_mean: 806.0
reward_std: 392.8321533203125
reward_max: 1565.0
reward_min: 237.0
total_envstep_count: 667567
total_train_sample_count: 667538
total_episode_count: 4844
total_duration: 851.2783247530455
[2024-11-19 22:40:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 985
train_sample_count: 985
avg_envstep_per_episode: 109.44444444444444
avg_sample_per_episode: 109.44444444444444
avg_envstep_per_sec: 804.5266872438184
avg_train_sample_per_sec: 804.5266872438184
avg_episode_per_sec: 7.351005264156716
collect_time: 1.2243223445756097
reward_mean: 634.3333129882812
reward_std: 299.1402587890625
reward_max: 1318.0
reward_min: 234.0
total_envstep_count: 668560
total_train_sample_count: 668535
total_episode_count: 4853
total_duration: 852.5026470976211
[2024-11-19 22:40:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 893
train_sample_count: 893
avg_envstep_per_episode: 89.3
avg_sample_per_episode: 89.3
avg_envstep_per_sec: 792.9506957568402
avg_train_sample_per_sec: 792.9506957568402
avg_episode_per_sec: 8.879627052148265
collect_time: 1.1261734238692693
reward_mean: 593.7999877929688
reward_std: 354.37939453125
reward_max: 1329.0
reward_min: 230.0
total_envstep_count: 669544
total_train_sample_count: 669524
total_episode_count: 4863
total_duration: 853.6288205214904
[2024-11-19 22:40:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 758
train_sample_count: 758
avg_envstep_per_episode: 126.33333333333333
avg_sample_per_episode: 126.33333333333333
avg_envstep_per_sec: 794.4755573345052
avg_train_sample_per_sec: 794.4755573345052
avg_episode_per_sec: 6.288724728241466
collect_time: 0.9540885090827941
reward_mean: 793.1666870117188
reward_std: 188.46876525878906
reward_max: 1044.0
reward_min: 621.0
total_envstep_count: 670524
total_train_sample_count: 670498
total_episode_count: 4869
total_duration: 854.5829090305732
[2024-11-19 22:40:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1202
train_sample_count: 1202
avg_envstep_per_episode: 171.71428571428572
avg_sample_per_episode: 171.71428571428572
avg_envstep_per_sec: 804.9360163074996
avg_train_sample_per_sec: 804.9360163074996
avg_episode_per_sec: 4.687647349544507
collect_time: 1.493286392518452
reward_mean: 625.7142944335938
reward_std: 414.1537780761719
reward_max: 1558.0
reward_min: 203.0
total_envstep_count: 671549
total_train_sample_count: 671496
total_episode_count: 4876
total_duration: 856.0761954230917
[2024-11-19 22:40:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1082
train_sample_count: 1082
avg_envstep_per_episode: 120.22222222222223
avg_sample_per_episode: 120.22222222222223
avg_envstep_per_sec: 799.8067799994346
avg_train_sample_per_sec: 799.8067799994346
avg_episode_per_sec: 6.652736617370528
collect_time: 1.352826741479692
reward_mean: 615.7777709960938
reward_std: 286.9532470703125
reward_max: 1297.0
reward_min: 246.0
total_envstep_count: 672549
total_train_sample_count: 672530
total_episode_count: 4885
total_duration: 857.4290221645714
[2024-11-19 22:40:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 16
envstep_count: 1143
train_sample_count: 1143
avg_envstep_per_episode: 71.4375
avg_sample_per_episode: 71.4375
avg_envstep_per_sec: 797.9680784187594
avg_train_sample_per_sec: 797.9680784187594
avg_episode_per_sec: 11.1701568282591
collect_time: 1.4323881254309698
reward_mean: 471.8125
reward_std: 369.4322204589844
reward_max: 1571.0
reward_min: 196.0
total_envstep_count: 673584
total_train_sample_count: 673541
total_episode_count: 4901
total_duration: 858.8614102900024
[2024-11-19 22:40:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 450
train_sample_count: 450
avg_envstep_per_episode: 64.28571428571429
avg_sample_per_episode: 64.28571428571429
avg_envstep_per_sec: 789.9918891948525
avg_train_sample_per_sec: 789.9918891948525
avg_episode_per_sec: 12.288762720808817
collect_time: 0.5696261014257159
reward_mean: 378.5714416503906
reward_std: 216.84085083007812
reward_max: 804.0
reward_min: 234.0
total_envstep_count: 674586
total_train_sample_count: 674543
total_episode_count: 4908
total_duration: 859.431036391428
[2024-11-19 22:40:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1099
train_sample_count: 1099
avg_envstep_per_episode: 219.8
avg_sample_per_episode: 219.8
avg_envstep_per_sec: 800.9832863884728
avg_train_sample_per_sec: 800.9832863884728
avg_episode_per_sec: 3.644145979929358
collect_time: 1.3720635856900896
reward_mean: 853.2000122070312
reward_std: 277.1277160644531
reward_max: 1400.0
reward_min: 633.0
total_envstep_count: 675573
total_train_sample_count: 675534
total_episode_count: 4913
total_duration: 860.8030999771181
[2024-11-19 22:40:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1201
train_sample_count: 1201
avg_envstep_per_episode: 109.18181818181819
avg_sample_per_episode: 109.18181818181819
avg_envstep_per_sec: 799.5143516613468
avg_train_sample_per_sec: 799.5143516613468
avg_episode_per_sec: 7.322779240861628
collect_time: 1.5021619030407498
reward_mean: 476.9090881347656
reward_std: 216.16636657714844
reward_max: 789.0
reward_min: 235.0
total_envstep_count: 676589
total_train_sample_count: 676555
total_episode_count: 4924
total_duration: 862.3052618801588
[2024-11-19 22:41:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1263
train_sample_count: 1263
avg_envstep_per_episode: 97.15384615384616
avg_sample_per_episode: 97.15384615384616
avg_envstep_per_sec: 782.556293640952
avg_train_sample_per_sec: 782.556293640952
avg_episode_per_sec: 8.054815373976545
collect_time: 1.613941399824052
reward_mean: 603.6153564453125
reward_std: 398.2002868652344
reward_max: 1335.0
reward_min: 193.0
total_envstep_count: 677641
total_train_sample_count: 677602
total_episode_count: 4937
total_duration: 863.9192032799829
[2024-11-19 22:41:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 480
train_sample_count: 480
avg_envstep_per_episode: 160.0
avg_sample_per_episode: 160.0
avg_envstep_per_sec: 797.4538607191945
avg_train_sample_per_sec: 797.4538607191945
avg_episode_per_sec: 4.984086629494966
collect_time: 0.6019157015141986
reward_mean: 637.3333129882812
reward_std: 55.763389587402344
reward_max: 714.0
reward_min: 583.0
total_envstep_count: 678614
total_train_sample_count: 678586
total_episode_count: 4940
total_duration: 864.521118981497
[2024-11-19 22:41:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1019
train_sample_count: 1019
avg_envstep_per_episode: 169.83333333333334
avg_sample_per_episode: 169.83333333333334
avg_envstep_per_sec: 802.3549006050307
avg_train_sample_per_sec: 802.3549006050307
avg_episode_per_sec: 4.7243664412465005
collect_time: 1.2700115612574985
reward_mean: 1000.5
reward_std: 429.981689453125
reward_max: 1424.0
reward_min: 236.0
total_envstep_count: 679633
total_train_sample_count: 679593
total_episode_count: 4946
total_duration: 865.7911305427546
[2024-11-19 22:41:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1216
train_sample_count: 1216
avg_envstep_per_episode: 110.54545454545455
avg_sample_per_episode: 110.54545454545455
avg_envstep_per_sec: 792.5033131131894
avg_train_sample_per_sec: 792.5033131131894
avg_episode_per_sec: 7.1690266811226016
collect_time: 1.5343784434454781
reward_mean: 699.727294921875
reward_std: 534.8607788085938
reward_max: 1668.0
reward_min: 225.0
total_envstep_count: 680615
total_train_sample_count: 680581
total_episode_count: 4957
total_duration: 867.3255089862
[2024-11-19 22:41:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 851
train_sample_count: 851
avg_envstep_per_episode: 121.57142857142857
avg_sample_per_episode: 121.57142857142857
avg_envstep_per_sec: 800.3374977022461
avg_train_sample_per_sec: 800.3374977022461
avg_episode_per_sec: 6.583269663825761
collect_time: 1.0633014227662767
reward_mean: 742.8571166992188
reward_std: 245.33326721191406
reward_max: 1337.0
reward_min: 616.0
total_envstep_count: 681610
total_train_sample_count: 681564
total_episode_count: 4964
total_duration: 868.3888104089663
[2024-11-19 22:41:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1373
train_sample_count: 1373
avg_envstep_per_episode: 114.41666666666667
avg_sample_per_episode: 114.41666666666667
avg_envstep_per_sec: 792.8755309560922
avg_train_sample_per_sec: 792.8755309560922
avg_episode_per_sec: 6.929720591021927
collect_time: 1.7316715504441944
reward_mean: 680.0
reward_std: 399.7411804199219
reward_max: 1419.0
reward_min: 199.0
total_envstep_count: 682633
total_train_sample_count: 682601
total_episode_count: 4976
total_duration: 870.1204819594104
[2024-11-19 22:41:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 622
train_sample_count: 622
avg_envstep_per_episode: 88.85714285714286
avg_sample_per_episode: 88.85714285714286
avg_envstep_per_sec: 798.998876350382
avg_train_sample_per_sec: 798.998876350382
avg_episode_per_sec: 8.991948769216519
collect_time: 0.7784741861479623
reward_mean: 569.4285888671875
reward_std: 391.48248291015625
reward_max: 1415.0
reward_min: 202.0
total_envstep_count: 683628
total_train_sample_count: 683583
total_episode_count: 4983
total_duration: 870.8989561455584
[2024-11-19 22:41:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1452
train_sample_count: 1452
avg_envstep_per_episode: 132.0
avg_sample_per_episode: 132.0
avg_envstep_per_sec: 790.9896972858804
avg_train_sample_per_sec: 790.9896972858804
avg_episode_per_sec: 5.9923461915597
collect_time: 1.8356749841145106
reward_mean: 967.4545288085938
reward_std: 407.6048278808594
reward_max: 1433.0
reward_min: 241.0
total_envstep_count: 684681
total_train_sample_count: 684639
total_episode_count: 4994
total_duration: 872.7346311296728
[2024-11-19 22:41:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 918
train_sample_count: 918
avg_envstep_per_episode: 131.14285714285714
avg_sample_per_episode: 131.14285714285714
avg_envstep_per_sec: 782.4783802644351
avg_train_sample_per_sec: 782.4783802644351
avg_episode_per_sec: 5.966610742757131
collect_time: 1.1731953535761153
reward_mean: 831.4285888671875
reward_std: 441.14068603515625
reward_max: 1431.0
reward_min: 238.0
total_envstep_count: 685658
total_train_sample_count: 685629
total_episode_count: 5001
total_duration: 873.907826483249
[2024-11-19 22:41:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1016
train_sample_count: 1016
avg_envstep_per_episode: 101.6
avg_sample_per_episode: 101.6
avg_envstep_per_sec: 796.7828165339333
avg_train_sample_per_sec: 796.7828165339333
avg_episode_per_sec: 7.842350556436352
collect_time: 1.275127900498254
reward_mean: 712.0
reward_std: 241.17462158203125
reward_max: 1041.0
reward_min: 250.0
total_envstep_count: 686690
total_train_sample_count: 686645
total_episode_count: 5011
total_duration: 875.1829543837472
[2024-11-19 22:41:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 831
train_sample_count: 831
avg_envstep_per_episode: 103.875
avg_sample_per_episode: 103.875
avg_envstep_per_sec: 797.4194186536649
avg_train_sample_per_sec: 797.4194186536649
avg_episode_per_sec: 7.676721238543103
collect_time: 1.042111567088536
reward_mean: 764.75
reward_std: 258.8420104980469
reward_max: 1330.0
reward_min: 602.0
total_envstep_count: 687684
total_train_sample_count: 687644
total_episode_count: 5019
total_duration: 876.2250659508358
[2024-11-19 22:42:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1136
train_sample_count: 1136
avg_envstep_per_episode: 126.22222222222223
avg_sample_per_episode: 126.22222222222223
avg_envstep_per_sec: 796.1410045333414
avg_train_sample_per_sec: 796.1410045333414
avg_episode_per_sec: 6.30745514154936
collect_time: 1.4268829183919087
reward_mean: 790.3333129882812
reward_std: 363.0221862792969
reward_max: 1428.0
reward_min: 240.0
total_envstep_count: 688662
total_train_sample_count: 688636
total_episode_count: 5028
total_duration: 877.6519488692277
[2024-11-19 22:42:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1166
train_sample_count: 1166
avg_envstep_per_episode: 116.6
avg_sample_per_episode: 116.6
avg_envstep_per_sec: 796.0729146960172
avg_train_sample_per_sec: 796.0729146960172
avg_episode_per_sec: 6.827383487958981
collect_time: 1.4646899529865811
reward_mean: 606.5
reward_std: 194.64544677734375
reward_max: 810.0
reward_min: 239.0
total_envstep_count: 689675
total_train_sample_count: 689634
total_episode_count: 5038
total_duration: 879.1166388222142
[2024-11-19 22:42:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 647
train_sample_count: 647
avg_envstep_per_episode: 129.4
avg_sample_per_episode: 129.4
avg_envstep_per_sec: 793.9973423601266
avg_train_sample_per_sec: 793.9973423601266
avg_episode_per_sec: 6.1359918265852125
collect_time: 0.8148641884326935
reward_mean: 841.2000122070312
reward_std: 289.5233459472656
reward_max: 1308.0
reward_min: 594.0
total_envstep_count: 690671
total_train_sample_count: 690641
total_episode_count: 5043
total_duration: 879.9315030106469
[2024-11-19 22:42:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 754
train_sample_count: 754
avg_envstep_per_episode: 150.8
avg_sample_per_episode: 150.8
avg_envstep_per_sec: 799.8200389635009
avg_train_sample_per_sec: 799.8200389635009
avg_episode_per_sec: 5.303846412224807
collect_time: 0.9427120643002646
reward_mean: 880.7999877929688
reward_std: 439.16436767578125
reward_max: 1424.0
reward_min: 243.0
total_envstep_count: 691682
total_train_sample_count: 691647
total_episode_count: 5048
total_duration: 880.8742150749472
[2024-11-19 22:42:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1354
train_sample_count: 1354
avg_envstep_per_episode: 193.42857142857142
avg_sample_per_episode: 193.42857142857142
avg_envstep_per_sec: 805.9049014451673
avg_train_sample_per_sec: 805.9049014451673
avg_episode_per_sec: 4.166421203926271
collect_time: 1.6800989764077323
reward_mean: 894.7142944335938
reward_std: 299.6663513183594
reward_max: 1330.0
reward_min: 589.0
total_envstep_count: 692685
total_train_sample_count: 692641
total_episode_count: 5055
total_duration: 882.5543140513549
[2024-11-19 22:42:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 765
train_sample_count: 765
avg_envstep_per_episode: 127.5
avg_sample_per_episode: 127.5
avg_envstep_per_sec: 802.2708125556476
avg_train_sample_per_sec: 802.2708125556476
avg_episode_per_sec: 6.292320098475667
collect_time: 0.9535433522292545
reward_mean: 732.0
reward_std: 357.6050109863281
reward_max: 1319.0
reward_min: 198.0
total_envstep_count: 693681
total_train_sample_count: 693634
total_episode_count: 5061
total_duration: 883.5078574035842
[2024-11-19 22:42:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 980
train_sample_count: 980
avg_envstep_per_episode: 140.0
avg_sample_per_episode: 140.0
avg_envstep_per_sec: 802.9824889195078
avg_train_sample_per_sec: 802.9824889195078
avg_episode_per_sec: 5.735589206567912
collect_time: 1.2204500266483853
reward_mean: 831.2857055664062
reward_std: 429.1039123535156
reward_max: 1325.0
reward_min: 247.0
total_envstep_count: 694651
total_train_sample_count: 694626
total_episode_count: 5068
total_duration: 884.7283074302326
[2024-11-19 22:42:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1083
train_sample_count: 1083
avg_envstep_per_episode: 120.33333333333333
avg_sample_per_episode: 120.33333333333333
avg_envstep_per_sec: 796.5511193981349
avg_train_sample_per_sec: 796.5511193981349
avg_episode_per_sec: 6.6195383883501515
collect_time: 1.3596114218235016
reward_mean: 816.888916015625
reward_std: 385.45452880859375
reward_max: 1340.0
reward_min: 247.0
total_envstep_count: 695667
total_train_sample_count: 695637
total_episode_count: 5077
total_duration: 886.0879188520561
[2024-11-19 22:42:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 796
train_sample_count: 796
avg_envstep_per_episode: 132.66666666666666
avg_sample_per_episode: 132.66666666666666
avg_envstep_per_sec: 803.6366084311403
avg_train_sample_per_sec: 803.6366084311403
avg_episode_per_sec: 6.0575623751090975
collect_time: 0.9904974358422416
reward_mean: 832.6666870117188
reward_std: 455.1376037597656
reward_max: 1690.0
reward_min: 226.0
total_envstep_count: 696653
total_train_sample_count: 696613
total_episode_count: 5083
total_duration: 887.0784162878983
[2024-11-19 22:42:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 960
train_sample_count: 960
avg_envstep_per_episode: 160.0
avg_sample_per_episode: 160.0
avg_envstep_per_sec: 798.1550639590471
avg_train_sample_per_sec: 798.1550639590471
avg_episode_per_sec: 4.988469149744045
collect_time: 1.2027738009180344
reward_mean: 882.3333129882812
reward_std: 441.2669677734375
reward_max: 1854.0
reward_min: 583.0
total_envstep_count: 697656
total_train_sample_count: 697609
total_episode_count: 5089
total_duration: 888.2811900888164
[2024-11-19 22:42:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1171
train_sample_count: 1171
avg_envstep_per_episode: 195.16666666666666
avg_sample_per_episode: 195.16666666666666
avg_envstep_per_sec: 800.9793176669026
avg_train_sample_per_sec: 800.9793176669026
avg_episode_per_sec: 4.104078485056717
collect_time: 1.4619603455066679
reward_mean: 1100.3333740234375
reward_std: 418.1509704589844
reward_max: 1683.0
reward_min: 621.0
total_envstep_count: 698643
total_train_sample_count: 698600
total_episode_count: 5095
total_duration: 889.7431504343231
[2024-11-19 22:42:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1186
train_sample_count: 1186
avg_envstep_per_episode: 131.77777777777777
avg_sample_per_episode: 131.77777777777777
avg_envstep_per_sec: 790.1007868044719
avg_train_sample_per_sec: 790.1007868044719
avg_episode_per_sec: 5.995705802057544
collect_time: 1.5010743183749065
reward_mean: 953.0
reward_std: 457.03369140625
reward_max: 1924.0
reward_min: 613.0
total_envstep_count: 699636
total_train_sample_count: 699594
total_episode_count: 5104
total_duration: 891.244224752698
[2024-11-19 22:42:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 964
train_sample_count: 964
avg_envstep_per_episode: 120.5
avg_sample_per_episode: 120.5
avg_envstep_per_sec: 629.3383750970199
avg_train_sample_per_sec: 629.3383750970199
avg_episode_per_sec: 5.222725104539584
collect_time: 1.5317673896040236
reward_mean: 770.125
reward_std: 370.2135925292969
reward_max: 1423.0
reward_min: 249.0
total_envstep_count: 700623
total_train_sample_count: 700606
total_episode_count: 5112
total_duration: 892.775992142302
[2024-11-19 22:42:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 16
envstep_count: 1475
train_sample_count: 1475
avg_envstep_per_episode: 92.1875
avg_sample_per_episode: 92.1875
avg_envstep_per_sec: 779.55489951228
avg_train_sample_per_sec: 779.55489951228
avg_episode_per_sec: 8.45618874047219
collect_time: 1.8921053551492237
reward_mean: 623.3125
reward_std: 401.2657775878906
reward_max: 1344.0
reward_min: 232.0
total_envstep_count: 701657
total_train_sample_count: 701613
total_episode_count: 5128
total_duration: 894.6680974974512
[2024-11-19 22:42:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 563
train_sample_count: 563
avg_envstep_per_episode: 93.83333333333333
avg_sample_per_episode: 93.83333333333333
avg_envstep_per_sec: 791.3985890463342
avg_train_sample_per_sec: 791.3985890463342
avg_episode_per_sec: 8.434087982731803
collect_time: 0.7113987916991824
reward_mean: 559.6666870117188
reward_std: 237.86106872558594
reward_max: 812.0
reward_min: 234.0
total_envstep_count: 702611
total_train_sample_count: 702584
total_episode_count: 5134
total_duration: 895.3794962891503
[2024-11-19 22:42:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1134
train_sample_count: 1134
avg_envstep_per_episode: 126.0
avg_sample_per_episode: 126.0
avg_envstep_per_sec: 787.1876339346056
avg_train_sample_per_sec: 787.1876339346056
avg_episode_per_sec: 6.2475209042429025
collect_time: 1.4405714103153775
reward_mean: 838.0
reward_std: 418.7863464355469
reward_max: 1694.0
reward_min: 241.0
total_envstep_count: 703619
total_train_sample_count: 703586
total_episode_count: 5143
total_duration: 896.8200676994657
[2024-11-19 22:42:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 676
train_sample_count: 676
avg_envstep_per_episode: 135.2
avg_sample_per_episode: 135.2
avg_envstep_per_sec: 774.6312897779885
avg_train_sample_per_sec: 774.6312897779885
avg_episode_per_sec: 5.729521374097548
collect_time: 0.8726732432842256
reward_mean: 814.2000122070312
reward_std: 131.4053192138672
reward_max: 1043.0
reward_min: 634.0
total_envstep_count: 704624
total_train_sample_count: 704586
total_episode_count: 5148
total_duration: 897.6927409427499
[2024-11-19 22:43:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1145
train_sample_count: 1145
avg_envstep_per_episode: 143.125
avg_sample_per_episode: 143.125
avg_envstep_per_sec: 769.9069402300255
avg_train_sample_per_sec: 769.9069402300255
avg_episode_per_sec: 5.379262464489261
collect_time: 1.4871927244322642
reward_mean: 939.5
reward_std: 405.3476867675781
reward_max: 1581.0
reward_min: 223.0
total_envstep_count: 705611
total_train_sample_count: 705575
total_episode_count: 5156
total_duration: 899.1799336671821
[2024-11-19 22:43:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 834
train_sample_count: 834
avg_envstep_per_episode: 104.25
avg_sample_per_episode: 104.25
avg_envstep_per_sec: 774.0226752383634
avg_train_sample_per_sec: 774.0226752383634
avg_episode_per_sec: 7.424677939936339
collect_time: 1.077487813574927
reward_mean: 599.375
reward_std: 254.51126098632812
reward_max: 1050.0
reward_min: 223.0
total_envstep_count: 706651
total_train_sample_count: 706625
total_episode_count: 5164
total_duration: 900.2574214807571
[2024-11-19 22:43:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1215
train_sample_count: 1215
avg_envstep_per_episode: 121.5
avg_sample_per_episode: 121.5
avg_envstep_per_sec: 777.252245730663
avg_train_sample_per_sec: 777.252245730663
avg_episode_per_sec: 6.397137824943729
collect_time: 1.5631990858486722
reward_mean: 641.7000122070312
reward_std: 307.4345703125
reward_max: 1412.0
reward_min: 235.0
total_envstep_count: 707681
total_train_sample_count: 707660
total_episode_count: 5174
total_duration: 901.8206205666057
[2024-11-19 22:43:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 560
train_sample_count: 560
avg_envstep_per_episode: 112.0
avg_sample_per_episode: 112.0
avg_envstep_per_sec: 773.7707004017099
avg_train_sample_per_sec: 773.7707004017099
avg_episode_per_sec: 6.90866696787241
collect_time: 0.7237286184515271
reward_mean: 609.4000244140625
reward_std: 190.04693603515625
reward_max: 761.0
reward_min: 244.0
total_envstep_count: 708692
total_train_sample_count: 708640
total_episode_count: 5179
total_duration: 902.5443491850573
[2024-11-19 22:43:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1587
train_sample_count: 1587
avg_envstep_per_episode: 158.7
avg_sample_per_episode: 158.7
avg_envstep_per_sec: 779.3835907343541
avg_train_sample_per_sec: 779.3835907343541
avg_episode_per_sec: 4.911049721073435
collect_time: 2.0362245483057837
reward_mean: 1025.199951171875
reward_std: 498.1968994140625
reward_max: 1575.0
reward_min: 241.0
total_envstep_count: 709707
total_train_sample_count: 709651
total_episode_count: 5189
total_duration: 904.580573733363
[2024-11-19 22:43:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 1338
train_sample_count: 1338
avg_envstep_per_episode: 95.57142857142857
avg_sample_per_episode: 95.57142857142857
avg_envstep_per_sec: 786.800761665838
avg_train_sample_per_sec: 786.800761665838
avg_episode_per_sec: 8.232593918775585
collect_time: 1.7005575810159952
reward_mean: 634.9285888671875
reward_std: 378.9518127441406
reward_max: 1581.0
reward_min: 231.0
total_envstep_count: 710744
total_train_sample_count: 710713
total_episode_count: 5203
total_duration: 906.2811313143791
[2024-11-19 22:43:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 617
train_sample_count: 617
avg_envstep_per_episode: 61.7
avg_sample_per_episode: 61.7
avg_envstep_per_sec: 790.2129429165917
avg_train_sample_per_sec: 790.2129429165917
avg_episode_per_sec: 12.807341052132767
collect_time: 0.7808021945612771
reward_mean: 436.6000061035156
reward_std: 186.5975341796875
reward_max: 652.0
reward_min: 250.0
total_envstep_count: 711736
total_train_sample_count: 711702
total_episode_count: 5213
total_duration: 907.0619335089403
[2024-11-19 22:43:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 911
train_sample_count: 911
avg_envstep_per_episode: 151.83333333333334
avg_sample_per_episode: 151.83333333333334
avg_envstep_per_sec: 793.5436023676752
avg_train_sample_per_sec: 793.5436023676752
avg_episode_per_sec: 5.226412309776126
collect_time: 1.1480150520801544
reward_mean: 992.1666870117188
reward_std: 519.2681884765625
reward_max: 1570.0
reward_min: 250.0
total_envstep_count: 712755
total_train_sample_count: 712721
total_episode_count: 5219
total_duration: 908.2099485610205
[2024-11-19 22:43:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1180
train_sample_count: 1180
avg_envstep_per_episode: 118.0
avg_sample_per_episode: 118.0
avg_envstep_per_sec: 787.0609728444044
avg_train_sample_per_sec: 787.0609728444044
avg_episode_per_sec: 6.670008244444105
collect_time: 1.4992485216685703
reward_mean: 864.4000244140625
reward_std: 518.7097778320312
reward_max: 1929.0
reward_min: 218.0
total_envstep_count: 713777
total_train_sample_count: 713733
total_episode_count: 5229
total_duration: 909.7091970826891
[2024-11-19 22:43:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 682
train_sample_count: 682
avg_envstep_per_episode: 113.66666666666667
avg_sample_per_episode: 113.66666666666667
avg_envstep_per_sec: 784.401472648239
avg_train_sample_per_sec: 784.401472648239
avg_episode_per_sec: 6.900892721245504
collect_time: 0.8694527276924677
reward_mean: 588.5
reward_std: 176.3932647705078
reward_max: 796.0
reward_min: 234.0
total_envstep_count: 714748
total_train_sample_count: 714727
total_episode_count: 5235
total_duration: 910.5786498103815
[2024-11-19 22:43:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1520
train_sample_count: 1520
avg_envstep_per_episode: 126.66666666666667
avg_sample_per_episode: 126.66666666666667
avg_envstep_per_sec: 788.1778737147528
avg_train_sample_per_sec: 788.1778737147528
avg_episode_per_sec: 6.2224568977480486
collect_time: 1.9284986938749042
reward_mean: 760.8333129882812
reward_std: 457.8520202636719
reward_max: 1578.0
reward_min: 240.0
total_envstep_count: 715794
total_train_sample_count: 715755
total_episode_count: 5247
total_duration: 912.5071485042564
[2024-11-19 22:43:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 613
train_sample_count: 613
avg_envstep_per_episode: 87.57142857142857
avg_sample_per_episode: 87.57142857142857
avg_envstep_per_sec: 789.0650099834911
avg_train_sample_per_sec: 789.0650099834911
avg_episode_per_sec: 9.010530293449326
collect_time: 0.776868815932955
reward_mean: 623.1428833007812
reward_std: 337.37744140625
reward_max: 1344.0
reward_min: 250.0
total_envstep_count: 716787
total_train_sample_count: 716740
total_episode_count: 5254
total_duration: 913.2840173201894
[2024-11-19 22:43:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1062
train_sample_count: 1062
avg_envstep_per_episode: 177.0
avg_sample_per_episode: 177.0
avg_envstep_per_sec: 793.8833970130282
avg_train_sample_per_sec: 793.8833970130282
avg_episode_per_sec: 4.4852169322769955
collect_time: 1.33772793837956
reward_mean: 980.8333129882812
reward_std: 306.4731750488281
reward_max: 1419.0
reward_min: 619.0
total_envstep_count: 717774
total_train_sample_count: 717742
total_episode_count: 5260
total_duration: 914.6217452585689
[2024-11-19 22:43:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 998
train_sample_count: 998
avg_envstep_per_episode: 166.33333333333334
avg_sample_per_episode: 166.33333333333334
avg_envstep_per_sec: 804.4012399729801
avg_train_sample_per_sec: 804.4012399729801
avg_episode_per_sec: 4.836079599035952
collect_time: 1.240674367972783
reward_mean: 968.0
reward_std: 417.16143798828125
reward_max: 1425.0
reward_min: 250.0
total_envstep_count: 718779
total_train_sample_count: 718716
total_episode_count: 5266
total_duration: 915.8624196265417
[2024-11-19 22:43:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1100
train_sample_count: 1100
avg_envstep_per_episode: 157.14285714285714
avg_sample_per_episode: 157.14285714285714
avg_envstep_per_sec: 789.3729082421758
avg_train_sample_per_sec: 789.3729082421758
avg_episode_per_sec: 5.0232821433593005
collect_time: 1.3935112144265855
reward_mean: 805.1428833007812
reward_std: 348.0067443847656
reward_max: 1390.0
reward_min: 238.0
total_envstep_count: 719749
total_train_sample_count: 719708
total_episode_count: 5273
total_duration: 917.2559308409683
[2024-11-19 22:43:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1142
train_sample_count: 1142
avg_envstep_per_episode: 126.88888888888889
avg_sample_per_episode: 126.88888888888889
avg_envstep_per_sec: 799.1381602298854
avg_train_sample_per_sec: 799.1381602298854
avg_episode_per_sec: 6.297936464158467
collect_time: 1.42903950384685
reward_mean: 873.4444580078125
reward_std: 479.9965515136719
reward_max: 1576.0
reward_min: 237.0
total_envstep_count: 720750
total_train_sample_count: 720718
total_episode_count: 5282
total_duration: 918.6849703448152
[2024-11-19 22:44:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 863
train_sample_count: 863
avg_envstep_per_episode: 86.3
avg_sample_per_episode: 86.3
avg_envstep_per_sec: 786.441263401945
avg_train_sample_per_sec: 786.441263401945
avg_episode_per_sec: 9.112876748574102
collect_time: 1.0973483210518244
reward_mean: 540.2999877929688
reward_std: 274.5957336425781
reward_max: 1046.0
reward_min: 229.0
total_envstep_count: 721772
total_train_sample_count: 721749
total_episode_count: 5292
total_duration: 919.782318665867
[2024-11-19 22:44:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 799
train_sample_count: 799
avg_envstep_per_episode: 159.8
avg_sample_per_episode: 159.8
avg_envstep_per_sec: 787.2836340065809
avg_train_sample_per_sec: 787.2836340065809
avg_episode_per_sec: 4.926681063870969
collect_time: 1.0148820139112928
reward_mean: 906.0
reward_std: 445.2392578125
reward_max: 1567.0
reward_min: 238.0
total_envstep_count: 722792
total_train_sample_count: 722752
total_episode_count: 5297
total_duration: 920.7972006797784
[2024-11-19 22:44:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1211
train_sample_count: 1211
avg_envstep_per_episode: 151.375
avg_sample_per_episode: 151.375
avg_envstep_per_sec: 793.5996392330699
avg_train_sample_per_sec: 793.5996392330699
avg_episode_per_sec: 5.242607030441419
collect_time: 1.5259583549840112
reward_mean: 794.5
reward_std: 324.91961669921875
reward_max: 1296.0
reward_min: 229.0
total_envstep_count: 723755
total_train_sample_count: 723723
total_episode_count: 5305
total_duration: 922.3231590347624
[2024-11-19 22:44:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 621
train_sample_count: 621
avg_envstep_per_episode: 124.2
avg_sample_per_episode: 124.2
avg_envstep_per_sec: 802.0017312130071
avg_train_sample_per_sec: 802.0017312130071
avg_episode_per_sec: 6.457340831022602
collect_time: 0.7743125430175236
reward_mean: 668.0
reward_std: 347.5082702636719
reward_max: 1303.0
reward_min: 236.0
total_envstep_count: 724750
total_train_sample_count: 724704
total_episode_count: 5310
total_duration: 923.09747157778
[2024-11-19 22:44:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1473
train_sample_count: 1473
avg_envstep_per_episode: 147.3
avg_sample_per_episode: 147.3
avg_envstep_per_sec: 798.1044867444745
avg_train_sample_per_sec: 798.1044867444745
avg_episode_per_sec: 5.418224621483193
collect_time: 1.8456230035849979
reward_mean: 770.5999755859375
reward_std: 337.9820251464844
reward_max: 1318.0
reward_min: 221.0
total_envstep_count: 725773
total_train_sample_count: 725733
total_episode_count: 5320
total_duration: 924.943094581365
[2024-11-19 22:44:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 867
train_sample_count: 867
avg_envstep_per_episode: 144.5
avg_sample_per_episode: 144.5
avg_envstep_per_sec: 799.8395928788999
avg_train_sample_per_sec: 799.8395928788999
avg_episode_per_sec: 5.53522209604775
collect_time: 1.0839673451014928
reward_mean: 704.6666870117188
reward_std: 323.922119140625
reward_max: 1315.0
reward_min: 228.0
total_envstep_count: 726761
total_train_sample_count: 726732
total_episode_count: 5326
total_duration: 926.0270619264666
[2024-11-19 22:44:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1085
train_sample_count: 1085
avg_envstep_per_episode: 135.625
avg_sample_per_episode: 135.625
avg_envstep_per_sec: 799.1623021570795
avg_train_sample_per_sec: 799.1623021570795
avg_episode_per_sec: 5.89244093756372
collect_time: 1.3576716482639313
reward_mean: 932.125
reward_std: 412.91595458984375
reward_max: 1424.0
reward_min: 234.0
total_envstep_count: 727777
total_train_sample_count: 727733
total_episode_count: 5334
total_duration: 927.3847335747305
[2024-11-19 22:44:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1070
train_sample_count: 1070
avg_envstep_per_episode: 97.27272727272727
avg_sample_per_episode: 97.27272727272727
avg_envstep_per_sec: 794.2466808416835
avg_train_sample_per_sec: 794.2466808416835
avg_episode_per_sec: 8.16515279369955
collect_time: 1.3471885068076
reward_mean: 625.0908813476562
reward_std: 212.82064819335938
reward_max: 1034.0
reward_min: 248.0
total_envstep_count: 728826
total_train_sample_count: 728779
total_episode_count: 5345
total_duration: 928.7319220815381
[2024-11-19 22:44:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1050
train_sample_count: 1050
avg_envstep_per_episode: 80.76923076923077
avg_sample_per_episode: 80.76923076923077
avg_envstep_per_sec: 788.913432108453
avg_train_sample_per_sec: 788.913432108453
avg_episode_per_sec: 9.767499635628464
collect_time: 1.330944508314133
reward_mean: 534.076904296875
reward_std: 334.24530029296875
reward_max: 1427.0
reward_min: 238.0
total_envstep_count: 729799
total_train_sample_count: 729781
total_episode_count: 5358
total_duration: 930.0628665898522
[2024-11-19 22:44:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 827
train_sample_count: 827
avg_envstep_per_episode: 118.14285714285714
avg_sample_per_episode: 118.14285714285714
avg_envstep_per_sec: 793.3817015095431
avg_train_sample_per_sec: 793.3817015095431
avg_episode_per_sec: 6.715443664530594
collect_time: 1.0423734230654582
reward_mean: 656.1428833007812
reward_std: 58.31791305541992
reward_max: 765.0
reward_min: 596.0
total_envstep_count: 730801
total_train_sample_count: 730752
total_episode_count: 5365
total_duration: 931.1052400129176
[2024-11-19 22:44:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 829
train_sample_count: 829
avg_envstep_per_episode: 138.16666666666666
avg_sample_per_episode: 138.16666666666666
avg_envstep_per_sec: 795.6204465682815
avg_train_sample_per_sec: 795.6204465682815
avg_episode_per_sec: 5.758410952243292
collect_time: 1.041954117161887
reward_mean: 959.5
reward_std: 363.3853759765625
reward_max: 1583.0
reward_min: 618.0
total_envstep_count: 731755
total_train_sample_count: 731725
total_episode_count: 5371
total_duration: 932.1471941300796
[2024-11-19 22:44:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1006
train_sample_count: 1006
avg_envstep_per_episode: 143.71428571428572
avg_sample_per_episode: 143.71428571428572
avg_envstep_per_sec: 796.7623313788893
avg_train_sample_per_sec: 796.7623313788893
avg_episode_per_sec: 5.544071888322291
collect_time: 1.2626098905290877
reward_mean: 828.4285888671875
reward_std: 418.1704406738281
reward_max: 1334.0
reward_min: 238.0
total_envstep_count: 732797
total_train_sample_count: 732779
total_episode_count: 5378
total_duration: 933.4098040206087
[2024-11-19 22:44:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 1427
train_sample_count: 1427
avg_envstep_per_episode: 101.92857142857143
avg_sample_per_episode: 101.92857142857143
avg_envstep_per_sec: 790.605363840653
avg_train_sample_per_sec: 790.605363840653
avg_episode_per_sec: 7.75646467678286
collect_time: 1.8049460138593403
reward_mean: 682.9285888671875
reward_std: 489.4501953125
reward_max: 1861.0
reward_min: 224.0
total_envstep_count: 733896
total_train_sample_count: 733870
total_episode_count: 5392
total_duration: 935.214750034468
[2024-11-19 22:44:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1041
train_sample_count: 1041
avg_envstep_per_episode: 104.1
avg_sample_per_episode: 104.1
avg_envstep_per_sec: 790.2312567726518
avg_train_sample_per_sec: 790.2312567726518
avg_episode_per_sec: 7.591078355164763
collect_time: 1.3173358951296126
reward_mean: 747.5
reward_std: 427.27117919921875
reward_max: 1686.0
reward_min: 236.0
total_envstep_count: 734897
total_train_sample_count: 734863
total_episode_count: 5402
total_duration: 936.5320859295977
[2024-11-19 22:44:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 390
train_sample_count: 390
avg_envstep_per_episode: 130.0
avg_sample_per_episode: 130.0
avg_envstep_per_sec: 779.0561613891923
avg_train_sample_per_sec: 779.0561613891923
avg_episode_per_sec: 5.992739702993787
collect_time: 0.5006057577473777
reward_mean: 910.3333129882812
reward_std: 491.92840576171875
reward_max: 1428.0
reward_min: 249.0
total_envstep_count: 735863
total_train_sample_count: 735841
total_episode_count: 5405
total_duration: 937.032691687345
[2024-11-19 22:44:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1330
train_sample_count: 1330
avg_envstep_per_episode: 147.77777777777777
avg_sample_per_episode: 147.77777777777777
avg_envstep_per_sec: 789.9324697901337
avg_train_sample_per_sec: 789.9324697901337
avg_episode_per_sec: 5.345407690309176
collect_time: 1.6836882276194436
reward_mean: 751.7777709960938
reward_std: 354.9678649902344
reward_max: 1325.0
reward_min: 221.0
total_envstep_count: 736910
total_train_sample_count: 736871
total_episode_count: 5414
total_duration: 938.7163799149645
[2024-11-19 22:44:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 813
train_sample_count: 813
avg_envstep_per_episode: 162.6
avg_sample_per_episode: 162.6
avg_envstep_per_sec: 789.632042909794
avg_train_sample_per_sec: 789.632042909794
avg_episode_per_sec: 4.8562856267515
collect_time: 1.0295934762273515
reward_mean: 895.4000244140625
reward_std: 617.3380126953125
reward_max: 1671.0
reward_min: 249.0
total_envstep_count: 737891
total_train_sample_count: 737852
total_episode_count: 5419
total_duration: 939.7459733911918
[2024-11-19 22:45:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 953
train_sample_count: 953
avg_envstep_per_episode: 95.3
avg_sample_per_episode: 95.3
avg_envstep_per_sec: 792.445376066109
avg_train_sample_per_sec: 792.445376066109
avg_episode_per_sec: 8.315271522204712
collect_time: 1.2026065502847945
reward_mean: 516.0
reward_std: 337.35943603515625
reward_max: 1034.0
reward_min: 246.0
total_envstep_count: 738885
total_train_sample_count: 738853
total_episode_count: 5429
total_duration: 940.9485799414766
[2024-11-19 22:45:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1293
train_sample_count: 1293
avg_envstep_per_episode: 143.66666666666666
avg_sample_per_episode: 143.66666666666666
avg_envstep_per_sec: 788.0140661398766
avg_train_sample_per_sec: 788.0140661398766
avg_episode_per_sec: 5.485016701669675
collect_time: 1.6408336545739854
reward_mean: 840.2222290039062
reward_std: 400.325927734375
reward_max: 1563.0
reward_min: 248.0
total_envstep_count: 739885
total_train_sample_count: 739846
total_episode_count: 5438
total_duration: 942.5894135960506
[2024-11-19 22:45:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 917
train_sample_count: 917
avg_envstep_per_episode: 101.88888888888889
avg_sample_per_episode: 101.88888888888889
avg_envstep_per_sec: 783.1718092370663
avg_train_sample_per_sec: 783.1718092370663
avg_episode_per_sec: 7.686528116830531
collect_time: 1.170879734413964
reward_mean: 641.4444580078125
reward_std: 265.2831115722656
reward_max: 1043.0
reward_min: 246.0
total_envstep_count: 740868
total_train_sample_count: 740823
total_episode_count: 5447
total_duration: 943.7602933304645
[2024-11-19 22:45:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 572
train_sample_count: 572
avg_envstep_per_episode: 114.4
avg_sample_per_episode: 114.4
avg_envstep_per_sec: 804.0025072546335
avg_train_sample_per_sec: 804.0025072546335
avg_episode_per_sec: 7.0279939445335105
collect_time: 0.711440567459379
reward_mean: 332.6000061035156
reward_std: 233.09791564941406
reward_max: 633.0
reward_min: 92.0
total_envstep_count: 741871
total_train_sample_count: 741827
total_episode_count: 5452
total_duration: 944.4717338979239
[2024-11-19 22:45:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 675
train_sample_count: 675
avg_envstep_per_episode: 112.5
avg_sample_per_episode: 112.5
avg_envstep_per_sec: 792.4804418724998
avg_train_sample_per_sec: 792.4804418724998
avg_episode_per_sec: 7.044270594422221
collect_time: 0.8517560362815857
reward_mean: 513.5
reward_std: 190.27064514160156
reward_max: 707.0
reward_min: 247.0
total_envstep_count: 742874
total_train_sample_count: 742838
total_episode_count: 5458
total_duration: 945.3234899342054
[2024-11-19 22:45:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1381
train_sample_count: 1381
avg_envstep_per_episode: 153.44444444444446
avg_sample_per_episode: 153.44444444444446
avg_envstep_per_sec: 796.5155448834003
avg_train_sample_per_sec: 796.5155448834003
avg_episode_per_sec: 5.190905071651414
collect_time: 1.733801692724228
reward_mean: 769.3333129882812
reward_std: 437.25103759765625
reward_max: 1804.0
reward_min: 250.0
total_envstep_count: 743890
total_train_sample_count: 743847
total_episode_count: 5467
total_duration: 947.0572916269297
[2024-11-19 22:45:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 698
train_sample_count: 698
avg_envstep_per_episode: 99.71428571428571
avg_sample_per_episode: 99.71428571428571
avg_envstep_per_sec: 796.5218528967
avg_train_sample_per_sec: 796.5218528967
avg_episode_per_sec: 7.988041504694699
collect_time: 0.876309918505805
reward_mean: 582.1428833007812
reward_std: 373.480712890625
reward_max: 1336.0
reward_min: 222.0
total_envstep_count: 744884
total_train_sample_count: 744857
total_episode_count: 5474
total_duration: 947.9336015454355
[2024-11-19 22:45:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 934
train_sample_count: 934
avg_envstep_per_episode: 133.42857142857142
avg_sample_per_episode: 133.42857142857142
avg_envstep_per_sec: 792.6753002329083
avg_train_sample_per_sec: 792.6753002329083
avg_episode_per_sec: 5.940821307955415
collect_time: 1.1782882596765245
reward_mean: 919.8571166992188
reward_std: 454.1854248046875
reward_max: 1583.0
reward_min: 249.0
total_envstep_count: 745958
total_train_sample_count: 745923
total_episode_count: 5481
total_duration: 949.111889805112
[2024-11-19 22:45:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 873
train_sample_count: 873
avg_envstep_per_episode: 174.6
avg_sample_per_episode: 174.6
avg_envstep_per_sec: 786.7556417290474
avg_train_sample_per_sec: 786.7556417290474
avg_episode_per_sec: 4.506046058012872
collect_time: 1.109620260340827
reward_mean: 1149.800048828125
reward_std: 370.1736755371094
reward_max: 1573.0
reward_min: 613.0
total_envstep_count: 746939
total_train_sample_count: 746892
total_episode_count: 5486
total_duration: 950.2215100654529
[2024-11-19 22:45:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 673
train_sample_count: 673
avg_envstep_per_episode: 84.125
avg_sample_per_episode: 84.125
avg_envstep_per_sec: 806.5467550733127
avg_train_sample_per_sec: 806.5467550733127
avg_episode_per_sec: 9.587480000871475
collect_time: 0.834421558039529
reward_mean: 536.5
reward_std: 331.1551818847656
reward_max: 1041.0
reward_min: 224.0
total_envstep_count: 747893
total_train_sample_count: 747865
total_episode_count: 5494
total_duration: 951.0559316234924
[2024-11-19 22:45:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1003
train_sample_count: 1003
avg_envstep_per_episode: 167.16666666666666
avg_sample_per_episode: 167.16666666666666
avg_envstep_per_sec: 795.4203254412436
avg_train_sample_per_sec: 795.4203254412436
avg_episode_per_sec: 4.758247211014418
collect_time: 1.2609685318810602
reward_mean: 1048.3333740234375
reward_std: 315.08551025390625
reward_max: 1336.0
reward_min: 623.0
total_envstep_count: 748888
total_train_sample_count: 748844
total_episode_count: 5500
total_duration: 952.3169001553734
[2024-11-19 22:45:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 666
train_sample_count: 666
avg_envstep_per_episode: 166.5
avg_sample_per_episode: 166.5
avg_envstep_per_sec: 786.783234604581
avg_train_sample_per_sec: 786.783234604581
avg_episode_per_sec: 4.725424832459946
collect_time: 0.8464847377368382
reward_mean: 1057.25
reward_std: 471.7686767578125
reward_max: 1691.0
reward_min: 588.0
total_envstep_count: 749860
total_train_sample_count: 749822
total_episode_count: 5504
total_duration: 953.1633848931103
[2024-11-19 22:45:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1206
train_sample_count: 1206
avg_envstep_per_episode: 150.75
avg_sample_per_episode: 150.75
avg_envstep_per_sec: 793.1098269986031
avg_train_sample_per_sec: 793.1098269986031
avg_episode_per_sec: 5.261093379758561
collect_time: 1.5205964658941542
reward_mean: 983.25
reward_std: 401.3681945800781
reward_max: 1676.0
reward_min: 619.0
total_envstep_count: 750853
total_train_sample_count: 750800
total_episode_count: 5512
total_duration: 954.6839813590045
[2024-11-19 22:45:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 444
train_sample_count: 444
avg_envstep_per_episode: 111.0
avg_sample_per_episode: 111.0
avg_envstep_per_sec: 799.5492552628274
avg_train_sample_per_sec: 799.5492552628274
avg_episode_per_sec: 7.203146443809255
collect_time: 0.5553128804479326
reward_mean: 888.0
reward_std: 472.48968505859375
reward_max: 1348.0
reward_min: 249.0
total_envstep_count: 751809
total_train_sample_count: 751784
total_episode_count: 5516
total_duration: 955.2392942394524
[2024-11-19 22:45:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1344
train_sample_count: 1344
avg_envstep_per_episode: 134.4
avg_sample_per_episode: 134.4
avg_envstep_per_sec: 788.9009237405237
avg_train_sample_per_sec: 788.9009237405237
avg_episode_per_sec: 5.869798539736039
collect_time: 1.70363598210471
reward_mean: 921.0
reward_std: 439.0257263183594
reward_max: 1586.0
reward_min: 246.0
total_envstep_count: 752823
total_train_sample_count: 752780
total_episode_count: 5526
total_duration: 956.9429302215572
[2024-11-19 22:45:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 657
train_sample_count: 657
avg_envstep_per_episode: 131.4
avg_sample_per_episode: 131.4
avg_envstep_per_sec: 794.0603190930402
avg_train_sample_per_sec: 794.0603190930402
avg_episode_per_sec: 6.043077009840489
collect_time: 0.8273930634771074
reward_mean: 693.2000122070312
reward_std: 382.3503112792969
reward_max: 1390.0
reward_min: 214.0
total_envstep_count: 753796
total_train_sample_count: 753761
total_episode_count: 5531
total_duration: 957.7703232850342
[2024-11-19 22:46:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2870
train_sample_count: 2870
avg_envstep_per_episode: 410.0
avg_sample_per_episode: 410.0
avg_envstep_per_sec: 797.0006054656859
avg_train_sample_per_sec: 797.0006054656859
avg_episode_per_sec: 1.9439039157699658
collect_time: 3.6010010285036915
reward_mean: 898.4285888671875
reward_std: 566.769287109375
reward_max: 1838.0
reward_min: 218.0
total_envstep_count: 754814
total_train_sample_count: 754783
total_episode_count: 5538
total_duration: 961.3713243135379
[2024-11-19 22:46:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1061
train_sample_count: 1061
avg_envstep_per_episode: 132.625
avg_sample_per_episode: 132.625
avg_envstep_per_sec: 791.4174045098775
avg_train_sample_per_sec: 791.4174045098775
avg_episode_per_sec: 5.967331984994364
collect_time: 1.340632634503501
reward_mean: 687.0
reward_std: 284.68621826171875
reward_max: 1335.0
reward_min: 250.0
total_envstep_count: 755823
total_train_sample_count: 755796
total_episode_count: 5546
total_duration: 962.7119569480415
[2024-11-19 22:46:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1107
train_sample_count: 1107
avg_envstep_per_episode: 100.63636363636364
avg_sample_per_episode: 100.63636363636364
avg_envstep_per_sec: 789.8687811239664
avg_train_sample_per_sec: 789.8687811239664
avg_episode_per_sec: 7.848741275847905
collect_time: 1.4014986114842551
reward_mean: 691.5454711914062
reward_std: 473.7541198730469
reward_max: 1689.0
reward_min: 235.0
total_envstep_count: 756815
total_train_sample_count: 756783
total_episode_count: 5557
total_duration: 964.1134555595257
[2024-11-19 22:46:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 975
train_sample_count: 975
avg_envstep_per_episode: 121.875
avg_sample_per_episode: 121.875
avg_envstep_per_sec: 787.2719667397607
avg_train_sample_per_sec: 787.2719667397607
avg_episode_per_sec: 6.459667419403165
collect_time: 1.2384538522788457
reward_mean: 777.125
reward_std: 422.5415344238281
reward_max: 1410.0
reward_min: 227.0
total_envstep_count: 757817
total_train_sample_count: 757770
total_episode_count: 5565
total_duration: 965.3519094118046
[2024-11-19 22:46:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1035
train_sample_count: 1035
avg_envstep_per_episode: 129.375
avg_sample_per_episode: 129.375
avg_envstep_per_sec: 799.1885219522438
avg_train_sample_per_sec: 799.1885219522438
avg_episode_per_sec: 6.177302585138117
collect_time: 1.2950636446475983
reward_mean: 773.625
reward_std: 408.04437255859375
reward_max: 1572.0
reward_min: 245.0
total_envstep_count: 758819
total_train_sample_count: 758781
total_episode_count: 5573
total_duration: 966.6469730564522
[2024-11-19 22:46:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 526
train_sample_count: 526
avg_envstep_per_episode: 131.5
avg_sample_per_episode: 131.5
avg_envstep_per_sec: 792.4714640104922
avg_train_sample_per_sec: 792.4714640104922
avg_episode_per_sec: 6.026398965859257
collect_time: 0.6637462973594666
reward_mean: 893.25
reward_std: 452.1766052246094
reward_max: 1676.0
reward_min: 611.0
total_envstep_count: 759799
total_train_sample_count: 759763
total_episode_count: 5577
total_duration: 967.3107193538117
[2024-11-19 22:46:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 906
train_sample_count: 906
avg_envstep_per_episode: 129.42857142857142
avg_sample_per_episode: 129.42857142857142
avg_envstep_per_sec: 783.956744191276
avg_train_sample_per_sec: 783.956744191276
avg_episode_per_sec: 6.05706093746019
collect_time: 1.155676007270813
reward_mean: 678.1428833007812
reward_std: 443.6554260253906
reward_max: 1420.0
reward_min: 212.0
total_envstep_count: 760848
total_train_sample_count: 760789
total_episode_count: 5584
total_duration: 968.4663953610825
[2024-11-19 22:46:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1699
train_sample_count: 1699
avg_envstep_per_episode: 154.45454545454547
avg_sample_per_episode: 154.45454545454547
avg_envstep_per_sec: 791.0147234186769
avg_train_sample_per_sec: 791.0147234186769
avg_episode_per_sec: 5.121343118072658
collect_time: 2.147874053035464
reward_mean: 774.8181762695312
reward_std: 307.02197265625
reward_max: 1557.0
reward_min: 249.0
total_envstep_count: 761817
total_train_sample_count: 761792
total_episode_count: 5595
total_duration: 970.614269414118
[2024-11-19 22:46:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 646
train_sample_count: 646
avg_envstep_per_episode: 92.28571428571429
avg_sample_per_episode: 92.28571428571429
avg_envstep_per_sec: 790.8563198254519
avg_train_sample_per_sec: 790.8563198254519
avg_episode_per_sec: 8.569650524424402
collect_time: 0.816836110183171
reward_mean: 680.1428833007812
reward_std: 299.1795349121094
reward_max: 1334.0
reward_min: 246.0
total_envstep_count: 762803
total_train_sample_count: 762762
total_episode_count: 5602
total_duration: 971.4311055243012
[2024-11-19 22:46:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 645
train_sample_count: 645
avg_envstep_per_episode: 129.0
avg_sample_per_episode: 129.0
avg_envstep_per_sec: 803.4858836065681
avg_train_sample_per_sec: 803.4858836065681
avg_episode_per_sec: 6.228572741136187
collect_time: 0.8027521244117193
reward_mean: 805.7999877929688
reward_std: 274.2855224609375
reward_max: 1333.0
reward_min: 592.0
total_envstep_count: 763774
total_train_sample_count: 763743
total_episode_count: 5607
total_duration: 972.233857648713
[2024-11-19 22:46:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1322
train_sample_count: 1322
avg_envstep_per_episode: 165.25
avg_sample_per_episode: 165.25
avg_envstep_per_sec: 793.6743278246037
avg_train_sample_per_sec: 793.6743278246037
avg_episode_per_sec: 4.802870365050551
collect_time: 1.6656706077711922
reward_mean: 950.25
reward_std: 457.4600524902344
reward_max: 1690.0
reward_min: 248.0
total_envstep_count: 764782
total_train_sample_count: 764753
total_episode_count: 5615
total_duration: 973.8995282564841
[2024-11-19 22:46:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1187
train_sample_count: 1187
avg_envstep_per_episode: 169.57142857142858
avg_sample_per_episode: 169.57142857142858
avg_envstep_per_sec: 798.2809301296841
avg_train_sample_per_sec: 798.2809301296841
avg_episode_per_sec: 4.707638172626612
collect_time: 1.4869452033724104
reward_mean: 1050.7142333984375
reward_std: 453.54656982421875
reward_max: 1662.0
reward_min: 243.0
total_envstep_count: 765793
total_train_sample_count: 765772
total_episode_count: 5622
total_duration: 975.3864734598566
[2024-11-19 22:46:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 511
train_sample_count: 511
avg_envstep_per_episode: 127.75
avg_sample_per_episode: 127.75
avg_envstep_per_sec: 786.6353799922726
avg_train_sample_per_sec: 786.6353799922726
avg_episode_per_sec: 6.1576154989610385
collect_time: 0.6496021066393171
reward_mean: 697.0
reward_std: 75.7957763671875
reward_max: 794.0
reward_min: 608.0
total_envstep_count: 766789
total_train_sample_count: 766751
total_episode_count: 5626
total_duration: 976.0360755664959
[2024-11-19 22:46:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1164
train_sample_count: 1164
avg_envstep_per_episode: 166.28571428571428
avg_sample_per_episode: 166.28571428571428
avg_envstep_per_sec: 792.208480672961
avg_train_sample_per_sec: 792.208480672961
avg_episode_per_sec: 4.764140347689628
collect_time: 1.4693101985113963
reward_mean: 1016.2857055664062
reward_std: 365.2821350097656
reward_max: 1343.0
reward_min: 582.0
total_envstep_count: 767786
total_train_sample_count: 767759
total_episode_count: 5633
total_duration: 977.5053857650073
[2024-11-19 22:46:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1571
train_sample_count: 1571
avg_envstep_per_episode: 120.84615384615384
avg_sample_per_episode: 120.84615384615384
avg_envstep_per_sec: 794.8577407385079
avg_train_sample_per_sec: 794.8577407385079
avg_episode_per_sec: 6.577435155697391
collect_time: 1.9764543005398336
reward_mean: 778.076904296875
reward_std: 444.05291748046875
reward_max: 1661.0
reward_min: 207.0
total_envstep_count: 768857
total_train_sample_count: 768826
total_episode_count: 5646
total_duration: 979.4818400655471
[2024-11-19 22:46:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 166
train_sample_count: 166
avg_envstep_per_episode: 166.0
avg_sample_per_episode: 166.0
avg_envstep_per_sec: 790.6839088866237
avg_train_sample_per_sec: 790.6839088866237
avg_episode_per_sec: 4.7631560776302635
collect_time: 0.20994483147348678
reward_mean: 634.0
reward_std: 0.0
reward_max: 634.0
reward_min: 634.0
total_envstep_count: 769840
total_train_sample_count: 769796
total_episode_count: 5647
total_duration: 979.6917848970206
[2024-11-19 22:46:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1230
train_sample_count: 1230
avg_envstep_per_episode: 153.75
avg_sample_per_episode: 153.75
avg_envstep_per_sec: 804.3286294810495
avg_train_sample_per_sec: 804.3286294810495
avg_episode_per_sec: 5.2314057202019475
collect_time: 1.529225685766765
reward_mean: 688.5
reward_std: 207.90623474121094
reward_max: 1034.0
reward_min: 247.0
total_envstep_count: 770826
total_train_sample_count: 770786
total_episode_count: 5655
total_duration: 981.2210105827874
[2024-11-19 22:47:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1241
train_sample_count: 1241
avg_envstep_per_episode: 155.125
avg_sample_per_episode: 155.125
avg_envstep_per_sec: 793.0114771614453
avg_train_sample_per_sec: 793.0114771614453
avg_episode_per_sec: 5.112080432950494
collect_time: 1.5649206042289736
reward_mean: 900.0
reward_std: 292.3970031738281
reward_max: 1322.0
reward_min: 602.0
total_envstep_count: 771850
total_train_sample_count: 771823
total_episode_count: 5663
total_duration: 982.7859311870163
[2024-11-19 22:47:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 860
train_sample_count: 860
avg_envstep_per_episode: 122.85714285714286
avg_sample_per_episode: 122.85714285714286
avg_envstep_per_sec: 799.9248847652403
avg_train_sample_per_sec: 799.9248847652403
avg_episode_per_sec: 6.511016503903119
collect_time: 1.0751009455748965
reward_mean: 773.7142944335938
reward_std: 419.5326232910156
reward_max: 1714.0
reward_min: 239.0
total_envstep_count: 772851
total_train_sample_count: 772803
total_episode_count: 5670
total_duration: 983.8610321325913
[2024-11-19 22:47:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1346
train_sample_count: 1346
avg_envstep_per_episode: 122.36363636363636
avg_sample_per_episode: 122.36363636363636
avg_envstep_per_sec: 792.5878204345121
avg_train_sample_per_sec: 792.5878204345121
avg_episode_per_sec: 6.477315025839252
collect_time: 1.6982345240456718
reward_mean: 720.272705078125
reward_std: 351.8160705566406
reward_max: 1337.0
reward_min: 245.0
total_envstep_count: 773842
total_train_sample_count: 773801
total_episode_count: 5681
total_duration: 985.559266656637
[2024-11-19 22:47:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 289
train_sample_count: 289
avg_envstep_per_episode: 144.5
avg_sample_per_episode: 144.5
avg_envstep_per_sec: 788.8048084770136
avg_train_sample_per_sec: 788.8048084770136
avg_episode_per_sec: 5.458856806069298
collect_time: 0.36637707693236216
reward_mean: 698.0
reward_std: 107.0
reward_max: 805.0
reward_min: 591.0
total_envstep_count: 774816
total_train_sample_count: 774774
total_episode_count: 5683
total_duration: 985.9256437335694
[2024-11-19 22:47:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1040
train_sample_count: 1040
avg_envstep_per_episode: 208.0
avg_sample_per_episode: 208.0
avg_envstep_per_sec: 784.9104871058728
avg_train_sample_per_sec: 784.9104871058728
avg_episode_per_sec: 3.773608111085927
collect_time: 1.3249918520450592
reward_mean: 1055.5999755859375
reward_std: 361.4452209472656
reward_max: 1422.0
reward_min: 594.0
total_envstep_count: 775771
total_train_sample_count: 775754
total_episode_count: 5688
total_duration: 987.2506355856144
[2024-11-19 22:47:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 931
train_sample_count: 931
avg_envstep_per_episode: 186.2
avg_sample_per_episode: 186.2
avg_envstep_per_sec: 790.3573761329815
avg_train_sample_per_sec: 790.3573761329815
avg_episode_per_sec: 4.244669044752854
collect_time: 1.1779481385435375
reward_mean: 973.2000122070312
reward_std: 491.109130859375
reward_max: 1557.0
reward_min: 228.0
total_envstep_count: 776782
total_train_sample_count: 776757
total_episode_count: 5693
total_duration: 988.428583724158
[2024-11-19 22:47:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1307
train_sample_count: 1307
avg_envstep_per_episode: 145.22222222222223
avg_sample_per_episode: 145.22222222222223
avg_envstep_per_sec: 793.3902776888343
avg_train_sample_per_sec: 793.3902776888343
avg_episode_per_sec: 5.463284238102149
collect_time: 1.647360746349607
reward_mean: 740.7777709960938
reward_std: 513.968994140625
reward_max: 1809.0
reward_min: 229.0
total_envstep_count: 777776
total_train_sample_count: 777740
total_episode_count: 5702
total_duration: 990.0759444705076
[2024-11-19 22:47:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1366
train_sample_count: 1366
avg_envstep_per_episode: 170.75
avg_sample_per_episode: 170.75
avg_envstep_per_sec: 794.7768012120375
avg_train_sample_per_sec: 794.7768012120375
avg_episode_per_sec: 4.654622554682504
collect_time: 1.7187215302671706
reward_mean: 816.0
reward_std: 567.8554077148438
reward_max: 1845.0
reward_min: 228.0
total_envstep_count: 778761
total_train_sample_count: 778722
total_episode_count: 5710
total_duration: 991.7946660007748
[2024-11-19 22:47:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 782
train_sample_count: 782
avg_envstep_per_episode: 97.75
avg_sample_per_episode: 97.75
avg_envstep_per_sec: 798.9880626476512
avg_train_sample_per_sec: 798.9880626476512
avg_episode_per_sec: 8.17379092222661
collect_time: 0.9787380269595557
reward_mean: 662.0
reward_std: 280.72271728515625
reward_max: 1330.0
reward_min: 246.0
total_envstep_count: 779769
total_train_sample_count: 779720
total_episode_count: 5718
total_duration: 992.7734040277344
[2024-11-19 22:47:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 708
train_sample_count: 708
avg_envstep_per_episode: 118.0
avg_sample_per_episode: 118.0
avg_envstep_per_sec: 784.9570427903395
avg_train_sample_per_sec: 784.9570427903395
avg_episode_per_sec: 6.652178328731691
collect_time: 0.9019601855959211
reward_mean: 753.3333129882812
reward_std: 238.73602294921875
reward_max: 1287.0
reward_min: 637.0
total_envstep_count: 780740
total_train_sample_count: 780692
total_episode_count: 5724
total_duration: 993.6753642133303
[2024-11-19 22:47:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1324
train_sample_count: 1324
avg_envstep_per_episode: 147.11111111111111
avg_sample_per_episode: 147.11111111111111
avg_envstep_per_sec: 784.4164341224334
avg_train_sample_per_sec: 784.4164341224334
avg_episode_per_sec: 5.332135881496904
collect_time: 1.687878966331482
reward_mean: 857.3333129882812
reward_std: 212.855712890625
reward_max: 1114.0
reward_min: 602.0
total_envstep_count: 781710
total_train_sample_count: 781692
total_episode_count: 5733
total_duration: 995.3632431796618
[2024-11-19 22:47:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 884
train_sample_count: 884
avg_envstep_per_episode: 176.8
avg_sample_per_episode: 176.8
avg_envstep_per_sec: 791.2058110401393
avg_train_sample_per_sec: 791.2058110401393
avg_episode_per_sec: 4.4751459900460375
collect_time: 1.1172819861343928
reward_mean: 1111.800048828125
reward_std: 283.8382568359375
reward_max: 1427.0
reward_min: 651.0
total_envstep_count: 782707
total_train_sample_count: 782672
total_episode_count: 5738
total_duration: 996.4805251657962
[2024-11-19 22:47:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1204
train_sample_count: 1204
avg_envstep_per_episode: 133.77777777777777
avg_sample_per_episode: 133.77777777777777
avg_envstep_per_sec: 767.2830300022667
avg_train_sample_per_sec: 767.2830300022667
avg_episode_per_sec: 5.735504377093356
collect_time: 1.569173242364611
reward_mean: 926.3333129882812
reward_std: 574.2916259765625
reward_max: 1860.0
reward_min: 235.0
total_envstep_count: 783755
total_train_sample_count: 783708
total_episode_count: 5747
total_duration: 998.0496984081608
[2024-11-19 22:47:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 942
train_sample_count: 942
avg_envstep_per_episode: 157.0
avg_sample_per_episode: 157.0
avg_envstep_per_sec: 777.5748453225322
avg_train_sample_per_sec: 777.5748453225322
avg_episode_per_sec: 4.9527060211626255
collect_time: 1.2114589427198683
reward_mean: 930.3333129882812
reward_std: 412.8448791503906
reward_max: 1768.0
reward_min: 617.0
total_envstep_count: 784726
total_train_sample_count: 784686
total_episode_count: 5753
total_duration: 999.2611573508807
[2024-11-19 22:47:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 500
train_sample_count: 500
avg_envstep_per_episode: 83.33333333333333
avg_sample_per_episode: 83.33333333333333
avg_envstep_per_sec: 782.803059560155
avg_train_sample_per_sec: 782.803059560155
avg_episode_per_sec: 9.39363671472186
collect_time: 0.6387302577495575
reward_mean: 434.5
reward_std: 202.61683654785156
reward_max: 651.0
reward_min: 222.0
total_envstep_count: 785721
total_train_sample_count: 785690
total_episode_count: 5759
total_duration: 999.8998876086303
[2024-11-19 22:47:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1476
train_sample_count: 1476
avg_envstep_per_episode: 164.0
avg_sample_per_episode: 164.0
avg_envstep_per_sec: 796.4844598690377
avg_train_sample_per_sec: 796.4844598690377
avg_episode_per_sec: 4.856612560177059
collect_time: 1.8531435004302432
reward_mean: 789.111083984375
reward_std: 254.26690673828125
reward_max: 1274.0
reward_min: 606.0
total_envstep_count: 786707
total_train_sample_count: 786674
total_episode_count: 5768
total_duration: 1001.7530311090605
[2024-11-19 22:48:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 455
train_sample_count: 455
avg_envstep_per_episode: 151.66666666666666
avg_sample_per_episode: 151.66666666666666
avg_envstep_per_sec: 788.2793402133991
avg_train_sample_per_sec: 788.2793402133991
avg_episode_per_sec: 5.197446199209225
collect_time: 0.577206552028656
reward_mean: 937.0
reward_std: 448.33245849609375
reward_max: 1571.0
reward_min: 614.0
total_envstep_count: 787681
total_train_sample_count: 787645
total_episode_count: 5771
total_duration: 1002.3302376610892
[2024-11-19 22:48:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1228
train_sample_count: 1228
avg_envstep_per_episode: 153.5
avg_sample_per_episode: 153.5
avg_envstep_per_sec: 797.8879717243145
avg_train_sample_per_sec: 797.8879717243145
avg_episode_per_sec: 5.197967242503678
collect_time: 1.5390631811959403
reward_mean: 876.75
reward_std: 394.1686706542969
reward_max: 1429.0
reward_min: 249.0
total_envstep_count: 788706
total_train_sample_count: 788645
total_episode_count: 5779
total_duration: 1003.8693008422852
[2024-11-19 22:48:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 932
train_sample_count: 932
avg_envstep_per_episode: 103.55555555555556
avg_sample_per_episode: 103.55555555555556
avg_envstep_per_sec: 791.8959217878737
avg_train_sample_per_sec: 791.8959217878737
avg_episode_per_sec: 7.647063622415089
collect_time: 1.1769223383494785
reward_mean: 786.888916015625
reward_std: 430.62860107421875
reward_max: 1437.0
reward_min: 239.0
total_envstep_count: 789716
total_train_sample_count: 789661
total_episode_count: 5788
total_duration: 1005.0462231806347
[2024-11-19 22:48:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 621
train_sample_count: 621
avg_envstep_per_episode: 124.2
avg_sample_per_episode: 124.2
avg_envstep_per_sec: 788.4538328028168
avg_train_sample_per_sec: 788.4538328028168
avg_episode_per_sec: 6.348259523372116
collect_time: 0.7876174535070146
reward_mean: 894.7999877929688
reward_std: 343.9415283203125
reward_max: 1322.0
reward_min: 610.0
total_envstep_count: 790720
total_train_sample_count: 790690
total_episode_count: 5793
total_duration: 1005.8338406341417
[2024-11-19 22:48:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1929
train_sample_count: 1929
avg_envstep_per_episode: 214.33333333333334
avg_sample_per_episode: 214.33333333333334
avg_envstep_per_sec: 791.698354843059
avg_train_sample_per_sec: 791.698354843059
avg_episode_per_sec: 3.693771484493277
collect_time: 2.436534051384245
reward_mean: 881.5555419921875
reward_std: 261.146240234375
reward_max: 1335.0
reward_min: 602.0
total_envstep_count: 791743
total_train_sample_count: 791707
total_episode_count: 5802
total_duration: 1008.2703746855259
[2024-11-19 22:48:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 682
train_sample_count: 682
avg_envstep_per_episode: 170.5
avg_sample_per_episode: 170.5
avg_envstep_per_sec: 790.8784027861078
avg_train_sample_per_sec: 790.8784027861078
avg_episode_per_sec: 4.638583007543154
collect_time: 0.8623323099953788
reward_mean: 1079.75
reward_std: 284.880126953125
reward_max: 1333.0
reward_min: 629.0
total_envstep_count: 792731
total_train_sample_count: 792689
total_episode_count: 5806
total_duration: 1009.1327069955213
[2024-11-19 22:48:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1390
train_sample_count: 1390
avg_envstep_per_episode: 154.44444444444446
avg_sample_per_episode: 154.44444444444446
avg_envstep_per_sec: 794.9817283532186
avg_train_sample_per_sec: 794.9817283532186
avg_episode_per_sec: 5.147363708761847
collect_time: 1.748467858348574
reward_mean: 1041.5555419921875
reward_std: 541.9385375976562
reward_max: 1857.0
reward_min: 619.0
total_envstep_count: 793716
total_train_sample_count: 793671
total_episode_count: 5815
total_duration: 1010.8811748538699
[2024-11-19 22:48:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 764
train_sample_count: 764
avg_envstep_per_episode: 109.14285714285714
avg_sample_per_episode: 109.14285714285714
avg_envstep_per_sec: 775.6770357043224
avg_train_sample_per_sec: 775.6770357043224
avg_episode_per_sec: 7.106988547029132
collect_time: 0.9849460082394736
reward_mean: 658.8571166992188
reward_std: 60.2552375793457
reward_max: 764.0
reward_min: 602.0
total_envstep_count: 794693
total_train_sample_count: 794651
total_episode_count: 5822
total_duration: 1011.8661208621094
[2024-11-19 22:48:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 848
train_sample_count: 848
avg_envstep_per_episode: 106.0
avg_sample_per_episode: 106.0
avg_envstep_per_sec: 783.9367714182694
avg_train_sample_per_sec: 783.9367714182694
avg_episode_per_sec: 7.395629919040277
collect_time: 1.081719892365592
reward_mean: 696.25
reward_std: 321.1416015625
reward_max: 1436.0
reward_min: 209.0
total_envstep_count: 795678
total_train_sample_count: 795643
total_episode_count: 5830
total_duration: 1012.947840754475
[2024-11-19 22:48:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1001
train_sample_count: 1001
avg_envstep_per_episode: 111.22222222222223
avg_sample_per_episode: 111.22222222222223
avg_envstep_per_sec: 791.7107738849667
avg_train_sample_per_sec: 791.7107738849667
avg_episode_per_sec: 7.118278686278422
collect_time: 1.2643506101199558
reward_mean: 605.7777709960938
reward_std: 390.2334899902344
reward_max: 1407.0
reward_min: 239.0
total_envstep_count: 796718
total_train_sample_count: 796680
total_episode_count: 5839
total_duration: 1014.212191364595
[2024-11-19 22:48:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1134
train_sample_count: 1134
avg_envstep_per_episode: 141.75
avg_sample_per_episode: 141.75
avg_envstep_per_sec: 785.7742022562267
avg_train_sample_per_sec: 785.7742022562267
avg_episode_per_sec: 5.543380615564209
collect_time: 1.4431626754147666
reward_mean: 909.75
reward_std: 429.1336364746094
reward_max: 1433.0
reward_min: 232.0
total_envstep_count: 797703
total_train_sample_count: 797658
total_episode_count: 5847
total_duration: 1015.6553540400098
[2024-11-19 22:48:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 844
train_sample_count: 844
avg_envstep_per_episode: 168.8
avg_sample_per_episode: 168.8
avg_envstep_per_sec: 794.6252796862179
avg_train_sample_per_sec: 794.6252796862179
avg_episode_per_sec: 4.707495732738258
collect_time: 1.062135853937694
reward_mean: 1064.5999755859375
reward_std: 367.7165222167969
reward_max: 1428.0
reward_min: 603.0
total_envstep_count: 798675
total_train_sample_count: 798646
total_episode_count: 5852
total_duration: 1016.7174898939475
[2024-11-19 22:49:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1169
train_sample_count: 1169
avg_envstep_per_episode: 194.83333333333334
avg_sample_per_episode: 194.83333333333334
avg_envstep_per_sec: 792.3150480077543
avg_train_sample_per_sec: 792.3150480077543
avg_episode_per_sec: 4.066629844351177
collect_time: 1.4754231955323902
reward_mean: 1103.5
reward_std: 334.927734375
reward_max: 1573.0
reward_min: 649.0
total_envstep_count: 799671
total_train_sample_count: 799635
total_episode_count: 5858
total_duration: 1018.1929130894798
[2024-11-19 22:49:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1049
train_sample_count: 1049
avg_envstep_per_episode: 116.55555555555556
avg_sample_per_episode: 116.55555555555556
avg_envstep_per_sec: 781.75321403387
avg_train_sample_per_sec: 781.75321403387
avg_episode_per_sec: 6.707129577030344
collect_time: 1.3418556920119695
reward_mean: 728.6666870117188
reward_std: 182.05067443847656
reward_max: 1066.0
reward_min: 601.0
total_envstep_count: 800686
total_train_sample_count: 800636
total_episode_count: 5867
total_duration: 1019.5347687814918
[2024-11-19 22:49:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 658
train_sample_count: 658
avg_envstep_per_episode: 109.66666666666667
avg_sample_per_episode: 109.66666666666667
avg_envstep_per_sec: 792.6434527676747
avg_train_sample_per_sec: 792.6434527676747
avg_episode_per_sec: 7.2277518489453625
collect_time: 0.8301336467266084
reward_mean: 611.8333129882812
reward_std: 251.34201049804688
reward_max: 1025.0
reward_min: 157.0
total_envstep_count: 801681
total_train_sample_count: 801642
total_episode_count: 5873
total_duration: 1020.3649024282184
[2024-11-19 22:49:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1314
train_sample_count: 1314
avg_envstep_per_episode: 187.71428571428572
avg_sample_per_episode: 187.71428571428572
avg_envstep_per_sec: 794.140044098526
avg_train_sample_per_sec: 794.140044098526
avg_episode_per_sec: 4.230578621529439
collect_time: 1.6546200002942766
reward_mean: 802.5714111328125
reward_std: 411.59234619140625
reward_max: 1413.0
reward_min: 216.0
total_envstep_count: 802661
total_train_sample_count: 802632
total_episode_count: 5880
total_duration: 1022.0195224285127
[2024-11-19 22:49:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1048
train_sample_count: 1048
avg_envstep_per_episode: 149.71428571428572
avg_sample_per_episode: 149.71428571428572
avg_envstep_per_sec: 801.9709350243002
avg_train_sample_per_sec: 801.9709350243002
avg_episode_per_sec: 5.356676092719562
collect_time: 1.306780525616237
reward_mean: 867.0
reward_std: 325.42718505859375
reward_max: 1416.0
reward_min: 612.0
total_envstep_count: 803656
total_train_sample_count: 803620
total_episode_count: 5887
total_duration: 1023.3263029541289
[2024-11-19 22:49:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 636
train_sample_count: 636
avg_envstep_per_episode: 90.85714285714286
avg_sample_per_episode: 90.85714285714286
avg_envstep_per_sec: 796.4287590925958
avg_train_sample_per_sec: 796.4287590925958
avg_episode_per_sec: 8.765725335924797
collect_time: 0.7985648342541285
reward_mean: 665.7142944335938
reward_std: 413.1034851074219
reward_max: 1580.0
reward_min: 250.0
total_envstep_count: 804634
total_train_sample_count: 804604
total_episode_count: 5894
total_duration: 1024.124867788383
[2024-11-19 22:49:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1151
train_sample_count: 1151
avg_envstep_per_episode: 164.42857142857142
avg_sample_per_episode: 164.42857142857142
avg_envstep_per_sec: 795.8693141702444
avg_train_sample_per_sec: 795.8693141702444
avg_episode_per_sec: 4.84021303144371
collect_time: 1.4462173368249622
reward_mean: 1020.7142944335938
reward_std: 633.8541259765625
reward_max: 1904.0
reward_min: 198.0
total_envstep_count: 805629
total_train_sample_count: 805599
total_episode_count: 5901
total_duration: 1025.571085125208
[2024-11-19 22:49:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1164
train_sample_count: 1164
avg_envstep_per_episode: 129.33333333333334
avg_sample_per_episode: 129.33333333333334
avg_envstep_per_sec: 797.7274380520146
avg_train_sample_per_sec: 797.7274380520146
avg_episode_per_sec: 6.1679956550413495
collect_time: 1.4591449967452457
reward_mean: 803.3333129882812
reward_std: 567.912353515625
reward_max: 1841.0
reward_min: 236.0
total_envstep_count: 806669
total_train_sample_count: 806619
total_episode_count: 5910
total_duration: 1027.030230121953
[2024-11-19 22:49:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 825
train_sample_count: 825
avg_envstep_per_episode: 165.0
avg_sample_per_episode: 165.0
avg_envstep_per_sec: 790.9045620887721
avg_train_sample_per_sec: 790.9045620887721
avg_episode_per_sec: 4.7933609823561945
collect_time: 1.0431094212191445
reward_mean: 1193.0
reward_std: 455.6160583496094
reward_max: 1568.0
reward_min: 631.0
total_envstep_count: 807649
total_train_sample_count: 807600
total_episode_count: 5915
total_duration: 1028.0733395431723
[2024-11-19 22:49:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1276
train_sample_count: 1276
avg_envstep_per_episode: 141.77777777777777
avg_sample_per_episode: 141.77777777777777
avg_envstep_per_sec: 797.4749101050542
avg_train_sample_per_sec: 797.4749101050542
avg_episode_per_sec: 5.624823033656337
collect_time: 1.6000503386769975
reward_mean: 1009.111083984375
reward_std: 423.0987548828125
reward_max: 1765.0
reward_min: 619.0
total_envstep_count: 808657
total_train_sample_count: 808612
total_episode_count: 5924
total_duration: 1029.6733898818493
[2024-11-19 22:49:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 788
train_sample_count: 788
avg_envstep_per_episode: 131.33333333333334
avg_sample_per_episode: 131.33333333333334
avg_envstep_per_sec: 796.8632327986033
avg_train_sample_per_sec: 796.8632327986033
avg_episode_per_sec: 6.067486544151802
collect_time: 0.9888773475374495
reward_mean: 780.0
reward_std: 349.515869140625
reward_max: 1561.0
reward_min: 601.0
total_envstep_count: 809637
total_train_sample_count: 809604
total_episode_count: 5930
total_duration: 1030.6622672293868
[2024-11-19 22:49:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 717
train_sample_count: 717
avg_envstep_per_episode: 179.25
avg_sample_per_episode: 179.25
avg_envstep_per_sec: 595.0848194685846
avg_train_sample_per_sec: 595.0848194685846
avg_episode_per_sec: 3.319859522837292
collect_time: 1.2048702580588204
reward_mean: 1155.5
reward_std: 365.1441345214844
reward_max: 1759.0
reward_min: 776.0
total_envstep_count: 810610
total_train_sample_count: 810573
total_episode_count: 5934
total_duration: 1031.8671374874457
[2024-11-19 22:49:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1218
train_sample_count: 1218
avg_envstep_per_episode: 152.25
avg_sample_per_episode: 152.25
avg_envstep_per_sec: 795.0252513904455
avg_train_sample_per_sec: 795.0252513904455
avg_episode_per_sec: 5.221840731628542
collect_time: 1.532026810305459
reward_mean: 886.375
reward_std: 387.3118591308594
reward_max: 1325.0
reward_min: 248.0
total_envstep_count: 811618
total_train_sample_count: 811575
total_episode_count: 5942
total_duration: 1033.3991642977512
[2024-11-19 22:49:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 417
train_sample_count: 417
avg_envstep_per_episode: 139.0
avg_sample_per_episode: 139.0
avg_envstep_per_sec: 788.4083383481524
avg_train_sample_per_sec: 788.4083383481524
avg_episode_per_sec: 5.67200243415937
collect_time: 0.5289137363433838
reward_mean: 1038.0
reward_std: 475.313232421875
reward_max: 1700.0
reward_min: 606.0
total_envstep_count: 812591
total_train_sample_count: 812556
total_episode_count: 5945
total_duration: 1033.9280780340946
[2024-11-19 22:49:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1516
train_sample_count: 1516
avg_envstep_per_episode: 216.57142857142858
avg_sample_per_episode: 216.57142857142858
avg_envstep_per_sec: 791.1962176000088
avg_train_sample_per_sec: 791.1962176000088
avg_episode_per_sec: 3.65328068812669
collect_time: 1.9160860053130555
reward_mean: 1398.7142333984375
reward_std: 556.3236083984375
reward_max: 1814.0
reward_min: 195.0
total_envstep_count: 813561
total_train_sample_count: 813532
total_episode_count: 5952
total_duration: 1035.8441640394076
[2024-11-19 22:49:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 863
train_sample_count: 863
avg_envstep_per_episode: 143.83333333333334
avg_sample_per_episode: 143.83333333333334
avg_envstep_per_sec: 800.7604241635045
avg_train_sample_per_sec: 800.7604241635045
avg_episode_per_sec: 5.567279889896903
collect_time: 1.0777255892753599
reward_mean: 835.3333129882812
reward_std: 299.4181213378906
reward_max: 1419.0
reward_min: 587.0
total_envstep_count: 814564
total_train_sample_count: 814515
total_episode_count: 5958
total_duration: 1036.921889628683
[2024-11-19 22:50:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 681
train_sample_count: 681
avg_envstep_per_episode: 170.25
avg_sample_per_episode: 170.25
avg_envstep_per_sec: 796.0942717018962
avg_train_sample_per_sec: 796.0942717018962
avg_episode_per_sec: 4.676030964475161
collect_time: 0.8554263285228183
reward_mean: 590.75
reward_std: 259.2714538574219
reward_max: 800.0
reward_min: 165.0
total_envstep_count: 815529
total_train_sample_count: 815496
total_episode_count: 5962
total_duration: 1037.7773159572057
[2024-11-19 22:50:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1139
train_sample_count: 1139
avg_envstep_per_episode: 189.83333333333334
avg_sample_per_episode: 189.83333333333334
avg_envstep_per_sec: 794.2057806001561
avg_train_sample_per_sec: 794.2057806001561
avg_episode_per_sec: 4.183700336787478
collect_time: 1.4341371314866203
reward_mean: 1079.8333740234375
reward_std: 458.4805908203125
reward_max: 1744.0
reward_min: 626.0
total_envstep_count: 816500
total_train_sample_count: 816467
total_episode_count: 5968
total_duration: 1039.2114530886922
[2024-11-19 22:50:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1438
train_sample_count: 1438
avg_envstep_per_episode: 143.8
avg_sample_per_episode: 143.8
avg_envstep_per_sec: 793.046755738493
avg_train_sample_per_sec: 793.046755738493
avg_episode_per_sec: 5.514928760351133
collect_time: 1.8132600500470117
reward_mean: 839.5
reward_std: 364.0443115234375
reward_max: 1429.0
reward_min: 210.0
total_envstep_count: 817506
total_train_sample_count: 817461
total_episode_count: 5978
total_duration: 1041.0247131387393
[2024-11-19 22:50:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 260
train_sample_count: 260
avg_envstep_per_episode: 260.0
avg_sample_per_episode: 260.0
avg_envstep_per_sec: 783.6725884349819
avg_train_sample_per_sec: 783.6725884349819
avg_episode_per_sec: 3.014125340134546
collect_time: 0.33177120628811063
reward_mean: 1567.0
reward_std: 0.0
reward_max: 1567.0
reward_min: 1567.0
total_envstep_count: 818481
total_train_sample_count: 818441
total_episode_count: 5979
total_duration: 1041.3564843450274
[2024-11-19 22:50:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1151
train_sample_count: 1151
avg_envstep_per_episode: 143.875
avg_sample_per_episode: 143.875
avg_envstep_per_sec: 789.7462577268178
avg_train_sample_per_sec: 789.7462577268178
avg_episode_per_sec: 5.4891138677797935
collect_time: 1.4574301413127353
reward_mean: 788.25
reward_std: 421.2267150878906
reward_max: 1430.0
reward_min: 248.0
total_envstep_count: 819481
total_train_sample_count: 819436
total_episode_count: 5987
total_duration: 1042.81391448634
[2024-11-19 22:50:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1082
train_sample_count: 1082
avg_envstep_per_episode: 270.5
avg_sample_per_episode: 270.5
avg_envstep_per_sec: 793.2762694838498
avg_train_sample_per_sec: 793.2762694838498
avg_episode_per_sec: 2.9326294620475037
collect_time: 1.3639636550630843
reward_mean: 1302.0
reward_std: 423.3326110839844
reward_max: 1727.0
reward_min: 626.0
total_envstep_count: 820453
total_train_sample_count: 820410
total_episode_count: 5991
total_duration: 1044.1778781414032
[2024-11-19 22:50:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 785
train_sample_count: 785
avg_envstep_per_episode: 98.125
avg_sample_per_episode: 98.125
avg_envstep_per_sec: 795.2510247458721
avg_train_sample_per_sec: 795.2510247458721
avg_episode_per_sec: 8.104469041996149
collect_time: 0.9871096994195665
reward_mean: 779.25
reward_std: 534.7599487304688
reward_max: 1846.0
reward_min: 207.0
total_envstep_count: 821429
total_train_sample_count: 821387
total_episode_count: 5999
total_duration: 1045.1649878408227
[2024-11-19 22:50:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1615
train_sample_count: 1615
avg_envstep_per_episode: 201.875
avg_sample_per_episode: 201.875
avg_envstep_per_sec: 784.8614261362987
avg_train_sample_per_sec: 784.8614261362987
avg_episode_per_sec: 3.8878584576411086
collect_time: 2.057688078710011
reward_mean: 989.0
reward_std: 527.3430786132812
reward_max: 1767.0
reward_min: 248.0
total_envstep_count: 822461
total_train_sample_count: 822414
total_episode_count: 6007
total_duration: 1047.2226759195328
[2024-11-19 22:50:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 315
train_sample_count: 315
avg_envstep_per_episode: 157.5
avg_sample_per_episode: 157.5
avg_envstep_per_sec: 786.4660400692513
avg_train_sample_per_sec: 786.4660400692513
avg_episode_per_sec: 4.993435175042865
collect_time: 0.4005258764539446
reward_mean: 829.5
reward_std: 203.5
reward_max: 1033.0
reward_min: 626.0
total_envstep_count: 823427
total_train_sample_count: 823377
total_episode_count: 6009
total_duration: 1047.6232017959867
[2024-11-19 22:50:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1109
train_sample_count: 1109
avg_envstep_per_episode: 123.22222222222223
avg_sample_per_episode: 123.22222222222223
avg_envstep_per_sec: 785.0367068798066
avg_train_sample_per_sec: 785.0367068798066
avg_episode_per_sec: 6.370902039601677
collect_time: 1.4126727964196888
reward_mean: 790.2222290039062
reward_std: 263.1694641113281
reward_max: 1436.0
reward_min: 589.0
total_envstep_count: 824412
total_train_sample_count: 824378
total_episode_count: 6018
total_duration: 1049.0358745924063
[2024-11-19 22:50:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 633
train_sample_count: 633
avg_envstep_per_episode: 105.5
avg_sample_per_episode: 105.5
avg_envstep_per_sec: 801.212224523847
avg_train_sample_per_sec: 801.212224523847
avg_episode_per_sec: 7.594428668472483
collect_time: 0.7900528482028417
reward_mean: 786.3333129882812
reward_std: 290.9912109375
reward_max: 1429.0
reward_min: 623.0
total_envstep_count: 825407
total_train_sample_count: 825371
total_episode_count: 6024
total_duration: 1049.8259274406091
[2024-11-19 22:51:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1260
train_sample_count: 1260
avg_envstep_per_episode: 157.5
avg_sample_per_episode: 157.5
avg_envstep_per_sec: 795.4187288116016
avg_train_sample_per_sec: 795.4187288116016
avg_episode_per_sec: 5.050277643248264
collect_time: 1.5840713254043035
reward_mean: 962.125
reward_std: 682.2962036132812
reward_max: 2299.0
reward_min: 247.0
total_envstep_count: 826408
total_train_sample_count: 826379
total_episode_count: 6032
total_duration: 1051.4099987660134
[2024-11-19 22:51:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 445
train_sample_count: 445
avg_envstep_per_episode: 111.25
avg_sample_per_episode: 111.25
avg_envstep_per_sec: 794.5127618990979
avg_train_sample_per_sec: 794.5127618990979
avg_episode_per_sec: 7.141687747407621
collect_time: 0.5600916956152234
reward_mean: 678.0
reward_std: 77.97114562988281
reward_max: 810.0
reward_min: 608.0
total_envstep_count: 827412
total_train_sample_count: 827364
total_episode_count: 6036
total_duration: 1051.9700904616286
[2024-11-19 22:51:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1345
train_sample_count: 1345
avg_envstep_per_episode: 134.5
avg_sample_per_episode: 134.5
avg_envstep_per_sec: 787.5896427981859
avg_train_sample_per_sec: 787.5896427981859
avg_episode_per_sec: 5.855685076566438
collect_time: 1.70774211202349
reward_mean: 897.4000244140625
reward_std: 545.7736206054688
reward_max: 1913.0
reward_min: 249.0
total_envstep_count: 828443
total_train_sample_count: 828397
total_episode_count: 6046
total_duration: 1053.677832573652
[2024-11-19 22:51:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 901
train_sample_count: 901
avg_envstep_per_episode: 81.9090909090909
avg_sample_per_episode: 81.9090909090909
avg_envstep_per_sec: 795.6375713263423
avg_train_sample_per_sec: 795.6375713263423
avg_episode_per_sec: 9.713666242607953
collect_time: 1.1324251549584525
reward_mean: 529.0
reward_std: 226.1407470703125
reward_max: 814.0
reward_min: 208.0
total_envstep_count: 829427
total_train_sample_count: 829394
total_episode_count: 6057
total_duration: 1054.8102577286104
[2024-11-19 22:51:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 632
train_sample_count: 632
avg_envstep_per_episode: 126.4
avg_sample_per_episode: 126.4
avg_envstep_per_sec: 787.2372502069678
avg_train_sample_per_sec: 787.2372502069678
avg_episode_per_sec: 6.228142802270315
collect_time: 0.8028075397014619
reward_mean: 853.5999755859375
reward_std: 459.7876281738281
reward_max: 1773.0
reward_min: 609.0
total_envstep_count: 830422
total_train_sample_count: 830386
total_episode_count: 6062
total_duration: 1055.6130652683119
[2024-11-19 22:51:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1055
train_sample_count: 1055
avg_envstep_per_episode: 150.71428571428572
avg_sample_per_episode: 150.71428571428572
avg_envstep_per_sec: 799.4207004778889
avg_train_sample_per_sec: 799.4207004778889
avg_episode_per_sec: 5.304213178526277
collect_time: 1.3197056310517445
reward_mean: 951.8571166992188
reward_std: 400.144775390625
reward_max: 1847.0
reward_min: 622.0
total_envstep_count: 831394
total_train_sample_count: 831357
total_episode_count: 6069
total_duration: 1056.9327708993635
[2024-11-19 22:51:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 872
train_sample_count: 872
avg_envstep_per_episode: 145.33333333333334
avg_sample_per_episode: 145.33333333333334
avg_envstep_per_sec: 800.0881813465656
avg_train_sample_per_sec: 800.0881813465656
avg_episode_per_sec: 5.505193908347929
collect_time: 1.0898798661572593
reward_mean: 775.3333129882812
reward_std: 246.26861572265625
reward_max: 1305.0
reward_min: 606.0
total_envstep_count: 832383
total_train_sample_count: 832349
total_episode_count: 6075
total_duration: 1058.0226507655207
[2024-11-19 22:51:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 723
train_sample_count: 723
avg_envstep_per_episode: 103.28571428571429
avg_sample_per_episode: 103.28571428571429
avg_envstep_per_sec: 793.9904518498123
avg_train_sample_per_sec: 793.9904518498123
avg_episode_per_sec: 7.687321110579095
collect_time: 0.910590295280729
reward_mean: 772.8571166992188
reward_std: 456.81549072265625
reward_max: 1437.0
reward_min: 248.0
total_envstep_count: 833392
total_train_sample_count: 833336
total_episode_count: 6082
total_duration: 1058.9332410608015
[2024-11-19 22:51:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 865
train_sample_count: 865
avg_envstep_per_episode: 173.0
avg_sample_per_episode: 173.0
avg_envstep_per_sec: 788.569723554132
avg_train_sample_per_sec: 788.569723554132
avg_episode_per_sec: 4.5582064945325556
collect_time: 1.0969226615769523
reward_mean: 1104.800048828125
reward_std: 393.4881896972656
reward_max: 1427.0
reward_min: 609.0
total_envstep_count: 834347
total_train_sample_count: 834309
total_episode_count: 6087
total_duration: 1060.0301637223783
[2024-11-19 22:51:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 928
train_sample_count: 928
avg_envstep_per_episode: 132.57142857142858
avg_sample_per_episode: 132.57142857142858
avg_envstep_per_sec: 795.49026597384
avg_train_sample_per_sec: 795.49026597384
avg_episode_per_sec: 6.000465368337155
collect_time: 1.1665761853967396
reward_mean: 702.5714111328125
reward_std: 95.13277435302734
reward_max: 816.0
reward_min: 616.0
total_envstep_count: 835357
total_train_sample_count: 835321
total_episode_count: 6094
total_duration: 1061.196739907775
[2024-11-19 22:51:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 768
train_sample_count: 768
avg_envstep_per_episode: 128.0
avg_sample_per_episode: 128.0
avg_envstep_per_sec: 798.9083638663047
avg_train_sample_per_sec: 798.9083638663047
avg_episode_per_sec: 6.241471592705506
collect_time: 0.96131175330707
reward_mean: 755.5
reward_std: 148.28997802734375
reward_max: 1040.0
reward_min: 627.0
total_envstep_count: 836368
total_train_sample_count: 836329
total_episode_count: 6100
total_duration: 1062.158051661082
[2024-11-19 22:51:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2944
train_sample_count: 2944
avg_envstep_per_episode: 420.57142857142856
avg_sample_per_episode: 420.57142857142856
avg_envstep_per_sec: 792.350939835782
avg_train_sample_per_sec: 792.350939835782
avg_episode_per_sec: 1.8839866096638838
collect_time: 3.715525346142905
reward_mean: 997.5714111328125
reward_std: 467.825927734375
reward_max: 1773.0
reward_min: 625.0
total_envstep_count: 837330
total_train_sample_count: 837305
total_episode_count: 6107
total_duration: 1065.8735770072249
[2024-11-19 22:51:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 871
train_sample_count: 871
avg_envstep_per_episode: 145.16666666666666
avg_sample_per_episode: 145.16666666666666
avg_envstep_per_sec: 793.6182438273951
avg_train_sample_per_sec: 793.6182438273951
avg_episode_per_sec: 5.466945422461964
collect_time: 1.0975050117288316
reward_mean: 955.6666870117188
reward_std: 624.0455932617188
reward_max: 1849.0
reward_min: 246.0
total_envstep_count: 838333
total_train_sample_count: 838284
total_episode_count: 6113
total_duration: 1066.9710820189537
[2024-11-19 22:51:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 994
train_sample_count: 994
avg_envstep_per_episode: 124.25
avg_sample_per_episode: 124.25
avg_envstep_per_sec: 795.3710338259444
avg_train_sample_per_sec: 795.3710338259444
avg_episode_per_sec: 6.4013765297862735
collect_time: 1.2497312043394362
reward_mean: 791.75
reward_std: 420.6235656738281
reward_max: 1431.0
reward_min: 227.0
total_envstep_count: 839358
total_train_sample_count: 839326
total_episode_count: 6121
total_duration: 1068.2208132232931
[2024-11-19 22:51:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1148
train_sample_count: 1148
avg_envstep_per_episode: 164.0
avg_sample_per_episode: 164.0
avg_envstep_per_sec: 793.5975709747031
avg_train_sample_per_sec: 793.5975709747031
avg_episode_per_sec: 4.839009579114043
collect_time: 1.4465770082814353
reward_mean: 989.2857055664062
reward_std: 490.78558349609375
reward_max: 1763.0
reward_min: 615.0
total_envstep_count: 840367
total_train_sample_count: 840330
total_episode_count: 6128
total_duration: 1069.6673902315745
[2024-11-19 22:51:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 649
train_sample_count: 649
avg_envstep_per_episode: 162.25
avg_sample_per_episode: 162.25
avg_envstep_per_sec: 779.2570604072353
avg_train_sample_per_sec: 779.2570604072353
avg_episode_per_sec: 4.802817013295749
collect_time: 0.8328445553779601
reward_mean: 1029.75
reward_std: 352.0563659667969
reward_max: 1423.0
reward_min: 624.0
total_envstep_count: 841339
total_train_sample_count: 841303
total_episode_count: 6132
total_duration: 1070.5002347869524
[2024-11-19 22:52:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1532
train_sample_count: 1532
avg_envstep_per_episode: 170.22222222222223
avg_sample_per_episode: 170.22222222222223
avg_envstep_per_sec: 795.894693275159
avg_train_sample_per_sec: 795.894693275159
avg_episode_per_sec: 4.67562156623788
collect_time: 1.924877767051969
reward_mean: 992.6666870117188
reward_std: 449.16192626953125
reward_max: 1555.0
reward_min: 250.0
total_envstep_count: 842339
total_train_sample_count: 842307
total_episode_count: 6141
total_duration: 1072.4251125540045
[2024-11-19 22:52:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 617
train_sample_count: 617
avg_envstep_per_episode: 102.83333333333333
avg_sample_per_episode: 102.83333333333333
avg_envstep_per_sec: 794.8887950778296
avg_train_sample_per_sec: 794.8887950778296
avg_episode_per_sec: 7.72987483057857
collect_time: 0.7762092053890229
reward_mean: 737.6666870117188
reward_std: 355.9858093261719
reward_max: 1426.0
reward_min: 230.0
total_envstep_count: 843312
total_train_sample_count: 843296
total_episode_count: 6147
total_duration: 1073.2013217593935
[2024-11-19 22:52:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1366
train_sample_count: 1366
avg_envstep_per_episode: 170.75
avg_sample_per_episode: 170.75
avg_envstep_per_sec: 792.4075522296137
avg_train_sample_per_sec: 792.4075522296137
avg_episode_per_sec: 4.640747011593637
collect_time: 1.7238604000636508
reward_mean: 1149.375
reward_std: 314.4781188964844
reward_max: 1577.0
reward_min: 616.0
total_envstep_count: 844321
total_train_sample_count: 844290
total_episode_count: 6155
total_duration: 1074.925182159457
[2024-11-19 22:52:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 944
train_sample_count: 944
avg_envstep_per_episode: 104.88888888888889
avg_sample_per_episode: 104.88888888888889
avg_envstep_per_sec: 790.8135032695022
avg_train_sample_per_sec: 790.8135032695022
avg_episode_per_sec: 7.539535518459237
collect_time: 1.1937074874128613
reward_mean: 718.888916015625
reward_std: 396.8443603515625
reward_max: 1424.0
reward_min: 180.0
total_envstep_count: 845329
total_train_sample_count: 845282
total_episode_count: 6164
total_duration: 1076.11888964687
[2024-11-19 22:52:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 525
train_sample_count: 525
avg_envstep_per_episode: 131.25
avg_sample_per_episode: 131.25
avg_envstep_per_sec: 794.622664332041
avg_train_sample_per_sec: 794.622664332041
avg_episode_per_sec: 6.054267918720313
collect_time: 0.6606909462383815
reward_mean: 852.5
reward_std: 337.35626220703125
reward_max: 1431.0
reward_min: 616.0
total_envstep_count: 846295
total_train_sample_count: 846263
total_episode_count: 6168
total_duration: 1076.7795805931084
[2024-11-19 22:52:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1382
train_sample_count: 1382
avg_envstep_per_episode: 153.55555555555554
avg_sample_per_episode: 153.55555555555554
avg_envstep_per_sec: 686.2308362664899
avg_train_sample_per_sec: 686.2308362664899
avg_episode_per_sec: 4.468941770186982
collect_time: 2.01389959028789
reward_mean: 880.6666870117188
reward_std: 360.5649719238281
reward_max: 1429.0
reward_min: 609.0
total_envstep_count: 847305
total_train_sample_count: 847273
total_episode_count: 6177
total_duration: 1078.7934801833962
[2024-11-19 22:52:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 830
train_sample_count: 830
avg_envstep_per_episode: 118.57142857142857
avg_sample_per_episode: 118.57142857142857
avg_envstep_per_sec: 796.4670261496896
avg_train_sample_per_sec: 796.4670261496896
avg_episode_per_sec: 6.7171917868046105
collect_time: 1.0421021495546612
reward_mean: 795.4285888671875
reward_std: 262.97467041015625
reward_max: 1424.0
reward_min: 637.0
total_envstep_count: 848306
total_train_sample_count: 848271
total_episode_count: 6184
total_duration: 1079.835582332951
[2024-11-19 22:52:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1283
train_sample_count: 1283
avg_envstep_per_episode: 128.3
avg_sample_per_episode: 128.3
avg_envstep_per_sec: 797.808827669445
avg_train_sample_per_sec: 797.808827669445
avg_episode_per_sec: 6.218307308413444
collect_time: 1.6081546800477164
reward_mean: 817.0999755859375
reward_std: 429.8738098144531
reward_max: 1569.0
reward_min: 169.0
total_envstep_count: 849347
total_train_sample_count: 849314
total_episode_count: 6194
total_duration: 1081.4437370129986
[2024-11-19 22:52:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 826
train_sample_count: 826
avg_envstep_per_episode: 137.66666666666666
avg_sample_per_episode: 137.66666666666666
avg_envstep_per_sec: 806.400203712644
avg_train_sample_per_sec: 806.400203712644
avg_episode_per_sec: 5.85762859839693
collect_time: 1.024305296795709
reward_mean: 911.0
reward_std: 367.4293518066406
reward_max: 1428.0
reward_min: 605.0
total_envstep_count: 850342
total_train_sample_count: 850296
total_episode_count: 6200
total_duration: 1082.4680423097943
[2024-11-19 22:52:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 869
train_sample_count: 869
avg_envstep_per_episode: 217.25
avg_sample_per_episode: 217.25
avg_envstep_per_sec: 798.0055608714383
avg_train_sample_per_sec: 798.0055608714383
avg_episode_per_sec: 3.6732131685681857
collect_time: 1.0889648426146734
reward_mean: 1335.0
reward_std: 435.421630859375
reward_max: 1747.0
reward_min: 607.0
total_envstep_count: 851322
total_train_sample_count: 851285
total_episode_count: 6204
total_duration: 1083.557007152409
[2024-11-19 22:52:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 786
train_sample_count: 786
avg_envstep_per_episode: 131.0
avg_sample_per_episode: 131.0
avg_envstep_per_sec: 796.4990915996932
avg_train_sample_per_sec: 796.4990915996932
avg_episode_per_sec: 6.080145737402239
collect_time: 0.9868184512569791
reward_mean: 966.3333129882812
reward_std: 477.3970031738281
reward_max: 1432.0
reward_min: 249.0
total_envstep_count: 852332
total_train_sample_count: 852287
total_episode_count: 6210
total_duration: 1084.543825603666
[2024-11-19 22:52:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 771
train_sample_count: 771
avg_envstep_per_episode: 192.75
avg_sample_per_episode: 192.75
avg_envstep_per_sec: 797.5925096053828
avg_train_sample_per_sec: 797.5925096053828
avg_episode_per_sec: 4.13796373336126
collect_time: 0.9666590279056911
reward_mean: 1160.75
reward_std: 554.4895629882812
reward_max: 1682.0
reward_min: 228.0
total_envstep_count: 853320
total_train_sample_count: 853274
total_episode_count: 6214
total_duration: 1085.5104846315717
[2024-11-19 22:52:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1069
train_sample_count: 1069
avg_envstep_per_episode: 213.8
avg_sample_per_episode: 213.8
avg_envstep_per_sec: 798.6256618804149
avg_train_sample_per_sec: 798.6256618804149
avg_episode_per_sec: 3.735386631807366
collect_time: 1.3385495245456696
reward_mean: 1048.800048828125
reward_std: 493.2449035644531
reward_max: 1844.0
reward_min: 610.0
total_envstep_count: 854291
total_train_sample_count: 854259
total_episode_count: 6219
total_duration: 1086.8490341561173
[2024-11-19 22:52:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1462
train_sample_count: 1462
avg_envstep_per_episode: 182.75
avg_sample_per_episode: 182.75
avg_envstep_per_sec: 802.4551527879769
avg_train_sample_per_sec: 802.4551527879769
avg_episode_per_sec: 4.390999468060065
collect_time: 1.8219086698123388
reward_mean: 962.125
reward_std: 549.014892578125
reward_max: 1727.0
reward_min: 192.0
total_envstep_count: 855308
total_train_sample_count: 855265
total_episode_count: 6227
total_duration: 1088.6709428259296
[2024-11-19 22:52:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1111
train_sample_count: 1111
avg_envstep_per_episode: 123.44444444444444
avg_sample_per_episode: 123.44444444444444
avg_envstep_per_sec: 795.2622206735609
avg_train_sample_per_sec: 795.2622206735609
avg_episode_per_sec: 6.442268214277271
collect_time: 1.3970234862395696
reward_mean: 907.4444580078125
reward_std: 437.2040100097656
reward_max: 1683.0
reward_min: 248.0
total_envstep_count: 856308
total_train_sample_count: 856268
total_episode_count: 6236
total_duration: 1090.0679663121691
[2024-11-19 22:52:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1018
train_sample_count: 1018
avg_envstep_per_episode: 127.25
avg_sample_per_episode: 127.25
avg_envstep_per_sec: 804.1481878736382
avg_train_sample_per_sec: 804.1481878736382
avg_episode_per_sec: 6.3194356610894955
collect_time: 1.2659358254500797
reward_mean: 831.75
reward_std: 355.2480773925781
reward_max: 1335.0
reward_min: 248.0
total_envstep_count: 857293
total_train_sample_count: 857262
total_episode_count: 6244
total_duration: 1091.3339021376191
[2024-11-19 22:52:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 498
train_sample_count: 498
avg_envstep_per_episode: 99.6
avg_sample_per_episode: 99.6
avg_envstep_per_sec: 800.04126476541
avg_train_sample_per_sec: 800.04126476541
avg_episode_per_sec: 8.03254281892982
collect_time: 0.6224678925105503
reward_mean: 527.4000244140625
reward_std: 327.4810485839844
reward_max: 1054.0
reward_min: 118.0
total_envstep_count: 858304
total_train_sample_count: 858264
total_episode_count: 6249
total_duration: 1091.9563700301296
[2024-11-19 22:53:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1354
train_sample_count: 1354
avg_envstep_per_episode: 193.42857142857142
avg_sample_per_episode: 193.42857142857142
avg_envstep_per_sec: 798.5853590292468
avg_train_sample_per_sec: 798.5853590292468
avg_episode_per_sec: 4.128580142691822
collect_time: 1.6954981514385767
reward_mean: 902.7142944335938
reward_std: 545.67724609375
reward_max: 1683.0
reward_min: 145.0
total_envstep_count: 859307
total_train_sample_count: 859270
total_episode_count: 6256
total_duration: 1093.6518681815683
[2024-11-19 22:53:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 773
train_sample_count: 773
avg_envstep_per_episode: 96.625
avg_sample_per_episode: 96.625
avg_envstep_per_sec: 800.5932455283817
avg_train_sample_per_sec: 800.5932455283817
avg_episode_per_sec: 8.285570458249746
collect_time: 0.9655340015888212
reward_mean: 716.375
reward_std: 415.0445251464844
reward_max: 1435.0
reward_min: 246.0
total_envstep_count: 860309
total_train_sample_count: 860259
total_episode_count: 6264
total_duration: 1094.617402183157
[2024-11-19 22:53:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1023
train_sample_count: 1023
avg_envstep_per_episode: 170.5
avg_sample_per_episode: 170.5
avg_envstep_per_sec: 789.0674044514528
avg_train_sample_per_sec: 789.0674044514528
avg_episode_per_sec: 4.627961316430809
collect_time: 1.2964671892779216
reward_mean: 1113.3333740234375
reward_std: 383.8327331542969
reward_max: 1554.0
reward_min: 616.0
total_envstep_count: 861295
total_train_sample_count: 861258
total_episode_count: 6270
total_duration: 1095.913869372435
[2024-11-19 22:53:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1312
train_sample_count: 1312
avg_envstep_per_episode: 131.2
avg_sample_per_episode: 131.2
avg_envstep_per_sec: 799.6069175542744
avg_train_sample_per_sec: 799.6069175542744
avg_episode_per_sec: 6.094564920383189
collect_time: 1.640806215150016
reward_mean: 800.4000244140625
reward_std: 360.0505676269531
reward_max: 1436.0
reward_min: 246.0
total_envstep_count: 862333
total_train_sample_count: 862294
total_episode_count: 6280
total_duration: 1097.554675587585
[2024-11-19 22:53:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 582
train_sample_count: 582
avg_envstep_per_episode: 97.0
avg_sample_per_episode: 97.0
avg_envstep_per_sec: 798.0205834581685
avg_train_sample_per_sec: 798.0205834581685
avg_episode_per_sec: 8.227016324311016
collect_time: 0.729304496731077
reward_mean: 652.6666870117188
reward_std: 394.3106384277344
reward_max: 1425.0
reward_min: 247.0
total_envstep_count: 863304
total_train_sample_count: 863272
total_episode_count: 6286
total_duration: 1098.2839800843162
[2024-11-19 22:53:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 635
train_sample_count: 635
avg_envstep_per_episode: 158.75
avg_sample_per_episode: 158.75
avg_envstep_per_sec: 797.9832678315862
avg_train_sample_per_sec: 797.9832678315862
avg_episode_per_sec: 5.026666254057236
collect_time: 0.7957560334886825
reward_mean: 965.25
reward_std: 548.9901733398438
reward_max: 1559.0
reward_min: 238.0
total_envstep_count: 864316
total_train_sample_count: 864267
total_episode_count: 6290
total_duration: 1099.079736117805
[2024-11-19 22:53:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1280
train_sample_count: 1280
avg_envstep_per_episode: 182.85714285714286
avg_sample_per_episode: 182.85714285714286
avg_envstep_per_sec: 800.2014450148521
avg_train_sample_per_sec: 800.2014450148521
avg_episode_per_sec: 4.376101652424972
collect_time: 1.5995972113949914
reward_mean: 1009.4285888671875
reward_std: 354.8338928222656
reward_max: 1424.0
reward_min: 619.0
total_envstep_count: 865301
total_train_sample_count: 865271
total_episode_count: 6297
total_duration: 1100.6793333291998
[2024-11-19 22:53:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1215
train_sample_count: 1215
avg_envstep_per_episode: 202.5
avg_sample_per_episode: 202.5
avg_envstep_per_sec: 800.8353778133693
avg_train_sample_per_sec: 800.8353778133693
avg_episode_per_sec: 3.954742606485774
collect_time: 1.5171657417501725
reward_mean: 911.3333129882812
reward_std: 274.8603820800781
reward_max: 1387.0
reward_min: 606.0
total_envstep_count: 866295
total_train_sample_count: 866258
total_episode_count: 6303
total_duration: 1102.19649907095
[2024-11-19 22:53:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1563
train_sample_count: 1563
avg_envstep_per_episode: 130.25
avg_sample_per_episode: 130.25
avg_envstep_per_sec: 802.7693579703644
avg_train_sample_per_sec: 802.7693579703644
avg_episode_per_sec: 6.163296414359803
collect_time: 1.947010040283203
reward_mean: 712.9166870117188
reward_std: 206.77581787109375
reward_max: 1053.0
reward_min: 241.0
total_envstep_count: 867288
total_train_sample_count: 867257
total_episode_count: 6315
total_duration: 1104.1435091112332
[2024-11-19 22:53:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 77.33333333333333
avg_sample_per_episode: 77.33333333333333
avg_envstep_per_sec: 791.728834707214
avg_train_sample_per_sec: 791.728834707214
avg_episode_per_sec: 10.237872862593285
collect_time: 0.8790888616016933
reward_mean: 563.111083984375
reward_std: 399.8147888183594
reward_max: 1567.0
reward_min: 233.0
total_envstep_count: 868283
total_train_sample_count: 868253
total_episode_count: 6324
total_duration: 1105.022597972835
[2024-11-19 22:53:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 745
train_sample_count: 745
avg_envstep_per_episode: 124.16666666666667
avg_sample_per_episode: 124.16666666666667
avg_envstep_per_sec: 755.8510720675977
avg_train_sample_per_sec: 755.8510720675977
avg_episode_per_sec: 6.0873911844370285
collect_time: 0.9856439019952501
reward_mean: 753.1666870117188
reward_std: 499.49554443359375
reward_max: 1429.0
reward_min: 223.0
total_envstep_count: 869278
total_train_sample_count: 869238
total_episode_count: 6330
total_duration: 1106.0082418748302
[2024-11-19 22:54:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1171
train_sample_count: 1171
avg_envstep_per_episode: 167.28571428571428
avg_sample_per_episode: 167.28571428571428
avg_envstep_per_sec: 749.133160885736
avg_train_sample_per_sec: 749.133160885736
avg_episode_per_sec: 4.4781657781384725
collect_time: 1.5631399878433772
reward_mean: 753.8571166992188
reward_std: 437.16961669921875
reward_max: 1413.0
reward_min: 221.0
total_envstep_count: 870289
total_train_sample_count: 870265
total_episode_count: 6337
total_duration: 1107.5713818626737
[2024-11-19 22:54:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1085
train_sample_count: 1085
avg_envstep_per_episode: 217.0
avg_sample_per_episode: 217.0
avg_envstep_per_sec: 774.4601859493395
avg_train_sample_per_sec: 774.4601859493395
avg_episode_per_sec: 3.5689409490752975
collect_time: 1.4009758276598794
reward_mean: 1298.800048828125
reward_std: 370.4064636230469
reward_max: 1765.0
reward_min: 629.0
total_envstep_count: 871308
total_train_sample_count: 871266
total_episode_count: 6342
total_duration: 1108.9723576903336
[2024-11-19 22:54:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 910
train_sample_count: 910
avg_envstep_per_episode: 151.66666666666666
avg_sample_per_episode: 151.66666666666666
avg_envstep_per_sec: 790.4100495579462
avg_train_sample_per_sec: 790.4100495579462
avg_episode_per_sec: 5.211494832250195
collect_time: 1.1513011512302216
reward_mean: 1015.8333129882812
reward_std: 491.71112060546875
reward_max: 1574.0
reward_min: 236.0
total_envstep_count: 872286
total_train_sample_count: 872248
total_episode_count: 6348
total_duration: 1110.1236588415638
[2024-11-19 22:54:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 987
train_sample_count: 987
avg_envstep_per_episode: 164.5
avg_sample_per_episode: 164.5
avg_envstep_per_sec: 788.7737988684422
avg_train_sample_per_sec: 788.7737988684422
avg_episode_per_sec: 4.794977500720013
collect_time: 1.2513093125252497
reward_mean: 1037.0
reward_std: 348.74249267578125
reward_max: 1570.0
reward_min: 632.0
total_envstep_count: 873273
total_train_sample_count: 873223
total_episode_count: 6354
total_duration: 1111.3749681540892
[2024-11-19 22:54:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 960
train_sample_count: 960
avg_envstep_per_episode: 137.14285714285714
avg_sample_per_episode: 137.14285714285714
avg_envstep_per_sec: 793.43861476687
avg_train_sample_per_sec: 793.43861476687
avg_episode_per_sec: 5.78548989934176
collect_time: 1.2099234674658095
reward_mean: 781.8571166992188
reward_std: 300.4726867675781
reward_max: 1417.0
reward_min: 584.0
total_envstep_count: 874235
total_train_sample_count: 874207
total_episode_count: 6361
total_duration: 1112.584891621555
[2024-11-19 22:54:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 795
train_sample_count: 795
avg_envstep_per_episode: 159.0
avg_sample_per_episode: 159.0
avg_envstep_per_sec: 788.6066499271941
avg_train_sample_per_sec: 788.6066499271941
avg_episode_per_sec: 4.959790251114429
collect_time: 1.008107147046498
reward_mean: 985.5999755859375
reward_std: 338.3699645996094
reward_max: 1549.0
reward_min: 623.0
total_envstep_count: 875247
total_train_sample_count: 875194
total_episode_count: 6366
total_duration: 1113.5929987686015
[2024-11-19 22:54:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1161
train_sample_count: 1161
avg_envstep_per_episode: 129.0
avg_sample_per_episode: 129.0
avg_envstep_per_sec: 785.8384240244704
avg_train_sample_per_sec: 785.8384240244704
avg_episode_per_sec: 6.0917707288718645
collect_time: 1.4774029425212316
reward_mean: 872.888916015625
reward_std: 378.908203125
reward_max: 1565.0
reward_min: 587.0
total_envstep_count: 876234
total_train_sample_count: 876187
total_episode_count: 6375
total_duration: 1115.0704017111227
[2024-11-19 22:54:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 943
train_sample_count: 943
avg_envstep_per_episode: 157.16666666666666
avg_sample_per_episode: 157.16666666666666
avg_envstep_per_sec: 794.9022908712011
avg_train_sample_per_sec: 794.9022908712011
avg_episode_per_sec: 5.057702805118989
collect_time: 1.1863093248435428
reward_mean: 1029.1666259765625
reward_std: 335.3130187988281
reward_max: 1430.0
reward_min: 606.0
total_envstep_count: 877236
total_train_sample_count: 877190
total_episode_count: 6381
total_duration: 1116.2567110359662
[2024-11-19 22:54:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 867
train_sample_count: 867
avg_envstep_per_episode: 144.5
avg_sample_per_episode: 144.5
avg_envstep_per_sec: 792.5026127383986
avg_train_sample_per_sec: 792.5026127383986
avg_episode_per_sec: 5.484447146978537
collect_time: 1.0940027024064747
reward_mean: 884.8333129882812
reward_std: 371.2009582519531
reward_max: 1422.0
reward_min: 602.0
total_envstep_count: 878224
total_train_sample_count: 878189
total_episode_count: 6387
total_duration: 1117.3507137383726
[2024-11-19 22:54:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1197
train_sample_count: 1197
avg_envstep_per_episode: 171.0
avg_sample_per_episode: 171.0
avg_envstep_per_sec: 789.3432796129177
avg_train_sample_per_sec: 789.3432796129177
avg_episode_per_sec: 4.616042570835776
collect_time: 1.5164504860128676
reward_mean: 1141.5714111328125
reward_std: 473.7355651855469
reward_max: 1693.0
reward_min: 250.0
total_envstep_count: 879235
total_train_sample_count: 879194
total_episode_count: 6394
total_duration: 1118.8671642243855
[2024-11-19 22:54:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1072
train_sample_count: 1072
avg_envstep_per_episode: 153.14285714285714
avg_sample_per_episode: 153.14285714285714
avg_envstep_per_sec: 797.6865210833121
avg_train_sample_per_sec: 797.6865210833121
avg_episode_per_sec: 5.208773924984314
collect_time: 1.3438863158226013
reward_mean: 899.5714111328125
reward_std: 337.1417236328125
reward_max: 1427.0
reward_min: 607.0
total_envstep_count: 880230
total_train_sample_count: 880182
total_episode_count: 6401
total_duration: 1120.2110505402081
[2024-11-19 22:54:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 699
train_sample_count: 699
avg_envstep_per_episode: 174.75
avg_sample_per_episode: 174.75
avg_envstep_per_sec: 787.0701561266928
avg_train_sample_per_sec: 787.0701561266928
avg_episode_per_sec: 4.503978003586226
collect_time: 0.8881038044180188
reward_mean: 924.25
reward_std: 328.39105224609375
reward_max: 1412.0
reward_min: 609.0
total_envstep_count: 881210
total_train_sample_count: 881181
total_episode_count: 6405
total_duration: 1121.0991543446262
[2024-11-19 22:54:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1262
train_sample_count: 1262
avg_envstep_per_episode: 180.28571428571428
avg_sample_per_episode: 180.28571428571428
avg_envstep_per_sec: 789.7052927928275
avg_train_sample_per_sec: 789.7052927928275
avg_episode_per_sec: 4.3802987714340675
collect_time: 1.5980645077569144
reward_mean: 1183.7142333984375
reward_std: 353.2403869628906
reward_max: 1432.0
reward_min: 611.0
total_envstep_count: 882235
total_train_sample_count: 882203
total_episode_count: 6412
total_duration: 1122.697218852383
[2024-11-19 22:54:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 924
train_sample_count: 924
avg_envstep_per_episode: 154.0
avg_sample_per_episode: 154.0
avg_envstep_per_sec: 790.7353973436144
avg_train_sample_per_sec: 790.7353973436144
avg_episode_per_sec: 5.134645437296197
collect_time: 1.168532486472811
reward_mean: 858.6666870117188
reward_std: 351.7459716796875
reward_max: 1394.0
reward_min: 600.0
total_envstep_count: 883229
total_train_sample_count: 883199
total_episode_count: 6418
total_duration: 1123.8657513388557
[2024-11-19 22:54:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 952
train_sample_count: 952
avg_envstep_per_episode: 158.66666666666666
avg_sample_per_episode: 158.66666666666666
avg_envstep_per_sec: 635.1381472427322
avg_train_sample_per_sec: 635.1381472427322
avg_episode_per_sec: 4.002971516235707
collect_time: 1.4988865086010523
reward_mean: 884.8333129882812
reward_std: 573.702392578125
reward_max: 1564.0
reward_min: 189.0
total_envstep_count: 884216
total_train_sample_count: 884175
total_episode_count: 6424
total_duration: 1125.3646378474568
[2024-11-19 22:54:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 761
train_sample_count: 761
avg_envstep_per_episode: 152.2
avg_sample_per_episode: 152.2
avg_envstep_per_sec: 796.604089662653
avg_train_sample_per_sec: 796.604089662653
avg_episode_per_sec: 5.233929629846603
collect_time: 0.9553051633494241
reward_mean: 833.4000244140625
reward_std: 305.17181396484375
reward_max: 1431.0
reward_min: 609.0
total_envstep_count: 885211
total_train_sample_count: 885176
total_episode_count: 6429
total_duration: 1126.3199430108064
[2024-11-19 22:55:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1144
train_sample_count: 1144
avg_envstep_per_episode: 228.8
avg_sample_per_episode: 228.8
avg_envstep_per_sec: 791.113995517484
avg_train_sample_per_sec: 791.113995517484
avg_episode_per_sec: 3.457666064324668
collect_time: 1.4460621433598655
reward_mean: 1295.4000244140625
reward_std: 353.17449951171875
reward_max: 1693.0
reward_min: 636.0
total_envstep_count: 886207
total_train_sample_count: 886176
total_episode_count: 6434
total_duration: 1127.7660051541661
[2024-11-19 22:55:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1250
train_sample_count: 1250
avg_envstep_per_episode: 208.33333333333334
avg_sample_per_episode: 208.33333333333334
avg_envstep_per_sec: 787.5971311126998
avg_train_sample_per_sec: 787.5971311126998
avg_episode_per_sec: 3.780466229340959
collect_time: 1.5871058319296156
reward_mean: 1252.1666259765625
reward_std: 197.43304443359375
reward_max: 1567.0
reward_min: 1022.0
total_envstep_count: 887234
total_train_sample_count: 887186
total_episode_count: 6440
total_duration: 1129.3531109860958
[2024-11-19 22:55:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1109
train_sample_count: 1109
avg_envstep_per_episode: 110.9
avg_sample_per_episode: 110.9
avg_envstep_per_sec: 794.6500532573722
avg_train_sample_per_sec: 794.6500532573722
avg_episode_per_sec: 7.165464862555205
collect_time: 1.395582867520196
reward_mean: 442.1000061035156
reward_std: 368.1840515136719
reward_max: 1336.0
reward_min: 127.0
total_envstep_count: 888233
total_train_sample_count: 888199
total_episode_count: 6450
total_duration: 1130.748693853616
[2024-11-19 22:55:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 525
train_sample_count: 525
avg_envstep_per_episode: 175.0
avg_sample_per_episode: 175.0
avg_envstep_per_sec: 771.715039831467
avg_train_sample_per_sec: 771.715039831467
avg_episode_per_sec: 4.4098002276083825
collect_time: 0.6803029264722552
reward_mean: 989.3333129882812
reward_std: 403.1131591796875
reward_max: 1547.0
reward_min: 608.0
total_envstep_count: 889230
total_train_sample_count: 889180
total_episode_count: 6453
total_duration: 1131.4289967800883
[2024-11-19 22:55:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1185
train_sample_count: 1185
avg_envstep_per_episode: 169.28571428571428
avg_sample_per_episode: 169.28571428571428
avg_envstep_per_sec: 777.9429916458239
avg_train_sample_per_sec: 777.9429916458239
avg_episode_per_sec: 4.595443832506977
collect_time: 1.5232478635651725
reward_mean: 829.5714111328125
reward_std: 505.224365234375
reward_max: 1560.0
reward_min: 156.0
total_envstep_count: 890232
total_train_sample_count: 890173
total_episode_count: 6460
total_duration: 1132.9522446436533
[2024-11-19 22:55:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1171
train_sample_count: 1171
avg_envstep_per_episode: 167.28571428571428
avg_sample_per_episode: 167.28571428571428
avg_envstep_per_sec: 783.6883490791538
avg_train_sample_per_sec: 783.6883490791538
avg_episode_per_sec: 4.684729669986401
collect_time: 1.494216420820781
reward_mean: 763.7142944335938
reward_std: 269.5852355957031
reward_max: 1405.0
reward_min: 610.0
total_envstep_count: 891226
total_train_sample_count: 891188
total_episode_count: 6467
total_duration: 1134.446461064474
[2024-11-19 22:55:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 579
train_sample_count: 579
avg_envstep_per_episode: 144.75
avg_sample_per_episode: 144.75
avg_envstep_per_sec: 786.0685578421441
avg_train_sample_per_sec: 786.0685578421441
avg_episode_per_sec: 5.4305254427781975
collect_time: 0.7365769743919373
reward_mean: 801.25
reward_std: 307.8801574707031
reward_max: 1333.0
reward_min: 589.0
total_envstep_count: 892214
total_train_sample_count: 892163
total_episode_count: 6471
total_duration: 1135.183038038866
[2024-11-19 22:55:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1157
train_sample_count: 1157
avg_envstep_per_episode: 192.83333333333334
avg_sample_per_episode: 192.83333333333334
avg_envstep_per_sec: 792.7822132730024
avg_train_sample_per_sec: 792.7822132730024
avg_episode_per_sec: 4.111230146618854
collect_time: 1.4594172026429857
reward_mean: 1002.3333129882812
reward_std: 315.5020751953125
reward_max: 1420.0
reward_min: 618.0
total_envstep_count: 893194
total_train_sample_count: 893164
total_episode_count: 6477
total_duration: 1136.642455241509
[2024-11-19 22:55:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 915
train_sample_count: 915
avg_envstep_per_episode: 152.5
avg_sample_per_episode: 152.5
avg_envstep_per_sec: 797.7279213610534
avg_train_sample_per_sec: 797.7279213610534
avg_episode_per_sec: 5.231002763023301
collect_time: 1.1470076143741608
reward_mean: 592.8333129882812
reward_std: 193.67018127441406
reward_max: 809.0
reward_min: 191.0
total_envstep_count: 894180
total_train_sample_count: 894139
total_episode_count: 6483
total_duration: 1137.7894628558831
[2024-11-19 22:55:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1117
train_sample_count: 1117
avg_envstep_per_episode: 279.25
avg_sample_per_episode: 279.25
avg_envstep_per_sec: 787.7025965445924
avg_train_sample_per_sec: 787.7025965445924
avg_episode_per_sec: 2.8207792177066873
collect_time: 1.4180478836808885
reward_mean: 1375.25
reward_std: 431.8404541015625
reward_max: 1745.0
reward_min: 639.0
total_envstep_count: 895185
total_train_sample_count: 895148
total_episode_count: 6487
total_duration: 1139.207510739564
[2024-11-19 22:55:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1115
train_sample_count: 1115
avg_envstep_per_episode: 185.83333333333334
avg_sample_per_episode: 185.83333333333334
avg_envstep_per_sec: 781.4230542874946
avg_train_sample_per_sec: 781.4230542874946
avg_episode_per_sec: 4.204967108273514
collect_time: 1.4268839316708701
reward_mean: 1263.6666259765625
reward_std: 400.8697509765625
reward_max: 1710.0
reward_min: 625.0
total_envstep_count: 896196
total_train_sample_count: 896167
total_episode_count: 6493
total_duration: 1140.6343946712348
[2024-11-19 22:55:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1233
train_sample_count: 1233
avg_envstep_per_episode: 154.125
avg_sample_per_episode: 154.125
avg_envstep_per_sec: 787.9451767163719
avg_train_sample_per_sec: 787.9451767163719
avg_episode_per_sec: 5.112377464502007
collect_time: 1.564829681600843
reward_mean: 836.0
reward_std: 252.29347229003906
reward_max: 1338.0
reward_min: 600.0
total_envstep_count: 897237
total_train_sample_count: 897208
total_episode_count: 6501
total_duration: 1142.1992243528357
[2024-11-19 22:55:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 764
train_sample_count: 764
avg_envstep_per_episode: 127.33333333333333
avg_sample_per_episode: 127.33333333333333
avg_envstep_per_sec: 789.3160909182149
avg_train_sample_per_sec: 789.3160909182149
avg_episode_per_sec: 6.198817467944095
collect_time: 0.967926549060004
reward_mean: 737.8333129882812
reward_std: 152.2721405029297
reward_max: 1032.0
reward_min: 607.0
total_envstep_count: 898240
total_train_sample_count: 898188
total_episode_count: 6507
total_duration: 1143.1671509018956
[2024-11-19 22:55:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1114
train_sample_count: 1114
avg_envstep_per_episode: 159.14285714285714
avg_sample_per_episode: 159.14285714285714
avg_envstep_per_sec: 789.1640253503202
avg_train_sample_per_sec: 789.1640253503202
avg_episode_per_sec: 4.958840374732712
collect_time: 1.411620352949415
reward_mean: 903.7142944335938
reward_std: 330.2980041503906
reward_max: 1420.0
reward_min: 621.0
total_envstep_count: 899201
total_train_sample_count: 899158
total_episode_count: 6514
total_duration: 1144.5787712548452
[2024-11-19 22:55:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 566
train_sample_count: 566
avg_envstep_per_episode: 188.66666666666666
avg_sample_per_episode: 188.66666666666666
avg_envstep_per_sec: 798.5805780546891
avg_train_sample_per_sec: 798.5805780546891
avg_episode_per_sec: 4.232759247639695
collect_time: 0.7087575324944086
reward_mean: 1432.3333740234375
reward_std: 7.133645057678223
reward_max: 1442.0
reward_min: 1425.0
total_envstep_count: 900175
total_train_sample_count: 900144
total_episode_count: 6517
total_duration: 1145.2875287873396
[2024-11-19 22:55:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 375
train_sample_count: 375
avg_envstep_per_episode: 187.5
avg_sample_per_episode: 187.5
avg_envstep_per_sec: 801.1151022480996
avg_train_sample_per_sec: 801.1151022480996
avg_episode_per_sec: 4.27261387865653
collect_time: 0.4680975292410169
reward_mean: 969.5
reward_std: 340.5
reward_max: 1310.0
reward_min: 629.0
total_envstep_count: 901149
total_train_sample_count: 901107
total_episode_count: 6519
total_duration: 1145.7556263165807
[2024-11-19 22:56:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1721
train_sample_count: 1721
avg_envstep_per_episode: 286.8333333333333
avg_sample_per_episode: 286.8333333333333
avg_envstep_per_sec: 799.4448445052527
avg_train_sample_per_sec: 799.4448445052527
avg_episode_per_sec: 2.7871406548701434
collect_time: 2.1527438844953264
reward_mean: 1002.8333129882812
reward_std: 327.9580383300781
reward_max: 1396.0
reward_min: 561.0
total_envstep_count: 902160
total_train_sample_count: 902108
total_episode_count: 6525
total_duration: 1147.908370201076
[2024-11-19 22:56:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 842
train_sample_count: 842
avg_envstep_per_episode: 168.4
avg_sample_per_episode: 168.4
avg_envstep_per_sec: 796.9375095217436
avg_train_sample_per_sec: 796.9375095217436
avg_episode_per_sec: 4.732408013787076
collect_time: 1.0565445721149445
reward_mean: 998.7999877929688
reward_std: 354.2030029296875
reward_max: 1426.0
reward_min: 586.0
total_envstep_count: 903155
total_train_sample_count: 903130
total_episode_count: 6530
total_duration: 1148.964914773191
[2024-11-19 22:56:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1225
train_sample_count: 1225
avg_envstep_per_episode: 245.0
avg_sample_per_episode: 245.0
avg_envstep_per_sec: 790.9506174297802
avg_train_sample_per_sec: 790.9506174297802
avg_episode_per_sec: 3.2283698670603274
collect_time: 1.5487692568983351
reward_mean: 976.7999877929688
reward_std: 398.1634826660156
reward_max: 1493.0
reward_min: 614.0
total_envstep_count: 904206
total_train_sample_count: 904163
total_episode_count: 6535
total_duration: 1150.5136840300893
[2024-11-19 22:56:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 543
train_sample_count: 543
avg_envstep_per_episode: 135.75
avg_sample_per_episode: 135.75
avg_envstep_per_sec: 806.0324970387687
avg_train_sample_per_sec: 806.0324970387687
avg_episode_per_sec: 5.937624287578407
collect_time: 0.6736701088292258
reward_mean: 561.5
reward_std: 203.42874145507812
reward_max: 801.0
reward_min: 239.0
total_envstep_count: 905178
total_train_sample_count: 905162
total_episode_count: 6539
total_duration: 1151.1873541389184
[2024-11-19 22:56:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1800
train_sample_count: 1800
avg_envstep_per_episode: 257.14285714285717
avg_sample_per_episode: 257.14285714285717
avg_envstep_per_sec: 794.372426197888
avg_train_sample_per_sec: 794.372426197888
avg_episode_per_sec: 3.0892261018806755
collect_time: 2.265939678464617
reward_mean: 778.1428833007812
reward_std: 265.1875
reward_max: 1396.0
reward_min: 601.0
total_envstep_count: 906212
total_train_sample_count: 906158
total_episode_count: 6546
total_duration: 1153.453293817383
[2024-11-19 22:56:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 841
train_sample_count: 841
avg_envstep_per_episode: 105.125
avg_sample_per_episode: 105.125
avg_envstep_per_sec: 801.1679537833412
avg_train_sample_per_sec: 801.1679537833412
avg_episode_per_sec: 7.6210982523980135
collect_time: 1.0497174731322698
reward_mean: 596.625
reward_std: 137.59718322753906
reward_max: 731.0
reward_min: 244.0
total_envstep_count: 907198
total_train_sample_count: 907167
total_episode_count: 6554
total_duration: 1154.5030112905151
[2024-11-19 22:56:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 471
train_sample_count: 471
avg_envstep_per_episode: 117.75
avg_sample_per_episode: 117.75
avg_envstep_per_sec: 786.3527174093564
avg_train_sample_per_sec: 786.3527174093564
avg_episode_per_sec: 6.678154712605999
collect_time: 0.5989678544657571
reward_mean: 830.0
reward_std: 349.72918701171875
reward_max: 1435.0
reward_min: 605.0
total_envstep_count: 908211
total_train_sample_count: 908154
total_episode_count: 6558
total_duration: 1155.101979144981
[2024-11-19 22:56:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1448
train_sample_count: 1448
avg_envstep_per_episode: 181.0
avg_sample_per_episode: 181.0
avg_envstep_per_sec: 798.974868636456
avg_train_sample_per_sec: 798.974868636456
avg_episode_per_sec: 4.41422579357158
collect_time: 1.812322335583823
reward_mean: 899.25
reward_std: 403.8863525390625
reward_max: 1412.0
reward_min: 239.0
total_envstep_count: 909204
total_train_sample_count: 909158
total_episode_count: 6566
total_duration: 1156.9143014805647
[2024-11-19 22:56:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 727
train_sample_count: 727
avg_envstep_per_episode: 242.33333333333334
avg_sample_per_episode: 242.33333333333334
avg_envstep_per_sec: 799.0006193151276
avg_train_sample_per_sec: 799.0006193151276
avg_episode_per_sec: 3.297113972414557
collect_time: 0.9098866539342063
reward_mean: 840.6666870117188
reward_std: 315.0040588378906
reward_max: 1286.0
reward_min: 608.0
total_envstep_count: 910185
total_train_sample_count: 910137
total_episode_count: 6569
total_duration: 1157.8241881344989
[2024-11-19 22:56:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1512
train_sample_count: 1512
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 798.9674616157264
avg_train_sample_per_sec: 798.9674616157264
avg_episode_per_sec: 3.698923433406141
collect_time: 1.892442524433136
reward_mean: 1186.857177734375
reward_std: 368.1872253417969
reward_max: 1437.0
reward_min: 591.0
total_envstep_count: 911155
total_train_sample_count: 911121
total_episode_count: 6576
total_duration: 1159.716630658932
[2024-11-19 22:56:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 661
train_sample_count: 661
avg_envstep_per_episode: 132.2
avg_sample_per_episode: 132.2
avg_envstep_per_sec: 792.5907133929476
avg_train_sample_per_sec: 792.5907133929476
avg_episode_per_sec: 5.995391175438333
collect_time: 0.8339739399296897
reward_mean: 1006.0
reward_std: 343.8179626464844
reward_max: 1431.0
reward_min: 610.0
total_envstep_count: 912158
total_train_sample_count: 912106
total_episode_count: 6581
total_duration: 1160.5506045988616
[2024-11-19 22:56:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 166.66666666666666
avg_sample_per_episode: 166.66666666666666
avg_envstep_per_sec: 795.0879458791735
avg_train_sample_per_sec: 795.0879458791735
avg_episode_per_sec: 4.770527675275041
collect_time: 1.257722501243864
reward_mean: 1098.6666259765625
reward_std: 366.1587219238281
reward_max: 1568.0
reward_min: 620.0
total_envstep_count: 913138
total_train_sample_count: 913094
total_episode_count: 6587
total_duration: 1161.8083271001055
[2024-11-19 22:56:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 800
train_sample_count: 800
avg_envstep_per_episode: 160.0
avg_sample_per_episode: 160.0
avg_envstep_per_sec: 803.5265658398256
avg_train_sample_per_sec: 803.5265658398256
avg_episode_per_sec: 5.02204103649891
collect_time: 0.9956111397062029
reward_mean: 734.5999755859375
reward_std: 542.7723388671875
reward_max: 1754.0
reward_min: 119.0
total_envstep_count: 914150
total_train_sample_count: 914098
total_episode_count: 6592
total_duration: 1162.8039382398117
[2024-11-19 22:56:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1219
train_sample_count: 1219
avg_envstep_per_episode: 203.16666666666666
avg_sample_per_episode: 203.16666666666666
avg_envstep_per_sec: 799.2038381841157
avg_train_sample_per_sec: 799.2038381841157
avg_episode_per_sec: 3.933735052587936
collect_time: 1.525267950126103
reward_mean: 1024.8333740234375
reward_std: 353.42156982421875
reward_max: 1412.0
reward_min: 606.0
total_envstep_count: 915082
total_train_sample_count: 915065
total_episode_count: 6598
total_duration: 1164.3292061899378
[2024-11-19 22:56:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 765
train_sample_count: 765
avg_envstep_per_episode: 191.25
avg_sample_per_episode: 191.25
avg_envstep_per_sec: 806.9552655798509
avg_train_sample_per_sec: 806.9552655798509
avg_episode_per_sec: 4.219373937672423
collect_time: 0.9480079412460327
reward_mean: 916.0
reward_std: 318.53729248046875
reward_max: 1388.0
reward_min: 622.0
total_envstep_count: 916086
total_train_sample_count: 916046
total_episode_count: 6602
total_duration: 1165.2772141311839
[2024-11-19 22:56:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1503
train_sample_count: 1503
avg_envstep_per_episode: 187.875
avg_sample_per_episode: 187.875
avg_envstep_per_sec: 796.2004574380478
avg_train_sample_per_sec: 796.2004574380478
avg_episode_per_sec: 4.237926586496595
collect_time: 1.8877155695642742
reward_mean: 1154.375
reward_std: 337.138671875
reward_max: 1436.0
reward_min: 600.0
total_envstep_count: 917104
total_train_sample_count: 917057
total_episode_count: 6610
total_duration: 1167.1649297007482
[2024-11-19 22:57:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 527
train_sample_count: 527
avg_envstep_per_episode: 175.66666666666666
avg_sample_per_episode: 175.66666666666666
avg_envstep_per_sec: 794.6419686242558
avg_train_sample_per_sec: 794.6419686242558
avg_episode_per_sec: 4.523578569018534
collect_time: 0.6631917527743748
reward_mean: 1127.6666259765625
reward_std: 120.01480865478516
reward_max: 1297.0
reward_min: 1033.0
total_envstep_count: 918061
total_train_sample_count: 918028
total_episode_count: 6613
total_duration: 1167.8281214535225
[2024-11-19 22:57:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1217
train_sample_count: 1217
avg_envstep_per_episode: 152.125
avg_sample_per_episode: 152.125
avg_envstep_per_sec: 789.3780608326247
avg_train_sample_per_sec: 789.3780608326247
avg_episode_per_sec: 5.189009438505339
collect_time: 1.541720071009227
reward_mean: 1072.125
reward_std: 360.54974365234375
reward_max: 1434.0
reward_min: 653.0
total_envstep_count: 919085
total_train_sample_count: 919053
total_episode_count: 6621
total_duration: 1169.3698415245317
[2024-11-19 22:57:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1015
train_sample_count: 1015
avg_envstep_per_episode: 169.16666666666666
avg_sample_per_episode: 169.16666666666666
avg_envstep_per_sec: 795.7687915263798
avg_train_sample_per_sec: 795.7687915263798
avg_episode_per_sec: 4.704051969614068
collect_time: 1.2754961124488289
reward_mean: 854.8333129882812
reward_std: 185.169677734375
reward_max: 1041.0
reward_min: 615.0
total_envstep_count: 920066
total_train_sample_count: 920044
total_episode_count: 6627
total_duration: 1170.6453376369805
[2024-11-19 22:57:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1278
train_sample_count: 1278
avg_envstep_per_episode: 142.0
avg_sample_per_episode: 142.0
avg_envstep_per_sec: 801.8780044738677
avg_train_sample_per_sec: 801.8780044738677
avg_episode_per_sec: 5.647028200520195
collect_time: 1.5937586426734924
reward_mean: 1045.888916015625
reward_std: 508.5107727050781
reward_max: 1723.0
reward_min: 234.0
total_envstep_count: 921081
total_train_sample_count: 921046
total_episode_count: 6636
total_duration: 1172.239096279654
[2024-11-19 22:57:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 707
train_sample_count: 707
avg_envstep_per_episode: 141.4
avg_sample_per_episode: 141.4
avg_envstep_per_sec: 799.2362832512963
avg_train_sample_per_sec: 799.2362832512963
avg_episode_per_sec: 5.652307519457541
collect_time: 0.8845944745200021
reward_mean: 983.5999755859375
reward_std: 373.2980651855469
reward_max: 1438.0
reward_min: 604.0
total_envstep_count: 922100
total_train_sample_count: 922053
total_episode_count: 6641
total_duration: 1173.123690754174
[2024-11-19 22:57:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 564
train_sample_count: 564
avg_envstep_per_episode: 188.0
avg_sample_per_episode: 188.0
avg_envstep_per_sec: 797.4024326809363
avg_train_sample_per_sec: 797.4024326809363
avg_episode_per_sec: 4.241502301494342
collect_time: 0.707296563046319
reward_mean: 703.6666870117188
reward_std: 71.41117095947266
reward_max: 761.0
reward_min: 603.0
total_envstep_count: 923089
total_train_sample_count: 923037
total_episode_count: 6644
total_duration: 1173.8309873172204
[2024-11-19 22:57:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1730
train_sample_count: 1730
avg_envstep_per_episode: 173.0
avg_sample_per_episode: 173.0
avg_envstep_per_sec: 795.0726684732376
avg_train_sample_per_sec: 795.0726684732376
avg_episode_per_sec: 4.595795771521605
collect_time: 2.1759017365319386
reward_mean: 1009.7999877929688
reward_std: 377.0201110839844
reward_max: 1431.0
reward_min: 612.0
total_envstep_count: 924075
total_train_sample_count: 924035
total_episode_count: 6654
total_duration: 1176.0068890537523
[2024-11-19 22:57:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1068
train_sample_count: 1068
avg_envstep_per_episode: 133.5
avg_sample_per_episode: 133.5
avg_envstep_per_sec: 797.4802450526244
avg_train_sample_per_sec: 797.4802450526244
avg_episode_per_sec: 5.973634794401681
collect_time: 1.3392181268760137
reward_mean: 785.0
reward_std: 171.6508026123047
reward_max: 1054.0
reward_min: 600.0
total_envstep_count: 925068
total_train_sample_count: 925031
total_episode_count: 6662
total_duration: 1177.3461071806282
[2024-11-19 22:57:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 291
train_sample_count: 291
avg_envstep_per_episode: 145.5
avg_sample_per_episode: 145.5
avg_envstep_per_sec: 798.5516792566863
avg_train_sample_per_sec: 798.5516792566863
avg_episode_per_sec: 5.488327692485816
collect_time: 0.364409727709634
reward_mean: 1036.5
reward_std: 385.5
reward_max: 1422.0
reward_min: 651.0
total_envstep_count: 926058
total_train_sample_count: 926018
total_episode_count: 6664
total_duration: 1177.710516908338
[2024-11-19 22:57:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1254
train_sample_count: 1254
avg_envstep_per_episode: 179.14285714285714
avg_sample_per_episode: 179.14285714285714
avg_envstep_per_sec: 790.6988069167697
avg_train_sample_per_sec: 790.6988069167697
avg_episode_per_sec: 4.413789193315302
collect_time: 1.5859389049666266
reward_mean: 1014.4285888671875
reward_std: 448.2967224121094
reward_max: 1705.0
reward_min: 624.0
total_envstep_count: 927044
total_train_sample_count: 927020
total_episode_count: 6671
total_duration: 1179.2964558133046
[2024-11-19 22:57:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 717
train_sample_count: 717
avg_envstep_per_episode: 179.25
avg_sample_per_episode: 179.25
avg_envstep_per_sec: 797.5281073548183
avg_train_sample_per_sec: 797.5281073548183
avg_episode_per_sec: 4.449250250236085
collect_time: 0.899027875491551
reward_mean: 954.75
reward_std: 350.7594299316406
reward_max: 1558.0
reward_min: 705.0
total_envstep_count: 928024
total_train_sample_count: 927989
total_episode_count: 6675
total_duration: 1180.1954836887962
[2024-11-19 22:58:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 995
train_sample_count: 995
avg_envstep_per_episode: 199.0
avg_sample_per_episode: 199.0
avg_envstep_per_sec: 795.0929038725169
avg_train_sample_per_sec: 795.0929038725169
avg_episode_per_sec: 3.995441728002598
collect_time: 1.2514260851201555
reward_mean: 1028.800048828125
reward_std: 237.4147491455078
reward_max: 1392.0
reward_min: 642.0
total_envstep_count: 929035
total_train_sample_count: 928996
total_episode_count: 6680
total_duration: 1181.4469097739163
[2024-11-19 22:58:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1270
train_sample_count: 1270
avg_envstep_per_episode: 211.66666666666666
avg_sample_per_episode: 211.66666666666666
avg_envstep_per_sec: 794.1452805005081
avg_train_sample_per_sec: 794.1452805005081
avg_episode_per_sec: 3.7518674669315346
collect_time: 1.5992036107040586
reward_mean: 1316.0
reward_std: 310.6358947753906
reward_max: 1574.0
reward_min: 652.0
total_envstep_count: 930006
total_train_sample_count: 929978
total_episode_count: 6686
total_duration: 1183.0461133846204
[2024-11-19 22:58:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1260
train_sample_count: 1260
avg_envstep_per_episode: 140.0
avg_sample_per_episode: 140.0
avg_envstep_per_sec: 794.1128876674065
avg_train_sample_per_sec: 794.1128876674065
avg_episode_per_sec: 5.672234911910047
collect_time: 1.5866761761052266
reward_mean: 802.6666870117188
reward_std: 353.9322204589844
reward_max: 1426.0
reward_min: 247.0
total_envstep_count: 931037
total_train_sample_count: 930998
total_episode_count: 6695
total_duration: 1184.6327895607255
[2024-11-19 22:58:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 609
train_sample_count: 609
avg_envstep_per_episode: 121.8
avg_sample_per_episode: 121.8
avg_envstep_per_sec: 792.6795989511546
avg_train_sample_per_sec: 792.6795989511546
avg_episode_per_sec: 6.508042684328034
collect_time: 0.7682801485061646
reward_mean: 708.0
reward_std: 366.33154296875
reward_max: 1290.0
reward_min: 150.0
total_envstep_count: 932017
total_train_sample_count: 931991
total_episode_count: 6700
total_duration: 1185.4010697092317
[2024-11-19 22:58:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1249
train_sample_count: 1249
avg_envstep_per_episode: 178.42857142857142
avg_sample_per_episode: 178.42857142857142
avg_envstep_per_sec: 793.3269971390337
avg_train_sample_per_sec: 793.3269971390337
avg_episode_per_sec: 4.446188134486178
collect_time: 1.574382322175162
reward_mean: 1001.8571166992188
reward_std: 425.8424987792969
reward_max: 1431.0
reward_min: 167.0
total_envstep_count: 933021
total_train_sample_count: 932988
total_episode_count: 6707
total_duration: 1186.9754520314068
[2024-11-19 22:58:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1015
train_sample_count: 1015
avg_envstep_per_episode: 169.16666666666666
avg_sample_per_episode: 169.16666666666666
avg_envstep_per_sec: 791.669729550505
avg_train_sample_per_sec: 791.669729550505
avg_episode_per_sec: 4.679821061382295
collect_time: 1.2821003028324673
reward_mean: 1031.0
reward_std: 367.3222961425781
reward_max: 1435.0
reward_min: 617.0
total_envstep_count: 934040
total_train_sample_count: 933979
total_episode_count: 6713
total_duration: 1188.2575523342393
[2024-11-19 22:58:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 819
train_sample_count: 819
avg_envstep_per_episode: 204.75
avg_sample_per_episode: 204.75
avg_envstep_per_sec: 802.6736387874718
avg_train_sample_per_sec: 802.6736387874718
avg_episode_per_sec: 3.920261972099984
collect_time: 1.0203399743352617
reward_mean: 1265.25
reward_std: 316.80780029296875
reward_max: 1557.0
reward_min: 733.0
total_envstep_count: 935021
total_train_sample_count: 934990
total_episode_count: 6717
total_duration: 1189.2778923085746
[2024-11-19 22:58:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1117
train_sample_count: 1117
avg_envstep_per_episode: 186.16666666666666
avg_sample_per_episode: 186.16666666666666
avg_envstep_per_sec: 795.1841776420662
avg_train_sample_per_sec: 795.1841776420662
avg_episode_per_sec: 4.271356370503489
collect_time: 1.4047060183116367
reward_mean: 1185.5
reward_std: 385.87811279296875
reward_max: 1557.0
reward_min: 637.0
total_envstep_count: 936000
total_train_sample_count: 935975
total_episode_count: 6723
total_duration: 1190.6825983268861
[2024-11-19 22:58:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1308
train_sample_count: 1308
avg_envstep_per_episode: 130.8
avg_sample_per_episode: 130.8
avg_envstep_per_sec: 793.9666060265937
avg_train_sample_per_sec: 793.9666060265937
avg_episode_per_sec: 6.0700810858302265
collect_time: 1.647424450942448
reward_mean: 906.0999755859375
reward_std: 415.295166015625
reward_max: 1575.0
reward_min: 250.0
total_envstep_count: 937031
total_train_sample_count: 936995
total_episode_count: 6733
total_duration: 1192.3300227778286
[2024-11-19 22:58:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 516
train_sample_count: 516
avg_envstep_per_episode: 129.0
avg_sample_per_episode: 129.0
avg_envstep_per_sec: 795.9565702720231
avg_train_sample_per_sec: 795.9565702720231
avg_episode_per_sec: 6.170205971100954
collect_time: 0.6482765759740557
reward_mean: 662.5
reward_std: 79.04903411865234
reward_max: 798.0
reward_min: 602.0
total_envstep_count: 938027
total_train_sample_count: 937991
total_episode_count: 6737
total_duration: 1192.9782993538026
[2024-11-19 22:58:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 731
train_sample_count: 731
avg_envstep_per_episode: 182.75
avg_sample_per_episode: 182.75
avg_envstep_per_sec: 791.8670864105433
avg_train_sample_per_sec: 791.8670864105433
avg_episode_per_sec: 4.333062032342234
collect_time: 0.9231347186224801
reward_mean: 1010.0
reward_std: 260.8495788574219
reward_max: 1428.0
reward_min: 781.0
total_envstep_count: 939000
total_train_sample_count: 938974
total_episode_count: 6741
total_duration: 1193.9014340724252
[2024-11-19 22:58:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1658
train_sample_count: 1658
avg_envstep_per_episode: 150.72727272727272
avg_sample_per_episode: 150.72727272727272
avg_envstep_per_sec: 790.0590111118992
avg_train_sample_per_sec: 790.0590111118992
avg_episode_per_sec: 5.241646032708619
collect_time: 2.0985774184976305
reward_mean: 966.6363525390625
reward_std: 429.706298828125
reward_max: 1693.0
reward_min: 609.0
total_envstep_count: 940046
total_train_sample_count: 939984
total_episode_count: 6752
total_duration: 1196.0000114909228
[2024-11-19 22:58:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 707
train_sample_count: 707
avg_envstep_per_episode: 117.83333333333333
avg_sample_per_episode: 117.83333333333333
avg_envstep_per_sec: 786.5471501292923
avg_train_sample_per_sec: 786.5471501292923
avg_episode_per_sec: 6.675081896429637
collect_time: 0.8988653761999947
reward_mean: 949.8333129882812
reward_std: 469.683349609375
reward_max: 1431.0
reward_min: 250.0
total_envstep_count: 941026
total_train_sample_count: 940991
total_episode_count: 6758
total_duration: 1196.898876867123
[2024-11-19 22:58:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1340
train_sample_count: 1340
avg_envstep_per_episode: 134.0
avg_sample_per_episode: 134.0
avg_envstep_per_sec: 795.9836674382337
avg_train_sample_per_sec: 795.9836674382337
avg_episode_per_sec: 5.940176622673387
collect_time: 1.6834516269820077
reward_mean: 894.2999877929688
reward_std: 350.70587158203125
reward_max: 1425.0
reward_min: 604.0
total_envstep_count: 942050
total_train_sample_count: 942007
total_episode_count: 6768
total_duration: 1198.582328494105
[2024-11-19 22:58:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 977
train_sample_count: 977
avg_envstep_per_episode: 139.57142857142858
avg_sample_per_episode: 139.57142857142858
avg_envstep_per_sec: 802.6650008771195
avg_train_sample_per_sec: 802.6650008771195
avg_episode_per_sec: 5.750926311299731
collect_time: 1.2171952170985085
reward_mean: 864.0
reward_std: 358.2640686035156
reward_max: 1430.0
reward_min: 601.0
total_envstep_count: 943029
total_train_sample_count: 942984
total_episode_count: 6775
total_duration: 1199.7995237112036
[2024-11-19 22:58:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 870
train_sample_count: 870
avg_envstep_per_episode: 145.0
avg_sample_per_episode: 145.0
avg_envstep_per_sec: 799.0861585268145
avg_train_sample_per_sec: 799.0861585268145
avg_episode_per_sec: 5.510939024322859
collect_time: 1.0887436739036018
reward_mean: 1019.8333129882812
reward_std: 442.9012145996094
reward_max: 1433.0
reward_min: 249.0
total_envstep_count: 944008
total_train_sample_count: 943974
total_episode_count: 6781
total_duration: 1200.8882673851072
[2024-11-19 22:59:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 943
train_sample_count: 943
avg_envstep_per_episode: 157.16666666666666
avg_sample_per_episode: 157.16666666666666
avg_envstep_per_sec: 799.4167642353735
avg_train_sample_per_sec: 799.4167642353735
avg_episode_per_sec: 5.08642691984331
collect_time: 1.1796099884169442
reward_mean: 976.8333129882812
reward_std: 471.1554870605469
reward_max: 1430.0
reward_min: 244.0
total_envstep_count: 945019
total_train_sample_count: 944977
total_episode_count: 6787
total_duration: 1202.0678773735242
[2024-11-19 22:59:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 695
train_sample_count: 695
avg_envstep_per_episode: 173.75
avg_sample_per_episode: 173.75
avg_envstep_per_sec: 796.7617476216761
avg_train_sample_per_sec: 796.7617476216761
avg_episode_per_sec: 4.5856791230024525
collect_time: 0.8722808318478721
reward_mean: 1072.75
reward_std: 260.7780456542969
reward_max: 1338.0
reward_min: 809.0
total_envstep_count: 945991
total_train_sample_count: 945960
total_episode_count: 6791
total_duration: 1202.940158205372
[2024-11-19 22:59:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1332
train_sample_count: 1332
avg_envstep_per_episode: 190.28571428571428
avg_sample_per_episode: 190.28571428571428
avg_envstep_per_sec: 792.1505598694176
avg_train_sample_per_sec: 792.1505598694176
avg_episode_per_sec: 4.16295339270715
collect_time: 1.6814985275268555
reward_mean: 1454.857177734375
reward_std: 195.5946502685547
reward_max: 1700.0
reward_min: 1034.0
total_envstep_count: 946992
total_train_sample_count: 946956
total_episode_count: 6798
total_duration: 1204.6216567328988
[2024-11-19 22:59:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 893
train_sample_count: 893
avg_envstep_per_episode: 127.57142857142857
avg_sample_per_episode: 127.57142857142857
avg_envstep_per_sec: 802.6130067533464
avg_train_sample_per_sec: 802.6130067533464
avg_episode_per_sec: 6.2914793362524355
collect_time: 1.11261590889522
reward_mean: 949.8571166992188
reward_std: 391.9010009765625
reward_max: 1439.0
reward_min: 596.0
total_envstep_count: 948002
total_train_sample_count: 947957
total_episode_count: 6805
total_duration: 1205.734272641794
[2024-11-19 22:59:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1048
train_sample_count: 1048
avg_envstep_per_episode: 131.0
avg_sample_per_episode: 131.0
avg_envstep_per_sec: 789.0970850501287
avg_train_sample_per_sec: 789.0970850501287
avg_episode_per_sec: 6.0236418706116694
collect_time: 1.3281002044677734
reward_mean: 948.0
reward_std: 501.6701965332031
reward_max: 1428.0
reward_min: 249.0
total_envstep_count: 949011
total_train_sample_count: 948969
total_episode_count: 6813
total_duration: 1207.0623728462617
[2024-11-19 22:59:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1166
train_sample_count: 1166
avg_envstep_per_episode: 129.55555555555554
avg_sample_per_episode: 129.55555555555554
avg_envstep_per_sec: 790.8517513652591
avg_train_sample_per_sec: 790.8517513652591
avg_episode_per_sec: 6.104344564568895
collect_time: 1.474359762100946
reward_mean: 812.888916015625
reward_std: 375.4237365722656
reward_max: 1428.0
reward_min: 251.0
total_envstep_count: 950003
total_train_sample_count: 949979
total_episode_count: 6822
total_duration: 1208.5367326083626
[2024-11-19 22:59:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1120
train_sample_count: 1120
avg_envstep_per_episode: 160.0
avg_sample_per_episode: 160.0
avg_envstep_per_sec: 793.4501373082538
avg_train_sample_per_sec: 793.4501373082538
avg_episode_per_sec: 4.959063358176587
collect_time: 1.4115568796793618
reward_mean: 1104.0
reward_std: 354.3565673828125
reward_max: 1434.0
reward_min: 633.0
total_envstep_count: 951005
total_train_sample_count: 950967
total_episode_count: 6829
total_duration: 1209.948289488042
[2024-11-19 22:59:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 668
train_sample_count: 668
avg_envstep_per_episode: 133.6
avg_sample_per_episode: 133.6
avg_envstep_per_sec: 794.1477832316838
avg_train_sample_per_sec: 794.1477832316838
avg_episode_per_sec: 5.94421993436889
collect_time: 0.8411532640457153
reward_mean: 932.2000122070312
reward_std: 365.48126220703125
reward_max: 1418.0
reward_min: 613.0
total_envstep_count: 951977
total_train_sample_count: 951947
total_episode_count: 6834
total_duration: 1210.7894427520878
[2024-11-19 22:59:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 767
train_sample_count: 767
avg_envstep_per_episode: 127.83333333333333
avg_sample_per_episode: 127.83333333333333
avg_envstep_per_sec: 798.2382170248368
avg_train_sample_per_sec: 798.2382170248368
avg_episode_per_sec: 6.24436675638725
collect_time: 0.9608660468033381
reward_mean: 834.3333129882812
reward_std: 422.9813232421875
reward_max: 1438.0
reward_min: 251.0
total_envstep_count: 952987
total_train_sample_count: 952942
total_episode_count: 6840
total_duration: 1211.7503087988912
[2024-11-19 22:59:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1366
train_sample_count: 1366
avg_envstep_per_episode: 195.14285714285714
avg_sample_per_episode: 195.14285714285714
avg_envstep_per_sec: 787.846680362426
avg_train_sample_per_sec: 787.846680362426
avg_episode_per_sec: 4.037281670964116
collect_time: 1.7338398879482633
reward_mean: 1134.142822265625
reward_std: 398.3944091796875
reward_max: 1632.0
reward_min: 620.0
total_envstep_count: 953973
total_train_sample_count: 953948
total_episode_count: 6847
total_duration: 1213.4841486868395
[2024-11-19 22:59:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 955
train_sample_count: 955
avg_envstep_per_episode: 136.42857142857142
avg_sample_per_episode: 136.42857142857142
avg_envstep_per_sec: 800.2935133145478
avg_train_sample_per_sec: 800.2935133145478
avg_episode_per_sec: 5.8660257520438055
collect_time: 1.1933121837320781
reward_mean: 1036.2857666015625
reward_std: 359.1468811035156
reward_max: 1436.0
reward_min: 622.0
total_envstep_count: 954967
total_train_sample_count: 954939
total_episode_count: 6854
total_duration: 1214.6774608705716
[2024-11-19 22:59:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 958
train_sample_count: 958
avg_envstep_per_episode: 119.75
avg_sample_per_episode: 119.75
avg_envstep_per_sec: 792.407427085624
avg_train_sample_per_sec: 792.407427085624
avg_episode_per_sec: 6.617181019504167
collect_time: 1.2089740293366569
reward_mean: 783.625
reward_std: 275.6841125488281
reward_max: 1431.0
reward_min: 599.0
total_envstep_count: 955954
total_train_sample_count: 955921
total_episode_count: 6862
total_duration: 1215.8864348999082
[2024-11-19 22:59:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 899
train_sample_count: 899
avg_envstep_per_episode: 128.42857142857142
avg_sample_per_episode: 128.42857142857142
avg_envstep_per_sec: 795.2974980565763
avg_train_sample_per_sec: 795.2974980565763
avg_episode_per_sec: 6.1925277935439755
collect_time: 1.1303946035248893
reward_mean: 790.0
reward_std: 377.266845703125
reward_max: 1345.0
reward_min: 169.0
total_envstep_count: 956965
total_train_sample_count: 956928
total_episode_count: 6869
total_duration: 1217.016829503433
[2024-11-19 22:59:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 896
train_sample_count: 896
avg_envstep_per_episode: 149.33333333333334
avg_sample_per_episode: 149.33333333333334
avg_envstep_per_sec: 800.2106206436803
avg_train_sample_per_sec: 800.2106206436803
avg_episode_per_sec: 5.35855326323893
collect_time: 1.1197052087102617
reward_mean: 904.1666870117188
reward_std: 388.0993957519531
reward_max: 1578.0
reward_min: 628.0
total_envstep_count: 957953
total_train_sample_count: 957932
total_episode_count: 6875
total_duration: 1218.1365347121432
[2024-11-19 22:59:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1190
train_sample_count: 1190
avg_envstep_per_episode: 148.75
avg_sample_per_episode: 148.75
avg_envstep_per_sec: 796.9851957829261
avg_train_sample_per_sec: 796.9851957829261
avg_episode_per_sec: 5.357883669128915
collect_time: 1.4931268564292364
reward_mean: 946.375
reward_std: 476.9116516113281
reward_max: 1440.0
reward_min: 237.0
total_envstep_count: 958963
total_train_sample_count: 958930
total_episode_count: 6883
total_duration: 1219.6296615685724
[2024-11-19 22:59:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1316
train_sample_count: 1316
avg_envstep_per_episode: 164.5
avg_sample_per_episode: 164.5
avg_envstep_per_sec: 791.085459904525
avg_train_sample_per_sec: 791.085459904525
avg_episode_per_sec: 4.809030151395289
collect_time: 1.663537085056305
reward_mean: 1069.75
reward_std: 370.9726257324219
reward_max: 1585.0
reward_min: 611.0
total_envstep_count: 959948
total_train_sample_count: 959922
total_episode_count: 6891
total_duration: 1221.2931986536287
[2024-11-19 22:59:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 887
train_sample_count: 887
avg_envstep_per_episode: 126.71428571428571
avg_sample_per_episode: 126.71428571428571
avg_envstep_per_sec: 792.0820979944316
avg_train_sample_per_sec: 792.0820979944316
avg_episode_per_sec: 6.2509297474194145
collect_time: 1.119833414043699
reward_mean: 796.5714111328125
reward_std: 264.72027587890625
reward_max: 1338.0
reward_min: 599.0
total_envstep_count: 960950
total_train_sample_count: 960905
total_episode_count: 6898
total_duration: 1222.4130320676725
[2024-11-19 23:00:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 792
train_sample_count: 792
avg_envstep_per_episode: 132.0
avg_sample_per_episode: 132.0
avg_envstep_per_sec: 785.3919427011488
avg_train_sample_per_sec: 785.3919427011488
avg_episode_per_sec: 5.949938959857187
collect_time: 1.0084137065070016
reward_mean: 743.1666870117188
reward_std: 440.5838317871094
reward_max: 1315.0
reward_min: 238.0
total_envstep_count: 961952
total_train_sample_count: 961913
total_episode_count: 6904
total_duration: 1223.4214457741796
[2024-11-19 23:00:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 898
train_sample_count: 898
avg_envstep_per_episode: 149.66666666666666
avg_sample_per_episode: 149.66666666666666
avg_envstep_per_sec: 787.0334720746988
avg_train_sample_per_sec: 787.0334720746988
avg_episode_per_sec: 5.25857553724743
collect_time: 1.1409934035369327
reward_mean: 1099.1666259765625
reward_std: 318.689697265625
reward_max: 1330.0
reward_min: 646.0
total_envstep_count: 962978
total_train_sample_count: 962931
total_episode_count: 6910
total_duration: 1224.5624391777164
[2024-11-19 23:00:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 981
train_sample_count: 981
avg_envstep_per_episode: 196.2
avg_sample_per_episode: 196.2
avg_envstep_per_sec: 786.929137927704
avg_train_sample_per_sec: 786.929137927704
avg_episode_per_sec: 4.0108518752686235
collect_time: 1.2466179643358504
reward_mean: 1107.5999755859375
reward_std: 356.9109802246094
reward_max: 1425.0
reward_min: 555.0
total_envstep_count: 963945
total_train_sample_count: 963912
total_episode_count: 6915
total_duration: 1225.8090571420523
[2024-11-19 23:00:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 945
train_sample_count: 945
avg_envstep_per_episode: 157.5
avg_sample_per_episode: 157.5
avg_envstep_per_sec: 791.0800578120434
avg_train_sample_per_sec: 791.0800578120434
avg_episode_per_sec: 5.0227305257907515
collect_time: 1.1945693620613644
reward_mean: 867.3333129882812
reward_std: 316.6152648925781
reward_max: 1322.0
reward_min: 578.0
total_envstep_count: 964947
total_train_sample_count: 964905
total_episode_count: 6921
total_duration: 1227.0036265041138
[2024-11-19 23:00:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 933
train_sample_count: 933
avg_envstep_per_episode: 155.5
avg_sample_per_episode: 155.5
avg_envstep_per_sec: 799.8163686826327
avg_train_sample_per_sec: 799.8163686826327
avg_episode_per_sec: 5.1435136249686995
collect_time: 1.1665177614915938
reward_mean: 989.5
reward_std: 376.21923828125
reward_max: 1429.0
reward_min: 588.0
total_envstep_count: 965949
total_train_sample_count: 965898
total_episode_count: 6927
total_duration: 1228.1701442656054
[2024-11-19 23:00:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1279
train_sample_count: 1279
avg_envstep_per_episode: 159.875
avg_sample_per_episode: 159.875
avg_envstep_per_sec: 796.2413355096193
avg_train_sample_per_sec: 796.2413355096193
avg_episode_per_sec: 4.980399283875649
collect_time: 1.6062969139644077
reward_mean: 963.0
reward_std: 359.87255859375
reward_max: 1683.0
reward_min: 619.0
total_envstep_count: 966925
total_train_sample_count: 966889
total_episode_count: 6935
total_duration: 1229.7764411795697
[2024-11-19 23:00:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 926
train_sample_count: 926
avg_envstep_per_episode: 115.75
avg_sample_per_episode: 115.75
avg_envstep_per_sec: 783.6830660863072
avg_train_sample_per_sec: 783.6830660863072
avg_episode_per_sec: 6.7704800525814886
collect_time: 1.1816001137097676
reward_mean: 734.75
reward_std: 397.3498840332031
reward_max: 1351.0
reward_min: 251.0
total_envstep_count: 967910
total_train_sample_count: 967875
total_episode_count: 6943
total_duration: 1230.9580412932794
[2024-11-19 23:00:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 937
train_sample_count: 937
avg_envstep_per_episode: 156.16666666666666
avg_sample_per_episode: 156.16666666666666
avg_envstep_per_sec: 789.9388733122805
avg_train_sample_per_sec: 789.9388733122805
avg_episode_per_sec: 5.058306552693365
collect_time: 1.1861677297524045
reward_mean: 1056.3333740234375
reward_std: 371.2154235839844
reward_max: 1578.0
reward_min: 615.0
total_envstep_count: 968904
total_train_sample_count: 968872
total_episode_count: 6949
total_duration: 1232.1442090230319
[2024-11-19 23:00:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 843
train_sample_count: 843
avg_envstep_per_episode: 105.375
avg_sample_per_episode: 105.375
avg_envstep_per_sec: 791.4071754752482
avg_train_sample_per_sec: 791.4071754752482
avg_episode_per_sec: 7.510388379361786
collect_time: 1.065191251891
reward_mean: 616.625
reward_std: 268.8986511230469
reward_max: 1050.0
reward_min: 198.0
total_envstep_count: 969905
total_train_sample_count: 969859
total_episode_count: 6957
total_duration: 1233.209400274923
[2024-11-19 23:00:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 962
train_sample_count: 962
avg_envstep_per_episode: 160.33333333333334
avg_sample_per_episode: 160.33333333333334
avg_envstep_per_sec: 789.1258255168518
avg_train_sample_per_sec: 789.1258255168518
avg_episode_per_sec: 4.9217826955313
collect_time: 1.2190704814025333
reward_mean: 1069.3333740234375
reward_std: 514.5128784179688
reward_max: 1845.0
reward_min: 249.0
total_envstep_count: 970875
total_train_sample_count: 970833
total_episode_count: 6963
total_duration: 1234.4284707563254
[2024-11-19 23:00:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 954
train_sample_count: 954
avg_envstep_per_episode: 190.8
avg_sample_per_episode: 190.8
avg_envstep_per_sec: 789.5523066813425
avg_train_sample_per_sec: 789.5523066813425
avg_episode_per_sec: 4.138114814891733
collect_time: 1.2082796692848208
reward_mean: 1012.0
reward_std: 285.5093688964844
reward_max: 1332.0
reward_min: 593.0
total_envstep_count: 971879
total_train_sample_count: 971823
total_episode_count: 6968
total_duration: 1235.6367504256102
[2024-11-19 23:00:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1033
train_sample_count: 1033
avg_envstep_per_episode: 172.16666666666666
avg_sample_per_episode: 172.16666666666666
avg_envstep_per_sec: 788.5757785195245
avg_train_sample_per_sec: 788.5757785195245
avg_episode_per_sec: 4.580304618700046
collect_time: 1.3099565420831953
reward_mean: 1143.5
reward_std: 352.5718688964844
reward_max: 1435.0
reward_min: 640.0
total_envstep_count: 972882
total_train_sample_count: 972844
total_episode_count: 6974
total_duration: 1236.9467069676934
[2024-11-19 23:00:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1457
train_sample_count: 1457
avg_envstep_per_episode: 182.125
avg_sample_per_episode: 182.125
avg_envstep_per_sec: 785.383874167267
avg_train_sample_per_sec: 785.383874167267
avg_episode_per_sec: 4.312334243883415
collect_time: 1.855143768446786
reward_mean: 1011.75
reward_std: 340.5046691894531
reward_max: 1421.0
reward_min: 616.0
total_envstep_count: 973892
total_train_sample_count: 973845
total_episode_count: 6982
total_duration: 1238.8018507361403
[2024-11-19 23:00:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 685
train_sample_count: 685
avg_envstep_per_episode: 114.16666666666667
avg_sample_per_episode: 114.16666666666667
avg_envstep_per_sec: 797.0208221059409
avg_train_sample_per_sec: 797.0208221059409
avg_episode_per_sec: 6.981204281219919
collect_time: 0.859450570174626
reward_mean: 697.6666870117188
reward_std: 158.0565948486328
reward_max: 1039.0
reward_min: 583.0
total_envstep_count: 974880
total_train_sample_count: 974866
total_episode_count: 6988
total_duration: 1239.661301306315
[2024-11-19 23:00:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1125
train_sample_count: 1125
avg_envstep_per_episode: 140.625
avg_sample_per_episode: 140.625
avg_envstep_per_sec: 794.4740756533317
avg_train_sample_per_sec: 794.4740756533317
avg_episode_per_sec: 5.649593426868137
collect_time: 1.4160311009202684
reward_mean: 886.875
reward_std: 396.36578369140625
reward_max: 1430.0
reward_min: 252.0
total_envstep_count: 975888
total_train_sample_count: 975847
total_episode_count: 6996
total_duration: 1241.0773324072352
[2024-11-19 23:00:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 977
train_sample_count: 977
avg_envstep_per_episode: 162.83333333333334
avg_sample_per_episode: 162.83333333333334
avg_envstep_per_sec: 796.1842778534377
avg_train_sample_per_sec: 796.1842778534377
avg_episode_per_sec: 4.889565677707909
collect_time: 1.2271028544221605
reward_mean: 889.5
reward_std: 345.9849548339844
reward_max: 1425.0
reward_min: 581.0
total_envstep_count: 976874
total_train_sample_count: 976836
total_episode_count: 7002
total_duration: 1242.3044352616573
[2024-11-19 23:01:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 920
train_sample_count: 920
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 793.9945593008721
avg_train_sample_per_sec: 793.9945593008721
avg_episode_per_sec: 4.315187822287348
collect_time: 1.1586981160300118
reward_mean: 915.0
reward_std: 329.2002258300781
reward_max: 1322.0
reward_min: 598.0
total_envstep_count: 977853
total_train_sample_count: 977816
total_episode_count: 7007
total_duration: 1243.4631333776874
[2024-11-19 23:01:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 908
train_sample_count: 908
avg_envstep_per_episode: 181.6
avg_sample_per_episode: 181.6
avg_envstep_per_sec: 799.3736052489338
avg_train_sample_per_sec: 799.3736052489338
avg_episode_per_sec: 4.401837033309107
collect_time: 1.1358893939426968
reward_mean: 917.5999755859375
reward_std: 421.0223693847656
reward_max: 1318.0
reward_min: 193.0
total_envstep_count: 978840
total_train_sample_count: 978796
total_episode_count: 7012
total_duration: 1244.5990227716302
[2024-11-19 23:01:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 553
train_sample_count: 553
avg_envstep_per_episode: 184.33333333333334
avg_sample_per_episode: 184.33333333333334
avg_envstep_per_sec: 790.1996291167559
avg_train_sample_per_sec: 790.1996291167559
avg_episode_per_sec: 4.286797264647862
collect_time: 0.6998231581279211
reward_mean: 1075.3333740234375
reward_std: 324.1217041015625
reward_max: 1310.0
reward_min: 617.0
total_envstep_count: 979813
total_train_sample_count: 979769
total_episode_count: 7015
total_duration: 1245.298845929758
[2024-11-19 23:01:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1786
train_sample_count: 1786
avg_envstep_per_episode: 178.6
avg_sample_per_episode: 178.6
avg_envstep_per_sec: 797.3167061383543
avg_train_sample_per_sec: 797.3167061383543
avg_episode_per_sec: 4.4642592728911215
collect_time: 2.2400132673127313
reward_mean: 869.5999755859375
reward_std: 267.3900451660156
reward_max: 1301.0
reward_min: 594.0
total_envstep_count: 980819
total_train_sample_count: 980775
total_episode_count: 7025
total_duration: 1247.5388591970707
[2024-11-19 23:01:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 667
train_sample_count: 667
avg_envstep_per_episode: 133.4
avg_sample_per_episode: 133.4
avg_envstep_per_sec: 796.6436961837712
avg_train_sample_per_sec: 796.6436961837712
avg_episode_per_sec: 5.971841800478045
collect_time: 0.8372626347201211
reward_mean: 954.5999755859375
reward_std: 447.05194091796875
reward_max: 1322.0
reward_min: 251.0
total_envstep_count: 981799
total_train_sample_count: 981754
total_episode_count: 7030
total_duration: 1248.376121831791
[2024-11-19 23:01:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1089
train_sample_count: 1089
avg_envstep_per_episode: 181.5
avg_sample_per_episode: 181.5
avg_envstep_per_sec: 796.9426266903881
avg_train_sample_per_sec: 796.9426266903881
avg_episode_per_sec: 4.390868466613709
collect_time: 1.3664722698075429
reward_mean: 999.0
reward_std: 405.73553466796875
reward_max: 1566.0
reward_min: 598.0
total_envstep_count: 982801
total_train_sample_count: 982747
total_episode_count: 7036
total_duration: 1249.7425941015983
[2024-11-19 23:01:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 598
train_sample_count: 598
avg_envstep_per_episode: 119.6
avg_sample_per_episode: 119.6
avg_envstep_per_sec: 801.0118697287887
avg_train_sample_per_sec: 801.0118697287887
avg_episode_per_sec: 6.697423659939705
collect_time: 0.7465557285717556
reward_mean: 786.4000244140625
reward_std: 279.53216552734375
reward_max: 1322.0
reward_min: 586.0
total_envstep_count: 983765
total_train_sample_count: 983741
total_episode_count: 7041
total_duration: 1250.4891498301702
[2024-11-19 23:01:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 871
train_sample_count: 871
avg_envstep_per_episode: 174.2
avg_sample_per_episode: 174.2
avg_envstep_per_sec: 798.0716486273177
avg_train_sample_per_sec: 798.0716486273177
avg_episode_per_sec: 4.581352747573581
collect_time: 1.091380706855229
reward_mean: 890.0
reward_std: 550.457275390625
reward_max: 1643.0
reward_min: 76.0
total_envstep_count: 984760
total_train_sample_count: 984720
total_episode_count: 7046
total_duration: 1251.5805305370254
[2024-11-19 23:01:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 636
train_sample_count: 636
avg_envstep_per_episode: 212.0
avg_sample_per_episode: 212.0
avg_envstep_per_sec: 798.965685868006
avg_train_sample_per_sec: 798.965685868006
avg_episode_per_sec: 3.7687060654151225
collect_time: 0.7960291802883148
reward_mean: 882.0
reward_std: 197.30349731445312
reward_max: 1025.0
reward_min: 603.0
total_envstep_count: 985741
total_train_sample_count: 985704
total_episode_count: 7049
total_duration: 1252.3765597173137
[2024-11-19 23:01:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1195
train_sample_count: 1195
avg_envstep_per_episode: 199.16666666666666
avg_sample_per_episode: 199.16666666666666
avg_envstep_per_sec: 804.523771132327
avg_train_sample_per_sec: 804.523771132327
avg_episode_per_sec: 4.039449896898714
collect_time: 1.4853507663522447
reward_mean: 780.6666870117188
reward_std: 233.51492309570312
reward_max: 1262.0
reward_min: 578.0
total_envstep_count: 986721
total_train_sample_count: 986683
total_episode_count: 7055
total_duration: 1253.861910483666
[2024-11-19 23:01:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1147
train_sample_count: 1147
avg_envstep_per_episode: 163.85714285714286
avg_sample_per_episode: 163.85714285714286
avg_envstep_per_sec: 801.0944069723146
avg_train_sample_per_sec: 801.0944069723146
avg_episode_per_sec: 4.888980687712469
collect_time: 1.4317912970270428
reward_mean: 926.7142944335938
reward_std: 330.5790100097656
reward_max: 1321.0
reward_min: 604.0
total_envstep_count: 987707
total_train_sample_count: 987662
total_episode_count: 7062
total_duration: 1255.293701780693
[2024-11-19 23:01:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1314
train_sample_count: 1314
avg_envstep_per_episode: 262.8
avg_sample_per_episode: 262.8
avg_envstep_per_sec: 799.0334746571677
avg_train_sample_per_sec: 799.0334746571677
avg_episode_per_sec: 3.0404622323332107
collect_time: 1.6444867977074216
reward_mean: 1184.5999755859375
reward_std: 352.34222412109375
reward_max: 1594.0
reward_min: 583.0
total_envstep_count: 988687
total_train_sample_count: 988640
total_episode_count: 7067
total_duration: 1256.9381885784005
[2024-11-19 23:01:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 869
train_sample_count: 869
avg_envstep_per_episode: 173.8
avg_sample_per_episode: 173.8
avg_envstep_per_sec: 799.8694176978148
avg_train_sample_per_sec: 799.8694176978148
avg_episode_per_sec: 4.602240608157738
collect_time: 1.0864273352282388
reward_mean: 1156.199951171875
reward_std: 380.6906433105469
reward_max: 1690.0
reward_min: 635.0
total_envstep_count: 989667
total_train_sample_count: 989629
total_episode_count: 7072
total_duration: 1258.0246159136288
[2024-11-19 23:01:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 990
train_sample_count: 990
avg_envstep_per_episode: 165.0
avg_sample_per_episode: 165.0
avg_envstep_per_sec: 802.5862136198463
avg_train_sample_per_sec: 802.5862136198463
avg_episode_per_sec: 4.864158870423311
collect_time: 1.233512341976166
reward_mean: 1021.6666870117188
reward_std: 317.9447937011719
reward_max: 1320.0
reward_min: 589.0
total_envstep_count: 990670
total_train_sample_count: 990643
total_episode_count: 7078
total_duration: 1259.258128255605
[2024-11-19 23:01:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 837
train_sample_count: 837
avg_envstep_per_episode: 167.4
avg_sample_per_episode: 167.4
avg_envstep_per_sec: 803.744412345704
avg_train_sample_per_sec: 803.744412345704
avg_episode_per_sec: 4.80134057554184
collect_time: 1.0413758243833269
reward_mean: 803.5999755859375
reward_std: 411.445556640625
reward_max: 1300.0
reward_min: 246.0
total_envstep_count: 991643
total_train_sample_count: 991624
total_episode_count: 7083
total_duration: 1260.2995040799883
[2024-11-19 23:01:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1358
train_sample_count: 1358
avg_envstep_per_episode: 194.0
avg_sample_per_episode: 194.0
avg_envstep_per_sec: 793.8057319332254
avg_train_sample_per_sec: 793.8057319332254
avg_episode_per_sec: 4.091782123367142
collect_time: 1.7107460243361337
reward_mean: 1019.0
reward_std: 358.2341613769531
reward_max: 1400.0
reward_min: 576.0
total_envstep_count: 992636
total_train_sample_count: 992610
total_episode_count: 7090
total_duration: 1262.0102501043245
[2024-11-19 23:01:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 822
train_sample_count: 822
avg_envstep_per_episode: 164.4
avg_sample_per_episode: 164.4
avg_envstep_per_sec: 811.6330876962303
avg_train_sample_per_sec: 811.6330876962303
avg_episode_per_sec: 4.936940922726462
collect_time: 1.0127729049750738
reward_mean: 1085.0
reward_std: 392.40948486328125
reward_max: 1557.0
reward_min: 615.0
total_envstep_count: 993631
total_train_sample_count: 993588
total_episode_count: 7095
total_duration: 1263.0230230092995
[2024-11-19 23:02:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 865
train_sample_count: 865
avg_envstep_per_episode: 173.0
avg_sample_per_episode: 173.0
avg_envstep_per_sec: 622.3291303668891
avg_train_sample_per_sec: 622.3291303668891
avg_episode_per_sec: 3.5972782102132315
collect_time: 1.389939756620498
reward_mean: 1041.800048828125
reward_std: 329.30615234375
reward_max: 1314.0
reward_min: 635.0
total_envstep_count: 994602
total_train_sample_count: 994561
total_episode_count: 7100
total_duration: 1264.4129627659202
[2024-11-19 23:02:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1406
train_sample_count: 1406
avg_envstep_per_episode: 200.85714285714286
avg_sample_per_episode: 200.85714285714286
avg_envstep_per_sec: 804.5091764075664
avg_train_sample_per_sec: 804.5091764075664
avg_episode_per_sec: 4.005379967889733
collect_time: 1.7476494255520048
reward_mean: 1141.7142333984375
reward_std: 380.8770751953125
reward_max: 1413.0
reward_min: 247.0
total_envstep_count: 995579
total_train_sample_count: 995535
total_episode_count: 7107
total_duration: 1266.1606121914722
[2024-11-19 23:02:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 273
train_sample_count: 273
avg_envstep_per_episode: 91.0
avg_sample_per_episode: 91.0
avg_envstep_per_sec: 799.017704798932
avg_train_sample_per_sec: 799.017704798932
avg_episode_per_sec: 8.780414338449802
collect_time: 0.3416695254189628
reward_mean: 559.3333129882812
reward_std: 516.6600341796875
reward_max: 1290.0
reward_min: 193.0
total_envstep_count: 996536
total_train_sample_count: 996504
total_episode_count: 7110
total_duration: 1266.502281716891
[2024-11-19 23:02:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1453
train_sample_count: 1453
avg_envstep_per_episode: 161.44444444444446
avg_sample_per_episode: 161.44444444444446
avg_envstep_per_sec: 795.3715534187074
avg_train_sample_per_sec: 795.3715534187074
avg_episode_per_sec: 4.926595995022964
collect_time: 1.826819168669837
reward_mean: 1006.3333129882812
reward_std: 358.4497375488281
reward_max: 1339.0
reward_min: 578.0
total_envstep_count: 997553
total_train_sample_count: 997525
total_episode_count: 7119
total_duration: 1268.3291008855608
[2024-11-19 23:02:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 177
train_sample_count: 177
avg_envstep_per_episode: 177.0
avg_sample_per_episode: 177.0
avg_envstep_per_sec: 791.1368277396933
avg_train_sample_per_sec: 791.1368277396933
avg_episode_per_sec: 4.46969959174968
collect_time: 0.2237286823136466
reward_mean: 1340.0
reward_std: 0.0
reward_max: 1340.0
reward_min: 1340.0
total_envstep_count: 998648
total_train_sample_count: 998602
total_episode_count: 7120
total_duration: 1268.5528295678744
[2024-11-19 23:02:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1411
train_sample_count: 1411
avg_envstep_per_episode: 235.16666666666666
avg_sample_per_episode: 235.16666666666666
avg_envstep_per_sec: 801.7433908242906
avg_train_sample_per_sec: 801.7433908242906
avg_episode_per_sec: 3.4092560913860694
collect_time: 1.7599147260189059
reward_mean: 1331.6666259765625
reward_std: 190.36865234375
reward_max: 1678.0
reward_min: 1021.0
total_envstep_count: 999644
total_train_sample_count: 999617
total_episode_count: 7126
total_duration: 1270.3127442938933
[2024-11-19 23:02:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 622
train_sample_count: 622
avg_envstep_per_episode: 124.4
avg_sample_per_episode: 124.4
avg_envstep_per_sec: 786.6189199482295
avg_train_sample_per_sec: 786.6189199482295
avg_episode_per_sec: 6.323303215017923
collect_time: 0.7907259591988154
reward_mean: 595.2000122070312
reward_std: 188.76058959960938
reward_max: 741.0
reward_min: 229.0
total_envstep_count: 1000639
total_train_sample_count: 1000599
total_episode_count: 7131
total_duration: 1271.1034702530922
[2024-11-19 23:02:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 930
train_sample_count: 930
avg_envstep_per_episode: 155.0
avg_sample_per_episode: 155.0
avg_envstep_per_sec: 797.4523050809815
avg_train_sample_per_sec: 797.4523050809815
avg_episode_per_sec: 5.144853581167623
collect_time: 1.166213946683066
reward_mean: 1011.5
reward_std: 391.8093566894531
reward_max: 1554.0
reward_min: 612.0
total_envstep_count: 1001633
total_train_sample_count: 1001589
total_episode_count: 7137
total_duration: 1272.2696841997752
[2024-11-19 23:02:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1250
train_sample_count: 1250
avg_envstep_per_episode: 138.88888888888889
avg_sample_per_episode: 138.88888888888889
avg_envstep_per_sec: 800.9041011266864
avg_train_sample_per_sec: 800.9041011266864
avg_episode_per_sec: 5.766509528112143
collect_time: 1.5607361708368577
reward_mean: 723.111083984375
reward_std: 378.7477722167969
reward_max: 1329.0
reward_min: 196.0
total_envstep_count: 1002617
total_train_sample_count: 1002587
total_episode_count: 7146
total_duration: 1273.830420370612
[2024-11-19 23:02:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 598
train_sample_count: 598
avg_envstep_per_episode: 119.6
avg_sample_per_episode: 119.6
avg_envstep_per_sec: 797.9886088609887
avg_train_sample_per_sec: 797.9886088609887
avg_episode_per_sec: 6.672145559038368
collect_time: 0.7493841307503837
reward_mean: 915.4000244140625
reward_std: 254.55577087402344
reward_max: 1344.0
reward_min: 612.0
total_envstep_count: 1003628
total_train_sample_count: 1003581
total_episode_count: 7151
total_duration: 1274.5798045013623
[2024-11-19 23:02:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 698
train_sample_count: 698
avg_envstep_per_episode: 116.33333333333333
avg_sample_per_episode: 116.33333333333333
avg_envstep_per_sec: 788.3602321054495
avg_train_sample_per_sec: 788.3602321054495
avg_episode_per_sec: 6.776735519531085
collect_time: 0.8853820519787924
reward_mean: 804.0
reward_std: 421.4826965332031
reward_max: 1410.0
reward_min: 248.0
total_envstep_count: 1004607
total_train_sample_count: 1004591
total_episode_count: 7157
total_duration: 1275.465186553341
[2024-11-19 23:02:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 948
train_sample_count: 948
avg_envstep_per_episode: 158.0
avg_sample_per_episode: 158.0
avg_envstep_per_sec: 804.6510241203408
avg_train_sample_per_sec: 804.6510241203408
avg_episode_per_sec: 5.09272800076165
collect_time: 1.1781504920550756
reward_mean: 1000.0
reward_std: 341.0273742675781
reward_max: 1342.0
reward_min: 581.0
total_envstep_count: 1005634
total_train_sample_count: 1005587
total_episode_count: 7163
total_duration: 1276.643337045396
[2024-11-19 23:02:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 784
train_sample_count: 784
avg_envstep_per_episode: 196.0
avg_sample_per_episode: 196.0
avg_envstep_per_sec: 796.4579477598022
avg_train_sample_per_sec: 796.4579477598022
avg_episode_per_sec: 4.063560957958175
collect_time: 0.9843583106994629
reward_mean: 1076.0
reward_std: 488.5795593261719
reward_max: 1744.0
reward_min: 580.0
total_envstep_count: 1006630
total_train_sample_count: 1006599
total_episode_count: 7167
total_duration: 1277.6276953560955
[2024-11-19 23:02:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 794
train_sample_count: 794
avg_envstep_per_episode: 198.5
avg_sample_per_episode: 198.5
avg_envstep_per_sec: 792.6368211198936
avg_train_sample_per_sec: 792.6368211198936
avg_episode_per_sec: 3.99313260010022
collect_time: 1.0017198026180267
reward_mean: 915.0
reward_std: 290.6398010253906
reward_max: 1317.0
reward_min: 582.0
total_envstep_count: 1007618
total_train_sample_count: 1007573
total_episode_count: 7171
total_duration: 1278.6294151587135
[2024-11-19 23:02:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1057
train_sample_count: 1057
avg_envstep_per_episode: 211.4
avg_sample_per_episode: 211.4
avg_envstep_per_sec: 802.7665046146024
avg_train_sample_per_sec: 802.7665046146024
avg_episode_per_sec: 3.797381762604552
collect_time: 1.3166966906615665
reward_mean: 1270.800048828125
reward_std: 369.6021423339844
reward_max: 1691.0
reward_min: 581.0
total_envstep_count: 1008607
total_train_sample_count: 1008582
total_episode_count: 7176
total_duration: 1279.946111849375
[2024-11-19 23:02:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 935
train_sample_count: 935
avg_envstep_per_episode: 187.0
avg_sample_per_episode: 187.0
avg_envstep_per_sec: 823.0843881530301
avg_train_sample_per_sec: 823.0843881530301
avg_episode_per_sec: 4.401520792262193
collect_time: 1.1359710054738181
reward_mean: 1233.5999755859375
reward_std: 338.7539367675781
reward_max: 1582.0
reward_min: 584.0
total_envstep_count: 1009618
total_train_sample_count: 1009565
total_episode_count: 7181
total_duration: 1281.0820828548487
[2024-11-19 23:03:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2928
train_sample_count: 2928
avg_envstep_per_episode: 488.0
avg_sample_per_episode: 488.0
avg_envstep_per_sec: 799.0209919334078
avg_train_sample_per_sec: 799.0209919334078
avg_episode_per_sec: 1.6373380982241963
collect_time: 3.664484449795314
reward_mean: 993.0
reward_std: 359.3693542480469
reward_max: 1371.0
reward_min: 570.0
total_envstep_count: 1010606
total_train_sample_count: 1010573
total_episode_count: 7187
total_duration: 1284.746567304644
[2024-11-19 23:03:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1032
train_sample_count: 1032
avg_envstep_per_episode: 147.42857142857142
avg_sample_per_episode: 147.42857142857142
avg_envstep_per_sec: 810.0754598566957
avg_train_sample_per_sec: 810.0754598566957
avg_episode_per_sec: 5.494697886624874
collect_time: 1.2739553919860296
reward_mean: 735.1428833007812
reward_std: 450.2949523925781
reward_max: 1404.0
reward_min: 199.0
total_envstep_count: 1011584
total_train_sample_count: 1011557
total_episode_count: 7194
total_duration: 1286.02052269663
[2024-11-19 23:03:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 881
train_sample_count: 881
avg_envstep_per_episode: 176.2
avg_sample_per_episode: 176.2
avg_envstep_per_sec: 797.4159312826838
avg_train_sample_per_sec: 797.4159312826838
avg_episode_per_sec: 4.525629575951667
collect_time: 1.1048186591693334
reward_mean: 847.0
reward_std: 283.988037109375
reward_max: 1321.0
reward_min: 612.0
total_envstep_count: 1012595
total_train_sample_count: 1012558
total_episode_count: 7199
total_duration: 1287.1253413557993
[2024-11-19 23:03:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1207
train_sample_count: 1207
avg_envstep_per_episode: 150.875
avg_sample_per_episode: 150.875
avg_envstep_per_sec: 799.4541584216842
avg_train_sample_per_sec: 799.4541584216842
avg_episode_per_sec: 5.298784811411329
collect_time: 1.5097801259585788
reward_mean: 939.25
reward_std: 408.31231689453125
reward_max: 1333.0
reward_min: 235.0
total_envstep_count: 1013564
total_train_sample_count: 1013537
total_episode_count: 7207
total_duration: 1288.6351214817578
[2024-11-19 23:03:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 841
train_sample_count: 841
avg_envstep_per_episode: 140.16666666666666
avg_sample_per_episode: 140.16666666666666
avg_envstep_per_sec: 808.5579758651803
avg_train_sample_per_sec: 808.5579758651803
avg_episode_per_sec: 5.768546795708778
collect_time: 1.0401233122462317
reward_mean: 731.8333129882812
reward_std: 344.87939453125
reward_max: 1305.0
reward_min: 235.0
total_envstep_count: 1014536
total_train_sample_count: 1014510
total_episode_count: 7213
total_duration: 1289.675244794004
[2024-11-19 23:03:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 672
train_sample_count: 672
avg_envstep_per_episode: 168.0
avg_sample_per_episode: 168.0
avg_envstep_per_sec: 814.9449281736636
avg_train_sample_per_sec: 814.9449281736636
avg_episode_per_sec: 4.850862667700378
collect_time: 0.8245955975282759
reward_mean: 609.5
reward_std: 18.06239128112793
reward_max: 639.0
reward_min: 590.0
total_envstep_count: 1015525
total_train_sample_count: 1015482
total_episode_count: 7217
total_duration: 1290.4998403915322
[2024-11-19 23:03:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1211
train_sample_count: 1211
avg_envstep_per_episode: 201.83333333333334
avg_sample_per_episode: 201.83333333333334
avg_envstep_per_sec: 799.0707191115126
avg_train_sample_per_sec: 799.0707191115126
avg_episode_per_sec: 3.9590621921297076
collect_time: 1.5155104185853685
reward_mean: 1180.5
reward_std: 354.923828125
reward_max: 1695.0
reward_min: 638.0
total_envstep_count: 1016520
total_train_sample_count: 1016477
total_episode_count: 7223
total_duration: 1292.0153508101175
[2024-11-19 23:03:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 984
train_sample_count: 984
avg_envstep_per_episode: 196.8
avg_sample_per_episode: 196.8
avg_envstep_per_sec: 797.2561064113138
avg_train_sample_per_sec: 797.2561064113138
avg_episode_per_sec: 4.051098101683505
collect_time: 1.2342332558972497
reward_mean: 1161.199951171875
reward_std: 430.3349304199219
reward_max: 1830.0
reward_min: 652.0
total_envstep_count: 1017531
total_train_sample_count: 1017497
total_episode_count: 7228
total_duration: 1293.2495840660147
[2024-11-19 23:03:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 816
train_sample_count: 816
avg_envstep_per_episode: 163.2
avg_sample_per_episode: 163.2
avg_envstep_per_sec: 798.5835061748387
avg_train_sample_per_sec: 798.5835061748387
avg_episode_per_sec: 4.893281287836022
collect_time: 1.0218092330864497
reward_mean: 856.5999755859375
reward_std: 433.1090393066406
reward_max: 1336.0
reward_min: 190.0
total_envstep_count: 1018535
total_train_sample_count: 1018493
total_episode_count: 7233
total_duration: 1294.2713932991012
[2024-11-19 23:03:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1085
train_sample_count: 1085
avg_envstep_per_episode: 180.83333333333334
avg_sample_per_episode: 180.83333333333334
avg_envstep_per_sec: 800.437220806724
avg_train_sample_per_sec: 800.437220806724
avg_episode_per_sec: 4.426380944553312
collect_time: 1.3555091789790563
reward_mean: 1010.8333129882812
reward_std: 408.842041015625
reward_max: 1572.0
reward_min: 601.0
total_envstep_count: 1019529
total_train_sample_count: 1019482
total_episode_count: 7239
total_duration: 1295.6269024780802
[2024-11-19 23:03:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1229
train_sample_count: 1229
avg_envstep_per_episode: 245.8
avg_sample_per_episode: 245.8
avg_envstep_per_sec: 806.0680600597884
avg_train_sample_per_sec: 806.0680600597884
avg_episode_per_sec: 3.27936558201704
collect_time: 1.5246851486819133
reward_mean: 1302.4000244140625
reward_std: 354.89862060546875
reward_max: 1558.0
reward_min: 606.0
total_envstep_count: 1020492
total_train_sample_count: 1020459
total_episode_count: 7244
total_duration: 1297.1515876267622
[2024-11-19 23:04:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 345
train_sample_count: 345
avg_envstep_per_episode: 172.5
avg_sample_per_episode: 172.5
avg_envstep_per_sec: 810.7099137311873
avg_train_sample_per_sec: 810.7099137311873
avg_episode_per_sec: 4.69976761583297
collect_time: 0.42555295569556095
reward_mean: 1032.0
reward_std: 396.0
reward_max: 1428.0
reward_min: 636.0
total_envstep_count: 1021466
total_train_sample_count: 1021428
total_episode_count: 7246
total_duration: 1297.5771405824578
[2024-11-19 23:04:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1332
train_sample_count: 1332
avg_envstep_per_episode: 222.0
avg_sample_per_episode: 222.0
avg_envstep_per_sec: 797.118932719663
avg_train_sample_per_sec: 797.118932719663
avg_episode_per_sec: 3.590625823061545
collect_time: 1.671017893723079
reward_mean: 1149.0
reward_std: 340.4208068847656
reward_max: 1549.0
reward_min: 637.0
total_envstep_count: 1022469
total_train_sample_count: 1022436
total_episode_count: 7252
total_duration: 1299.2481584761808
[2024-11-19 23:04:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 836
train_sample_count: 836
avg_envstep_per_episode: 167.2
avg_sample_per_episode: 167.2
avg_envstep_per_sec: 799.7368127909776
avg_train_sample_per_sec: 799.7368127909776
avg_episode_per_sec: 4.783114909036947
collect_time: 1.0453439014298573
reward_mean: 1070.5999755859375
reward_std: 570.2156372070312
reward_max: 1842.0
reward_min: 601.0
total_envstep_count: 1023481
total_train_sample_count: 1023428
total_episode_count: 7257
total_duration: 1300.2935023776106
[2024-11-19 23:04:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1261
train_sample_count: 1261
avg_envstep_per_episode: 252.2
avg_sample_per_episode: 252.2
avg_envstep_per_sec: 800.1102275675684
avg_train_sample_per_sec: 800.1102275675684
avg_episode_per_sec: 3.1725227104185896
collect_time: 1.5760328471660614
reward_mean: 1322.199951171875
reward_std: 334.7287902832031
reward_max: 1674.0
reward_min: 710.0
total_envstep_count: 1024437
total_train_sample_count: 1024413
total_episode_count: 7262
total_duration: 1301.8695352247767
[2024-11-19 23:04:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1053
train_sample_count: 1053
avg_envstep_per_episode: 210.6
avg_sample_per_episode: 210.6
avg_envstep_per_sec: 793.1671643890095
avg_train_sample_per_sec: 793.1671643890095
avg_episode_per_sec: 3.766225851799665
collect_time: 1.327588996716908
reward_mean: 1303.0
reward_std: 348.10516357421875
reward_max: 1574.0
reward_min: 631.0
total_envstep_count: 1025432
total_train_sample_count: 1025394
total_episode_count: 7267
total_duration: 1303.1971242214936
[2024-11-19 23:04:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 654
train_sample_count: 654
avg_envstep_per_episode: 130.8
avg_sample_per_episode: 130.8
avg_envstep_per_sec: 794.899061915529
avg_train_sample_per_sec: 794.899061915529
avg_episode_per_sec: 6.077209953482638
collect_time: 0.8227459703172957
reward_mean: 897.7999877929688
reward_std: 340.7699279785156
reward_max: 1417.0
reward_min: 607.0
total_envstep_count: 1026459
total_train_sample_count: 1026432
total_episode_count: 7272
total_duration: 1304.019870191811
[2024-11-19 23:04:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1220
train_sample_count: 1220
avg_envstep_per_episode: 174.28571428571428
avg_sample_per_episode: 174.28571428571428
avg_envstep_per_sec: 801.8734482381329
avg_train_sample_per_sec: 801.8734482381329
avg_episode_per_sec: 4.600913227595845
collect_time: 1.5214370829718453
reward_mean: 816.5714111328125
reward_std: 387.0636291503906
reward_max: 1747.0
reward_min: 585.0
total_envstep_count: 1027462
total_train_sample_count: 1027436
total_episode_count: 7279
total_duration: 1305.5413072747829
[2024-11-19 23:04:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 938
train_sample_count: 938
avg_envstep_per_episode: 156.33333333333334
avg_sample_per_episode: 156.33333333333334
avg_envstep_per_sec: 802.4033835213004
avg_train_sample_per_sec: 802.4033835213004
avg_episode_per_sec: 5.13264424427271
collect_time: 1.1689880916050501
reward_mean: 914.6666870117188
reward_std: 425.75177001953125
reward_max: 1418.0
reward_min: 246.0
total_envstep_count: 1028480
total_train_sample_count: 1028446
total_episode_count: 7285
total_duration: 1306.710295366388
[2024-11-19 23:04:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1568
train_sample_count: 1568
avg_envstep_per_episode: 174.22222222222223
avg_sample_per_episode: 174.22222222222223
avg_envstep_per_sec: 806.5380050285463
avg_train_sample_per_sec: 806.5380050285463
avg_episode_per_sec: 4.629363549270993
collect_time: 1.9441117346286771
reward_mean: 1030.77783203125
reward_std: 399.8040466308594
reward_max: 1675.0
reward_min: 593.0
total_envstep_count: 1029505
total_train_sample_count: 1029462
total_episode_count: 7294
total_duration: 1308.6544071010167
[2024-11-19 23:04:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 535
train_sample_count: 535
avg_envstep_per_episode: 89.16666666666667
avg_sample_per_episode: 89.16666666666667
avg_envstep_per_sec: 548.6670813717474
avg_train_sample_per_sec: 548.6670813717474
avg_episode_per_sec: 6.1532756789354845
collect_time: 0.9750903929982866
reward_mean: 554.0
reward_std: 142.1818084716797
reward_max: 640.0
reward_min: 237.0
total_envstep_count: 1030501
total_train_sample_count: 1030465
total_episode_count: 7300
total_duration: 1309.629497494015
[2024-11-19 23:04:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1221
train_sample_count: 1221
avg_envstep_per_episode: 174.42857142857142
avg_sample_per_episode: 174.42857142857142
avg_envstep_per_sec: 806.924081695109
avg_train_sample_per_sec: 806.924081695109
avg_episode_per_sec: 4.626100386458446
collect_time: 1.5131535019193378
reward_mean: 1103.5714111328125
reward_std: 346.19476318359375
reward_max: 1431.0
reward_min: 574.0
total_envstep_count: 1031487
total_train_sample_count: 1031446
total_episode_count: 7307
total_duration: 1311.1426509959342
[2024-11-19 23:04:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 666
train_sample_count: 666
avg_envstep_per_episode: 111.0
avg_sample_per_episode: 111.0
avg_envstep_per_sec: 808.6583891977618
avg_train_sample_per_sec: 808.6583891977618
avg_episode_per_sec: 7.285210713493351
collect_time: 0.8235863362039839
reward_mean: 743.3333129882812
reward_std: 266.4361572265625
reward_max: 1338.0
reward_min: 605.0
total_envstep_count: 1032474
total_train_sample_count: 1032436
total_episode_count: 7313
total_duration: 1311.9662373321382
[2024-11-19 23:04:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 830
train_sample_count: 830
avg_envstep_per_episode: 138.33333333333334
avg_sample_per_episode: 138.33333333333334
avg_envstep_per_sec: 804.7553014881546
avg_train_sample_per_sec: 804.7553014881546
avg_episode_per_sec: 5.817508203528829
collect_time: 1.031369409390858
reward_mean: 948.8333129882812
reward_std: 484.1282043457031
reward_max: 1702.0
reward_min: 600.0
total_envstep_count: 1033462
total_train_sample_count: 1033434
total_episode_count: 7319
total_duration: 1312.9976067415291
[2024-11-19 23:04:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1433
train_sample_count: 1433
avg_envstep_per_episode: 159.22222222222223
avg_sample_per_episode: 159.22222222222223
avg_envstep_per_sec: 805.8292149945939
avg_train_sample_per_sec: 805.8292149945939
avg_episode_per_sec: 5.061034846441972
collect_time: 1.7782924388136183
reward_mean: 831.3333129882812
reward_std: 478.8372497558594
reward_max: 1647.0
reward_min: 196.0
total_envstep_count: 1034456
total_train_sample_count: 1034435
total_episode_count: 7328
total_duration: 1314.7758991803428
[2024-11-19 23:04:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 744
train_sample_count: 744
avg_envstep_per_episode: 148.8
avg_sample_per_episode: 148.8
avg_envstep_per_sec: 801.7589173176095
avg_train_sample_per_sec: 801.7589173176095
avg_episode_per_sec: 5.388164766919418
collect_time: 0.9279597444193703
reward_mean: 934.2000122070312
reward_std: 462.6352233886719
reward_max: 1567.0
reward_min: 247.0
total_envstep_count: 1035445
total_train_sample_count: 1035419
total_episode_count: 7333
total_duration: 1315.7038589247622
[2024-11-19 23:04:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1242
train_sample_count: 1242
avg_envstep_per_episode: 207.0
avg_sample_per_episode: 207.0
avg_envstep_per_sec: 807.095852680935
avg_train_sample_per_sec: 807.095852680935
avg_episode_per_sec: 3.899013781067319
collect_time: 1.5388506778648923
reward_mean: 1327.6666259765625
reward_std: 148.09756469726562
reward_max: 1522.0
reward_min: 1039.0
total_envstep_count: 1036457
total_train_sample_count: 1036421
total_episode_count: 7339
total_duration: 1317.2427096026272
[2024-11-19 23:04:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 722
train_sample_count: 722
avg_envstep_per_episode: 180.5
avg_sample_per_episode: 180.5
avg_envstep_per_sec: 806.2680252827712
avg_train_sample_per_sec: 806.2680252827712
avg_episode_per_sec: 4.466858865832528
collect_time: 0.8954838556902749
reward_mean: 982.0
reward_std: 561.708984375
reward_max: 1617.0
reward_min: 245.0
total_envstep_count: 1037462
total_train_sample_count: 1037419
total_episode_count: 7343
total_duration: 1318.1381934583176
[2024-11-19 23:05:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1261
train_sample_count: 1261
avg_envstep_per_episode: 210.16666666666666
avg_sample_per_episode: 210.16666666666666
avg_envstep_per_sec: 796.8578726597939
avg_train_sample_per_sec: 796.8578726597939
avg_episode_per_sec: 3.79155213002281
collect_time: 1.5824653846876962
reward_mean: 1106.5
reward_std: 362.7022399902344
reward_max: 1503.0
reward_min: 576.0
total_envstep_count: 1038488
total_train_sample_count: 1038440
total_episode_count: 7349
total_duration: 1319.7206588430054
[2024-11-19 23:05:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 337
train_sample_count: 337
avg_envstep_per_episode: 168.5
avg_sample_per_episode: 168.5
avg_envstep_per_sec: 793.7461242770764
avg_train_sample_per_sec: 793.7461242770764
avg_episode_per_sec: 4.710659491258614
collect_time: 0.42456900221960886
reward_mean: 1006.5
reward_std: 423.5
reward_max: 1430.0
reward_min: 583.0
total_envstep_count: 1039454
total_train_sample_count: 1039413
total_episode_count: 7351
total_duration: 1320.145227845225
[2024-11-19 23:05:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 845
train_sample_count: 845
avg_envstep_per_episode: 211.25
avg_sample_per_episode: 211.25
avg_envstep_per_sec: 804.1779020620061
avg_train_sample_per_sec: 804.1779020620061
avg_episode_per_sec: 3.8067592997018043
collect_time: 1.0507625213691165
reward_mean: 605.5
reward_std: 287.94921875
reward_max: 804.0
reward_min: 108.0
total_envstep_count: 1040435
total_train_sample_count: 1040402
total_episode_count: 7355
total_duration: 1321.195990366594
[2024-11-19 23:05:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1329
train_sample_count: 1329
avg_envstep_per_episode: 443.0
avg_sample_per_episode: 443.0
avg_envstep_per_sec: 801.6011518889454
avg_train_sample_per_sec: 801.6011518889454
avg_episode_per_sec: 1.8094834128418633
collect_time: 1.6579317493098125
reward_mean: 1154.6666259765625
reward_std: 317.9751892089844
reward_max: 1383.0
reward_min: 705.0
total_envstep_count: 1041394
total_train_sample_count: 1041371
total_episode_count: 7358
total_duration: 1322.853922115904
[2024-11-19 23:05:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 439
train_sample_count: 439
avg_envstep_per_episode: 146.33333333333334
avg_sample_per_episode: 146.33333333333334
avg_envstep_per_sec: 820.4128440785964
avg_train_sample_per_sec: 820.4128440785964
avg_episode_per_sec: 5.606465904865123
collect_time: 0.5350964495113918
reward_mean: 463.0
reward_std: 203.10260009765625
reward_max: 629.0
reward_min: 177.0
total_envstep_count: 1042399
total_train_sample_count: 1042350
total_episode_count: 7361
total_duration: 1323.3890185654154
[2024-11-19 23:05:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1206
train_sample_count: 1206
avg_envstep_per_episode: 201.0
avg_sample_per_episode: 201.0
avg_envstep_per_sec: 805.6882676746487
avg_train_sample_per_sec: 805.6882676746487
avg_episode_per_sec: 4.008399341664918
collect_time: 1.4968568469796861
reward_mean: 1023.3333129882812
reward_std: 405.03033447265625
reward_max: 1471.0
reward_min: 605.0
total_envstep_count: 1043362
total_train_sample_count: 1043328
total_episode_count: 7367
total_duration: 1324.885875412395
[2024-11-19 23:05:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1317
train_sample_count: 1317
avg_envstep_per_episode: 131.7
avg_sample_per_episode: 131.7
avg_envstep_per_sec: 812.3222202867147
avg_train_sample_per_sec: 812.3222202867147
avg_episode_per_sec: 6.167974337788267
collect_time: 1.6212778219154904
reward_mean: 791.5
reward_std: 376.1891174316406
reward_max: 1564.0
reward_min: 251.0
total_envstep_count: 1044401
total_train_sample_count: 1044345
total_episode_count: 7377
total_duration: 1326.5071532343106
[2024-11-19 23:05:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 489
train_sample_count: 489
avg_envstep_per_episode: 163.0
avg_sample_per_episode: 163.0
avg_envstep_per_sec: 808.4990051512511
avg_train_sample_per_sec: 808.4990051512511
avg_episode_per_sec: 4.960116596019946
collect_time: 0.6048244919095721
reward_mean: 1197.3333740234375
reward_std: 274.7245178222656
reward_max: 1433.0
reward_min: 812.0
total_envstep_count: 1045366
total_train_sample_count: 1045314
total_episode_count: 7380
total_duration: 1327.1119777262202
[2024-11-19 23:05:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 983
train_sample_count: 983
avg_envstep_per_episode: 196.6
avg_sample_per_episode: 196.6
avg_envstep_per_sec: 814.2354177178174
avg_train_sample_per_sec: 814.2354177178174
avg_episode_per_sec: 4.141584016875979
collect_time: 1.207267552614212
reward_mean: 1218.4000244140625
reward_std: 432.6428527832031
reward_max: 1699.0
reward_min: 606.0
total_envstep_count: 1046337
total_train_sample_count: 1046297
total_episode_count: 7385
total_duration: 1328.3192452788344
[2024-11-19 23:05:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 583
train_sample_count: 583
avg_envstep_per_episode: 145.75
avg_sample_per_episode: 145.75
avg_envstep_per_sec: 800.5732939404112
avg_train_sample_per_sec: 800.5732939404112
avg_episode_per_sec: 5.492784177978807
collect_time: 0.7282281390258245
reward_mean: 984.0
reward_std: 352.791015625
reward_max: 1342.0
reward_min: 612.0
total_envstep_count: 1047325
total_train_sample_count: 1047276
total_episode_count: 7389
total_duration: 1329.0474734178601
[2024-11-19 23:05:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 618
train_sample_count: 618
avg_envstep_per_episode: 206.0
avg_sample_per_episode: 206.0
avg_envstep_per_sec: 805.1935158291795
avg_train_sample_per_sec: 805.1935158291795
avg_episode_per_sec: 3.9087063875202888
collect_time: 0.7675173580646515
reward_mean: 951.6666870117188
reward_std: 331.3531188964844
reward_max: 1410.0
reward_min: 638.0
total_envstep_count: 1048291
total_train_sample_count: 1048254
total_episode_count: 7392
total_duration: 1329.8149907759248
[2024-11-19 23:06:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1164
train_sample_count: 1164
avg_envstep_per_episode: 194.0
avg_sample_per_episode: 194.0
avg_envstep_per_sec: 806.9512603012557
avg_train_sample_per_sec: 806.9512603012557
avg_episode_per_sec: 4.159542578872452
collect_time: 1.442466301577432
reward_mean: 1204.5
reward_std: 412.1402282714844
reward_max: 1571.0
reward_min: 602.0
total_envstep_count: 1049301
total_train_sample_count: 1049274
total_episode_count: 7398
total_duration: 1331.2574570775023
[2024-11-19 23:06:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2239
train_sample_count: 2239
avg_envstep_per_episode: 447.8
avg_sample_per_episode: 447.8
avg_envstep_per_sec: 802.6442794611397
avg_train_sample_per_sec: 802.6442794611397
avg_episode_per_sec: 1.7924168813334964
collect_time: 2.7895296301160544
reward_mean: 1150.0
reward_std: 436.7402038574219
reward_max: 1653.0
reward_min: 602.0
total_envstep_count: 1050304
total_train_sample_count: 1050265
total_episode_count: 7403
total_duration: 1334.0469867076183
[2024-11-19 23:06:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1159
train_sample_count: 1159
avg_envstep_per_episode: 193.16666666666666
avg_sample_per_episode: 193.16666666666666
avg_envstep_per_sec: 803.4353565002721
avg_train_sample_per_sec: 803.4353565002721
avg_episode_per_sec: 4.15928571095913
collect_time: 1.4425553849765231
reward_mean: 1206.6666259765625
reward_std: 281.8685607910156
reward_max: 1435.0
reward_min: 807.0
total_envstep_count: 1051284
total_train_sample_count: 1051256
total_episode_count: 7409
total_duration: 1335.4895420925948
[2024-11-19 23:06:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1055
train_sample_count: 1055
avg_envstep_per_episode: 175.83333333333334
avg_sample_per_episode: 175.83333333333334
avg_envstep_per_sec: 807.1272900090361
avg_train_sample_per_sec: 807.1272900090361
avg_episode_per_sec: 4.590297383937646
collect_time: 1.307104855775833
reward_mean: 829.6666870117188
reward_std: 434.2267761230469
reward_max: 1698.0
reward_min: 246.0
total_envstep_count: 1052288
total_train_sample_count: 1052251
total_episode_count: 7415
total_duration: 1336.7966469483706
[2024-11-19 23:06:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 233
train_sample_count: 233
avg_envstep_per_episode: 233.0
avg_sample_per_episode: 233.0
avg_envstep_per_sec: 819.6236033562537
avg_train_sample_per_sec: 819.6236033562537
avg_episode_per_sec: 3.517697868481776
collect_time: 0.28427683029856
reward_mean: 1576.0
reward_std: 0.0
reward_max: 1576.0
reward_min: 1576.0
total_envstep_count: 1053271
total_train_sample_count: 1053216
total_episode_count: 7416
total_duration: 1337.080923778669
[2024-11-19 23:06:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1874
train_sample_count: 1874
avg_envstep_per_episode: 208.22222222222223
avg_sample_per_episode: 208.22222222222223
avg_envstep_per_sec: 807.7234934229667
avg_train_sample_per_sec: 807.7234934229667
avg_episode_per_sec: 3.8791416439736928
collect_time: 2.320100894996098
reward_mean: 1121.0
reward_std: 303.3886413574219
reward_max: 1436.0
reward_min: 608.0
total_envstep_count: 1054262
total_train_sample_count: 1054226
total_episode_count: 7425
total_duration: 1339.4010246736652
[2024-11-19 23:06:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 867
train_sample_count: 867
avg_envstep_per_episode: 216.75
avg_sample_per_episode: 216.75
avg_envstep_per_sec: 801.1597678069334
avg_train_sample_per_sec: 801.1597678069334
avg_episode_per_sec: 3.696238836479508
collect_time: 1.0821811514241353
reward_mean: 1297.5
reward_std: 148.64974975585938
reward_max: 1414.0
reward_min: 1046.0
total_envstep_count: 1055242
total_train_sample_count: 1055213
total_episode_count: 7429
total_duration: 1340.4832058250893
[2024-11-19 23:06:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1103
train_sample_count: 1103
avg_envstep_per_episode: 157.57142857142858
avg_sample_per_episode: 157.57142857142858
avg_envstep_per_sec: 800.1574133907218
avg_train_sample_per_sec: 800.1574133907218
avg_episode_per_sec: 5.078061553703583
collect_time: 1.378478761230196
reward_mean: 1214.142822265625
reward_std: 410.698486328125
reward_max: 1705.0
reward_min: 583.0
total_envstep_count: 1056260
total_train_sample_count: 1056208
total_episode_count: 7436
total_duration: 1341.8616845863194
[2024-11-19 23:06:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 206
train_sample_count: 206
avg_envstep_per_episode: 206.0
avg_sample_per_episode: 206.0
avg_envstep_per_sec: 803.068771134179
avg_train_sample_per_sec: 803.068771134179
avg_episode_per_sec: 3.898392092884364
collect_time: 0.2565160138266427
reward_mean: 1428.0
reward_std: 0.0
reward_max: 1428.0
reward_min: 1428.0
total_envstep_count: 1057219
total_train_sample_count: 1057170
total_episode_count: 7437
total_duration: 1342.118200600146
[2024-11-19 23:06:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1717
train_sample_count: 1717
avg_envstep_per_episode: 245.28571428571428
avg_sample_per_episode: 245.28571428571428
avg_envstep_per_sec: 801.3396079953525
avg_train_sample_per_sec: 801.3396079953525
avg_episode_per_sec: 3.2669640395850132
collect_time: 2.14266209091459
reward_mean: 1191.2857666015625
reward_std: 322.0823669433594
reward_max: 1633.0
reward_min: 722.0
total_envstep_count: 1058175
total_train_sample_count: 1058155
total_episode_count: 7444
total_duration: 1344.2608626910608
[2024-11-19 23:06:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 742
train_sample_count: 742
avg_envstep_per_episode: 123.66666666666667
avg_sample_per_episode: 123.66666666666667
avg_envstep_per_sec: 797.026692671822
avg_train_sample_per_sec: 797.026692671822
avg_episode_per_sec: 6.444959779017429
collect_time: 0.9309600378785815
reward_mean: 834.5
reward_std: 459.9553527832031
reward_max: 1563.0
reward_min: 249.0
total_envstep_count: 1059177
total_train_sample_count: 1059137
total_episode_count: 7450
total_duration: 1345.1918227289393
[2024-11-19 23:06:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 933
train_sample_count: 933
avg_envstep_per_episode: 186.6
avg_sample_per_episode: 186.6
avg_envstep_per_sec: 804.6815152460518
avg_train_sample_per_sec: 804.6815152460518
avg_episode_per_sec: 4.312333950943472
collect_time: 1.1594649340425218
reward_mean: 1122.5999755859375
reward_std: 435.2160949707031
reward_max: 1569.0
reward_min: 595.0
total_envstep_count: 1060165
total_train_sample_count: 1060118
total_episode_count: 7455
total_duration: 1346.3512876629818
[2024-11-19 23:07:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 460
train_sample_count: 460
avg_envstep_per_episode: 230.0
avg_sample_per_episode: 230.0
avg_envstep_per_sec: 817.3658177980758
avg_train_sample_per_sec: 817.3658177980758
avg_episode_per_sec: 3.553764425209025
collect_time: 0.5627835052353996
reward_mean: 1377.0
reward_std: 47.0
reward_max: 1424.0
reward_min: 1330.0
total_envstep_count: 1061139
total_train_sample_count: 1061082
total_episode_count: 7457
total_duration: 1346.914071168217
[2024-11-19 23:07:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1308
train_sample_count: 1308
avg_envstep_per_episode: 261.6
avg_sample_per_episode: 261.6
avg_envstep_per_sec: 811.6480990443212
avg_train_sample_per_sec: 811.6480990443212
avg_episode_per_sec: 3.1026303480287507
collect_time: 1.6115358386720928
reward_mean: 1424.4000244140625
reward_std: 139.3163299560547
reward_max: 1683.0
reward_min: 1278.0
total_envstep_count: 1062103
total_train_sample_count: 1062066
total_episode_count: 7462
total_duration: 1348.5256070068892
[2024-11-19 23:07:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1328
train_sample_count: 1328
avg_envstep_per_episode: 265.6
avg_sample_per_episode: 265.6
avg_envstep_per_sec: 804.257253172622
avg_train_sample_per_sec: 804.257253172622
avg_episode_per_sec: 3.028077007427041
collect_time: 1.6512129604816437
reward_mean: 983.4000244140625
reward_std: 230.1595916748047
reward_max: 1300.0
reward_min: 583.0
total_envstep_count: 1063099
total_train_sample_count: 1063046
total_episode_count: 7467
total_duration: 1350.1768199673709
[2024-11-19 23:07:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1344
train_sample_count: 1344
avg_envstep_per_episode: 192.0
avg_sample_per_episode: 192.0
avg_envstep_per_sec: 807.204476379084
avg_train_sample_per_sec: 807.204476379084
avg_episode_per_sec: 4.204189981141062
collect_time: 1.6650056328092302
reward_mean: 1179.5714111328125
reward_std: 247.5069122314453
reward_max: 1332.0
reward_min: 622.0
total_envstep_count: 1064069
total_train_sample_count: 1064042
total_episode_count: 7474
total_duration: 1351.84182560018
[2024-11-19 23:07:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 318
train_sample_count: 318
avg_envstep_per_episode: 159.0
avg_sample_per_episode: 159.0
avg_envstep_per_sec: 808.7486989311769
avg_train_sample_per_sec: 808.7486989311769
avg_episode_per_sec: 5.086469804598597
collect_time: 0.39320001431873863
reward_mean: 1097.0
reward_std: 472.0
reward_max: 1569.0
reward_min: 625.0
total_envstep_count: 1065043
total_train_sample_count: 1065020
total_episode_count: 7476
total_duration: 1352.235025614499
[2024-11-19 23:07:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1437
train_sample_count: 1437
avg_envstep_per_episode: 159.66666666666666
avg_sample_per_episode: 159.66666666666666
avg_envstep_per_sec: 808.9385634293669
avg_train_sample_per_sec: 808.9385634293669
avg_episode_per_sec: 5.066421065319625
collect_time: 1.7764018986906325
reward_mean: 941.6666870117188
reward_std: 469.7742004394531
reward_max: 1489.0
reward_min: 200.0
total_envstep_count: 1066068
total_train_sample_count: 1066037
total_episode_count: 7485
total_duration: 1354.0114275131896
[2024-11-19 23:07:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 931
train_sample_count: 931
avg_envstep_per_episode: 186.2
avg_sample_per_episode: 186.2
avg_envstep_per_sec: 802.7622583346279
avg_train_sample_per_sec: 802.7622583346279
avg_episode_per_sec: 4.311290324031299
collect_time: 1.15974560379982
reward_mean: 1102.4000244140625
reward_std: 300.392822265625
reward_max: 1417.0
reward_min: 599.0
total_envstep_count: 1067096
total_train_sample_count: 1067052
total_episode_count: 7490
total_duration: 1355.1711731169894
[2024-11-19 23:07:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 936
train_sample_count: 936
avg_envstep_per_episode: 187.2
avg_sample_per_episode: 187.2
avg_envstep_per_sec: 800.1934455121104
avg_train_sample_per_sec: 800.1934455121104
avg_episode_per_sec: 4.274537636282641
collect_time: 1.1697171543325697
reward_mean: 1052.0
reward_std: 395.9146423339844
reward_max: 1574.0
reward_min: 609.0
total_envstep_count: 1068084
total_train_sample_count: 1068036
total_episode_count: 7495
total_duration: 1356.340890271322
[2024-11-19 23:07:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 661
train_sample_count: 661
avg_envstep_per_episode: 132.2
avg_sample_per_episode: 132.2
avg_envstep_per_sec: 795.0798044565797
avg_train_sample_per_sec: 795.0798044565797
avg_episode_per_sec: 6.014219398309983
collect_time: 0.8313630861895424
reward_mean: 968.4000244140625
reward_std: 438.6126403808594
reward_max: 1571.0
reward_min: 612.0
total_envstep_count: 1069103
total_train_sample_count: 1069069
total_episode_count: 7500
total_duration: 1357.1722533575116
[2024-11-19 23:07:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1124
train_sample_count: 1124
avg_envstep_per_episode: 187.33333333333334
avg_sample_per_episode: 187.33333333333334
avg_envstep_per_sec: 807.4620214855157
avg_train_sample_per_sec: 807.4620214855157
avg_episode_per_sec: 4.310295488356846
collect_time: 1.3920159339904785
reward_mean: 1076.3333740234375
reward_std: 365.93017578125
reward_max: 1548.0
reward_min: 600.0
total_envstep_count: 1070098
total_train_sample_count: 1070061
total_episode_count: 7506
total_duration: 1358.5642692915021
[2024-11-19 23:07:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 928
train_sample_count: 928
avg_envstep_per_episode: 132.57142857142858
avg_sample_per_episode: 132.57142857142858
avg_envstep_per_sec: 803.167671955889
avg_train_sample_per_sec: 803.167671955889
avg_episode_per_sec: 6.058376835874162
collect_time: 1.1554249908242908
reward_mean: 883.7142944335938
reward_std: 512.6860961914062
reward_max: 1902.0
reward_min: 250.0
total_envstep_count: 1071107
total_train_sample_count: 1071073
total_episode_count: 7513
total_duration: 1359.7196942823264
[2024-11-19 23:07:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 697
train_sample_count: 697
avg_envstep_per_episode: 174.25
avg_sample_per_episode: 174.25
avg_envstep_per_sec: 797.1642994799896
avg_train_sample_per_sec: 797.1642994799896
avg_episode_per_sec: 4.574830986972681
collect_time: 0.874349240745817
reward_mean: 1164.5
reward_std: 296.47808837890625
reward_max: 1338.0
reward_min: 651.0
total_envstep_count: 1072087
total_train_sample_count: 1072046
total_episode_count: 7517
total_duration: 1360.5940435230723
[2024-11-19 23:07:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1127
train_sample_count: 1127
avg_envstep_per_episode: 225.4
avg_sample_per_episode: 225.4
avg_envstep_per_sec: 810.6051283974675
avg_train_sample_per_sec: 810.6051283974675
avg_episode_per_sec: 3.596296044354337
collect_time: 1.390319355896541
reward_mean: 994.7999877929688
reward_std: 311.4093322753906
reward_max: 1422.0
reward_min: 637.0
total_envstep_count: 1073099
total_train_sample_count: 1073065
total_episode_count: 7522
total_duration: 1361.9843628789688
[2024-11-19 23:07:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1001
train_sample_count: 1001
avg_envstep_per_episode: 166.83333333333334
avg_sample_per_episode: 166.83333333333334
avg_envstep_per_sec: 813.4815259995931
avg_train_sample_per_sec: 813.4815259995931
avg_episode_per_sec: 4.8760131428547036
collect_time: 1.2305135003158028
reward_mean: 1068.6666259765625
reward_std: 350.2816467285156
reward_max: 1423.0
reward_min: 604.0
total_envstep_count: 1074086
total_train_sample_count: 1074042
total_episode_count: 7528
total_duration: 1363.2148763792845
[2024-11-19 23:07:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 510
train_sample_count: 510
avg_envstep_per_episode: 170.0
avg_sample_per_episode: 170.0
avg_envstep_per_sec: 803.2763065174616
avg_train_sample_per_sec: 803.2763065174616
avg_episode_per_sec: 4.7251547442203625
collect_time: 0.6348998418876103
reward_mean: 1403.3333740234375
reward_std: 39.936058044433594
reward_max: 1435.0
reward_min: 1347.0
total_envstep_count: 1075043
total_train_sample_count: 1075008
total_episode_count: 7531
total_duration: 1363.849776221172
[2024-11-19 23:07:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1061
train_sample_count: 1061
avg_envstep_per_episode: 176.83333333333334
avg_sample_per_episode: 176.83333333333334
avg_envstep_per_sec: 807.3429105477023
avg_train_sample_per_sec: 807.3429105477023
avg_episode_per_sec: 4.565558400835263
collect_time: 1.314187547990254
reward_mean: 1151.3333740234375
reward_std: 277.17303466796875
reward_max: 1426.0
reward_min: 654.0
total_envstep_count: 1076029
total_train_sample_count: 1075985
total_episode_count: 7537
total_duration: 1365.1639637691624
[2024-11-19 23:07:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 691
train_sample_count: 691
avg_envstep_per_episode: 115.16666666666667
avg_sample_per_episode: 115.16666666666667
avg_envstep_per_sec: 805.6596163461192
avg_train_sample_per_sec: 805.6596163461192
avg_episode_per_sec: 6.995597247578458
collect_time: 0.8576823089803967
reward_mean: 812.8333129882812
reward_std: 500.1470947265625
reward_max: 1664.0
reward_min: 239.0
total_envstep_count: 1077007
total_train_sample_count: 1076964
total_episode_count: 7543
total_duration: 1366.0216460781428
[2024-11-19 23:08:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 827
train_sample_count: 827
avg_envstep_per_episode: 165.4
avg_sample_per_episode: 165.4
avg_envstep_per_sec: 798.5582355692898
avg_train_sample_per_sec: 798.5582355692898
avg_episode_per_sec: 4.828042536694618
collect_time: 1.0356163936001914
reward_mean: 1011.0
reward_std: 427.0409851074219
reward_max: 1683.0
reward_min: 602.0
total_envstep_count: 1078010
total_train_sample_count: 1077971
total_episode_count: 7548
total_duration: 1367.057262471743
[2024-11-19 23:08:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1020
train_sample_count: 1020
avg_envstep_per_episode: 170.0
avg_sample_per_episode: 170.0
avg_envstep_per_sec: 794.6584891540145
avg_train_sample_per_sec: 794.6584891540145
avg_episode_per_sec: 4.674461700905968
collect_time: 1.2835702555520192
reward_mean: 973.6666870117188
reward_std: 371.6403503417969
reward_max: 1492.0
reward_min: 612.0
total_envstep_count: 1078997
total_train_sample_count: 1078967
total_episode_count: 7554
total_duration: 1368.3408327272948
[2024-11-19 23:08:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 2533
train_sample_count: 2533
avg_envstep_per_episode: 281.44444444444446
avg_sample_per_episode: 281.44444444444446
avg_envstep_per_sec: 806.023931225264
avg_train_sample_per_sec: 806.023931225264
avg_episode_per_sec: 2.8638828981553006
collect_time: 3.1425865931170325
reward_mean: 835.4444580078125
reward_std: 521.365966796875
reward_max: 2089.0
reward_min: 243.0
total_envstep_count: 1080052
total_train_sample_count: 1080012
total_episode_count: 7563
total_duration: 1371.483419320412
[2024-11-19 23:08:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 587
train_sample_count: 587
avg_envstep_per_episode: 195.66666666666666
avg_sample_per_episode: 195.66666666666666
avg_envstep_per_sec: 802.5103570745216
avg_train_sample_per_sec: 802.5103570745216
avg_episode_per_sec: 4.101415794247981
collect_time: 0.7314547342913492
reward_mean: 1165.6666259765625
reward_std: 298.4295959472656
reward_max: 1427.0
reward_min: 748.0
total_envstep_count: 1081049
total_train_sample_count: 1081007
total_episode_count: 7566
total_duration: 1372.2148740547034
[2024-11-19 23:08:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1313
train_sample_count: 1313
avg_envstep_per_episode: 187.57142857142858
avg_sample_per_episode: 187.57142857142858
avg_envstep_per_sec: 805.2588511567434
avg_train_sample_per_sec: 805.2588511567434
avg_episode_per_sec: 4.293078414392387
collect_time: 1.6305315962859561
reward_mean: 1191.5714111328125
reward_std: 149.63941955566406
reward_max: 1419.0
reward_min: 1039.0
total_envstep_count: 1082090
total_train_sample_count: 1082044
total_episode_count: 7573
total_duration: 1373.8454056509893
[2024-11-19 23:08:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 784
train_sample_count: 784
avg_envstep_per_episode: 156.8
avg_sample_per_episode: 156.8
avg_envstep_per_sec: 809.1965864874727
avg_train_sample_per_sec: 809.1965864874727
avg_episode_per_sec: 5.1606925158639845
collect_time: 0.9688622185162137
reward_mean: 896.0
reward_std: 391.76983642578125
reward_max: 1660.0
reward_min: 607.0
total_envstep_count: 1083086
total_train_sample_count: 1083044
total_episode_count: 7578
total_duration: 1374.8142678695056
[2024-11-19 23:08:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1017
train_sample_count: 1017
avg_envstep_per_episode: 203.4
avg_sample_per_episode: 203.4
avg_envstep_per_sec: 803.4016161854461
avg_train_sample_per_sec: 803.4016161854461
avg_episode_per_sec: 3.9498604532224486
collect_time: 1.265867505754743
reward_mean: 1118.4000244140625
reward_std: 279.7846374511719
reward_max: 1331.0
reward_min: 601.0
total_envstep_count: 1084066
total_train_sample_count: 1084025
total_episode_count: 7583
total_duration: 1376.0801353752604
[2024-11-19 23:08:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 997
train_sample_count: 997
avg_envstep_per_episode: 199.4
avg_sample_per_episode: 199.4
avg_envstep_per_sec: 806.1388762460383
avg_train_sample_per_sec: 806.1388762460383
avg_episode_per_sec: 4.04282284977953
collect_time: 1.2367596072810036
reward_mean: 1096.199951171875
reward_std: 320.7487487792969
reward_max: 1405.0
reward_min: 609.0
total_envstep_count: 1085062
total_train_sample_count: 1085022
total_episode_count: 7588
total_duration: 1377.3168949825415
[2024-11-19 23:08:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1250
train_sample_count: 1250
avg_envstep_per_episode: 178.57142857142858
avg_sample_per_episode: 178.57142857142858
avg_envstep_per_sec: 810.8369588302754
avg_train_sample_per_sec: 810.8369588302754
avg_episode_per_sec: 4.540686969449542
collect_time: 1.5416169507162911
reward_mean: 1062.7142333984375
reward_std: 410.8756408691406
reward_max: 1575.0
reward_min: 582.0
total_envstep_count: 1086040
total_train_sample_count: 1086020
total_episode_count: 7595
total_duration: 1378.858511933258
[2024-11-19 23:08:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 530
train_sample_count: 530
avg_envstep_per_episode: 176.66666666666666
avg_sample_per_episode: 176.66666666666666
avg_envstep_per_sec: 813.0807383202613
avg_train_sample_per_sec: 813.0807383202613
avg_episode_per_sec: 4.6023438018128
collect_time: 0.6518417852265495
reward_mean: 1115.0
reward_std: 368.92547607421875
reward_max: 1428.0
reward_min: 597.0
total_envstep_count: 1087061
total_train_sample_count: 1087018
total_episode_count: 7598
total_duration: 1379.5103537184843
[2024-11-19 23:08:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1630
train_sample_count: 1630
avg_envstep_per_episode: 163.0
avg_sample_per_episode: 163.0
avg_envstep_per_sec: 806.0088132282362
avg_train_sample_per_sec: 806.0088132282362
avg_episode_per_sec: 4.944839344958505
collect_time: 2.022310393197196
reward_mean: 1140.5
reward_std: 516.3204956054688
reward_max: 1839.0
reward_min: 248.0
total_envstep_count: 1088083
total_train_sample_count: 1088024
total_episode_count: 7608
total_duration: 1381.5326641116815
[2024-11-19 23:09:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 961
train_sample_count: 961
avg_envstep_per_episode: 120.125
avg_sample_per_episode: 120.125
avg_envstep_per_sec: 805.8039602706306
avg_train_sample_per_sec: 805.8039602706306
avg_episode_per_sec: 6.708045454906394
collect_time: 1.1925977624598005
reward_mean: 711.5
reward_std: 238.82054138183594
reward_max: 1041.0
reward_min: 244.0
total_envstep_count: 1089036
total_train_sample_count: 1088997
total_episode_count: 7616
total_duration: 1382.7252618741413
[2024-11-19 23:09:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 761
train_sample_count: 761
avg_envstep_per_episode: 152.2
avg_sample_per_episode: 152.2
avg_envstep_per_sec: 808.5080282224593
avg_train_sample_per_sec: 808.5080282224593
avg_episode_per_sec: 5.312142103958339
collect_time: 0.941239880664008
reward_mean: 1136.5999755859375
reward_std: 418.89788818359375
reward_max: 1578.0
reward_min: 606.0
total_envstep_count: 1090047
total_train_sample_count: 1090010
total_episode_count: 7621
total_duration: 1383.6665017548053
[2024-11-19 23:09:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1091
train_sample_count: 1091
avg_envstep_per_episode: 155.85714285714286
avg_sample_per_episode: 155.85714285714286
avg_envstep_per_sec: 802.9588699572707
avg_train_sample_per_sec: 802.9588699572707
avg_episode_per_sec: 5.151890091384872
collect_time: 1.3587246381101155
reward_mean: 950.5714111328125
reward_std: 517.7823486328125
reward_max: 1684.0
reward_min: 246.0
total_envstep_count: 1091057
total_train_sample_count: 1091017
total_episode_count: 7628
total_duration: 1385.0252263929153
[2024-11-19 23:09:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1294
train_sample_count: 1294
avg_envstep_per_episode: 129.4
avg_sample_per_episode: 129.4
avg_envstep_per_sec: 800.3414349757254
avg_train_sample_per_sec: 800.3414349757254
avg_episode_per_sec: 6.18501881743219
collect_time: 1.6168099556650437
reward_mean: 727.2000122070312
reward_std: 430.12274169921875
reward_max: 1431.0
reward_min: 198.0
total_envstep_count: 1092048
total_train_sample_count: 1092011
total_episode_count: 7638
total_duration: 1386.6420363485804
[2024-11-19 23:09:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 618
train_sample_count: 618
avg_envstep_per_episode: 123.6
avg_sample_per_episode: 123.6
avg_envstep_per_sec: 808.5330856118482
avg_train_sample_per_sec: 808.5330856118482
avg_episode_per_sec: 6.541529818866086
collect_time: 0.7643471998827798
reward_mean: 967.0
reward_std: 473.32525634765625
reward_max: 1853.0
reward_min: 611.0
total_envstep_count: 1093013
total_train_sample_count: 1092989
total_episode_count: 7643
total_duration: 1387.4063835484633
[2024-11-19 23:09:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1017
train_sample_count: 1017
avg_envstep_per_episode: 113.0
avg_sample_per_episode: 113.0
avg_envstep_per_sec: 808.3802003843045
avg_train_sample_per_sec: 808.3802003843045
avg_episode_per_sec: 7.153807083046943
collect_time: 1.258071387097949
reward_mean: 720.2222290039062
reward_std: 390.0343933105469
reward_max: 1417.0
reward_min: 238.0
total_envstep_count: 1094052
total_train_sample_count: 1094006
total_episode_count: 7652
total_duration: 1388.6644549355613
[2024-11-19 23:09:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1268
train_sample_count: 1268
avg_envstep_per_episode: 126.8
avg_sample_per_episode: 126.8
avg_envstep_per_sec: 805.6076180526711
avg_train_sample_per_sec: 805.6076180526711
avg_episode_per_sec: 6.353372382118858
collect_time: 1.5739672411055792
reward_mean: 809.5
reward_std: 460.2856140136719
reward_max: 1431.0
reward_min: 230.0
total_envstep_count: 1095116
total_train_sample_count: 1095070
total_episode_count: 7662
total_duration: 1390.2384221766667
[2024-11-19 23:09:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 743
train_sample_count: 743
avg_envstep_per_episode: 148.6
avg_sample_per_episode: 148.6
avg_envstep_per_sec: 806.5048593418794
avg_train_sample_per_sec: 806.5048593418794
avg_episode_per_sec: 5.4273543697300095
collect_time: 0.92125917332513
reward_mean: 642.0
reward_std: 83.75201416015625
reward_max: 807.0
reward_min: 587.0
total_envstep_count: 1096144
total_train_sample_count: 1096101
total_episode_count: 7667
total_duration: 1391.1596813499918
[2024-11-19 23:09:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1171
train_sample_count: 1171
avg_envstep_per_episode: 146.375
avg_sample_per_episode: 146.375
avg_envstep_per_sec: 805.5475114041092
avg_train_sample_per_sec: 805.5475114041092
avg_episode_per_sec: 5.503313485254376
collect_time: 1.4536696885313307
reward_mean: 970.125
reward_std: 357.0733337402344
reward_max: 1343.0
reward_min: 603.0
total_envstep_count: 1097177
total_train_sample_count: 1097152
total_episode_count: 7675
total_duration: 1392.6133510385232
[2024-11-19 23:09:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 661
train_sample_count: 661
avg_envstep_per_episode: 165.25
avg_sample_per_episode: 165.25
avg_envstep_per_sec: 799.5885924057386
avg_train_sample_per_sec: 799.5885924057386
avg_episode_per_sec: 4.838660165844106
collect_time: 0.8266751255307879
reward_mean: 1242.0
reward_std: 363.9203186035156
reward_max: 1572.0
reward_min: 628.0
total_envstep_count: 1098150
total_train_sample_count: 1098125
total_episode_count: 7679
total_duration: 1393.440026164054
[2024-11-19 23:09:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1094
train_sample_count: 1094
avg_envstep_per_episode: 218.8
avg_sample_per_episode: 218.8
avg_envstep_per_sec: 802.1693057041778
avg_train_sample_per_sec: 802.1693057041778
avg_episode_per_sec: 3.6662216896900266
collect_time: 1.3638018710272652
reward_mean: 1315.199951171875
reward_std: 90.76431274414062
reward_max: 1427.0
reward_min: 1149.0
total_envstep_count: 1099153
total_train_sample_count: 1099099
total_episode_count: 7684
total_duration: 1394.8038280350813
[2024-11-19 23:09:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1632
train_sample_count: 1632
avg_envstep_per_episode: 163.2
avg_sample_per_episode: 163.2
avg_envstep_per_sec: 804.9686498291844
avg_train_sample_per_sec: 804.9686498291844
avg_episode_per_sec: 4.932405942580787
collect_time: 2.0274081485612054
reward_mean: 1019.2000122070312
reward_std: 433.118408203125
reward_max: 1697.0
reward_min: 238.0
total_envstep_count: 1100120
total_train_sample_count: 1100083
total_episode_count: 7694
total_duration: 1396.8312361836424
[2024-11-19 23:09:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 492
train_sample_count: 492
avg_envstep_per_episode: 164.0
avg_sample_per_episode: 164.0
avg_envstep_per_sec: 794.1690682749344
avg_train_sample_per_sec: 794.1690682749344
avg_episode_per_sec: 4.8424943187495995
collect_time: 0.6195154402937209
reward_mean: 920.3333129882812
reward_std: 300.7306213378906
reward_max: 1332.0
reward_min: 622.0
total_envstep_count: 1101109
total_train_sample_count: 1101067
total_episode_count: 7697
total_duration: 1397.4507516239362
[2024-11-19 23:09:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 729
train_sample_count: 729
avg_envstep_per_episode: 145.8
avg_sample_per_episode: 145.8
avg_envstep_per_sec: 800.4647206667265
avg_train_sample_per_sec: 800.4647206667265
avg_episode_per_sec: 5.490155834476862
collect_time: 0.9107209614345004
reward_mean: 612.2000122070312
reward_std: 16.833301544189453
reward_max: 637.0
reward_min: 598.0
total_envstep_count: 1102104
total_train_sample_count: 1102060
total_episode_count: 7702
total_duration: 1398.3614725853706
[2024-11-19 23:09:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1107
train_sample_count: 1107
avg_envstep_per_episode: 221.4
avg_sample_per_episode: 221.4
avg_envstep_per_sec: 808.1640134242483
avg_train_sample_per_sec: 808.1640134242483
avg_episode_per_sec: 3.6502439630724854
collect_time: 1.3697714592729295
reward_mean: 1174.199951171875
reward_std: 321.155029296875
reward_max: 1418.0
reward_min: 601.0
total_envstep_count: 1103076
total_train_sample_count: 1103047
total_episode_count: 7707
total_duration: 1399.7312440446435
[2024-11-19 23:09:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1160
train_sample_count: 1160
avg_envstep_per_episode: 145.0
avg_sample_per_episode: 145.0
avg_envstep_per_sec: 806.9424091513082
avg_train_sample_per_sec: 806.9424091513082
avg_episode_per_sec: 5.56512006311247
collect_time: 1.4375251403876712
reward_mean: 866.875
reward_std: 401.9649658203125
reward_max: 1566.0
reward_min: 223.0
total_envstep_count: 1104053
total_train_sample_count: 1104027
total_episode_count: 7715
total_duration: 1401.1687691850311
[2024-11-19 23:10:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1148
train_sample_count: 1148
avg_envstep_per_episode: 164.0
avg_sample_per_episode: 164.0
avg_envstep_per_sec: 806.5576251262406
avg_train_sample_per_sec: 806.5576251262406
avg_episode_per_sec: 4.918034299550247
collect_time: 1.423332895551409
reward_mean: 1059.0
reward_std: 499.7559509277344
reward_max: 1807.0
reward_min: 237.0
total_envstep_count: 1105078
total_train_sample_count: 1105043
total_episode_count: 7722
total_duration: 1402.5921020805824
[2024-11-19 23:10:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 625
train_sample_count: 625
avg_envstep_per_episode: 208.33333333333334
avg_sample_per_episode: 208.33333333333334
avg_envstep_per_sec: 807.4569712291246
avg_train_sample_per_sec: 807.4569712291246
avg_episode_per_sec: 3.8757934618997982
collect_time: 0.7740350535937717
reward_mean: 1177.6666259765625
reward_std: 397.0057373046875
reward_max: 1568.0
reward_min: 633.0
total_envstep_count: 1106051
total_train_sample_count: 1106016
total_episode_count: 7725
total_duration: 1403.3661371341761
[2024-11-19 23:10:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1130
train_sample_count: 1130
avg_envstep_per_episode: 188.33333333333334
avg_sample_per_episode: 188.33333333333334
avg_envstep_per_sec: 811.4391872157404
avg_train_sample_per_sec: 811.4391872157404
avg_episode_per_sec: 4.308526657782693
collect_time: 1.3925874148096358
reward_mean: 1041.8333740234375
reward_std: 421.5216369628906
reward_max: 1336.0
reward_min: 227.0
total_envstep_count: 1107053
total_train_sample_count: 1107026
total_episode_count: 7731
total_duration: 1404.7587245489858
[2024-11-19 23:10:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1093
train_sample_count: 1093
avg_envstep_per_episode: 182.16666666666666
avg_sample_per_episode: 182.16666666666666
avg_envstep_per_sec: 806.7614657980614
avg_train_sample_per_sec: 806.7614657980614
avg_episode_per_sec: 4.428699720757885
collect_time: 1.3547994622162411
reward_mean: 959.3333129882812
reward_std: 355.81768798828125
reward_max: 1331.0
reward_min: 597.0
total_envstep_count: 1108072
total_train_sample_count: 1108035
total_episode_count: 7737
total_duration: 1406.1135240112021
[2024-11-19 23:10:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 928
train_sample_count: 928
avg_envstep_per_episode: 154.66666666666666
avg_sample_per_episode: 154.66666666666666
avg_envstep_per_sec: 805.1408718887151
avg_train_sample_per_sec: 805.1408718887151
avg_episode_per_sec: 5.205652188935658
collect_time: 1.152593331677573
reward_mean: 897.6666870117188
reward_std: 510.45623779296875
reward_max: 1342.0
reward_min: 140.0
total_envstep_count: 1109058
total_train_sample_count: 1109011
total_episode_count: 7743
total_duration: 1407.2661173428796
[2024-11-19 23:10:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 780
train_sample_count: 780
avg_envstep_per_episode: 130.0
avg_sample_per_episode: 130.0
avg_envstep_per_sec: 806.8919479188272
avg_train_sample_per_sec: 806.8919479188272
avg_episode_per_sec: 6.206861137837133
collect_time: 0.96667218208313
reward_mean: 674.8333129882812
reward_std: 242.12490844726562
reward_max: 1027.0
reward_min: 224.0
total_envstep_count: 1110044
total_train_sample_count: 1109995
total_episode_count: 7749
total_duration: 1408.2327895249628
[2024-11-19 23:10:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1221
train_sample_count: 1221
avg_envstep_per_episode: 174.42857142857142
avg_sample_per_episode: 174.42857142857142
avg_envstep_per_sec: 805.0963929828564
avg_train_sample_per_sec: 805.0963929828564
avg_episode_per_sec: 4.6156222365929525
collect_time: 1.5165885857173376
reward_mean: 1008.8571166992188
reward_std: 304.03826904296875
reward_max: 1333.0
reward_min: 608.0
total_envstep_count: 1111023
total_train_sample_count: 1110988
total_episode_count: 7756
total_duration: 1409.74937811068
[2024-11-19 23:10:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 596
train_sample_count: 596
avg_envstep_per_episode: 149.0
avg_sample_per_episode: 149.0
avg_envstep_per_sec: 802.9978331479773
avg_train_sample_per_sec: 802.9978331479773
avg_episode_per_sec: 5.389247202335418
collect_time: 0.7422186902591161
reward_mean: 752.75
reward_std: 170.30615234375
reward_max: 1028.0
reward_min: 611.0
total_envstep_count: 1112011
total_train_sample_count: 1111980
total_episode_count: 7760
total_duration: 1410.491596800939
[2024-11-19 23:10:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1263
train_sample_count: 1263
avg_envstep_per_episode: 252.6
avg_sample_per_episode: 252.6
avg_envstep_per_sec: 805.0414205913354
avg_train_sample_per_sec: 805.0414205913354
avg_episode_per_sec: 3.1870206674241306
collect_time: 1.5688633748463223
reward_mean: 1189.5999755859375
reward_std: 492.09130859375
reward_max: 1839.0
reward_min: 611.0
total_envstep_count: 1112991
total_train_sample_count: 1112955
total_episode_count: 7765
total_duration: 1412.0604601757855
[2024-11-19 23:10:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 580
train_sample_count: 580
avg_envstep_per_episode: 193.33333333333334
avg_sample_per_episode: 193.33333333333334
avg_envstep_per_sec: 807.0797918594141
avg_train_sample_per_sec: 807.0797918594141
avg_episode_per_sec: 4.174550647548694
collect_time: 0.7186402210167476
reward_mean: 1022.6666870117188
reward_std: 317.5513916015625
reward_max: 1391.0
reward_min: 616.0
total_envstep_count: 1113980
total_train_sample_count: 1113931
total_episode_count: 7768
total_duration: 1412.7791003968023
[2024-11-19 23:10:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1656
train_sample_count: 1656
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 797.9235743463059
avg_train_sample_per_sec: 797.9235743463059
avg_episode_per_sec: 4.336541164925576
collect_time: 2.075386732816696
reward_mean: 1173.22216796875
reward_std: 464.9417419433594
reward_max: 1689.0
reward_min: 615.0
total_envstep_count: 1114979
total_train_sample_count: 1114939
total_episode_count: 7777
total_duration: 1414.854487129619
[2024-11-19 23:10:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1125
train_sample_count: 1125
avg_envstep_per_episode: 160.71428571428572
avg_sample_per_episode: 160.71428571428572
avg_envstep_per_sec: 798.7724664319103
avg_train_sample_per_sec: 798.7724664319103
avg_episode_per_sec: 4.970139791131887
collect_time: 1.408411089863096
reward_mean: 1088.0
reward_std: 403.8564147949219
reward_max: 1697.0
reward_min: 604.0
total_envstep_count: 1115988
total_train_sample_count: 1115956
total_episode_count: 7784
total_duration: 1416.2628982194822
[2024-11-19 23:10:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 90
train_sample_count: 90
avg_envstep_per_episode: 90.0
avg_sample_per_episode: 90.0
avg_envstep_per_sec: 787.7603785222201
avg_train_sample_per_sec: 787.7603785222201
avg_episode_per_sec: 8.752893094691334
collect_time: 0.11424793941634043
reward_mean: 634.0
reward_std: 0.0
reward_max: 634.0
reward_min: 634.0
total_envstep_count: 1116955
total_train_sample_count: 1116922
total_episode_count: 7785
total_duration: 1416.3771461588985
[2024-11-19 23:10:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1594
train_sample_count: 1594
avg_envstep_per_episode: 199.25
avg_sample_per_episode: 199.25
avg_envstep_per_sec: 798.8981281678699
avg_train_sample_per_sec: 798.8981281678699
avg_episode_per_sec: 4.009526364707001
collect_time: 1.9952481346470972
reward_mean: 1062.875
reward_std: 446.0855712890625
reward_max: 1668.0
reward_min: 228.0
total_envstep_count: 1117964
total_train_sample_count: 1117928
total_episode_count: 7793
total_duration: 1418.3723942935455
[2024-11-19 23:10:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1220
train_sample_count: 1220
avg_envstep_per_episode: 152.5
avg_sample_per_episode: 152.5
avg_envstep_per_sec: 795.0387946147349
avg_train_sample_per_sec: 795.0387946147349
avg_episode_per_sec: 5.2133691450146555
collect_time: 1.5345163132463184
reward_mean: 513.5
reward_std: 419.8535461425781
reward_max: 1388.0
reward_min: 123.0
total_envstep_count: 1118950
total_train_sample_count: 1118932
total_episode_count: 7801
total_duration: 1419.9069106067918
[2024-11-19 23:10:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 465
train_sample_count: 465
avg_envstep_per_episode: 93.0
avg_sample_per_episode: 93.0
avg_envstep_per_sec: 802.7582166152231
avg_train_sample_per_sec: 802.7582166152231
avg_episode_per_sec: 8.63180878080885
collect_time: 0.5792528688907623
reward_mean: 496.3999938964844
reward_std: 213.9248504638672
reward_max: 733.0
reward_min: 237.0
total_envstep_count: 1119954
total_train_sample_count: 1119901
total_episode_count: 7806
total_duration: 1420.4861634756826
[2024-11-19 23:10:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1377
train_sample_count: 1377
avg_envstep_per_episode: 196.71428571428572
avg_sample_per_episode: 196.71428571428572
avg_envstep_per_sec: 800.5965023819608
avg_train_sample_per_sec: 800.5965023819608
avg_episode_per_sec: 4.069844238688254
collect_time: 1.7199675440788271
reward_mean: 850.5714111328125
reward_std: 441.53912353515625
reward_max: 1419.0
reward_min: 230.0
total_envstep_count: 1120940
total_train_sample_count: 1120894
total_episode_count: 7813
total_duration: 1422.2061310197614
[2024-11-19 23:11:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1059
train_sample_count: 1059
avg_envstep_per_episode: 117.66666666666667
avg_sample_per_episode: 117.66666666666667
avg_envstep_per_sec: 795.1845917327453
avg_train_sample_per_sec: 795.1845917327453
avg_episode_per_sec: 6.757942705944011
collect_time: 1.3317662477493286
reward_mean: 677.111083984375
reward_std: 460.02593994140625
reward_max: 1425.0
reward_min: 229.0
total_envstep_count: 1121909
total_train_sample_count: 1121881
total_episode_count: 7822
total_duration: 1423.5378972675107
[2024-11-19 23:11:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 914
train_sample_count: 914
avg_envstep_per_episode: 114.25
avg_sample_per_episode: 114.25
avg_envstep_per_sec: 804.3604652370034
avg_train_sample_per_sec: 804.3604652370034
avg_episode_per_sec: 7.0403541815055
collect_time: 1.1363064689295632
reward_mean: 732.0
reward_std: 318.5074462890625
reward_max: 1574.0
reward_min: 583.0
total_envstep_count: 1122910
total_train_sample_count: 1122879
total_episode_count: 7830
total_duration: 1424.6742037364404
[2024-11-19 23:11:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 842
train_sample_count: 842
avg_envstep_per_episode: 168.4
avg_sample_per_episode: 168.4
avg_envstep_per_sec: 809.796762768914
avg_train_sample_per_sec: 809.796762768914
avg_episode_per_sec: 4.808769375112316
collect_time: 1.039767060961042
reward_mean: 941.7999877929688
reward_std: 422.9186096191406
reward_max: 1567.0
reward_min: 591.0
total_envstep_count: 1123929
total_train_sample_count: 1123877
total_episode_count: 7835
total_duration: 1425.7139707974015
[2024-11-19 23:11:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1068
train_sample_count: 1068
avg_envstep_per_episode: 213.6
avg_sample_per_episode: 213.6
avg_envstep_per_sec: 801.2645273517048
avg_train_sample_per_sec: 801.2645273517048
avg_episode_per_sec: 3.7512384239312024
collect_time: 1.3328931501933505
reward_mean: 1238.800048828125
reward_std: 366.4212646484375
reward_max: 1567.0
reward_min: 619.0
total_envstep_count: 1124908
total_train_sample_count: 1124873
total_episode_count: 7840
total_duration: 1427.0468639475948
[2024-11-19 23:11:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1088
train_sample_count: 1088
avg_envstep_per_episode: 155.42857142857142
avg_sample_per_episode: 155.42857142857142
avg_envstep_per_sec: 799.1794995013121
avg_train_sample_per_sec: 799.1794995013121
avg_episode_per_sec: 5.1417798681150595
collect_time: 1.3613962829113007
reward_mean: 901.4285888671875
reward_std: 272.0014953613281
reward_max: 1425.0
reward_min: 582.0
total_envstep_count: 1125925
total_train_sample_count: 1125877
total_episode_count: 7847
total_duration: 1428.4082602305061
[2024-11-19 23:11:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 686
train_sample_count: 686
avg_envstep_per_episode: 171.5
avg_sample_per_episode: 171.5
avg_envstep_per_sec: 803.0955332970972
avg_train_sample_per_sec: 803.0955332970972
avg_episode_per_sec: 4.682772788904357
collect_time: 0.8541947645800455
reward_mean: 1105.0
reward_std: 296.9132995605469
reward_max: 1422.0
reward_min: 654.0
total_envstep_count: 1126921
total_train_sample_count: 1126887
total_episode_count: 7851
total_duration: 1429.2624549950863
[2024-11-19 23:11:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1401
train_sample_count: 1401
avg_envstep_per_episode: 200.14285714285714
avg_sample_per_episode: 200.14285714285714
avg_envstep_per_sec: 799.855427075955
avg_train_sample_per_sec: 799.855427075955
avg_episode_per_sec: 3.9964225478456
collect_time: 1.7515665363697779
reward_mean: 1350.5714111328125
reward_std: 379.1825256347656
reward_max: 1855.0
reward_min: 640.0
total_envstep_count: 1127932
total_train_sample_count: 1127880
total_episode_count: 7858
total_duration: 1431.0140215314561
[2024-11-19 23:11:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 872
train_sample_count: 872
avg_envstep_per_episode: 174.4
avg_sample_per_episode: 174.4
avg_envstep_per_sec: 799.5435806224109
avg_train_sample_per_sec: 799.5435806224109
avg_episode_per_sec: 4.584538879715659
collect_time: 1.0906222263971963
reward_mean: 785.2000122070312
reward_std: 139.4078826904297
reward_max: 1033.0
reward_min: 611.0
total_envstep_count: 1128911
total_train_sample_count: 1128884
total_episode_count: 7863
total_duration: 1432.1046437578534
[2024-11-19 23:11:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 824
train_sample_count: 824
avg_envstep_per_episode: 206.0
avg_sample_per_episode: 206.0
avg_envstep_per_sec: 796.4634967063498
avg_train_sample_per_sec: 796.4634967063498
avg_episode_per_sec: 3.8663276539143197
collect_time: 1.0345734655857086
reward_mean: 1210.75
reward_std: 346.3368225097656
reward_max: 1572.0
reward_min: 639.0
total_envstep_count: 1129939
total_train_sample_count: 1129888
total_episode_count: 7867
total_duration: 1433.1392172234391
[2024-11-19 23:11:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1427
train_sample_count: 1427
avg_envstep_per_episode: 158.55555555555554
avg_sample_per_episode: 158.55555555555554
avg_envstep_per_sec: 791.6284890791536
avg_train_sample_per_sec: 791.6284890791536
avg_episode_per_sec: 4.992751507857311
collect_time: 1.8026132455893924
reward_mean: 1098.77783203125
reward_std: 473.37530517578125
reward_max: 1574.0
reward_min: 237.0
total_envstep_count: 1130915
total_train_sample_count: 1130883
total_episode_count: 7876
total_duration: 1434.9418304690284
[2024-11-19 23:11:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 748
train_sample_count: 748
avg_envstep_per_episode: 187.0
avg_sample_per_episode: 187.0
avg_envstep_per_sec: 787.5788889596018
avg_train_sample_per_sec: 787.5788889596018
avg_episode_per_sec: 4.211651812618192
collect_time: 0.949746127639498
reward_mean: 1237.25
reward_std: 427.4092712402344
reward_max: 1704.0
reward_min: 637.0
total_envstep_count: 1131927
total_train_sample_count: 1131883
total_episode_count: 7880
total_duration: 1435.8915765966678
[2024-11-19 23:11:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1259
train_sample_count: 1259
avg_envstep_per_episode: 179.85714285714286
avg_sample_per_episode: 179.85714285714286
avg_envstep_per_sec: 795.7268903317578
avg_train_sample_per_sec: 795.7268903317578
avg_episode_per_sec: 4.424216229008978
collect_time: 1.5822011487824579
reward_mean: 1083.7142333984375
reward_std: 430.9622802734375
reward_max: 1575.0
reward_min: 590.0
total_envstep_count: 1132906
total_train_sample_count: 1132878
total_episode_count: 7887
total_duration: 1437.4737777454502
[2024-11-19 23:11:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 752
train_sample_count: 752
avg_envstep_per_episode: 125.33333333333333
avg_sample_per_episode: 125.33333333333333
avg_envstep_per_sec: 803.1391750529998
avg_train_sample_per_sec: 803.1391750529998
avg_episode_per_sec: 6.408025332869679
collect_time: 0.9363258864198412
reward_mean: 637.1666870117188
reward_std: 179.1781463623047
reward_max: 774.0
reward_min: 250.0
total_envstep_count: 1133910
total_train_sample_count: 1133858
total_episode_count: 7893
total_duration: 1438.41010363187
[2024-11-19 23:11:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1267
train_sample_count: 1267
avg_envstep_per_episode: 140.77777777777777
avg_sample_per_episode: 140.77777777777777
avg_envstep_per_sec: 800.0904544662237
avg_train_sample_per_sec: 800.0904544662237
avg_episode_per_sec: 5.683357608678779
collect_time: 1.5835709486688885
reward_mean: 1016.7777709960938
reward_std: 566.2723388671875
reward_max: 1694.0
reward_min: 247.0
total_envstep_count: 1134911
total_train_sample_count: 1134861
total_episode_count: 7902
total_duration: 1439.993674580539
[2024-11-19 23:11:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 442
train_sample_count: 442
avg_envstep_per_episode: 147.33333333333334
avg_sample_per_episode: 147.33333333333334
avg_envstep_per_sec: 805.173432669176
avg_train_sample_per_sec: 805.173432669176
avg_episode_per_sec: 5.464978049790787
collect_time: 0.5489500548158373
reward_mean: 968.6666870117188
reward_std: 503.7091064453125
reward_max: 1681.0
reward_min: 608.0
total_envstep_count: 1135900
total_train_sample_count: 1135867
total_episode_count: 7905
total_duration: 1440.5426246353547
[2024-11-19 23:11:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1505
train_sample_count: 1505
avg_envstep_per_episode: 188.125
avg_sample_per_episode: 188.125
avg_envstep_per_sec: 802.7720418861238
avg_train_sample_per_sec: 802.7720418861238
avg_episode_per_sec: 4.267226800723582
collect_time: 1.8747538796492988
reward_mean: 1207.125
reward_std: 318.77239990234375
reward_max: 1689.0
reward_min: 620.0
total_envstep_count: 1136892
total_train_sample_count: 1136856
total_episode_count: 7913
total_duration: 1442.417378515004
[2024-11-19 23:11:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 400
train_sample_count: 400
avg_envstep_per_episode: 200.0
avg_sample_per_episode: 200.0
avg_envstep_per_sec: 803.103533024685
avg_train_sample_per_sec: 803.103533024685
avg_episode_per_sec: 4.015517665123426
collect_time: 0.4980677877153669
reward_mean: 1563.0
reward_std: 133.0
reward_max: 1696.0
reward_min: 1430.0
total_envstep_count: 1137867
total_train_sample_count: 1137832
total_episode_count: 7915
total_duration: 1442.9154463027194
[2024-11-19 23:12:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1686
train_sample_count: 1686
avg_envstep_per_episode: 140.5
avg_sample_per_episode: 140.5
avg_envstep_per_sec: 797.3676861348933
avg_train_sample_per_sec: 797.3676861348933
avg_episode_per_sec: 5.675214847935184
collect_time: 2.114457394395556
reward_mean: 790.75
reward_std: 480.61090087890625
reward_max: 1338.0
reward_min: 157.0
total_envstep_count: 1138912
total_train_sample_count: 1138870
total_episode_count: 7927
total_duration: 1445.0299036971148
[2024-11-19 23:12:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 506
train_sample_count: 506
avg_envstep_per_episode: 101.2
avg_sample_per_episode: 101.2
avg_envstep_per_sec: 798.7100226154608
avg_train_sample_per_sec: 798.7100226154608
avg_episode_per_sec: 7.8923915278207595
collect_time: 0.6335215355668747
reward_mean: 589.0
reward_std: 182.8518524169922
reward_max: 805.0
reward_min: 250.0
total_envstep_count: 1139899
total_train_sample_count: 1139868
total_episode_count: 7932
total_duration: 1445.6634252326817
[2024-11-19 23:12:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1269
train_sample_count: 1269
avg_envstep_per_episode: 181.28571428571428
avg_sample_per_episode: 181.28571428571428
avg_envstep_per_sec: 801.2635272513669
avg_train_sample_per_sec: 801.2635272513669
avg_episode_per_sec: 4.419893373332993
collect_time: 1.5837486130850655
reward_mean: 871.1428833007812
reward_std: 248.17242431640625
reward_max: 1315.0
reward_min: 625.0
total_envstep_count: 1140916
total_train_sample_count: 1140873
total_episode_count: 7939
total_duration: 1447.2471738457668
[2024-11-19 23:12:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1167
train_sample_count: 1167
avg_envstep_per_episode: 166.71428571428572
avg_sample_per_episode: 166.71428571428572
avg_envstep_per_sec: 799.3168517024674
avg_train_sample_per_sec: 799.3168517024674
avg_episode_per_sec: 4.794531244145048
collect_time: 1.4599967428616114
reward_mean: 918.1428833007812
reward_std: 287.80767822265625
reward_max: 1344.0
reward_min: 606.0
total_envstep_count: 1141870
total_train_sample_count: 1141848
total_episode_count: 7946
total_duration: 1448.7071705886285
[2024-11-19 23:12:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 690
train_sample_count: 690
avg_envstep_per_episode: 138.0
avg_sample_per_episode: 138.0
avg_envstep_per_sec: 808.3062868338467
avg_train_sample_per_sec: 808.3062868338467
avg_episode_per_sec: 5.857291933578599
collect_time: 0.8536368097577776
reward_mean: 998.2000122070312
reward_std: 318.1153259277344
reward_max: 1349.0
reward_min: 614.0
total_envstep_count: 1142905
total_train_sample_count: 1142862
total_episode_count: 7951
total_duration: 1449.5608073983863
[2024-11-19 23:12:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 785
train_sample_count: 785
avg_envstep_per_episode: 196.25
avg_sample_per_episode: 196.25
avg_envstep_per_sec: 800.546001837419
avg_train_sample_per_sec: 800.546001837419
avg_episode_per_sec: 4.079215295986848
collect_time: 0.9805807513850077
reward_mean: 1256.0
reward_std: 395.9457092285156
reward_max: 1665.0
reward_min: 605.0
total_envstep_count: 1143879
total_train_sample_count: 1143839
total_episode_count: 7955
total_duration: 1450.5413881497714
[2024-11-19 23:12:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1442
train_sample_count: 1442
avg_envstep_per_episode: 144.2
avg_sample_per_episode: 144.2
avg_envstep_per_sec: 803.1981287137844
avg_train_sample_per_sec: 803.1981287137844
avg_episode_per_sec: 5.570028631857035
collect_time: 1.7953229078224726
reward_mean: 951.4000244140625
reward_std: 340.4750061035156
reward_max: 1570.0
reward_min: 593.0
total_envstep_count: 1144895
total_train_sample_count: 1144849
total_episode_count: 7965
total_duration: 1452.336711057594
[2024-11-19 23:12:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 937
train_sample_count: 937
avg_envstep_per_episode: 187.4
avg_sample_per_episode: 187.4
avg_envstep_per_sec: 795.1556124528005
avg_train_sample_per_sec: 795.1556124528005
avg_episode_per_sec: 4.24309291597012
collect_time: 1.178385696240834
reward_mean: 1124.4000244140625
reward_std: 428.61199951171875
reward_max: 1839.0
reward_min: 614.0
total_envstep_count: 1145866
total_train_sample_count: 1145834
total_episode_count: 7970
total_duration: 1453.5150967538348
[2024-11-19 23:12:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 834
train_sample_count: 834
avg_envstep_per_episode: 166.8
avg_sample_per_episode: 166.8
avg_envstep_per_sec: 794.5447533544325
avg_train_sample_per_sec: 794.5447533544325
avg_episode_per_sec: 4.763457753923457
collect_time: 1.0496576769011363
reward_mean: 1068.800048828125
reward_std: 314.4222717285156
reward_max: 1326.0
reward_min: 607.0
total_envstep_count: 1146853
total_train_sample_count: 1146812
total_episode_count: 7975
total_duration: 1454.564754430736
[2024-11-19 23:12:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 763
train_sample_count: 763
avg_envstep_per_episode: 190.75
avg_sample_per_episode: 190.75
avg_envstep_per_sec: 799.4176727229645
avg_train_sample_per_sec: 799.4176727229645
avg_episode_per_sec: 4.190918336686576
collect_time: 0.9544447490147182
reward_mean: 1080.5
reward_std: 480.7444763183594
reward_max: 1690.0
reward_min: 597.0
total_envstep_count: 1147849
total_train_sample_count: 1147803
total_episode_count: 7979
total_duration: 1455.5191991797508
[2024-11-19 23:12:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1088
train_sample_count: 1088
avg_envstep_per_episode: 181.33333333333334
avg_sample_per_episode: 181.33333333333334
avg_envstep_per_sec: 801.7343215773706
avg_train_sample_per_sec: 801.7343215773706
avg_episode_per_sec: 4.42132897928697
collect_time: 1.3570580312183924
reward_mean: 1159.8333740234375
reward_std: 332.440673828125
reward_max: 1559.0
reward_min: 609.0
total_envstep_count: 1148827
total_train_sample_count: 1148795
total_episode_count: 7985
total_duration: 1456.8762572109692
[2024-11-19 23:12:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 550
train_sample_count: 550
avg_envstep_per_episode: 137.5
avg_sample_per_episode: 137.5
avg_envstep_per_sec: 811.2762078237623
avg_train_sample_per_sec: 811.2762078237623
avg_episode_per_sec: 5.900190602354635
collect_time: 0.6779442003795079
reward_mean: 673.75
reward_std: 69.11720275878906
reward_max: 788.0
reward_min: 602.0
total_envstep_count: 1149807
total_train_sample_count: 1149777
total_episode_count: 7989
total_duration: 1457.5542014113487
[2024-11-19 23:12:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1376
train_sample_count: 1376
avg_envstep_per_episode: 152.88888888888889
avg_sample_per_episode: 152.88888888888889
avg_envstep_per_sec: 802.1292532811889
avg_train_sample_per_sec: 802.1292532811889
avg_episode_per_sec: 5.2464849415194035
collect_time: 1.7154342574732642
reward_mean: 790.111083984375
reward_std: 398.6910400390625
reward_max: 1331.0
reward_min: 182.0
total_envstep_count: 1150816
total_train_sample_count: 1150769
total_episode_count: 7998
total_duration: 1459.269635668822
[2024-11-19 23:12:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1250
train_sample_count: 1250
avg_envstep_per_episode: 250.0
avg_sample_per_episode: 250.0
avg_envstep_per_sec: 805.7410313071398
avg_train_sample_per_sec: 805.7410313071398
avg_episode_per_sec: 3.2229641252285592
collect_time: 1.5513669422694616
reward_mean: 1022.0
reward_std: 720.4523315429688
reward_max: 2277.0
reward_min: 236.0
total_envstep_count: 1151780
total_train_sample_count: 1151743
total_episode_count: 8003
total_duration: 1460.8210026110914
[2024-11-19 23:12:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 921
train_sample_count: 921
avg_envstep_per_episode: 131.57142857142858
avg_sample_per_episode: 131.57142857142858
avg_envstep_per_sec: 799.388482786538
avg_train_sample_per_sec: 799.388482786538
avg_episode_per_sec: 6.075699652014947
collect_time: 1.1521306846823012
reward_mean: 824.7142944335938
reward_std: 391.8413391113281
reward_max: 1344.0
reward_min: 199.0
total_envstep_count: 1152798
total_train_sample_count: 1152748
total_episode_count: 8010
total_duration: 1461.9731332957738
[2024-11-19 23:12:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 275
train_sample_count: 275
avg_envstep_per_episode: 91.66666666666667
avg_sample_per_episode: 91.66666666666667
avg_envstep_per_sec: 787.5752018436144
avg_train_sample_per_sec: 787.5752018436144
avg_episode_per_sec: 8.591729474657612
collect_time: 0.3491730051381247
reward_mean: 741.6666870117188
reward_std: 459.8002014160156
reward_max: 1354.0
reward_min: 246.0
total_envstep_count: 1153779
total_train_sample_count: 1153743
total_episode_count: 8013
total_duration: 1462.3223063009118
[2024-11-19 23:12:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1997
train_sample_count: 1997
avg_envstep_per_episode: 181.54545454545453
avg_sample_per_episode: 181.54545454545453
avg_envstep_per_sec: 795.6702058654107
avg_train_sample_per_sec: 795.6702058654107
avg_episode_per_sec: 4.3827602726687624
collect_time: 2.5098338297435214
reward_mean: 911.4545288085938
reward_std: 421.29266357421875
reward_max: 1416.0
reward_min: 202.0
total_envstep_count: 1154785
total_train_sample_count: 1154744
total_episode_count: 8024
total_duration: 1464.8321401306553
[2024-11-19 23:13:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 460
train_sample_count: 460
avg_envstep_per_episode: 153.33333333333334
avg_sample_per_episode: 153.33333333333334
avg_envstep_per_sec: 797.9454137432168
avg_train_sample_per_sec: 797.9454137432168
avg_episode_per_sec: 5.20399182876011
collect_time: 0.5764805362338112
reward_mean: 932.0
reward_std: 299.2925109863281
reward_max: 1344.0
reward_min: 642.0
total_envstep_count: 1155743
total_train_sample_count: 1155708
total_episode_count: 8027
total_duration: 1465.408620666889
[2024-11-19 23:13:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 754
train_sample_count: 754
avg_envstep_per_episode: 188.5
avg_sample_per_episode: 188.5
avg_envstep_per_sec: 803.0095234203017
avg_train_sample_per_sec: 803.0095234203017
avg_episode_per_sec: 4.259997471725738
collect_time: 0.9389676934196836
reward_mean: 1036.25
reward_std: 419.9835510253906
reward_max: 1564.0
reward_min: 609.0
total_envstep_count: 1156739
total_train_sample_count: 1156702
total_episode_count: 8031
total_duration: 1466.3475883603087
[2024-11-19 23:13:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1212
train_sample_count: 1212
avg_envstep_per_episode: 242.4
avg_sample_per_episode: 242.4
avg_envstep_per_sec: 800.7953049328752
avg_train_sample_per_sec: 800.7953049328752
avg_episode_per_sec: 3.303610993947505
collect_time: 1.5134953870659782
reward_mean: 1257.4000244140625
reward_std: 391.0199890136719
reward_max: 1665.0
reward_min: 611.0
total_envstep_count: 1157719
total_train_sample_count: 1157686
total_episode_count: 8036
total_duration: 1467.8610837473748
[2024-11-19 23:13:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 676
train_sample_count: 676
avg_envstep_per_episode: 135.2
avg_sample_per_episode: 135.2
avg_envstep_per_sec: 810.5723226960924
avg_train_sample_per_sec: 810.5723226960924
avg_episode_per_sec: 5.995357416391216
collect_time: 0.833978635924203
reward_mean: 846.5999755859375
reward_std: 299.3116149902344
reward_max: 1427.0
reward_min: 623.0
total_envstep_count: 1158706
total_train_sample_count: 1158662
total_episode_count: 8041
total_duration: 1468.695062383299
[2024-11-19 23:13:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 778
train_sample_count: 778
avg_envstep_per_episode: 194.5
avg_sample_per_episode: 194.5
avg_envstep_per_sec: 797.2633748075349
avg_train_sample_per_sec: 797.2633748075349
avg_episode_per_sec: 4.0990404874423385
collect_time: 0.9758381290095194
reward_mean: 953.5
reward_std: 404.317626953125
reward_max: 1646.0
reward_min: 640.0
total_envstep_count: 1159711
total_train_sample_count: 1159680
total_episode_count: 8045
total_duration: 1469.6709005123087
[2024-11-19 23:13:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1772
train_sample_count: 1772
avg_envstep_per_episode: 253.14285714285714
avg_sample_per_episode: 253.14285714285714
avg_envstep_per_sec: 801.3626502347842
avg_train_sample_per_sec: 801.3626502347842
avg_episode_per_sec: 3.165653810182556
collect_time: 2.2112335775579726
reward_mean: 1094.5714111328125
reward_std: 615.5508422851562
reward_max: 2266.0
reward_min: 576.0
total_envstep_count: 1160720
total_train_sample_count: 1160684
total_episode_count: 8052
total_duration: 1471.8821340898667
[2024-11-19 23:13:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 139.2
avg_sample_per_episode: 139.2
avg_envstep_per_sec: 796.371279699998
avg_train_sample_per_sec: 796.371279699998
avg_episode_per_sec: 5.721058043821825
collect_time: 0.8739642146087827
reward_mean: 971.0
reward_std: 510.91485595703125
reward_max: 1582.0
reward_min: 201.0
total_envstep_count: 1161683
total_train_sample_count: 1161656
total_episode_count: 8057
total_duration: 1472.7560983044755
[2024-11-19 23:13:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 850
train_sample_count: 850
avg_envstep_per_episode: 170.0
avg_sample_per_episode: 170.0
avg_envstep_per_sec: 796.0738190649582
avg_train_sample_per_sec: 796.0738190649582
avg_episode_per_sec: 4.682787170970342
collect_time: 1.0677401764052254
reward_mean: 1047.4000244140625
reward_std: 497.2921142578125
reward_max: 1694.0
reward_min: 590.0
total_envstep_count: 1162718
total_train_sample_count: 1162674
total_episode_count: 8062
total_duration: 1473.8238384808808
[2024-11-19 23:13:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1519
train_sample_count: 1519
avg_envstep_per_episode: 217.0
avg_sample_per_episode: 217.0
avg_envstep_per_sec: 794.071912367614
avg_train_sample_per_sec: 794.071912367614
avg_episode_per_sec: 3.6593175685143504
collect_time: 1.9129249836717332
reward_mean: 1103.5714111328125
reward_std: 665.0410766601562
reward_max: 1831.0
reward_min: 226.0
total_envstep_count: 1163712
total_train_sample_count: 1163677
total_episode_count: 8069
total_duration: 1475.7367634645525
[2024-11-19 23:13:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 705
train_sample_count: 705
avg_envstep_per_episode: 176.25
avg_sample_per_episode: 176.25
avg_envstep_per_sec: 802.7568279304313
avg_train_sample_per_sec: 802.7568279304313
avg_episode_per_sec: 4.55464866910883
collect_time: 0.8782236107758112
reward_mean: 955.25
reward_std: 265.29547119140625
reward_max: 1342.0
reward_min: 640.0
total_envstep_count: 1164700
total_train_sample_count: 1164658
total_episode_count: 8073
total_duration: 1476.6149870753284
[2024-11-19 23:13:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1237
train_sample_count: 1237
avg_envstep_per_episode: 206.16666666666666
avg_sample_per_episode: 206.16666666666666
avg_envstep_per_sec: 795.6284853416179
avg_train_sample_per_sec: 795.6284853416179
avg_episode_per_sec: 3.8591519094985505
collect_time: 1.5547457422528947
reward_mean: 1287.0
reward_std: 620.3071899414062
reward_max: 1854.0
reward_min: 247.0
total_envstep_count: 1165671
total_train_sample_count: 1165643
total_episode_count: 8079
total_duration: 1478.1697328175812
[2024-11-19 23:14:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 747
train_sample_count: 747
avg_envstep_per_episode: 186.75
avg_sample_per_episode: 186.75
avg_envstep_per_sec: 794.890797587103
avg_train_sample_per_sec: 794.890797587103
avg_episode_per_sec: 4.25644336057351
collect_time: 0.9397517272404262
reward_mean: 955.75
reward_std: 305.08306884765625
reward_max: 1423.0
reward_min: 631.0
total_envstep_count: 1166676
total_train_sample_count: 1166642
total_episode_count: 8083
total_duration: 1479.1094845448217
[2024-11-19 23:14:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 811
train_sample_count: 811
avg_envstep_per_episode: 202.75
avg_sample_per_episode: 202.75
avg_envstep_per_sec: 797.0207853257122
avg_train_sample_per_sec: 797.0207853257122
avg_episode_per_sec: 3.931051962149012
collect_time: 1.017539335148675
reward_mean: 1334.5
reward_std: 370.1854248046875
reward_max: 1859.0
reward_min: 812.0
total_envstep_count: 1167648
total_train_sample_count: 1167609
total_episode_count: 8087
total_duration: 1480.1270238799705
[2024-11-19 23:14:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1159
train_sample_count: 1159
avg_envstep_per_episode: 165.57142857142858
avg_sample_per_episode: 165.57142857142858
avg_envstep_per_sec: 796.8659567145763
avg_train_sample_per_sec: 796.8659567145763
avg_episode_per_sec: 4.8128228619517115
collect_time: 1.4544478782585688
reward_mean: 1043.2857666015625
reward_std: 606.3195190429688
reward_max: 1688.0
reward_min: 230.0
total_envstep_count: 1168641
total_train_sample_count: 1168600
total_episode_count: 8094
total_duration: 1481.581471758229
[2024-11-19 23:14:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1090
train_sample_count: 1090
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 792.3099723224763
avg_train_sample_per_sec: 792.3099723224763
avg_episode_per_sec: 3.6344494143232855
collect_time: 1.375724196434021
reward_mean: 1187.199951171875
reward_std: 395.43414306640625
reward_max: 1751.0
reward_min: 776.0
total_envstep_count: 1169621
total_train_sample_count: 1169594
total_episode_count: 8099
total_duration: 1482.9571959546631
[2024-11-19 23:14:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 935
train_sample_count: 935
avg_envstep_per_episode: 187.0
avg_sample_per_episode: 187.0
avg_envstep_per_sec: 799.3032370040735
avg_train_sample_per_sec: 799.3032370040735
avg_episode_per_sec: 4.27434886098435
collect_time: 1.1697688145296914
reward_mean: 1071.4000244140625
reward_std: 554.2333984375
reward_max: 1572.0
reward_min: 229.0
total_envstep_count: 1170632
total_train_sample_count: 1170589
total_episode_count: 8104
total_duration: 1484.126964769193
[2024-11-19 23:14:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 515
train_sample_count: 515
avg_envstep_per_episode: 257.5
avg_sample_per_episode: 257.5
avg_envstep_per_sec: 804.1882781562447
avg_train_sample_per_sec: 804.1882781562447
avg_episode_per_sec: 3.123061274393183
collect_time: 0.6403972974845342
reward_mean: 1182.5
reward_std: 152.5
reward_max: 1335.0
reward_min: 1030.0
total_envstep_count: 1171606
total_train_sample_count: 1171560
total_episode_count: 8106
total_duration: 1484.7673620666774
[2024-11-19 23:14:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1440
train_sample_count: 1440
avg_envstep_per_episode: 288.0
avg_sample_per_episode: 288.0
avg_envstep_per_sec: 805.7144854072727
avg_train_sample_per_sec: 805.7144854072727
avg_episode_per_sec: 2.7976197409974746
collect_time: 1.787233599594661
reward_mean: 1447.0
reward_std: 345.8623962402344
reward_max: 1695.0
reward_min: 765.0
total_envstep_count: 1172602
total_train_sample_count: 1172556
total_episode_count: 8111
total_duration: 1486.554595666272
[2024-11-19 23:14:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1238
train_sample_count: 1238
avg_envstep_per_episode: 176.85714285714286
avg_sample_per_episode: 176.85714285714286
avg_envstep_per_sec: 800.5660539900872
avg_train_sample_per_sec: 800.5660539900872
avg_episode_per_sec: 4.5266255072137405
collect_time: 1.546405813523701
reward_mean: 1035.7142333984375
reward_std: 490.2913818359375
reward_max: 1690.0
reward_min: 247.0
total_envstep_count: 1173587
total_train_sample_count: 1173542
total_episode_count: 8118
total_duration: 1488.1010014797957
[2024-11-19 23:14:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1036
train_sample_count: 1036
avg_envstep_per_episode: 148.0
avg_sample_per_episode: 148.0
avg_envstep_per_sec: 793.2427307998736
avg_train_sample_per_sec: 793.2427307998736
avg_episode_per_sec: 5.359748181080227
collect_time: 1.306031508105142
reward_mean: 909.8571166992188
reward_std: 435.7808837890625
reward_max: 1628.0
reward_min: 248.0
total_envstep_count: 1174590
total_train_sample_count: 1174542
total_episode_count: 8125
total_duration: 1489.407032987901
[2024-11-19 23:14:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 586
train_sample_count: 586
avg_envstep_per_episode: 195.33333333333334
avg_sample_per_episode: 195.33333333333334
avg_envstep_per_sec: 794.0917344974572
avg_train_sample_per_sec: 794.0917344974572
avg_episode_per_sec: 4.06531604691531
collect_time: 0.7379500057016101
reward_mean: 1317.3333740234375
reward_std: 211.15606689453125
reward_max: 1561.0
reward_min: 1046.0
total_envstep_count: 1175556
total_train_sample_count: 1175512
total_episode_count: 8128
total_duration: 1490.1449829936025
[2024-11-19 23:14:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1176
train_sample_count: 1176
avg_envstep_per_episode: 196.0
avg_sample_per_episode: 196.0
avg_envstep_per_sec: 803.3708695688351
avg_train_sample_per_sec: 803.3708695688351
avg_episode_per_sec: 4.098830967187935
collect_time: 1.4638320165021081
reward_mean: 1320.8333740234375
reward_std: 325.0935363769531
reward_max: 1567.0
reward_min: 616.0
total_envstep_count: 1176534
total_train_sample_count: 1176484
total_episode_count: 8134
total_duration: 1491.6088150101045
[2024-11-19 23:14:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 805
train_sample_count: 805
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 807.3047439454575
avg_train_sample_per_sec: 807.3047439454575
avg_episode_per_sec: 5.01431517978545
collect_time: 0.9971451376165662
reward_mean: 1003.7999877929688
reward_std: 464.1884765625
reward_max: 1583.0
reward_min: 611.0
total_envstep_count: 1177498
total_train_sample_count: 1177457
total_episode_count: 8139
total_duration: 1492.6059601477211
[2024-11-19 23:14:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1346
train_sample_count: 1346
avg_envstep_per_episode: 269.2
avg_sample_per_episode: 269.2
avg_envstep_per_sec: 678.8338853465951
avg_train_sample_per_sec: 678.8338853465951
avg_episode_per_sec: 2.5216711937094916
collect_time: 1.9828120384897507
reward_mean: 1175.199951171875
reward_std: 450.4786071777344
reward_max: 1576.0
reward_min: 622.0
total_envstep_count: 1178478
total_train_sample_count: 1178443
total_episode_count: 8144
total_duration: 1494.588772186211
[2024-11-19 23:14:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 428
train_sample_count: 428
avg_envstep_per_episode: 142.66666666666666
avg_sample_per_episode: 142.66666666666666
avg_envstep_per_sec: 811.4427428627295
avg_train_sample_per_sec: 811.4427428627295
avg_episode_per_sec: 5.6876827770752065
collect_time: 0.5274555768285478
reward_mean: 891.0
reward_std: 109.60231018066406
reward_max: 1046.0
reward_min: 813.0
total_envstep_count: 1179435
total_train_sample_count: 1179411
total_episode_count: 8147
total_duration: 1495.1162277630394
[2024-11-19 23:14:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1633
train_sample_count: 1633
avg_envstep_per_episode: 204.125
avg_sample_per_episode: 204.125
avg_envstep_per_sec: 800.3546864907426
avg_train_sample_per_sec: 800.3546864907426
avg_episode_per_sec: 3.9209047715406857
collect_time: 2.0403453963143483
reward_mean: 1125.25
reward_std: 406.72955322265625
reward_max: 1613.0
reward_min: 602.0
total_envstep_count: 1180452
total_train_sample_count: 1180420
total_episode_count: 8155
total_duration: 1497.1565731593537
[2024-11-19 23:14:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 289
train_sample_count: 289
avg_envstep_per_episode: 144.5
avg_sample_per_episode: 144.5
avg_envstep_per_sec: 807.5345662343882
avg_train_sample_per_sec: 807.5345662343882
avg_episode_per_sec: 5.588474506812375
collect_time: 0.3578794172831944
reward_mean: 929.0
reward_std: 110.0
reward_max: 1039.0
reward_min: 819.0
total_envstep_count: 1181426
total_train_sample_count: 1181393
total_episode_count: 8157
total_duration: 1497.5144525766368
[2024-11-19 23:15:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1751
train_sample_count: 1751
avg_envstep_per_episode: 218.875
avg_sample_per_episode: 218.875
avg_envstep_per_sec: 794.3397178730798
avg_train_sample_per_sec: 794.3397178730798
avg_episode_per_sec: 3.629193456873009
collect_time: 2.2043465290750777
reward_mean: 1238.75
reward_std: 518.5006713867188
reward_max: 1671.0
reward_min: 237.0
total_envstep_count: 1182420
total_train_sample_count: 1182388
total_episode_count: 8165
total_duration: 1499.718799105712
[2024-11-19 23:15:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 667
train_sample_count: 667
avg_envstep_per_episode: 166.75
avg_sample_per_episode: 166.75
avg_envstep_per_sec: 797.1766157451681
avg_train_sample_per_sec: 797.1766157451681
avg_episode_per_sec: 4.780669359791113
collect_time: 0.8367029173033578
reward_mean: 1086.75
reward_std: 674.234130859375
reward_max: 1912.0
reward_min: 250.0
total_envstep_count: 1183393
total_train_sample_count: 1183367
total_episode_count: 8169
total_duration: 1500.5555020230154
[2024-11-19 23:15:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 874
train_sample_count: 874
avg_envstep_per_episode: 145.66666666666666
avg_sample_per_episode: 145.66666666666666
avg_envstep_per_sec: 793.324554111566
avg_train_sample_per_sec: 793.324554111566
avg_episode_per_sec: 5.446163987035923
collect_time: 1.1016928638730732
reward_mean: 950.5
reward_std: 392.8607482910156
reward_max: 1561.0
reward_min: 621.0
total_envstep_count: 1184419
total_train_sample_count: 1184373
total_episode_count: 8175
total_duration: 1501.6571948868884
[2024-11-19 23:15:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 884
train_sample_count: 884
avg_envstep_per_episode: 176.8
avg_sample_per_episode: 176.8
avg_envstep_per_sec: 796.9441642489583
avg_train_sample_per_sec: 796.9441642489583
avg_episode_per_sec: 4.507602738964696
collect_time: 1.1092370578220914
reward_mean: 1068.4000244140625
reward_std: 552.5731201171875
reward_max: 1681.0
reward_min: 244.0
total_envstep_count: 1185398
total_train_sample_count: 1185365
total_episode_count: 8180
total_duration: 1502.7664319447106
[2024-11-19 23:15:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 732
train_sample_count: 732
avg_envstep_per_episode: 146.4
avg_sample_per_episode: 146.4
avg_envstep_per_sec: 795.2408683744567
avg_train_sample_per_sec: 795.2408683744567
avg_episode_per_sec: 5.431973144634267
collect_time: 0.9204758320535932
reward_mean: 958.7999877929688
reward_std: 540.9826049804688
reward_max: 1606.0
reward_min: 249.0
total_envstep_count: 1186361
total_train_sample_count: 1186337
total_episode_count: 8185
total_duration: 1503.6869077767642
[2024-11-19 23:15:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 796
train_sample_count: 796
avg_envstep_per_episode: 199.0
avg_sample_per_episode: 199.0
avg_envstep_per_sec: 803.1627594595233
avg_train_sample_per_sec: 803.1627594595233
avg_episode_per_sec: 4.035993766128257
collect_time: 0.9910818082945687
reward_mean: 967.0
reward_std: 204.9548797607422
reward_max: 1111.0
reward_min: 616.0
total_envstep_count: 1187336
total_train_sample_count: 1187313
total_episode_count: 8189
total_duration: 1504.6779895850589
[2024-11-19 23:15:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 470
train_sample_count: 470
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 823.2388789080737
avg_train_sample_per_sec: 823.2388789080737
avg_episode_per_sec: 3.503144165566271
collect_time: 0.570915699005127
reward_mean: 696.5
reward_std: 93.5
reward_max: 790.0
reward_min: 603.0
total_envstep_count: 1188295
total_train_sample_count: 1188275
total_episode_count: 8191
total_duration: 1505.248905284064
[2024-11-19 23:15:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1918
train_sample_count: 1918
avg_envstep_per_episode: 191.8
avg_sample_per_episode: 191.8
avg_envstep_per_sec: 803.5355236531212
avg_train_sample_per_sec: 803.5355236531212
avg_episode_per_sec: 4.189444857419819
collect_time: 2.3869510974202837
reward_mean: 991.0
reward_std: 544.39013671875
reward_max: 1613.0
reward_min: 236.0
total_envstep_count: 1189333
total_train_sample_count: 1189293
total_episode_count: 8201
total_duration: 1507.6358563814842
[2024-11-19 23:15:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 219
train_sample_count: 219
avg_envstep_per_episode: 109.5
avg_sample_per_episode: 109.5
avg_envstep_per_sec: 802.2942758201152
avg_train_sample_per_sec: 802.2942758201152
avg_episode_per_sec: 7.326888363654021
collect_time: 0.27296717252050123
reward_mean: 642.5
reward_std: 392.5
reward_max: 1035.0
reward_min: 250.0
total_envstep_count: 1190300
total_train_sample_count: 1190268
total_episode_count: 8203
total_duration: 1507.9088235540048
[2024-11-19 23:15:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 938
train_sample_count: 938
avg_envstep_per_episode: 234.5
avg_sample_per_episode: 234.5
avg_envstep_per_sec: 804.7796415631128
avg_train_sample_per_sec: 804.7796415631128
avg_episode_per_sec: 3.431896126068711
collect_time: 1.1655364419732774
reward_mean: 1353.5
reward_std: 153.8091278076172
reward_max: 1561.0
reward_min: 1138.0
total_envstep_count: 1191289
total_train_sample_count: 1191242
total_episode_count: 8207
total_duration: 1509.074359995978
[2024-11-19 23:15:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1295
train_sample_count: 1295
avg_envstep_per_episode: 143.88888888888889
avg_sample_per_episode: 143.88888888888889
avg_envstep_per_sec: 800.2770446136823
avg_train_sample_per_sec: 800.2770446136823
avg_episode_per_sec: 5.561770966427136
collect_time: 1.6181896116052352
reward_mean: 799.111083984375
reward_std: 484.3725280761719
reward_max: 1632.0
reward_min: 244.0
total_envstep_count: 1192321
total_train_sample_count: 1192285
total_episode_count: 8216
total_duration: 1510.6925496075833
[2024-11-19 23:15:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 282
train_sample_count: 282
avg_envstep_per_episode: 141.0
avg_sample_per_episode: 141.0
avg_envstep_per_sec: 813.7836087429224
avg_train_sample_per_sec: 813.7836087429224
avg_episode_per_sec: 5.771514955623563
collect_time: 0.3465294667652675
reward_mean: 519.5
reward_std: 273.5
reward_max: 793.0
reward_min: 246.0
total_envstep_count: 1193311
total_train_sample_count: 1193251
total_episode_count: 8218
total_duration: 1511.0390790743486
[2024-11-19 23:15:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 930
train_sample_count: 930
avg_envstep_per_episode: 132.85714285714286
avg_sample_per_episode: 132.85714285714286
avg_envstep_per_sec: 798.6149696944574
avg_train_sample_per_sec: 798.6149696944574
avg_episode_per_sec: 6.011080417055055
collect_time: 1.1645161126341137
reward_mean: 708.8571166992188
reward_std: 402.3585510253906
reward_max: 1430.0
reward_min: 174.0
total_envstep_count: 1194297
total_train_sample_count: 1194265
total_episode_count: 8225
total_duration: 1512.2035951869827
[2024-11-19 23:15:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 628
train_sample_count: 628
avg_envstep_per_episode: 157.0
avg_sample_per_episode: 157.0
avg_envstep_per_sec: 805.7198540449156
avg_train_sample_per_sec: 805.7198540449156
avg_episode_per_sec: 5.131973592642774
collect_time: 0.7794272374539148
reward_mean: 1066.25
reward_std: 336.40777587890625
reward_max: 1560.0
reward_min: 610.0
total_envstep_count: 1195261
total_train_sample_count: 1195229
total_episode_count: 8229
total_duration: 1512.9830224244367
[2024-11-19 23:15:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 890
train_sample_count: 890
avg_envstep_per_episode: 178.0
avg_sample_per_episode: 178.0
avg_envstep_per_sec: 800.3323142288508
avg_train_sample_per_sec: 800.3323142288508
avg_episode_per_sec: 4.496248956341859
collect_time: 1.1120380674089703
reward_mean: 1074.800048828125
reward_std: 515.670166015625
reward_max: 1836.0
reward_min: 591.0
total_envstep_count: 1196289
total_train_sample_count: 1196239
total_episode_count: 8234
total_duration: 1514.0950604918457
[2024-11-19 23:15:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 467
train_sample_count: 467
avg_envstep_per_episode: 155.66666666666666
avg_sample_per_episode: 155.66666666666666
avg_envstep_per_sec: 797.1899220781924
avg_train_sample_per_sec: 797.1899220781924
avg_episode_per_sec: 5.1211344030719
collect_time: 0.585807706628527
reward_mean: 878.3333129882812
reward_std: 596.7167358398438
reward_max: 1674.0
reward_min: 237.0
total_envstep_count: 1197270
total_train_sample_count: 1197234
total_episode_count: 8237
total_duration: 1514.6808681984742
[2024-11-19 23:15:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 915
train_sample_count: 915
avg_envstep_per_episode: 228.75
avg_sample_per_episode: 228.75
avg_envstep_per_sec: 793.9805709698484
avg_train_sample_per_sec: 793.9805709698484
avg_episode_per_sec: 3.4709533157151844
collect_time: 1.1524211466312408
reward_mean: 1428.5
reward_std: 483.1886291503906
reward_max: 1849.0
reward_min: 638.0
total_envstep_count: 1198250
total_train_sample_count: 1198209
total_episode_count: 8241
total_duration: 1515.8332893451054
[2024-11-19 23:16:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2906
train_sample_count: 2906
avg_envstep_per_episode: 484.3333333333333
avg_sample_per_episode: 484.3333333333333
avg_envstep_per_sec: 801.7034155834311
avg_train_sample_per_sec: 801.7034155834311
avg_episode_per_sec: 1.6552720211633127
collect_time: 3.6247818626108628
reward_mean: 1126.8333740234375
reward_std: 455.2696533203125
reward_max: 1611.0
reward_min: 636.0
total_envstep_count: 1199245
total_train_sample_count: 1199207
total_episode_count: 8247
total_duration: 1519.4580712077163
[2024-11-19 23:16:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 281
train_sample_count: 281
avg_envstep_per_episode: 140.5
avg_sample_per_episode: 140.5
avg_envstep_per_sec: 786.4262777193188
avg_train_sample_per_sec: 786.4262777193188
avg_episode_per_sec: 5.597340054941771
collect_time: 0.3573125771113804
reward_mean: 1039.5
reward_std: 393.5
reward_max: 1433.0
reward_min: 646.0
total_envstep_count: 1200227
total_train_sample_count: 1200184
total_episode_count: 8249
total_duration: 1519.8153837848276
[2024-11-19 23:16:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2475
train_sample_count: 2475
avg_envstep_per_episode: 412.5
avg_sample_per_episode: 412.5
avg_envstep_per_sec: 797.8492479224049
avg_train_sample_per_sec: 797.8492479224049
avg_episode_per_sec: 1.9341799949634055
collect_time: 3.1020897825558986
reward_mean: 1308.8333740234375
reward_std: 455.76800537109375
reward_max: 1865.0
reward_min: 631.0
total_envstep_count: 1201199
total_train_sample_count: 1201171
total_episode_count: 8255
total_duration: 1522.9174735673835
[2024-11-19 23:16:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 727
train_sample_count: 727
avg_envstep_per_episode: 145.4
avg_sample_per_episode: 145.4
avg_envstep_per_sec: 797.4855226014263
avg_train_sample_per_sec: 797.4855226014263
avg_episode_per_sec: 5.48476975654351
collect_time: 0.9116152950695582
reward_mean: 946.2000122070312
reward_std: 589.062744140625
reward_max: 1891.0
reward_min: 242.0
total_envstep_count: 1202210
total_train_sample_count: 1202162
total_episode_count: 8260
total_duration: 1523.829088862453
[2024-11-19 23:16:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1010
train_sample_count: 1010
avg_envstep_per_episode: 168.33333333333334
avg_sample_per_episode: 168.33333333333334
avg_envstep_per_sec: 800.8124450641535
avg_train_sample_per_sec: 800.8124450641535
avg_episode_per_sec: 4.757301653846457
collect_time: 1.2612191608973913
reward_mean: 789.0
reward_std: 250.954833984375
reward_max: 1338.0
reward_min: 609.0
total_envstep_count: 1203188
total_train_sample_count: 1203148
total_episode_count: 8266
total_duration: 1525.0903080233504
[2024-11-19 23:16:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1447
train_sample_count: 1447
avg_envstep_per_episode: 180.875
avg_sample_per_episode: 180.875
avg_envstep_per_sec: 797.6790836131269
avg_train_sample_per_sec: 797.6790836131269
avg_episode_per_sec: 4.410112418040784
collect_time: 1.814012714794704
reward_mean: 994.125
reward_std: 403.93853759765625
reward_max: 1595.0
reward_min: 604.0
total_envstep_count: 1204228
total_train_sample_count: 1204187
total_episode_count: 8274
total_duration: 1526.904320738145
[2024-11-19 23:16:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 439
train_sample_count: 439
avg_envstep_per_episode: 109.75
avg_sample_per_episode: 109.75
avg_envstep_per_sec: 800.0890024555579
avg_train_sample_per_sec: 800.0890024555579
avg_episode_per_sec: 7.2901048059731925
collect_time: 0.5486889566693987
reward_mean: 620.5
reward_std: 282.0075378417969
reward_max: 1025.0
reward_min: 228.0
total_envstep_count: 1205240
total_train_sample_count: 1205214
total_episode_count: 8278
total_duration: 1527.4530096948145
[2024-11-19 23:16:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1532
train_sample_count: 1532
avg_envstep_per_episode: 191.5
avg_sample_per_episode: 191.5
avg_envstep_per_sec: 804.852397624663
avg_train_sample_per_sec: 804.852397624663
avg_episode_per_sec: 4.202884582896413
collect_time: 1.903454601764679
reward_mean: 975.0
reward_std: 401.3187561035156
reward_max: 1425.0
reward_min: 187.0
total_envstep_count: 1206258
total_train_sample_count: 1206230
total_episode_count: 8286
total_duration: 1529.3564642965791
[2024-11-19 23:16:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 808
train_sample_count: 808
avg_envstep_per_episode: 134.66666666666666
avg_sample_per_episode: 134.66666666666666
avg_envstep_per_sec: 806.477197222066
avg_train_sample_per_sec: 806.477197222066
avg_episode_per_sec: 5.988692058579699
collect_time: 1.0018882155418396
reward_mean: 772.6666870117188
reward_std: 522.7299194335938
reward_max: 1562.0
reward_min: 156.0
total_envstep_count: 1207244
total_train_sample_count: 1207218
total_episode_count: 8292
total_duration: 1530.358352512121
[2024-11-19 23:16:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1033
train_sample_count: 1033
avg_envstep_per_episode: 172.16666666666666
avg_sample_per_episode: 172.16666666666666
avg_envstep_per_sec: 802.9937584132338
avg_train_sample_per_sec: 802.9937584132338
avg_episode_per_sec: 4.664048935604455
collect_time: 1.2864359021186829
reward_mean: 1167.6666259765625
reward_std: 337.2119140625
reward_max: 1573.0
reward_min: 611.0
total_envstep_count: 1208257
total_train_sample_count: 1208227
total_episode_count: 8298
total_duration: 1531.6447884142397
[2024-11-19 23:16:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 792
train_sample_count: 792
avg_envstep_per_episode: 198.0
avg_sample_per_episode: 198.0
avg_envstep_per_sec: 805.2652994697271
avg_train_sample_per_sec: 805.2652994697271
avg_episode_per_sec: 4.066996461968318
collect_time: 0.9835267961025238
reward_mean: 1481.0
reward_std: 103.67015075683594
reward_max: 1584.0
reward_min: 1337.0
total_envstep_count: 1209237
total_train_sample_count: 1209199
total_episode_count: 8302
total_duration: 1532.6283152103422
[2024-11-19 23:16:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 780
train_sample_count: 780
avg_envstep_per_episode: 195.0
avg_sample_per_episode: 195.0
avg_envstep_per_sec: 813.5927728409494
avg_train_sample_per_sec: 813.5927728409494
avg_episode_per_sec: 4.172270629953586
collect_time: 0.9587105810642242
reward_mean: 956.0
reward_std: 306.1551818847656
reward_max: 1419.0
reward_min: 635.0
total_envstep_count: 1210217
total_train_sample_count: 1210183
total_episode_count: 8306
total_duration: 1533.5870257914064
[2024-11-19 23:16:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1569
train_sample_count: 1569
avg_envstep_per_episode: 224.14285714285714
avg_sample_per_episode: 224.14285714285714
avg_envstep_per_sec: 803.4287228147375
avg_train_sample_per_sec: 803.4287228147375
avg_episode_per_sec: 3.584449368835668
collect_time: 1.952880144119263
reward_mean: 1178.0
reward_std: 496.7966003417969
reward_max: 1907.0
reward_min: 579.0
total_envstep_count: 1211196
total_train_sample_count: 1211164
total_episode_count: 8313
total_duration: 1535.5399059355257
[2024-11-19 23:16:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 911
train_sample_count: 911
avg_envstep_per_episode: 151.83333333333334
avg_sample_per_episode: 151.83333333333334
avg_envstep_per_sec: 798.410264791706
avg_train_sample_per_sec: 798.410264791706
avg_episode_per_sec: 5.258464971185769
collect_time: 1.1410173944064548
reward_mean: 1164.3333740234375
reward_std: 374.43316650390625
reward_max: 1434.0
reward_min: 618.0
total_envstep_count: 1212214
total_train_sample_count: 1212171
total_episode_count: 8319
total_duration: 1536.680923329932
[2024-11-19 23:16:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 821
train_sample_count: 821
avg_envstep_per_episode: 117.28571428571429
avg_sample_per_episode: 117.28571428571429
avg_envstep_per_sec: 803.459992052952
avg_train_sample_per_sec: 803.459992052952
avg_episode_per_sec: 6.850450602156716
collect_time: 1.0218305928366525
reward_mean: 811.7142944335938
reward_std: 582.3294677734375
reward_max: 1923.0
reward_min: 236.0
total_envstep_count: 1213184
total_train_sample_count: 1213148
total_episode_count: 8326
total_duration: 1537.7027539227688
[2024-11-19 23:16:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1059
train_sample_count: 1059
avg_envstep_per_episode: 151.28571428571428
avg_sample_per_episode: 151.28571428571428
avg_envstep_per_sec: 803.6779337191547
avg_train_sample_per_sec: 803.6779337191547
avg_episode_per_sec: 5.312318730910371
collect_time: 1.3176920201097218
reward_mean: 1005.5714111328125
reward_std: 489.5256652832031
reward_max: 1570.0
reward_min: 231.0
total_envstep_count: 1214178
total_train_sample_count: 1214147
total_episode_count: 8333
total_duration: 1539.0204459428785
[2024-11-19 23:16:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 998
train_sample_count: 998
avg_envstep_per_episode: 166.33333333333334
avg_sample_per_episode: 166.33333333333334
avg_envstep_per_sec: 804.7886757610949
avg_train_sample_per_sec: 804.7886757610949
avg_episode_per_sec: 4.8384088723111915
collect_time: 1.2400770911148615
reward_mean: 828.5
reward_std: 266.10882568359375
reward_max: 1326.0
reward_min: 598.0
total_envstep_count: 1215190
total_train_sample_count: 1215169
total_episode_count: 8339
total_duration: 1540.2605230339934
[2024-11-19 23:17:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 852
train_sample_count: 852
avg_envstep_per_episode: 213.0
avg_sample_per_episode: 213.0
avg_envstep_per_sec: 806.9295335461393
avg_train_sample_per_sec: 806.9295335461393
avg_episode_per_sec: 3.7884015659443158
collect_time: 1.0558542779513767
reward_mean: 1584.25
reward_std: 455.3286437988281
reward_max: 1920.0
reward_min: 813.0
total_envstep_count: 1216226
total_train_sample_count: 1216177
total_episode_count: 8343
total_duration: 1541.3163773119447
[2024-11-19 23:17:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1493
train_sample_count: 1493
avg_envstep_per_episode: 165.88888888888889
avg_sample_per_episode: 165.88888888888889
avg_envstep_per_sec: 799.6741242653202
avg_train_sample_per_sec: 799.6741242653202
avg_episode_per_sec: 4.820540601733343
collect_time: 1.8670105167797633
reward_mean: 1038.0
reward_std: 355.9197692871094
reward_max: 1577.0
reward_min: 579.0
total_envstep_count: 1217227
total_train_sample_count: 1217190
total_episode_count: 8352
total_duration: 1543.1833878287246
[2024-11-19 23:17:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 594
train_sample_count: 594
avg_envstep_per_episode: 148.5
avg_sample_per_episode: 148.5
avg_envstep_per_sec: 795.6595618446167
avg_train_sample_per_sec: 795.6595618446167
avg_episode_per_sec: 5.357976847438496
collect_time: 0.7465504450457436
reward_mean: 837.0
reward_std: 345.7491760253906
reward_max: 1425.0
reward_min: 586.0
total_envstep_count: 1218215
total_train_sample_count: 1218180
total_episode_count: 8356
total_duration: 1543.9299382737704
[2024-11-19 23:17:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1469
train_sample_count: 1469
avg_envstep_per_episode: 163.22222222222223
avg_sample_per_episode: 163.22222222222223
avg_envstep_per_sec: 804.7679725132639
avg_train_sample_per_sec: 804.7679725132639
avg_episode_per_sec: 4.930504937113257
collect_time: 1.8253708524363381
reward_mean: 791.5555419921875
reward_std: 323.229248046875
reward_max: 1326.0
reward_min: 225.0
total_envstep_count: 1219257
total_train_sample_count: 1219217
total_episode_count: 8365
total_duration: 1545.7553091262068
[2024-11-19 23:17:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 403
train_sample_count: 403
avg_envstep_per_episode: 80.6
avg_sample_per_episode: 80.6
avg_envstep_per_sec: 802.950149638313
avg_train_sample_per_sec: 802.950149638313
avg_episode_per_sec: 9.962160665487755
collect_time: 0.5018991529941559
reward_mean: 467.20001220703125
reward_std: 224.15029907226562
reward_max: 649.0
reward_min: 141.0
total_envstep_count: 1220252
total_train_sample_count: 1220220
total_episode_count: 8370
total_duration: 1546.257208279201
[2024-11-19 23:17:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1715
train_sample_count: 1715
avg_envstep_per_episode: 155.9090909090909
avg_sample_per_episode: 155.9090909090909
avg_envstep_per_sec: 796.459865818877
avg_train_sample_per_sec: 796.459865818877
avg_episode_per_sec: 5.108488935281427
collect_time: 2.1532786190509796
reward_mean: 1158.0909423828125
reward_std: 459.3033142089844
reward_max: 1586.0
reward_min: 252.0
total_envstep_count: 1221250
total_train_sample_count: 1221215
total_episode_count: 8381
total_duration: 1548.410486898252
[2024-11-19 23:17:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 584
train_sample_count: 584
avg_envstep_per_episode: 146.0
avg_sample_per_episode: 146.0
avg_envstep_per_sec: 795.0489728843012
avg_train_sample_per_sec: 795.0489728843012
avg_episode_per_sec: 5.4455409101664465
collect_time: 0.7345459461212159
reward_mean: 837.0
reward_std: 350.8974304199219
reward_max: 1436.0
reward_min: 582.0
total_envstep_count: 1222239
total_train_sample_count: 1222195
total_episode_count: 8385
total_duration: 1549.1450328443732
[2024-11-19 23:17:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1061
train_sample_count: 1061
avg_envstep_per_episode: 212.2
avg_sample_per_episode: 212.2
avg_envstep_per_sec: 795.8345011410595
avg_train_sample_per_sec: 795.8345011410595
avg_episode_per_sec: 3.750398214613852
collect_time: 1.333191760948726
reward_mean: 1205.199951171875
reward_std: 426.0509033203125
reward_max: 1669.0
reward_min: 637.0
total_envstep_count: 1223242
total_train_sample_count: 1223208
total_episode_count: 8390
total_duration: 1550.4782246053219
[2024-11-19 23:17:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 587
train_sample_count: 587
avg_envstep_per_episode: 195.66666666666666
avg_sample_per_episode: 195.66666666666666
avg_envstep_per_sec: 793.0012793374758
avg_train_sample_per_sec: 793.0012793374758
avg_episode_per_sec: 4.052817441247747
collect_time: 0.7402257919311523
reward_mean: 1218.0
reward_std: 290.6280517578125
reward_max: 1426.0
reward_min: 807.0
total_envstep_count: 1224239
total_train_sample_count: 1224191
total_episode_count: 8393
total_duration: 1551.218450397253
[2024-11-19 23:17:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 437
train_sample_count: 437
avg_envstep_per_episode: 218.5
avg_sample_per_episode: 218.5
avg_envstep_per_sec: 806.1110243879531
avg_train_sample_per_sec: 806.1110243879531
avg_episode_per_sec: 3.689295306123355
collect_time: 0.5421089487416403
reward_mean: 971.0
reward_std: 329.0
reward_max: 1300.0
reward_min: 642.0
total_envstep_count: 1225213
total_train_sample_count: 1225180
total_episode_count: 8395
total_duration: 1551.7605593459946
[2024-11-19 23:17:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 878
train_sample_count: 878
avg_envstep_per_episode: 219.5
avg_sample_per_episode: 219.5
avg_envstep_per_sec: 806.8716128065249
avg_train_sample_per_sec: 806.8716128065249
avg_episode_per_sec: 3.675952677934054
collect_time: 1.0881532898971011
reward_mean: 1098.0
reward_std: 294.4656066894531
reward_max: 1406.0
reward_min: 650.0
total_envstep_count: 1226201
total_train_sample_count: 1226166
total_episode_count: 8399
total_duration: 1552.8487126358916
[2024-11-19 23:17:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1001
train_sample_count: 1001
avg_envstep_per_episode: 200.2
avg_sample_per_episode: 200.2
avg_envstep_per_sec: 806.8869267164067
avg_train_sample_per_sec: 806.8869267164067
avg_episode_per_sec: 4.030404229352681
collect_time: 1.2405703536101749
reward_mean: 894.7999877929688
reward_std: 501.9093017578125
reward_max: 1591.0
reward_min: 252.0
total_envstep_count: 1227180
total_train_sample_count: 1227131
total_episode_count: 8404
total_duration: 1554.0892829895017
[2024-11-19 23:17:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 749
train_sample_count: 749
avg_envstep_per_episode: 187.25
avg_sample_per_episode: 187.25
avg_envstep_per_sec: 805.8712507003326
avg_train_sample_per_sec: 805.8712507003326
avg_episode_per_sec: 4.303718294794833
collect_time: 0.9294288626738958
reward_mean: 1317.25
reward_std: 404.1202697753906
reward_max: 1575.0
reward_min: 619.0
total_envstep_count: 1228160
total_train_sample_count: 1228108
total_episode_count: 8408
total_duration: 1555.0187118521756
[2024-11-19 23:17:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 689
train_sample_count: 689
avg_envstep_per_episode: 172.25
avg_sample_per_episode: 172.25
avg_envstep_per_sec: 803.7956907465842
avg_train_sample_per_sec: 803.7956907465842
avg_episode_per_sec: 4.666448132055642
collect_time: 0.857182998032797
reward_mean: 961.75
reward_std: 388.4664611816406
reward_max: 1568.0
reward_min: 604.0
total_envstep_count: 1229132
total_train_sample_count: 1229097
total_episode_count: 8412
total_duration: 1555.8758948502084
[2024-11-19 23:17:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 557
train_sample_count: 557
avg_envstep_per_episode: 185.66666666666666
avg_sample_per_episode: 185.66666666666666
avg_envstep_per_sec: 804.9879123869226
avg_train_sample_per_sec: 804.9879123869226
avg_episode_per_sec: 4.335662005674628
collect_time: 0.6919358557178861
reward_mean: 1312.0
reward_std: 215.99229431152344
reward_max: 1574.0
reward_min: 1045.0
total_envstep_count: 1230121
total_train_sample_count: 1230074
total_episode_count: 8415
total_duration: 1556.5678307059263
[2024-11-19 23:17:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1140
train_sample_count: 1140
avg_envstep_per_episode: 228.0
avg_sample_per_episode: 228.0
avg_envstep_per_sec: 798.0967888612423
avg_train_sample_per_sec: 798.0967888612423
avg_episode_per_sec: 3.500424512549308
collect_time: 1.4283981791564397
reward_mean: 1418.800048828125
reward_std: 119.02167510986328
reward_max: 1571.0
reward_min: 1301.0
total_envstep_count: 1231108
total_train_sample_count: 1231070
total_episode_count: 8420
total_duration: 1557.9962288850827
[2024-11-19 23:18:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 362
train_sample_count: 362
avg_envstep_per_episode: 362.0
avg_sample_per_episode: 362.0
avg_envstep_per_sec: 797.8597508793572
avg_train_sample_per_sec: 797.8597508793572
avg_episode_per_sec: 2.2040324609926993
collect_time: 0.4537138257707868
reward_mean: 1291.0
reward_std: 0.0
reward_max: 1291.0
reward_min: 1291.0
total_envstep_count: 1232547
total_train_sample_count: 1232512
total_episode_count: 8421
total_duration: 1558.4499427108535
[2024-11-19 23:18:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1115
train_sample_count: 1115
avg_envstep_per_episode: 223.0
avg_sample_per_episode: 223.0
avg_envstep_per_sec: 808.7030434608704
avg_train_sample_per_sec: 808.7030434608704
avg_episode_per_sec: 3.626471046909733
collect_time: 1.3787508394036976
reward_mean: 779.0
reward_std: 394.6770935058594
reward_max: 1402.0
reward_min: 249.0
total_envstep_count: 1233550
total_train_sample_count: 1233507
total_episode_count: 8426
total_duration: 1559.8286935502572
[2024-11-19 23:18:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1274
train_sample_count: 1274
avg_envstep_per_episode: 212.33333333333334
avg_sample_per_episode: 212.33333333333334
avg_envstep_per_sec: 801.6628783565175
avg_train_sample_per_sec: 801.6628783565175
avg_episode_per_sec: 3.77549236274655
collect_time: 1.589196699006217
reward_mean: 1015.3333129882812
reward_std: 360.25531005859375
reward_max: 1434.0
reward_min: 587.0
total_envstep_count: 1234569
total_train_sample_count: 1234517
total_episode_count: 8432
total_duration: 1561.4178902492633
[2024-11-19 23:18:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 275
train_sample_count: 275
avg_envstep_per_episode: 137.5
avg_sample_per_episode: 137.5
avg_envstep_per_sec: 815.9991736957941
avg_train_sample_per_sec: 815.9991736957941
avg_episode_per_sec: 5.934539445060321
collect_time: 0.33701014518737793
reward_mean: 849.0
reward_std: 206.0
reward_max: 1055.0
reward_min: 643.0
total_envstep_count: 1235535
total_train_sample_count: 1235488
total_episode_count: 8434
total_duration: 1561.7549003944507
[2024-11-19 23:18:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 671
train_sample_count: 671
avg_envstep_per_episode: 134.2
avg_sample_per_episode: 134.2
avg_envstep_per_sec: 799.2414590398657
avg_train_sample_per_sec: 799.2414590398657
avg_episode_per_sec: 5.955599545751608
collect_time: 0.8395460375717707
reward_mean: 727.2000122070312
reward_std: 344.3634338378906
reward_max: 1316.0
reward_min: 248.0
total_envstep_count: 1236498
total_train_sample_count: 1236459
total_episode_count: 8439
total_duration: 1562.5944464320226
[2024-11-19 23:18:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2915
train_sample_count: 2915
avg_envstep_per_episode: 416.42857142857144
avg_sample_per_episode: 416.42857142857144
avg_envstep_per_sec: 797.556117503038
avg_train_sample_per_sec: 797.556117503038
avg_episode_per_sec: 1.9152290986350826
collect_time: 3.654915229195639
reward_mean: 1343.142822265625
reward_std: 343.7284851074219
reward_max: 1646.0
reward_min: 627.0
total_envstep_count: 1237515
total_train_sample_count: 1237478
total_episode_count: 8446
total_duration: 1566.2493616612182
[2024-11-19 23:18:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 461
train_sample_count: 461
avg_envstep_per_episode: 153.66666666666666
avg_sample_per_episode: 153.66666666666666
avg_envstep_per_sec: 788.533992430696
avg_train_sample_per_sec: 788.533992430696
avg_episode_per_sec: 5.131457651392815
collect_time: 0.584629203592028
reward_mean: 1056.3333740234375
reward_std: 203.40817260742188
reward_max: 1315.0
reward_min: 818.0
total_envstep_count: 1238504
total_train_sample_count: 1238467
total_episode_count: 8449
total_duration: 1566.8339908648102
[2024-11-19 23:18:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 2717
train_sample_count: 2717
avg_envstep_per_episode: 679.25
avg_sample_per_episode: 679.25
avg_envstep_per_sec: 800.2641425933041
avg_train_sample_per_sec: 800.2641425933041
avg_episode_per_sec: 1.178158472717415
collect_time: 3.395129002275921
reward_mean: 1530.25
reward_std: 694.544921875
reward_max: 2583.0
reward_min: 633.0
total_envstep_count: 1239493
total_train_sample_count: 1239468
total_episode_count: 8453
total_duration: 1570.2291198670862
[2024-11-19 23:18:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1122
train_sample_count: 1122
avg_envstep_per_episode: 224.4
avg_sample_per_episode: 224.4
avg_envstep_per_sec: 802.6052047818847
avg_train_sample_per_sec: 802.6052047818847
avg_episode_per_sec: 3.576672035569896
collect_time: 1.3979475753647943
reward_mean: 978.4000244140625
reward_std: 378.8216552734375
reward_max: 1642.0
reward_min: 583.0
total_envstep_count: 1240451
total_train_sample_count: 1240434
total_episode_count: 8458
total_duration: 1571.6270674424509
[2024-11-19 23:18:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 906
train_sample_count: 906
avg_envstep_per_episode: 181.2
avg_sample_per_episode: 181.2
avg_envstep_per_sec: 796.644629565981
avg_train_sample_per_sec: 796.644629565981
avg_episode_per_sec: 4.396493540651109
collect_time: 1.1372699524675096
reward_mean: 1117.4000244140625
reward_std: 385.83447265625
reward_max: 1577.0
reward_min: 628.0
total_envstep_count: 1241471
total_train_sample_count: 1241436
total_episode_count: 8463
total_duration: 1572.7643373949184
[2024-11-19 23:18:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1252
train_sample_count: 1252
avg_envstep_per_episode: 139.11111111111111
avg_sample_per_episode: 139.11111111111111
avg_envstep_per_sec: 793.4092695143945
avg_train_sample_per_sec: 793.4092695143945
avg_episode_per_sec: 5.703421266477277
collect_time: 1.578000217676163
reward_mean: 923.3333129882812
reward_std: 367.85504150390625
reward_max: 1432.0
reward_min: 238.0
total_envstep_count: 1242505
total_train_sample_count: 1242484
total_episode_count: 8472
total_duration: 1574.3423376125945
[2024-11-19 23:19:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1078
train_sample_count: 1078
avg_envstep_per_episode: 179.66666666666666
avg_sample_per_episode: 179.66666666666666
avg_envstep_per_sec: 791.9742305621413
avg_train_sample_per_sec: 791.9742305621413
avg_episode_per_sec: 4.40801983615292
collect_time: 1.3611553992543903
reward_mean: 1188.8333740234375
reward_std: 342.2871398925781
reward_max: 1587.0
reward_min: 595.0
total_envstep_count: 1243540
total_train_sample_count: 1243490
total_episode_count: 8478
total_duration: 1575.7034930118489
[2024-11-19 23:19:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 891
train_sample_count: 891
avg_envstep_per_episode: 148.5
avg_sample_per_episode: 148.5
avg_envstep_per_sec: 795.9578760542257
avg_train_sample_per_sec: 795.9578760542257
avg_episode_per_sec: 5.359985697334854
collect_time: 1.119405972106116
reward_mean: 860.1666870117188
reward_std: 450.97686767578125
reward_max: 1575.0
reward_min: 247.0
total_envstep_count: 1244527
total_train_sample_count: 1244477
total_episode_count: 8484
total_duration: 1576.822898983955
[2024-11-19 23:19:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 715
train_sample_count: 715
avg_envstep_per_episode: 238.33333333333334
avg_sample_per_episode: 238.33333333333334
avg_envstep_per_sec: 794.9763917146878
avg_train_sample_per_sec: 794.9763917146878
avg_episode_per_sec: 3.335565279921767
collect_time: 0.8993977776595524
reward_mean: 1391.3333740234375
reward_std: 238.54327392578125
reward_max: 1563.0
reward_min: 1054.0
total_envstep_count: 1245484
total_train_sample_count: 1245444
total_episode_count: 8487
total_duration: 1577.7222967616144
[2024-11-19 23:19:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1580
train_sample_count: 1580
avg_envstep_per_episode: 175.55555555555554
avg_sample_per_episode: 175.55555555555554
avg_envstep_per_sec: 800.0140525430403
avg_train_sample_per_sec: 800.0140525430403
avg_episode_per_sec: 4.557042071447698
collect_time: 1.9749653083937508
reward_mean: 1188.111083984375
reward_std: 362.297119140625
reward_max: 1621.0
reward_min: 645.0
total_envstep_count: 1246486
total_train_sample_count: 1246448
total_episode_count: 8496
total_duration: 1579.6972620700083
[2024-11-19 23:19:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 799
train_sample_count: 799
avg_envstep_per_episode: 159.8
avg_sample_per_episode: 159.8
avg_envstep_per_sec: 792.0188837081206
avg_train_sample_per_sec: 792.0188837081206
avg_episode_per_sec: 4.956313414944434
collect_time: 1.0088143306119102
reward_mean: 1139.0
reward_std: 426.52032470703125
reward_max: 1687.0
reward_min: 629.0
total_envstep_count: 1247458
total_train_sample_count: 1247439
total_episode_count: 8501
total_duration: 1580.70607640062
[2024-11-19 23:19:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 762
train_sample_count: 762
avg_envstep_per_episode: 152.4
avg_sample_per_episode: 152.4
avg_envstep_per_sec: 794.2560700238756
avg_train_sample_per_sec: 794.2560700238756
avg_episode_per_sec: 5.211654002781335
collect_time: 0.959388324192592
reward_mean: 1130.4000244140625
reward_std: 620.829345703125
reward_max: 1697.0
reward_min: 145.0
total_envstep_count: 1248437
total_train_sample_count: 1248405
total_episode_count: 8506
total_duration: 1581.6654647248126
[2024-11-19 23:19:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1320
train_sample_count: 1320
avg_envstep_per_episode: 188.57142857142858
avg_sample_per_episode: 188.57142857142858
avg_envstep_per_sec: 801.4672109919018
avg_train_sample_per_sec: 801.4672109919018
avg_episode_per_sec: 4.250204906775237
collect_time: 1.6469794171197074
reward_mean: 1066.0
reward_std: 345.0892333984375
reward_max: 1554.0
reward_min: 635.0
total_envstep_count: 1249447
total_train_sample_count: 1249401
total_episode_count: 8513
total_duration: 1583.3124441419322
[2024-11-19 23:19:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 889
train_sample_count: 889
avg_envstep_per_episode: 148.16666666666666
avg_sample_per_episode: 148.16666666666666
avg_envstep_per_sec: 805.624777632505
avg_train_sample_per_sec: 805.624777632505
avg_episode_per_sec: 5.4372875880709
collect_time: 1.103491382939475
reward_mean: 860.6666870117188
reward_std: 454.19586181640625
reward_max: 1571.0
reward_min: 228.0
total_envstep_count: 1250443
total_train_sample_count: 1250410
total_episode_count: 8519
total_duration: 1584.4159355248717
[2024-11-19 23:19:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 857
train_sample_count: 857
avg_envstep_per_episode: 171.4
avg_sample_per_episode: 171.4
avg_envstep_per_sec: 802.9613855956493
avg_train_sample_per_sec: 802.9613855956493
avg_episode_per_sec: 4.684722203008456
collect_time: 1.067299144608634
reward_mean: 1245.5999755859375
reward_std: 374.2633056640625
reward_max: 1581.0
reward_min: 606.0
total_envstep_count: 1251454
total_train_sample_count: 1251423
total_episode_count: 8524
total_duration: 1585.4832346694802
[2024-11-19 23:19:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1130
train_sample_count: 1130
avg_envstep_per_episode: 141.25
avg_sample_per_episode: 141.25
avg_envstep_per_sec: 802.9258582877178
avg_train_sample_per_sec: 802.9258582877178
avg_episode_per_sec: 5.684430855134286
collect_time: 1.4073528562273299
reward_mean: 827.625
reward_std: 248.62217712402344
reward_max: 1296.0
reward_min: 599.0
total_envstep_count: 1252471
total_train_sample_count: 1252445
total_episode_count: 8532
total_duration: 1586.8905875257076
[2024-11-19 23:19:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 558
train_sample_count: 558
avg_envstep_per_episode: 139.5
avg_sample_per_episode: 139.5
avg_envstep_per_sec: 787.7463333164621
avg_train_sample_per_sec: 787.7463333164621
avg_episode_per_sec: 5.646927120548115
collect_time: 0.7083498537540436
reward_mean: 998.5
reward_std: 426.5363464355469
reward_max: 1678.0
reward_min: 623.0
total_envstep_count: 1253467
total_train_sample_count: 1253447
total_episode_count: 8536
total_duration: 1587.5989373794616
[2024-11-19 23:19:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 801
train_sample_count: 801
avg_envstep_per_episode: 200.25
avg_sample_per_episode: 200.25
avg_envstep_per_sec: 799.8931635580985
avg_train_sample_per_sec: 799.8931635580985
avg_episode_per_sec: 3.9944727268818903
collect_time: 1.0013837303434099
reward_mean: 1158.75
reward_std: 286.1375427246094
reward_max: 1434.0
reward_min: 762.0
total_envstep_count: 1254455
total_train_sample_count: 1254416
total_episode_count: 8540
total_duration: 1588.600321109805
[2024-11-19 23:19:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 431
train_sample_count: 431
avg_envstep_per_episode: 143.66666666666666
avg_sample_per_episode: 143.66666666666666
avg_envstep_per_sec: 793.3643770686922
avg_train_sample_per_sec: 793.3643770686922
avg_episode_per_sec: 5.5222578450257
collect_time: 0.5432560529027667
reward_mean: 993.0
reward_std: 482.246826171875
reward_max: 1675.0
reward_min: 652.0
total_envstep_count: 1255461
total_train_sample_count: 1255423
total_episode_count: 8543
total_duration: 1589.1435771627077
[2024-11-19 23:19:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1486
train_sample_count: 1486
avg_envstep_per_episode: 247.66666666666666
avg_sample_per_episode: 247.66666666666666
avg_envstep_per_sec: 800.5082566464137
avg_train_sample_per_sec: 800.5082566464137
avg_episode_per_sec: 3.2322002287203784
collect_time: 1.8563206408705033
reward_mean: 1469.0
reward_std: 605.0374755859375
reward_max: 2600.0
reward_min: 621.0
total_envstep_count: 1256447
total_train_sample_count: 1256417
total_episode_count: 8549
total_duration: 1590.9998978035783
[2024-11-19 23:19:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 756
train_sample_count: 756
avg_envstep_per_episode: 151.2
avg_sample_per_episode: 151.2
avg_envstep_per_sec: 799.6042396744734
avg_train_sample_per_sec: 799.6042396744734
avg_episode_per_sec: 5.288387828534877
collect_time: 0.945467723267419
reward_mean: 882.2000122070312
reward_std: 450.38800048828125
reward_max: 1431.0
reward_min: 239.0
total_envstep_count: 1257458
total_train_sample_count: 1257425
total_episode_count: 8554
total_duration: 1591.9453655268458
[2024-11-19 23:19:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 654
train_sample_count: 654
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 796.1519726253672
avg_train_sample_per_sec: 796.1519726253672
avg_episode_per_sec: 3.652073268923703
collect_time: 0.8214512084211623
reward_mean: 1319.6666259765625
reward_std: 419.735107421875
reward_max: 1666.0
reward_min: 729.0
total_envstep_count: 1258487
total_train_sample_count: 1258439
total_episode_count: 8557
total_duration: 1592.766816735267
[2024-11-19 23:20:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1072
train_sample_count: 1072
avg_envstep_per_episode: 153.14285714285714
avg_sample_per_episode: 153.14285714285714
avg_envstep_per_sec: 800.0244327027757
avg_train_sample_per_sec: 800.0244327027757
avg_episode_per_sec: 5.2240401389173785
collect_time: 1.3399590764726912
reward_mean: 956.4285888671875
reward_std: 591.1762084960938
reward_max: 2360.0
reward_min: 593.0
total_envstep_count: 1259473
total_train_sample_count: 1259427
total_episode_count: 8564
total_duration: 1594.1067758117397
[2024-11-19 23:20:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 699
train_sample_count: 699
avg_envstep_per_episode: 349.5
avg_sample_per_episode: 349.5
avg_envstep_per_sec: 802.0092337888857
avg_train_sample_per_sec: 802.0092337888857
avg_episode_per_sec: 2.294733143888085
collect_time: 0.8715610376426153
reward_mean: 1155.5
reward_std: 115.5
reward_max: 1271.0
reward_min: 1040.0
total_envstep_count: 1260431
total_train_sample_count: 1260390
total_episode_count: 8566
total_duration: 1594.9783368493822
[2024-11-19 23:20:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 789
train_sample_count: 789
avg_envstep_per_episode: 197.25
avg_sample_per_episode: 197.25
avg_envstep_per_sec: 803.9629036282319
avg_train_sample_per_sec: 803.9629036282319
avg_episode_per_sec: 4.075857559585459
collect_time: 0.9813885646206992
reward_mean: 1232.25
reward_std: 321.4151306152344
reward_max: 1637.0
reward_min: 805.0
total_envstep_count: 1261387
total_train_sample_count: 1261359
total_episode_count: 8570
total_duration: 1595.9597254140028
[2024-11-19 23:20:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1094
train_sample_count: 1094
avg_envstep_per_episode: 182.33333333333334
avg_sample_per_episode: 182.33333333333334
avg_envstep_per_sec: 802.2421415992167
avg_train_sample_per_sec: 802.2421415992167
avg_episode_per_sec: 4.399865493231536
collect_time: 1.3636780508926936
reward_mean: 1064.3333740234375
reward_std: 371.3428955078125
reward_max: 1626.0
reward_min: 623.0
total_envstep_count: 1262399
total_train_sample_count: 1262357
total_episode_count: 8576
total_duration: 1597.3234034648956
[2024-11-19 23:20:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 699
train_sample_count: 699
avg_envstep_per_episode: 139.8
avg_sample_per_episode: 139.8
avg_envstep_per_sec: 809.1364578395951
avg_train_sample_per_sec: 809.1364578395951
avg_episode_per_sec: 5.787814433759621
collect_time: 0.8638839508805958
reward_mean: 891.2000122070312
reward_std: 738.8698120117188
reward_max: 2340.0
reward_min: 248.0
total_envstep_count: 1263363
total_train_sample_count: 1263332
total_episode_count: 8581
total_duration: 1598.1872874157762
[2024-11-19 23:20:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1150
train_sample_count: 1150
avg_envstep_per_episode: 230.0
avg_sample_per_episode: 230.0
avg_envstep_per_sec: 806.9306711253749
avg_train_sample_per_sec: 806.9306711253749
avg_episode_per_sec: 3.508394222284239
collect_time: 1.4251534129892076
reward_mean: 1245.4000244140625
reward_std: 324.54620361328125
reward_max: 1575.0
reward_min: 627.0
total_envstep_count: 1264359
total_train_sample_count: 1264314
total_episode_count: 8586
total_duration: 1599.6124408287653
[2024-11-19 23:20:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 969
train_sample_count: 969
avg_envstep_per_episode: 138.42857142857142
avg_sample_per_episode: 138.42857142857142
avg_envstep_per_sec: 799.2513725158035
avg_train_sample_per_sec: 799.2513725158035
avg_episode_per_sec: 5.773745725088364
collect_time: 1.2123845304761613
reward_mean: 1006.7142944335938
reward_std: 450.2940979003906
reward_max: 1643.0
reward_min: 614.0
total_envstep_count: 1265368
total_train_sample_count: 1265319
total_episode_count: 8593
total_duration: 1600.8248253592415
[2024-11-19 23:20:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2798
train_sample_count: 2798
avg_envstep_per_episode: 399.7142857142857
avg_sample_per_episode: 399.7142857142857
avg_envstep_per_sec: 800.8451282653197
avg_train_sample_per_sec: 800.8451282653197
avg_episode_per_sec: 2.0035439234657746
collect_time: 3.4938091039657593
reward_mean: 1117.7142333984375
reward_std: 563.653564453125
reward_max: 1771.0
reward_min: 252.0
total_envstep_count: 1266339
total_train_sample_count: 1266317
total_episode_count: 8600
total_duration: 1604.3186344632072
[2024-11-19 23:20:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 884
train_sample_count: 884
avg_envstep_per_episode: 147.33333333333334
avg_sample_per_episode: 147.33333333333334
avg_envstep_per_sec: 805.3356172482163
avg_train_sample_per_sec: 805.3356172482163
avg_episode_per_sec: 5.466078850101016
collect_time: 1.0976790062018804
reward_mean: 966.0
reward_std: 434.1190185546875
reward_max: 1695.0
reward_min: 591.0
total_envstep_count: 1267349
total_train_sample_count: 1267321
total_episode_count: 8606
total_duration: 1605.416313469409
[2024-11-19 23:20:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 784
train_sample_count: 784
avg_envstep_per_episode: 156.8
avg_sample_per_episode: 156.8
avg_envstep_per_sec: 806.7056919231503
avg_train_sample_per_sec: 806.7056919231503
avg_episode_per_sec: 5.144806708693561
collect_time: 0.9718538096972875
reward_mean: 1029.199951171875
reward_std: 503.73858642578125
reward_max: 1723.0
reward_min: 591.0
total_envstep_count: 1268305
total_train_sample_count: 1268285
total_episode_count: 8611
total_duration: 1606.3881672791063
[2024-11-19 23:20:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1158
train_sample_count: 1158
avg_envstep_per_episode: 128.66666666666666
avg_sample_per_episode: 128.66666666666666
avg_envstep_per_sec: 796.6486079287988
avg_train_sample_per_sec: 796.6486079287988
avg_episode_per_sec: 6.191569491674602
collect_time: 1.453589435134615
reward_mean: 996.4444580078125
reward_std: 459.3006896972656
reward_max: 1677.0
reward_min: 250.0
total_envstep_count: 1269354
total_train_sample_count: 1269323
total_episode_count: 8620
total_duration: 1607.8417567142408
[2024-11-19 23:20:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1391
train_sample_count: 1391
avg_envstep_per_episode: 126.45454545454545
avg_sample_per_episode: 126.45454545454545
avg_envstep_per_sec: 805.7156705676745
avg_train_sample_per_sec: 805.7156705676745
avg_episode_per_sec: 6.371583304273486
collect_time: 1.7264154723712375
reward_mean: 784.0
reward_std: 608.7025146484375
reward_max: 2331.0
reward_min: 250.0
total_envstep_count: 1270392
total_train_sample_count: 1270342
total_episode_count: 8631
total_duration: 1609.568172186612
[2024-11-19 23:20:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 592
train_sample_count: 592
avg_envstep_per_episode: 197.33333333333334
avg_sample_per_episode: 197.33333333333334
avg_envstep_per_sec: 809.6515176095999
avg_train_sample_per_sec: 809.6515176095999
avg_episode_per_sec: 4.10296377167027
collect_time: 0.7311787690435138
reward_mean: 1348.3333740234375
reward_std: 205.09727478027344
reward_max: 1565.0
reward_min: 1073.0
total_envstep_count: 1271373
total_train_sample_count: 1271330
total_episode_count: 8634
total_duration: 1610.2993509556554
[2024-11-19 23:20:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1308
train_sample_count: 1308
avg_envstep_per_episode: 163.5
avg_sample_per_episode: 163.5
avg_envstep_per_sec: 792.5867693216237
avg_train_sample_per_sec: 792.5867693216237
avg_episode_per_sec: 4.847625500438065
collect_time: 1.6502924987248013
reward_mean: 1165.125
reward_std: 534.6948852539062
reward_max: 1698.0
reward_min: 250.0
total_envstep_count: 1272421
total_train_sample_count: 1272398
total_episode_count: 8642
total_duration: 1611.9496434543803
[2024-11-19 23:20:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 991
train_sample_count: 991
avg_envstep_per_episode: 123.875
avg_sample_per_episode: 123.875
avg_envstep_per_sec: 797.9401443904716
avg_train_sample_per_sec: 797.9401443904716
avg_episode_per_sec: 6.44149460658302
collect_time: 1.2419477914060866
reward_mean: 970.375
reward_std: 355.3979797363281
reward_max: 1433.0
reward_min: 605.0
total_envstep_count: 1273438
total_train_sample_count: 1273389
total_episode_count: 8650
total_duration: 1613.1915912457864
[2024-11-19 23:20:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 865
train_sample_count: 865
avg_envstep_per_episode: 216.25
avg_sample_per_episode: 216.25
avg_envstep_per_sec: 810.0977347344835
avg_train_sample_per_sec: 810.0977347344835
avg_episode_per_sec: 3.7461166924137967
collect_time: 1.0677723969732011
reward_mean: 1398.75
reward_std: 40.021087646484375
reward_max: 1430.0
reward_min: 1330.0
total_envstep_count: 1274418
total_train_sample_count: 1274362
total_episode_count: 8654
total_duration: 1614.2593636427596
[2024-11-19 23:20:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1130
train_sample_count: 1130
avg_envstep_per_episode: 188.33333333333334
avg_sample_per_episode: 188.33333333333334
avg_envstep_per_sec: 800.50373742758
avg_train_sample_per_sec: 800.50373742758
avg_episode_per_sec: 4.250462322624318
collect_time: 1.411611148289272
reward_mean: 1129.0
reward_std: 265.9047546386719
reward_max: 1323.0
reward_min: 750.0
total_envstep_count: 1275382
total_train_sample_count: 1275348
total_episode_count: 8660
total_duration: 1615.6709747910488
[2024-11-19 23:21:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 805
train_sample_count: 805
avg_envstep_per_episode: 134.16666666666666
avg_sample_per_episode: 134.16666666666666
avg_envstep_per_sec: 801.1059184620221
avg_train_sample_per_sec: 801.1059184620221
avg_episode_per_sec: 5.970975789779048
collect_time: 1.0048608822481973
reward_mean: 1084.1666259765625
reward_std: 341.15802001953125
reward_max: 1436.0
reward_min: 626.0
total_envstep_count: 1276368
total_train_sample_count: 1276333
total_episode_count: 8666
total_duration: 1616.6758356732971
[2024-11-19 23:21:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1212
train_sample_count: 1212
avg_envstep_per_episode: 173.14285714285714
avg_sample_per_episode: 173.14285714285714
avg_envstep_per_sec: 796.5550090695091
avg_train_sample_per_sec: 796.5550090695091
avg_episode_per_sec: 4.600565233899805
collect_time: 1.5215521667684828
reward_mean: 1240.142822265625
reward_std: 546.5286254882812
reward_max: 1917.0
reward_min: 251.0
total_envstep_count: 1277361
total_train_sample_count: 1277329
total_episode_count: 8673
total_duration: 1618.1973878400656
[2024-11-19 23:21:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1120
train_sample_count: 1120
avg_envstep_per_episode: 124.44444444444444
avg_sample_per_episode: 124.44444444444444
avg_envstep_per_sec: 799.5520522542647
avg_train_sample_per_sec: 799.5520522542647
avg_episode_per_sec: 6.42497184847177
collect_time: 1.4007843477385384
reward_mean: 976.4444580078125
reward_std: 471.3800354003906
reward_max: 1686.0
reward_min: 235.0
total_envstep_count: 1278378
total_train_sample_count: 1278353
total_episode_count: 8682
total_duration: 1619.5981721878043
[2024-11-19 23:21:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 436
train_sample_count: 436
avg_envstep_per_episode: 109.0
avg_sample_per_episode: 109.0
avg_envstep_per_sec: 811.4996739519925
avg_train_sample_per_sec: 811.4996739519925
avg_episode_per_sec: 7.444951137174243
collect_time: 0.5372768640518188
reward_mean: 716.75
reward_std: 186.9176025390625
reward_max: 1039.0
reward_min: 580.0
total_envstep_count: 1279368
total_train_sample_count: 1279329
total_episode_count: 8686
total_duration: 1620.135449051856
[2024-11-19 23:21:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1194
train_sample_count: 1194
avg_envstep_per_episode: 238.8
avg_sample_per_episode: 238.8
avg_envstep_per_sec: 801.2821507207267
avg_train_sample_per_sec: 801.2821507207267
avg_episode_per_sec: 3.355452892465355
collect_time: 1.490111815077918
reward_mean: 1316.800048828125
reward_std: 354.5224304199219
reward_max: 1647.0
reward_min: 644.0
total_envstep_count: 1280371
total_train_sample_count: 1280319
total_episode_count: 8691
total_duration: 1621.625560866934
[2024-11-19 23:21:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1008
train_sample_count: 1008
avg_envstep_per_episode: 168.0
avg_sample_per_episode: 168.0
avg_envstep_per_sec: 796.786382702757
avg_train_sample_per_sec: 796.786382702757
avg_episode_per_sec: 4.74277608751641
collect_time: 1.2650818611894334
reward_mean: 1077.5
reward_std: 462.43585205078125
reward_max: 1435.0
reward_min: 252.0
total_envstep_count: 1281349
total_train_sample_count: 1281303
total_episode_count: 8697
total_duration: 1622.8906427281233
[2024-11-19 23:21:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1062
train_sample_count: 1062
avg_envstep_per_episode: 151.71428571428572
avg_sample_per_episode: 151.71428571428572
avg_envstep_per_sec: 794.7506097106316
avg_train_sample_per_sec: 794.7506097106316
avg_episode_per_sec: 5.238469178883636
collect_time: 1.336268241916384
reward_mean: 1060.2857666015625
reward_std: 429.40814208984375
reward_max: 1435.0
reward_min: 238.0
total_envstep_count: 1282358
total_train_sample_count: 1282317
total_episode_count: 8704
total_duration: 1624.2269109700396
[2024-11-19 23:21:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 856
train_sample_count: 856
avg_envstep_per_episode: 171.2
avg_sample_per_episode: 171.2
avg_envstep_per_sec: 793.8159478643942
avg_train_sample_per_sec: 793.8159478643942
avg_episode_per_sec: 4.636775396404172
collect_time: 1.0783356044973647
reward_mean: 1365.199951171875
reward_std: 388.4736328125
reward_max: 1679.0
reward_min: 622.0
total_envstep_count: 1283322
total_train_sample_count: 1283293
total_episode_count: 8709
total_duration: 1625.305246574537
[2024-11-19 23:21:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1274
train_sample_count: 1274
avg_envstep_per_episode: 159.25
avg_sample_per_episode: 159.25
avg_envstep_per_sec: 793.24007180891
avg_train_sample_per_sec: 793.24007180891
avg_episode_per_sec: 4.981099352018273
collect_time: 1.6060711571148465
reward_mean: 852.75
reward_std: 479.076904296875
reward_max: 1566.0
reward_min: 191.0
total_envstep_count: 1284402
total_train_sample_count: 1284351
total_episode_count: 8717
total_duration: 1626.911317731652
[2024-11-19 23:21:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 373
train_sample_count: 373
avg_envstep_per_episode: 124.33333333333333
avg_sample_per_episode: 124.33333333333333
avg_envstep_per_sec: 795.4326524320189
avg_train_sample_per_sec: 795.4326524320189
avg_episode_per_sec: 6.397581654949214
collect_time: 0.4689271918364933
reward_mean: 858.3333129882812
reward_std: 317.9689025878906
reward_max: 1308.0
reward_min: 631.0
total_envstep_count: 1285399
total_train_sample_count: 1285348
total_episode_count: 8720
total_duration: 1627.3802449234884
[2024-11-19 23:21:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1210
train_sample_count: 1210
avg_envstep_per_episode: 201.66666666666666
avg_sample_per_episode: 201.66666666666666
avg_envstep_per_sec: 793.184455297062
avg_train_sample_per_sec: 793.184455297062
avg_episode_per_sec: 3.933146059324274
collect_time: 1.525496360801515
reward_mean: 1271.6666259765625
reward_std: 514.8500366210938
reward_max: 1922.0
reward_min: 621.0
total_envstep_count: 1286385
total_train_sample_count: 1286354
total_episode_count: 8726
total_duration: 1628.90574128429
[2024-11-19 23:22:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 342
train_sample_count: 342
avg_envstep_per_episode: 171.0
avg_sample_per_episode: 171.0
avg_envstep_per_sec: 788.312172586886
avg_train_sample_per_sec: 788.312172586886
avg_episode_per_sec: 4.6100127051864686
collect_time: 0.43383828373182387
reward_mean: 1019.5
reward_std: 393.5
reward_max: 1413.0
reward_min: 626.0
total_envstep_count: 1287343
total_train_sample_count: 1287320
total_episode_count: 8728
total_duration: 1629.3395795680217
[2024-11-19 23:22:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1485
train_sample_count: 1485
avg_envstep_per_episode: 371.25
avg_sample_per_episode: 371.25
avg_envstep_per_sec: 800.3113387628479
avg_train_sample_per_sec: 800.3113387628479
avg_episode_per_sec: 2.155720777812385
collect_time: 1.855527877807617
reward_mean: 1663.0
reward_std: 705.318359375
reward_max: 2321.0
reward_min: 619.0
total_envstep_count: 1288332
total_train_sample_count: 1288289
total_episode_count: 8732
total_duration: 1631.1951074458293
[2024-11-19 23:22:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1383
train_sample_count: 1383
avg_envstep_per_episode: 276.6
avg_sample_per_episode: 276.6
avg_envstep_per_sec: 795.2886054864349
avg_train_sample_per_sec: 795.2886054864349
avg_episode_per_sec: 2.8752299547593454
collect_time: 1.7389913428397403
reward_mean: 1562.5999755859375
reward_std: 188.50209045410156
reward_max: 1842.0
reward_min: 1303.0
total_envstep_count: 1289344
total_train_sample_count: 1289300
total_episode_count: 8737
total_duration: 1632.934098788669
[2024-11-19 23:22:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 540
train_sample_count: 540
avg_envstep_per_episode: 180.0
avg_sample_per_episode: 180.0
avg_envstep_per_sec: 800.7905650984504
avg_train_sample_per_sec: 800.7905650984504
avg_episode_per_sec: 4.44883647276917
collect_time: 0.6743336192199162
reward_mean: 1067.0
reward_std: 398.12646484375
reward_max: 1568.0
reward_min: 594.0
total_envstep_count: 1290302
total_train_sample_count: 1290272
total_episode_count: 8740
total_duration: 1633.6084324078888
[2024-11-19 23:22:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1653
train_sample_count: 1653
avg_envstep_per_episode: 206.625
avg_sample_per_episode: 206.625
avg_envstep_per_sec: 801.609315079667
avg_train_sample_per_sec: 801.609315079667
avg_episode_per_sec: 3.8795369150861077
collect_time: 2.0621017856257304
reward_mean: 1275.25
reward_std: 688.0333251953125
reward_max: 2623.0
reward_min: 247.0
total_envstep_count: 1291327
total_train_sample_count: 1291289
total_episode_count: 8748
total_duration: 1635.6705341935146
[2024-11-19 23:22:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1101
train_sample_count: 1101
avg_envstep_per_episode: 137.625
avg_sample_per_episode: 137.625
avg_envstep_per_sec: 806.6572743311505
avg_train_sample_per_sec: 806.6572743311505
avg_episode_per_sec: 5.861269931561493
collect_time: 1.3648919250283924
reward_mean: 950.625
reward_std: 422.5023193359375
reward_max: 1329.0
reward_min: 247.0
total_envstep_count: 1292313
total_train_sample_count: 1292270
total_episode_count: 8756
total_duration: 1637.035426118543
[2024-11-19 23:22:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 776
train_sample_count: 776
avg_envstep_per_episode: 155.2
avg_sample_per_episode: 155.2
avg_envstep_per_sec: 798.9216100493427
avg_train_sample_per_sec: 798.9216100493427
avg_episode_per_sec: 5.147690786400404
collect_time: 0.9713093127523149
reward_mean: 974.0
reward_std: 371.68426513671875
reward_max: 1436.0
reward_min: 593.0
total_envstep_count: 1293308
total_train_sample_count: 1293274
total_episode_count: 8761
total_duration: 1638.0067354312953
[2024-11-19 23:22:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 653
train_sample_count: 653
avg_envstep_per_episode: 217.66666666666666
avg_sample_per_episode: 217.66666666666666
avg_envstep_per_sec: 790.9943586847847
avg_train_sample_per_sec: 790.9943586847847
avg_episode_per_sec: 3.633971019991354
collect_time: 0.8255431822368076
reward_mean: 1446.6666259765625
reward_std: 115.81690216064453
reward_max: 1601.0
reward_min: 1322.0
total_envstep_count: 1294323
total_train_sample_count: 1294299
total_episode_count: 8764
total_duration: 1638.832278613532
[2024-11-19 23:22:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1377
train_sample_count: 1377
avg_envstep_per_episode: 153.0
avg_sample_per_episode: 153.0
avg_envstep_per_sec: 795.8200033362165
avg_train_sample_per_sec: 795.8200033362165
avg_episode_per_sec: 5.201437930302069
collect_time: 1.7302907620157517
reward_mean: 991.7777709960938
reward_std: 324.220703125
reward_max: 1342.0
reward_min: 620.0
total_envstep_count: 1295316
total_train_sample_count: 1295292
total_episode_count: 8773
total_duration: 1640.5625693755478
[2024-11-19 23:22:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 981
train_sample_count: 981
avg_envstep_per_episode: 163.5
avg_sample_per_episode: 163.5
avg_envstep_per_sec: 794.2887522818348
avg_train_sample_per_sec: 794.2887522818348
avg_episode_per_sec: 4.858035182151895
collect_time: 1.235067218542099
reward_mean: 1129.1666259765625
reward_std: 310.3612976074219
reward_max: 1415.0
reward_min: 589.0
total_envstep_count: 1296321
total_train_sample_count: 1296273
total_episode_count: 8779
total_duration: 1641.79763659409
[2024-11-19 23:22:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 765
train_sample_count: 765
avg_envstep_per_episode: 127.5
avg_sample_per_episode: 127.5
avg_envstep_per_sec: 765.084436445413
avg_train_sample_per_sec: 765.084436445413
avg_episode_per_sec: 6.000662246630689
collect_time: 0.9998896377427239
reward_mean: 891.1666870117188
reward_std: 385.1503601074219
reward_max: 1688.0
reward_min: 610.0
total_envstep_count: 1297283
total_train_sample_count: 1297254
total_episode_count: 8785
total_duration: 1642.7975262318325
[2024-11-19 23:23:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 513
train_sample_count: 513
avg_envstep_per_episode: 171.0
avg_sample_per_episode: 171.0
avg_envstep_per_sec: 778.4618756724301
avg_train_sample_per_sec: 778.4618756724301
avg_episode_per_sec: 4.552408629663334
collect_time: 0.6589918094021934
reward_mean: 1264.6666259765625
reward_std: 161.47308349609375
reward_max: 1431.0
reward_min: 1046.0
total_envstep_count: 1298296
total_train_sample_count: 1298247
total_episode_count: 8788
total_duration: 1643.4565180412346
[2024-11-19 23:23:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 854
train_sample_count: 854
avg_envstep_per_episode: 284.6666666666667
avg_sample_per_episode: 284.6666666666667
avg_envstep_per_sec: 789.1278457926965
avg_train_sample_per_sec: 789.1278457926965
avg_episode_per_sec: 2.772111870466147
collect_time: 1.082207407270159
reward_mean: 1212.0
reward_std: 129.20010375976562
reward_max: 1317.0
reward_min: 1030.0
total_envstep_count: 1299254
total_train_sample_count: 1299221
total_episode_count: 8791
total_duration: 1644.5387254485047
[2024-11-19 23:23:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1277
train_sample_count: 1277
avg_envstep_per_episode: 182.42857142857142
avg_sample_per_episode: 182.42857142857142
avg_envstep_per_sec: 788.6235002283012
avg_train_sample_per_sec: 788.6235002283012
avg_episode_per_sec: 4.322916602661008
collect_time: 1.6192771324089597
reward_mean: 771.4285888671875
reward_std: 262.1313171386719
reward_max: 1315.0
reward_min: 582.0
total_envstep_count: 1300263
total_train_sample_count: 1300246
total_episode_count: 8798
total_duration: 1646.1580025809137
[2024-11-19 23:23:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 638
train_sample_count: 638
avg_envstep_per_episode: 212.66666666666666
avg_sample_per_episode: 212.66666666666666
avg_envstep_per_sec: 793.4938632961529
avg_train_sample_per_sec: 793.4938632961529
avg_episode_per_sec: 3.7311623665963305
collect_time: 0.8040389844349451
reward_mean: 1281.0
reward_std: 468.213623046875
reward_max: 1687.0
reward_min: 625.0
total_envstep_count: 1301300
total_train_sample_count: 1301256
total_episode_count: 8801
total_duration: 1646.9620415653487
[2024-11-19 23:23:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 971
train_sample_count: 971
avg_envstep_per_episode: 194.2
avg_sample_per_episode: 194.2
avg_envstep_per_sec: 788.9444789775406
avg_train_sample_per_sec: 788.9444789775406
avg_episode_per_sec: 4.062535937062516
collect_time: 1.2307583434241158
reward_mean: 805.0
reward_std: 315.9246826171875
reward_max: 1419.0
reward_min: 578.0
total_envstep_count: 1302271
total_train_sample_count: 1302227
total_episode_count: 8806
total_duration: 1648.192799908773
[2024-11-19 23:23:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1031
train_sample_count: 1031
avg_envstep_per_episode: 147.28571428571428
avg_sample_per_episode: 147.28571428571428
avg_envstep_per_sec: 787.8364782430235
avg_train_sample_per_sec: 787.8364782430235
avg_episode_per_sec: 5.349035254802294
collect_time: 1.308647198336465
reward_mean: 967.7142944335938
reward_std: 369.62786865234375
reward_max: 1400.0
reward_min: 250.0
total_envstep_count: 1303250
total_train_sample_count: 1303222
total_episode_count: 8813
total_duration: 1649.5014471071095
[2024-11-19 23:23:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 991
train_sample_count: 991
avg_envstep_per_episode: 123.875
avg_sample_per_episode: 123.875
avg_envstep_per_sec: 787.4967341889347
avg_train_sample_per_sec: 787.4967341889347
avg_episode_per_sec: 6.3571885706473035
collect_time: 1.2584179171494076
reward_mean: 898.875
reward_std: 384.5108642578125
reward_max: 1692.0
reward_min: 605.0
total_envstep_count: 1304258
total_train_sample_count: 1304225
total_episode_count: 8821
total_duration: 1650.759865024259
[2024-11-19 23:23:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 2160
train_sample_count: 2160
avg_envstep_per_episode: 240.0
avg_sample_per_episode: 240.0
avg_envstep_per_sec: 783.3570455259307
avg_train_sample_per_sec: 783.3570455259307
avg_episode_per_sec: 3.263987689691378
collect_time: 2.7573633406843463
reward_mean: 1080.22216796875
reward_std: 551.8983154296875
reward_max: 2184.0
reward_min: 644.0
total_envstep_count: 1305236
total_train_sample_count: 1305209
total_episode_count: 8830
total_duration: 1653.5172283649433
[2024-11-19 23:23:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 485
train_sample_count: 485
avg_envstep_per_episode: 121.25
avg_sample_per_episode: 121.25
avg_envstep_per_sec: 791.8149128754941
avg_train_sample_per_sec: 791.8149128754941
avg_episode_per_sec: 6.530432271138095
collect_time: 0.6125168800354004
reward_mean: 608.0
reward_std: 26.048032760620117
reward_max: 647.0
reward_min: 577.0
total_envstep_count: 1306241
total_train_sample_count: 1306186
total_episode_count: 8834
total_duration: 1654.1297452449787
[2024-11-19 23:23:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1257
train_sample_count: 1257
avg_envstep_per_episode: 157.125
avg_sample_per_episode: 157.125
avg_envstep_per_sec: 794.527322198997
avg_train_sample_per_sec: 794.527322198997
avg_episode_per_sec: 5.056657579627666
collect_time: 1.5820727178028653
reward_mean: 1049.375
reward_std: 290.1430358886719
reward_max: 1318.0
reward_min: 630.0
total_envstep_count: 1307236
total_train_sample_count: 1307191
total_episode_count: 8842
total_duration: 1655.7118179627817
[2024-11-19 23:23:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 939
train_sample_count: 939
avg_envstep_per_episode: 234.75
avg_sample_per_episode: 234.75
avg_envstep_per_sec: 792.5429894668454
avg_train_sample_per_sec: 792.5429894668454
avg_episode_per_sec: 3.3761149711047724
collect_time: 1.1847937745707375
reward_mean: 1195.25
reward_std: 239.19277954101562
reward_max: 1339.0
reward_min: 781.0
total_envstep_count: 1308192
total_train_sample_count: 1308154
total_episode_count: 8846
total_duration: 1656.8966117373525
[2024-11-19 23:23:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1020
train_sample_count: 1020
avg_envstep_per_episode: 170.0
avg_sample_per_episode: 170.0
avg_envstep_per_sec: 801.807581570996
avg_train_sample_per_sec: 801.807581570996
avg_episode_per_sec: 4.716515185711741
collect_time: 1.2721256613731384
reward_mean: 1023.8333129882812
reward_std: 388.8647766113281
reward_max: 1548.0
reward_min: 630.0
total_envstep_count: 1309179
total_train_sample_count: 1309138
total_episode_count: 8852
total_duration: 1658.1687373987256
[2024-11-19 23:23:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 928
train_sample_count: 928
avg_envstep_per_episode: 185.6
avg_sample_per_episode: 185.6
avg_envstep_per_sec: 799.4210489433441
avg_train_sample_per_sec: 799.4210489433441
avg_episode_per_sec: 4.3072254792206035
collect_time: 1.160840086993717
reward_mean: 1110.199951171875
reward_std: 361.7100524902344
reward_max: 1531.0
reward_min: 624.0
total_envstep_count: 1310158
total_train_sample_count: 1310126
total_episode_count: 8857
total_duration: 1659.3295774857193
[2024-11-19 23:23:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 646
train_sample_count: 646
avg_envstep_per_episode: 161.5
avg_sample_per_episode: 161.5
avg_envstep_per_sec: 787.1082430047815
avg_train_sample_per_sec: 787.1082430047815
avg_episode_per_sec: 4.8737352508036
collect_time: 0.8207257460980188
reward_mean: 1028.0
reward_std: 320.16949462890625
reward_max: 1342.0
reward_min: 617.0
total_envstep_count: 1311170
total_train_sample_count: 1311120
total_episode_count: 8861
total_duration: 1660.1503032318174
[2024-11-19 23:23:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 428
train_sample_count: 428
avg_envstep_per_episode: 214.0
avg_sample_per_episode: 214.0
avg_envstep_per_sec: 798.711751637251
avg_train_sample_per_sec: 798.711751637251
avg_episode_per_sec: 3.7322979048469676
collect_time: 0.5358629056385584
reward_mean: 1146.5
reward_std: 556.5
reward_max: 1703.0
reward_min: 590.0
total_envstep_count: 1312145
total_train_sample_count: 1312100
total_episode_count: 8863
total_duration: 1660.686166137456
[2024-11-19 23:23:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2018
train_sample_count: 2018
avg_envstep_per_episode: 252.25
avg_sample_per_episode: 252.25
avg_envstep_per_sec: 796.0109343666661
avg_train_sample_per_sec: 796.0109343666661
avg_episode_per_sec: 3.1556429509084882
collect_time: 2.535141055073057
reward_mean: 1456.75
reward_std: 357.49920654296875
reward_max: 1840.0
reward_min: 720.0
total_envstep_count: 1313161
total_train_sample_count: 1313122
total_episode_count: 8871
total_duration: 1663.2213071925291
[2024-11-19 23:24:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 901
train_sample_count: 901
avg_envstep_per_episode: 128.71428571428572
avg_sample_per_episode: 128.71428571428572
avg_envstep_per_sec: 781.9213481745367
avg_train_sample_per_sec: 781.9213481745367
avg_episode_per_sec: 6.074860640645679
collect_time: 1.1522898077964783
reward_mean: 837.7142944335938
reward_std: 314.39544677734375
reward_max: 1433.0
reward_min: 564.0
total_envstep_count: 1314171
total_train_sample_count: 1314131
total_episode_count: 8878
total_duration: 1664.3735970003256
[2024-11-19 23:24:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 682
train_sample_count: 682
avg_envstep_per_episode: 170.5
avg_sample_per_episode: 170.5
avg_envstep_per_sec: 791.5756731600037
avg_train_sample_per_sec: 791.5756731600037
avg_episode_per_sec: 4.642672569853394
collect_time: 0.8615727126598358
reward_mean: 916.0
reward_std: 569.1436767578125
reward_max: 1901.0
reward_min: 563.0
total_envstep_count: 1315167
total_train_sample_count: 1315125
total_episode_count: 8882
total_duration: 1665.2351697129855
[2024-11-19 23:24:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 889
train_sample_count: 889
avg_envstep_per_episode: 177.8
avg_sample_per_episode: 177.8
avg_envstep_per_sec: 791.837895316316
avg_train_sample_per_sec: 791.837895316316
avg_episode_per_sec: 4.453531469720563
collect_time: 1.1227045399802071
reward_mean: 969.0
reward_std: 381.94500732421875
reward_max: 1681.0
reward_min: 633.0
total_envstep_count: 1316178
total_train_sample_count: 1316134
total_episode_count: 8887
total_duration: 1666.3578742529658
[2024-11-19 23:24:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1430
train_sample_count: 1430
avg_envstep_per_episode: 238.33333333333334
avg_sample_per_episode: 238.33333333333334
avg_envstep_per_sec: 787.6494534721762
avg_train_sample_per_sec: 787.6494534721762
avg_episode_per_sec: 3.3048228817014387
collect_time: 1.8155284609113422
reward_mean: 1052.5
reward_std: 411.1474914550781
reward_max: 1627.0
reward_min: 595.0
total_envstep_count: 1317189
total_train_sample_count: 1317156
total_episode_count: 8893
total_duration: 1668.173402713877
[2024-11-19 23:24:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1159
train_sample_count: 1159
avg_envstep_per_episode: 144.875
avg_sample_per_episode: 144.875
avg_envstep_per_sec: 785.962117620696
avg_train_sample_per_sec: 785.962117620696
avg_episode_per_sec: 5.425105212222233
collect_time: 1.4746257790497372
reward_mean: 892.375
reward_std: 411.9137878417969
reward_max: 1424.0
reward_min: 236.0
total_envstep_count: 1318221
total_train_sample_count: 1318171
total_episode_count: 8901
total_duration: 1669.6480284929269
[2024-11-19 23:24:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1017
train_sample_count: 1017
avg_envstep_per_episode: 145.28571428571428
avg_sample_per_episode: 145.28571428571428
avg_envstep_per_sec: 781.5462705692796
avg_train_sample_per_sec: 781.5462705692796
avg_episode_per_sec: 5.379374527025523
collect_time: 1.3012665254729134
reward_mean: 1083.2857666015625
reward_std: 400.354736328125
reward_max: 1432.0
reward_min: 620.0
total_envstep_count: 1319334
total_train_sample_count: 1319308
total_episode_count: 8908
total_duration: 1670.9492950183999
[2024-11-19 23:24:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1182
train_sample_count: 1182
avg_envstep_per_episode: 131.33333333333334
avg_sample_per_episode: 131.33333333333334
avg_envstep_per_sec: 783.4631760339473
avg_train_sample_per_sec: 783.4631760339473
avg_episode_per_sec: 5.9654556550808175
collect_time: 1.5086860954761505
reward_mean: 889.111083984375
reward_std: 367.6847839355469
reward_max: 1436.0
reward_min: 245.0
total_envstep_count: 1320329
total_train_sample_count: 1320298
total_episode_count: 8917
total_duration: 1672.457981113876
[2024-11-19 23:24:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 168
train_sample_count: 168
avg_envstep_per_episode: 168.0
avg_sample_per_episode: 168.0
avg_envstep_per_sec: 794.3280891658574
avg_train_sample_per_sec: 794.3280891658574
avg_episode_per_sec: 4.728143387892008
collect_time: 0.21149950793811254
reward_mean: 1429.0
reward_std: 0.0
reward_max: 1429.0
reward_min: 1429.0
total_envstep_count: 1321288
total_train_sample_count: 1321258
total_episode_count: 8918
total_duration: 1672.669480621814
[2024-11-19 23:24:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1333
train_sample_count: 1333
avg_envstep_per_episode: 190.42857142857142
avg_sample_per_episode: 190.42857142857142
avg_envstep_per_sec: 789.6588524171012
avg_train_sample_per_sec: 789.6588524171012
avg_episode_per_sec: 4.146745661605182
collect_time: 1.6880707357610976
reward_mean: 1437.857177734375
reward_std: 359.5399475097656
reward_max: 1822.0
reward_min: 652.0
total_envstep_count: 1322298
total_train_sample_count: 1322243
total_episode_count: 8925
total_duration: 1674.3575513575752
[2024-11-19 23:24:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1347
train_sample_count: 1347
avg_envstep_per_episode: 224.5
avg_sample_per_episode: 224.5
avg_envstep_per_sec: 789.6519342089375
avg_train_sample_per_sec: 789.6519342089375
avg_episode_per_sec: 3.5173805532692097
collect_time: 1.7058148554393222
reward_mean: 1315.8333740234375
reward_std: 290.22027587890625
reward_max: 1908.0
reward_min: 1039.0
total_envstep_count: 1323278
total_train_sample_count: 1323242
total_episode_count: 8931
total_duration: 1676.0633662130144
[2024-11-19 23:24:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1189
train_sample_count: 1189
avg_envstep_per_episode: 132.11111111111111
avg_sample_per_episode: 132.11111111111111
avg_envstep_per_sec: 792.62809505721
avg_train_sample_per_sec: 792.62809505721
avg_episode_per_sec: 5.999708036597888
collect_time: 1.5000729944024769
reward_mean: 968.0
reward_std: 491.4737548828125
reward_max: 1680.0
reward_min: 235.0
total_envstep_count: 1324304
total_train_sample_count: 1324263
total_episode_count: 8940
total_duration: 1677.5634392074169
[2024-11-19 23:24:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 769
train_sample_count: 769
avg_envstep_per_episode: 109.85714285714286
avg_sample_per_episode: 109.85714285714286
avg_envstep_per_sec: 790.6513677377088
avg_train_sample_per_sec: 790.6513677377088
avg_episode_per_sec: 7.197086572384865
collect_time: 0.9726157841228305
reward_mean: 758.0
reward_std: 317.85980224609375
reward_max: 1317.0
reward_min: 251.0
total_envstep_count: 1325281
total_train_sample_count: 1325260
total_episode_count: 8947
total_duration: 1678.5360549915397
[2024-11-19 23:24:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 747
train_sample_count: 747
avg_envstep_per_episode: 149.4
avg_sample_per_episode: 149.4
avg_envstep_per_sec: 793.7330808927521
avg_train_sample_per_sec: 793.7330808927521
avg_episode_per_sec: 5.312805092990309
collect_time: 0.9411224226156871
reward_mean: 1091.4000244140625
reward_std: 399.2616271972656
reward_max: 1578.0
reward_min: 609.0
total_envstep_count: 1326309
total_train_sample_count: 1326247
total_episode_count: 8952
total_duration: 1679.4771774141554
[2024-11-19 23:24:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1097
train_sample_count: 1097
avg_envstep_per_episode: 156.71428571428572
avg_sample_per_episode: 156.71428571428572
avg_envstep_per_sec: 795.9882031571586
avg_train_sample_per_sec: 795.9882031571586
avg_episode_per_sec: 5.079231925341942
collect_time: 1.3781611280781885
reward_mean: 981.8571166992188
reward_std: 328.1839294433594
reward_max: 1343.0
reward_min: 609.0
total_envstep_count: 1327272
total_train_sample_count: 1327236
total_episode_count: 8959
total_duration: 1680.8553385422335
[2024-11-19 23:24:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 709
train_sample_count: 709
avg_envstep_per_episode: 141.8
avg_sample_per_episode: 141.8
avg_envstep_per_sec: 800.7248857674433
avg_train_sample_per_sec: 800.7248857674433
avg_episode_per_sec: 5.64686097156166
collect_time: 0.885447689465114
reward_mean: 815.7999877929688
reward_std: 261.9667053222656
reward_max: 1323.0
reward_min: 613.0
total_envstep_count: 1328275
total_train_sample_count: 1328233
total_episode_count: 8964
total_duration: 1681.7407862316986
[2024-11-19 23:24:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1135
train_sample_count: 1135
avg_envstep_per_episode: 141.875
avg_sample_per_episode: 141.875
avg_envstep_per_sec: 789.2862427154515
avg_train_sample_per_sec: 789.2862427154515
avg_episode_per_sec: 5.563251049976751
collect_time: 1.438008087021964
reward_mean: 941.625
reward_std: 348.4612121582031
reward_max: 1573.0
reward_min: 613.0
total_envstep_count: 1329267
total_train_sample_count: 1329248
total_episode_count: 8972
total_duration: 1683.1787943187205
[2024-11-19 23:25:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1189
train_sample_count: 1189
avg_envstep_per_episode: 237.8
avg_sample_per_episode: 237.8
avg_envstep_per_sec: 791.795144451333
avg_train_sample_per_sec: 791.795144451333
avg_episode_per_sec: 3.329668395506026
collect_time: 1.5016510373070124
reward_mean: 1177.4000244140625
reward_std: 619.55908203125
reward_max: 2286.0
reward_min: 594.0
total_envstep_count: 1330263
total_train_sample_count: 1330221
total_episode_count: 8977
total_duration: 1684.6804453560276
[2024-11-19 23:25:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1002
train_sample_count: 1002
avg_envstep_per_episode: 143.14285714285714
avg_sample_per_episode: 143.14285714285714
avg_envstep_per_sec: 789.4642900665198
avg_train_sample_per_sec: 789.4642900665198
avg_episode_per_sec: 5.515219591283072
collect_time: 1.2692151027066367
reward_mean: 971.0
reward_std: 434.309326171875
reward_max: 1693.0
reward_min: 582.0
total_envstep_count: 1331264
total_train_sample_count: 1331211
total_episode_count: 8984
total_duration: 1685.9496604587341
[2024-11-19 23:25:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1150
train_sample_count: 1150
avg_envstep_per_episode: 127.77777777777777
avg_sample_per_episode: 127.77777777777777
avg_envstep_per_sec: 788.5360098307418
avg_train_sample_per_sec: 788.5360098307418
avg_episode_per_sec: 6.171151381284067
collect_time: 1.458398837418783
reward_mean: 943.888916015625
reward_std: 474.99041748046875
reward_max: 1907.0
reward_min: 622.0
total_envstep_count: 1332240
total_train_sample_count: 1332205
total_episode_count: 8993
total_duration: 1687.408059296153
[2024-11-19 23:25:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 944
train_sample_count: 944
avg_envstep_per_episode: 157.33333333333334
avg_sample_per_episode: 157.33333333333334
avg_envstep_per_sec: 791.867421103955
avg_train_sample_per_sec: 791.867421103955
avg_episode_per_sec: 5.033055642609884
collect_time: 1.192118749732063
reward_mean: 1108.1666259765625
reward_std: 485.40545654296875
reward_max: 1912.0
reward_min: 607.0
total_envstep_count: 1333210
total_train_sample_count: 1333173
total_episode_count: 8999
total_duration: 1688.600178045885
[2024-11-19 23:25:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1009
train_sample_count: 1009
avg_envstep_per_episode: 144.14285714285714
avg_sample_per_episode: 144.14285714285714
avg_envstep_per_sec: 780.4151651963173
avg_train_sample_per_sec: 780.4151651963173
avg_episode_per_sec: 5.414178549429357
collect_time: 1.2929015798228127
reward_mean: 982.1428833007812
reward_std: 470.9308166503906
reward_max: 1696.0
reward_min: 588.0
total_envstep_count: 1334207
total_train_sample_count: 1334182
total_episode_count: 9006
total_duration: 1689.893079625708
[2024-11-19 23:25:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1049
train_sample_count: 1049
avg_envstep_per_episode: 174.83333333333334
avg_sample_per_episode: 174.83333333333334
avg_envstep_per_sec: 791.6526053875897
avg_train_sample_per_sec: 791.6526053875897
avg_episode_per_sec: 4.5280415942092835
collect_time: 1.3250761670725686
reward_mean: 1125.5
reward_std: 327.6963806152344
reward_max: 1430.0
reward_min: 651.0
total_envstep_count: 1335201
total_train_sample_count: 1335159
total_episode_count: 9012
total_duration: 1691.2181557927806
[2024-11-19 23:25:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 815
train_sample_count: 815
avg_envstep_per_episode: 163.0
avg_sample_per_episode: 163.0
avg_envstep_per_sec: 789.7315549758623
avg_train_sample_per_sec: 789.7315549758623
avg_episode_per_sec: 4.844978864882591
collect_time: 1.031996245895113
reward_mean: 945.2000122070312
reward_std: 386.89862060546875
reward_max: 1420.0
reward_min: 620.0
total_envstep_count: 1336181
total_train_sample_count: 1336130
total_episode_count: 9017
total_duration: 1692.2501520386757
[2024-11-19 23:25:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1076
train_sample_count: 1076
avg_envstep_per_episode: 134.5
avg_sample_per_episode: 134.5
avg_envstep_per_sec: 778.9892404099202
avg_train_sample_per_sec: 778.9892404099202
avg_episode_per_sec: 5.791741564386024
collect_time: 1.3812771013804845
reward_mean: 983.75
reward_std: 326.4845886230469
reward_max: 1437.0
reward_min: 616.0
total_envstep_count: 1337191
total_train_sample_count: 1337146
total_episode_count: 9025
total_duration: 1693.631429140056
[2024-11-19 23:25:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 790
train_sample_count: 790
avg_envstep_per_episode: 158.0
avg_sample_per_episode: 158.0
avg_envstep_per_sec: 784.2609762888073
avg_train_sample_per_sec: 784.2609762888073
avg_episode_per_sec: 4.963677065119034
collect_time: 1.0073177473885673
reward_mean: 983.7999877929688
reward_std: 333.12603759765625
reward_max: 1430.0
reward_min: 648.0
total_envstep_count: 1338154
total_train_sample_count: 1338116
total_episode_count: 9030
total_duration: 1694.6387468874445
[2024-11-19 23:25:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 911
train_sample_count: 911
avg_envstep_per_episode: 182.2
avg_sample_per_episode: 182.2
avg_envstep_per_sec: 796.745290007626
avg_train_sample_per_sec: 796.745290007626
avg_episode_per_sec: 4.372915971501789
collect_time: 1.1434018015861511
reward_mean: 949.4000244140625
reward_std: 249.4799346923828
reward_max: 1338.0
reward_min: 637.0
total_envstep_count: 1339141
total_train_sample_count: 1339099
total_episode_count: 9035
total_duration: 1695.7821486890307
[2024-11-19 23:25:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 999
train_sample_count: 999
avg_envstep_per_episode: 166.5
avg_sample_per_episode: 166.5
avg_envstep_per_sec: 795.3734522478165
avg_train_sample_per_sec: 795.3734522478165
avg_episode_per_sec: 4.777017731218118
collect_time: 1.2560137595449175
reward_mean: 1082.0
reward_std: 239.57948303222656
reward_max: 1321.0
reward_min: 609.0
total_envstep_count: 1340121
total_train_sample_count: 1340086
total_episode_count: 9041
total_duration: 1697.0381624485756
[2024-11-19 23:26:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1009
train_sample_count: 1009
avg_envstep_per_episode: 168.16666666666666
avg_sample_per_episode: 168.16666666666666
avg_envstep_per_sec: 790.2407932511305
avg_train_sample_per_sec: 790.2407932511305
avg_episode_per_sec: 4.699152388014651
collect_time: 1.2768260112830572
reward_mean: 997.8333129882812
reward_std: 327.0185546875
reward_max: 1331.0
reward_min: 622.0
total_envstep_count: 1341108
total_train_sample_count: 1341071
total_episode_count: 9047
total_duration: 1698.3149884598586
[2024-11-19 23:26:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1102
train_sample_count: 1102
avg_envstep_per_episode: 183.66666666666666
avg_sample_per_episode: 183.66666666666666
avg_envstep_per_sec: 792.1848700303491
avg_train_sample_per_sec: 792.1848700303491
avg_episode_per_sec: 4.313166261508253
collect_time: 1.3910894308771407
reward_mean: 1175.3333740234375
reward_std: 433.7482604980469
reward_max: 1709.0
reward_min: 635.0
total_envstep_count: 1342119
total_train_sample_count: 1342077
total_episode_count: 9053
total_duration: 1699.7060778907357
[2024-11-19 23:26:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 561
train_sample_count: 561
avg_envstep_per_episode: 112.2
avg_sample_per_episode: 112.2
avg_envstep_per_sec: 789.3049887563433
avg_train_sample_per_sec: 789.3049887563433
avg_episode_per_sec: 7.034803821357783
collect_time: 0.7107518741062708
reward_mean: 799.4000244140625
reward_std: 264.79547119140625
reward_max: 1324.0
reward_min: 632.0
total_envstep_count: 1343122
total_train_sample_count: 1343094
total_episode_count: 9058
total_duration: 1700.416829764842
[2024-11-19 23:26:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1282
train_sample_count: 1282
avg_envstep_per_episode: 213.66666666666666
avg_sample_per_episode: 213.66666666666666
avg_envstep_per_sec: 791.9642599562758
avg_train_sample_per_sec: 791.9642599562758
avg_episode_per_sec: 3.7065409982353
collect_time: 1.6187599173613958
reward_mean: 1123.5
reward_std: 531.4027709960938
reward_max: 1880.0
reward_min: 595.0
total_envstep_count: 1344117
total_train_sample_count: 1344076
total_episode_count: 9064
total_duration: 1702.0355896822034
[2024-11-19 23:26:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1389
train_sample_count: 1389
avg_envstep_per_episode: 198.42857142857142
avg_sample_per_episode: 198.42857142857142
avg_envstep_per_sec: 792.6066389629958
avg_train_sample_per_sec: 792.6066389629958
avg_episode_per_sec: 3.994417906940944
collect_time: 1.7524455785751345
reward_mean: 1084.4285888671875
reward_std: 398.5516052246094
reward_max: 1430.0
reward_min: 558.0
total_envstep_count: 1345127
total_train_sample_count: 1345069
total_episode_count: 9071
total_duration: 1703.7880352607785
[2024-11-19 23:26:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 430
train_sample_count: 430
avg_envstep_per_episode: 215.0
avg_sample_per_episode: 215.0
avg_envstep_per_sec: 797.7045457991921
avg_train_sample_per_sec: 797.7045457991921
avg_episode_per_sec: 3.7102537013915913
collect_time: 0.5390466962541853
reward_mean: 1225.5
reward_std: 203.5
reward_max: 1429.0
reward_min: 1022.0
total_envstep_count: 1346094
total_train_sample_count: 1346039
total_episode_count: 9073
total_duration: 1704.3270819570328
[2024-11-19 23:26:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1376
train_sample_count: 1376
avg_envstep_per_episode: 229.33333333333334
avg_sample_per_episode: 229.33333333333334
avg_envstep_per_sec: 798.7269496179324
avg_train_sample_per_sec: 798.7269496179324
avg_episode_per_sec: 3.482821001240984
collect_time: 1.7227414207799094
reward_mean: 1036.1666259765625
reward_std: 358.08074951171875
reward_max: 1676.0
reward_min: 625.0
total_envstep_count: 1347082
total_train_sample_count: 1347055
total_episode_count: 9079
total_duration: 1706.0498233778126
[2024-11-19 23:26:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 304
train_sample_count: 304
avg_envstep_per_episode: 152.0
avg_sample_per_episode: 152.0
avg_envstep_per_sec: 789.8255147383929
avg_train_sample_per_sec: 789.8255147383929
avg_episode_per_sec: 5.196220491699954
collect_time: 0.38489513737814773
reward_mean: 1240.0
reward_std: 194.0
reward_max: 1434.0
reward_min: 1046.0
total_envstep_count: 1348040
total_train_sample_count: 1348019
total_episode_count: 9081
total_duration: 1706.4347185151908
[2024-11-19 23:26:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1942
train_sample_count: 1942
avg_envstep_per_episode: 194.2
avg_sample_per_episode: 194.2
avg_envstep_per_sec: 797.6923728246046
avg_train_sample_per_sec: 797.6923728246046
avg_episode_per_sec: 4.107581734421239
collect_time: 2.4345224627426694
reward_mean: 1137.199951171875
reward_std: 498.0945129394531
reward_max: 1804.0
reward_min: 616.0
total_envstep_count: 1349041
total_train_sample_count: 1349025
total_episode_count: 9091
total_duration: 1708.8692409779335
[2024-11-19 23:26:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 593
train_sample_count: 593
avg_envstep_per_episode: 98.83333333333333
avg_sample_per_episode: 98.83333333333333
avg_envstep_per_sec: 798.9353667585333
avg_train_sample_per_sec: 798.9353667585333
avg_episode_per_sec: 8.083663070069477
collect_time: 0.7422377637454441
reward_mean: 759.6666870117188
reward_std: 302.8182373046875
reward_max: 1436.0
reward_min: 608.0
total_envstep_count: 1350083
total_train_sample_count: 1350050
total_episode_count: 9097
total_duration: 1709.6114787416789
[2024-11-19 23:26:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1135
train_sample_count: 1135
avg_envstep_per_episode: 162.14285714285714
avg_sample_per_episode: 162.14285714285714
avg_envstep_per_sec: 793.3137022757679
avg_train_sample_per_sec: 793.3137022757679
avg_episode_per_sec: 4.892683626370375
collect_time: 1.4307076718126024
reward_mean: 985.7142944335938
reward_std: 370.91766357421875
reward_max: 1671.0
reward_min: 605.0
total_envstep_count: 1351085
total_train_sample_count: 1351029
total_episode_count: 9104
total_duration: 1711.0421864134914
[2024-11-19 23:26:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 963
train_sample_count: 963
avg_envstep_per_episode: 137.57142857142858
avg_sample_per_episode: 137.57142857142858
avg_envstep_per_sec: 790.5243023537442
avg_train_sample_per_sec: 790.5243023537442
avg_episode_per_sec: 5.746282571626385
collect_time: 1.2181788682937622
reward_mean: 1066.2857666015625
reward_std: 519.9702758789062
reward_max: 1705.0
reward_min: 249.0
total_envstep_count: 1352055
total_train_sample_count: 1352028
total_episode_count: 9111
total_duration: 1712.2603652817852
[2024-11-19 23:26:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 506
train_sample_count: 506
avg_envstep_per_episode: 168.66666666666666
avg_sample_per_episode: 168.66666666666666
avg_envstep_per_sec: 804.4288220033295
avg_train_sample_per_sec: 804.4288220033295
avg_episode_per_sec: 4.769340841916973
collect_time: 0.6290177404880524
reward_mean: 1246.0
reward_std: 320.0593566894531
reward_max: 1579.0
reward_min: 814.0
total_envstep_count: 1353053
total_train_sample_count: 1353014
total_episode_count: 9114
total_duration: 1712.8893830222733
[2024-11-19 23:26:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1801
train_sample_count: 1801
avg_envstep_per_episode: 200.11111111111111
avg_sample_per_episode: 200.11111111111111
avg_envstep_per_sec: 803.8769557883614
avg_train_sample_per_sec: 803.8769557883614
avg_episode_per_sec: 4.017153027259996
collect_time: 2.2403926210744043
reward_mean: 1176.111083984375
reward_std: 429.1739807128906
reward_max: 1898.0
reward_min: 593.0
total_envstep_count: 1354092
total_train_sample_count: 1354047
total_episode_count: 9123
total_duration: 1715.1297756433476
[2024-11-19 23:26:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1028
train_sample_count: 1028
avg_envstep_per_episode: 128.5
avg_sample_per_episode: 128.5
avg_envstep_per_sec: 795.7472950438524
avg_train_sample_per_sec: 795.7472950438524
avg_episode_per_sec: 6.192585953648657
collect_time: 1.2918674136911121
reward_mean: 823.125
reward_std: 260.7874755859375
reward_max: 1345.0
reward_min: 593.0
total_envstep_count: 1355092
total_train_sample_count: 1355063
total_episode_count: 9131
total_duration: 1716.4216430570386
[2024-11-19 23:26:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 704
train_sample_count: 704
avg_envstep_per_episode: 117.33333333333333
avg_sample_per_episode: 117.33333333333333
avg_envstep_per_sec: 795.2348694217601
avg_train_sample_per_sec: 795.2348694217601
avg_episode_per_sec: 6.777569909844546
collect_time: 0.8852730521133967
reward_mean: 865.1666870117188
reward_std: 381.987548828125
reward_max: 1651.0
reward_min: 605.0
total_envstep_count: 1356087
total_train_sample_count: 1356043
total_episode_count: 9137
total_duration: 1717.306916109152
[2024-11-19 23:27:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1029
train_sample_count: 1029
avg_envstep_per_episode: 147.0
avg_sample_per_episode: 147.0
avg_envstep_per_sec: 794.8520004262274
avg_train_sample_per_sec: 794.8520004262274
avg_episode_per_sec: 5.407156465484539
collect_time: 1.294580625636237
reward_mean: 977.8571166992188
reward_std: 400.7793884277344
reward_max: 1705.0
reward_min: 621.0
total_envstep_count: 1357104
total_train_sample_count: 1357060
total_episode_count: 9144
total_duration: 1718.6014967347883
[2024-11-19 23:27:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1085
train_sample_count: 1085
avg_envstep_per_episode: 135.625
avg_sample_per_episode: 135.625
avg_envstep_per_sec: 790.4683043861171
avg_train_sample_per_sec: 790.4683043861171
avg_episode_per_sec: 5.828337728192569
collect_time: 1.372604055064065
reward_mean: 946.75
reward_std: 464.68585205078125
reward_max: 1680.0
reward_min: 251.0
total_envstep_count: 1358089
total_train_sample_count: 1358049
total_episode_count: 9152
total_duration: 1719.9741007898524
[2024-11-19 23:27:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 972
train_sample_count: 972
avg_envstep_per_episode: 162.0
avg_sample_per_episode: 162.0
avg_envstep_per_sec: 798.1726164813432
avg_train_sample_per_sec: 798.1726164813432
avg_episode_per_sec: 4.9269914597613775
collect_time: 1.2177816927433014
reward_mean: 988.1666870117188
reward_std: 470.647216796875
reward_max: 1833.0
reward_min: 605.0
total_envstep_count: 1359085
total_train_sample_count: 1359045
total_episode_count: 9158
total_duration: 1721.1918824825957
[2024-11-19 23:27:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 439
train_sample_count: 439
avg_envstep_per_episode: 219.5
avg_sample_per_episode: 219.5
avg_envstep_per_sec: 807.3340506520198
avg_train_sample_per_sec: 807.3340506520198
avg_episode_per_sec: 3.6780594562734383
collect_time: 0.5437649999346051
reward_mean: 1319.0
reward_std: 8.0
reward_max: 1327.0
reward_min: 1311.0
total_envstep_count: 1360059
total_train_sample_count: 1360036
total_episode_count: 9160
total_duration: 1721.7356474825303
[2024-11-19 23:27:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1803
train_sample_count: 1803
avg_envstep_per_episode: 180.3
avg_sample_per_episode: 180.3
avg_envstep_per_sec: 799.2073584770786
avg_train_sample_per_sec: 799.2073584770786
avg_episode_per_sec: 4.432653125219515
collect_time: 2.255985234464918
reward_mean: 1081.199951171875
reward_std: 400.6698913574219
reward_max: 1686.0
reward_min: 249.0
total_envstep_count: 1361068
total_train_sample_count: 1361011
total_episode_count: 9170
total_duration: 1723.9916327169954
[2024-11-19 23:27:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 562
train_sample_count: 562
avg_envstep_per_episode: 112.4
avg_sample_per_episode: 112.4
avg_envstep_per_sec: 798.3008756221261
avg_train_sample_per_sec: 798.3008756221261
avg_episode_per_sec: 7.102320957492226
collect_time: 0.7039952192987715
reward_mean: 811.7999877929688
reward_std: 363.45806884765625
reward_max: 1311.0
reward_min: 237.0
total_envstep_count: 1362056
total_train_sample_count: 1362017
total_episode_count: 9175
total_duration: 1724.6956279362942
[2024-11-19 23:27:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1068
train_sample_count: 1068
avg_envstep_per_episode: 178.0
avg_sample_per_episode: 178.0
avg_envstep_per_sec: 797.8628632999898
avg_train_sample_per_sec: 797.8628632999898
avg_episode_per_sec: 4.482375636516797
collect_time: 1.3385758996009829
reward_mean: 1044.5
reward_std: 439.9013977050781
reward_max: 1675.0
reward_min: 601.0
total_envstep_count: 1363043
total_train_sample_count: 1363013
total_episode_count: 9181
total_duration: 1726.0342038358951
[2024-11-19 23:27:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1026
train_sample_count: 1026
avg_envstep_per_episode: 146.57142857142858
avg_sample_per_episode: 146.57142857142858
avg_envstep_per_sec: 803.3768996464792
avg_train_sample_per_sec: 803.3768996464792
avg_episode_per_sec: 5.4811289449564855
collect_time: 1.2771091631480624
reward_mean: 934.5714111328125
reward_std: 444.8932189941406
reward_max: 1663.0
reward_min: 237.0
total_envstep_count: 1364028
total_train_sample_count: 1363991
total_episode_count: 9188
total_duration: 1727.3113129990431
[2024-11-19 23:27:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 908
train_sample_count: 908
avg_envstep_per_episode: 129.71428571428572
avg_sample_per_episode: 129.71428571428572
avg_envstep_per_sec: 790.1791124359064
avg_train_sample_per_sec: 790.1791124359064
avg_episode_per_sec: 6.0916891927878245
collect_time: 1.1491065578801292
reward_mean: 776.7142944335938
reward_std: 268.3232116699219
reward_max: 1330.0
reward_min: 565.0
total_envstep_count: 1365021
total_train_sample_count: 1364971
total_episode_count: 9195
total_duration: 1728.4604195569232
[2024-11-19 23:27:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1106
train_sample_count: 1106
avg_envstep_per_episode: 138.25
avg_sample_per_episode: 138.25
avg_envstep_per_sec: 789.2611883880321
avg_train_sample_per_sec: 789.2611883880321
avg_episode_per_sec: 5.708941688159364
collect_time: 1.4013105119977678
reward_mean: 958.875
reward_std: 407.9939880371094
reward_max: 1591.0
reward_min: 560.0
total_envstep_count: 1366015
total_train_sample_count: 1365969
total_episode_count: 9203
total_duration: 1729.861730068921
[2024-11-19 23:27:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 807
train_sample_count: 807
avg_envstep_per_episode: 134.5
avg_sample_per_episode: 134.5
avg_envstep_per_sec: 803.4157681370807
avg_train_sample_per_sec: 803.4157681370807
avg_episode_per_sec: 5.973351435963425
collect_time: 1.0044612416199277
reward_mean: 957.3333129882812
reward_std: 330.7061462402344
reward_max: 1414.0
reward_min: 636.0
total_envstep_count: 1366977
total_train_sample_count: 1366956
total_episode_count: 9209
total_duration: 1730.866191310541
[2024-11-19 23:27:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1017
train_sample_count: 1017
avg_envstep_per_episode: 145.28571428571428
avg_sample_per_episode: 145.28571428571428
avg_envstep_per_sec: 789.8610981130755
avg_train_sample_per_sec: 789.8610981130755
avg_episode_per_sec: 5.436605395075249
collect_time: 1.2875681590466272
reward_mean: 1030.857177734375
reward_std: 479.00653076171875
reward_max: 1831.0
reward_min: 622.0
total_envstep_count: 1367987
total_train_sample_count: 1367937
total_episode_count: 9216
total_duration: 1732.1537594695876
[2024-11-19 23:27:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1166
train_sample_count: 1166
avg_envstep_per_episode: 145.75
avg_sample_per_episode: 145.75
avg_envstep_per_sec: 798.0068032509777
avg_train_sample_per_sec: 798.0068032509777
avg_episode_per_sec: 5.475175322476691
collect_time: 1.461140425432296
reward_mean: 1100.375
reward_std: 534.549560546875
reward_max: 1908.0
reward_min: 248.0
total_envstep_count: 1369004
total_train_sample_count: 1368971
total_episode_count: 9224
total_duration: 1733.61489989502
[2024-11-19 23:27:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1102
train_sample_count: 1102
avg_envstep_per_episode: 137.75
avg_sample_per_episode: 137.75
avg_envstep_per_sec: 794.4048627312898
avg_train_sample_per_sec: 794.4048627312898
avg_episode_per_sec: 5.767004448140034
collect_time: 1.3872019818850925
reward_mean: 918.5
reward_std: 309.1015319824219
reward_max: 1431.0
reward_min: 619.0
total_envstep_count: 1370028
total_train_sample_count: 1369977
total_episode_count: 9232
total_duration: 1735.002101876905
[2024-11-19 23:27:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 675
train_sample_count: 675
avg_envstep_per_episode: 168.75
avg_sample_per_episode: 168.75
avg_envstep_per_sec: 801.4356384233212
avg_train_sample_per_sec: 801.4356384233212
avg_episode_per_sec: 4.749248227693755
collect_time: 0.8422385624476841
reward_mean: 1006.75
reward_std: 377.91162109375
reward_max: 1433.0
reward_min: 628.0
total_envstep_count: 1371017
total_train_sample_count: 1370976
total_episode_count: 9236
total_duration: 1735.8443404393527
[2024-11-19 23:27:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1222
train_sample_count: 1222
avg_envstep_per_episode: 244.4
avg_sample_per_episode: 244.4
avg_envstep_per_sec: 797.0339775051979
avg_train_sample_per_sec: 797.0339775051979
avg_episode_per_sec: 3.2611864873371434
collect_time: 1.533184323992048
reward_mean: 1408.0
reward_std: 404.6905212402344
reward_max: 1680.0
reward_min: 626.0
total_envstep_count: 1372020
total_train_sample_count: 1371982
total_episode_count: 9241
total_duration: 1737.3775247633448
[2024-11-19 23:27:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 901
train_sample_count: 901
avg_envstep_per_episode: 128.71428571428572
avg_sample_per_episode: 128.71428571428572
avg_envstep_per_sec: 786.6974573799076
avg_train_sample_per_sec: 786.6974573799076
avg_episode_per_sec: 6.11196692747986
collect_time: 1.145294155393328
reward_mean: 969.0
reward_std: 385.8934020996094
reward_max: 1634.0
reward_min: 615.0
total_envstep_count: 1373006
total_train_sample_count: 1372967
total_episode_count: 9248
total_duration: 1738.522818918738
[2024-11-19 23:28:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1162
train_sample_count: 1162
avg_envstep_per_episode: 193.66666666666666
avg_sample_per_episode: 193.66666666666666
avg_envstep_per_sec: 790.1316569761158
avg_train_sample_per_sec: 790.1316569761158
avg_episode_per_sec: 4.079853650479083
collect_time: 1.4706409871578214
reward_mean: 1294.6666259765625
reward_std: 606.8062744140625
reward_max: 2345.0
reward_min: 616.0
total_envstep_count: 1373994
total_train_sample_count: 1373961
total_episode_count: 9254
total_duration: 1739.9934599058959
[2024-11-19 23:28:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1015
train_sample_count: 1015
avg_envstep_per_episode: 126.875
avg_sample_per_episode: 126.875
avg_envstep_per_sec: 797.4284518957517
avg_train_sample_per_sec: 797.4284518957517
avg_episode_per_sec: 6.285150359769471
collect_time: 1.2728414663246699
reward_mean: 997.5
reward_std: 374.6745300292969
reward_max: 1584.0
reward_min: 640.0
total_envstep_count: 1375002
total_train_sample_count: 1374964
total_episode_count: 9262
total_duration: 1741.2663013722206
[2024-11-19 23:28:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 425
train_sample_count: 425
avg_envstep_per_episode: 141.66666666666666
avg_sample_per_episode: 141.66666666666666
avg_envstep_per_sec: 798.6629015274954
avg_train_sample_per_sec: 798.6629015274954
avg_episode_per_sec: 5.637620481370555
collect_time: 0.5321394034794399
reward_mean: 1142.3333740234375
reward_std: 273.1865539550781
reward_max: 1338.0
reward_min: 756.0
total_envstep_count: 1375959
total_train_sample_count: 1375929
total_episode_count: 9265
total_duration: 1741.7984407757
[2024-11-19 23:28:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1555
train_sample_count: 1555
avg_envstep_per_episode: 194.375
avg_sample_per_episode: 194.375
avg_envstep_per_sec: 781.1262751260081
avg_train_sample_per_sec: 781.1262751260081
avg_episode_per_sec: 4.018656077818691
collect_time: 1.9907152652740479
reward_mean: 1245.25
reward_std: 354.59405517578125
reward_max: 1919.0
reward_min: 613.0
total_envstep_count: 1376951
total_train_sample_count: 1376920
total_episode_count: 9273
total_duration: 1743.7891560409741
[2024-11-19 23:28:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 774
train_sample_count: 774
avg_envstep_per_episode: 154.8
avg_sample_per_episode: 154.8
avg_envstep_per_sec: 774.902340941636
avg_train_sample_per_sec: 774.902340941636
avg_episode_per_sec: 5.005829075850362
collect_time: 0.9988355423722949
reward_mean: 745.7999877929688
reward_std: 281.66534423828125
reward_max: 1309.0
reward_min: 597.0
total_envstep_count: 1377947
total_train_sample_count: 1377910
total_episode_count: 9278
total_duration: 1744.7879915833464
[2024-11-19 23:28:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1288
train_sample_count: 1288
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 792.0043022580708
avg_train_sample_per_sec: 792.0043022580708
avg_episode_per_sec: 4.304371207924298
collect_time: 1.6262537922177995
reward_mean: 1094.7142333984375
reward_std: 275.0702209472656
reward_max: 1583.0
reward_min: 622.0
total_envstep_count: 1378942
total_train_sample_count: 1378910
total_episode_count: 9285
total_duration: 1746.4142453755642
[2024-11-19 23:28:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 703
train_sample_count: 703
avg_envstep_per_episode: 140.6
avg_sample_per_episode: 140.6
avg_envstep_per_sec: 793.3871069631585
avg_train_sample_per_sec: 793.3871069631585
avg_episode_per_sec: 5.642867048102123
collect_time: 0.8860743939876556
reward_mean: 1029.800048828125
reward_std: 493.3402404785156
reward_max: 1693.0
reward_min: 612.0
total_envstep_count: 1379954
total_train_sample_count: 1379913
total_episode_count: 9290
total_duration: 1747.3003197695518
[2024-11-19 23:28:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1343
train_sample_count: 1343
avg_envstep_per_episode: 134.3
avg_sample_per_episode: 134.3
avg_envstep_per_sec: 791.0531245031079
avg_train_sample_per_sec: 791.0531245031079
avg_episode_per_sec: 5.890194523478093
collect_time: 1.6977367997169495
reward_mean: 964.0
reward_std: 431.8941955566406
reward_max: 1924.0
reward_min: 607.0
total_envstep_count: 1380971
total_train_sample_count: 1380920
total_episode_count: 9300
total_duration: 1748.9980565692688
[2024-11-19 23:28:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 538
train_sample_count: 538
avg_envstep_per_episode: 89.66666666666667
avg_sample_per_episode: 89.66666666666667
avg_envstep_per_sec: 778.0107048852852
avg_train_sample_per_sec: 778.0107048852852
avg_episode_per_sec: 8.676699310988312
collect_time: 0.6915071947234017
reward_mean: 597.8333129882812
reward_std: 283.8963623046875
reward_max: 1046.0
reward_min: 238.0
total_envstep_count: 1381974
total_train_sample_count: 1381926
total_episode_count: 9306
total_duration: 1749.6895637639923
[2024-11-19 23:28:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1154
train_sample_count: 1154
avg_envstep_per_episode: 164.85714285714286
avg_sample_per_episode: 164.85714285714286
avg_envstep_per_sec: 806.0638668681371
avg_train_sample_per_sec: 806.0638668681371
avg_episode_per_sec: 4.8894688631516114
collect_time: 1.4316483438014984
reward_mean: 961.5714111328125
reward_std: 319.9003601074219
reward_max: 1432.0
reward_min: 642.0
total_envstep_count: 1382984
total_train_sample_count: 1382948
total_episode_count: 9313
total_duration: 1751.1212121077938
[2024-11-19 23:28:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 731
train_sample_count: 731
avg_envstep_per_episode: 146.2
avg_sample_per_episode: 146.2
avg_envstep_per_sec: 798.7300769055176
avg_train_sample_per_sec: 798.7300769055176
avg_episode_per_sec: 5.4632700198735815
collect_time: 0.915202796459198
reward_mean: 1199.5999755859375
reward_std: 311.9587097167969
reward_max: 1437.0
reward_min: 653.0
total_envstep_count: 1383955
total_train_sample_count: 1383931
total_episode_count: 9318
total_duration: 1752.036414904253
[2024-11-19 23:28:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 14
envstep_count: 1738
train_sample_count: 1738
avg_envstep_per_episode: 124.14285714285714
avg_sample_per_episode: 124.14285714285714
avg_envstep_per_sec: 794.9964741944918
avg_train_sample_per_sec: 794.9964741944918
avg_episode_per_sec: 6.403884141957932
collect_time: 2.186173217637198
reward_mean: 921.1428833007812
reward_std: 385.96575927734375
reward_max: 1846.0
reward_min: 593.0
total_envstep_count: 1384975
total_train_sample_count: 1384937
total_episode_count: 9332
total_duration: 1754.22258812189
[2024-11-19 23:28:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 924
train_sample_count: 924
avg_envstep_per_episode: 132.0
avg_sample_per_episode: 132.0
avg_envstep_per_sec: 798.4275575949534
avg_train_sample_per_sec: 798.4275575949534
avg_episode_per_sec: 6.048693618143586
collect_time: 1.1572746847357067
reward_mean: 944.8571166992188
reward_std: 264.1289978027344
reward_max: 1429.0
reward_min: 622.0
total_envstep_count: 1385976
total_train_sample_count: 1385945
total_episode_count: 9339
total_duration: 1755.3798628066259
[2024-11-19 23:28:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 453
train_sample_count: 453
avg_envstep_per_episode: 151.0
avg_sample_per_episode: 151.0
avg_envstep_per_sec: 799.0640104011821
avg_train_sample_per_sec: 799.0640104011821
avg_episode_per_sec: 5.291814638418425
collect_time: 0.5669132811682565
reward_mean: 988.6666870117188
reward_std: 413.3008117675781
reward_max: 1571.0
reward_min: 654.0
total_envstep_count: 1386981
total_train_sample_count: 1386938
total_episode_count: 9342
total_duration: 1755.9467760877942
[2024-11-19 23:28:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 931
train_sample_count: 931
avg_envstep_per_episode: 155.16666666666666
avg_sample_per_episode: 155.16666666666666
avg_envstep_per_sec: 798.3668307117432
avg_train_sample_per_sec: 798.3668307117432
avg_episode_per_sec: 5.1452212505590325
collect_time: 1.166130610874721
reward_mean: 913.8333129882812
reward_std: 337.004638671875
reward_max: 1423.0
reward_min: 607.0
total_envstep_count: 1387968
total_train_sample_count: 1387929
total_episode_count: 9348
total_duration: 1757.112906698669
[2024-11-19 23:28:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1147
train_sample_count: 1147
avg_envstep_per_episode: 191.16666666666666
avg_sample_per_episode: 191.16666666666666
avg_envstep_per_sec: 805.6836089544273
avg_train_sample_per_sec: 805.6836089544273
avg_episode_per_sec: 4.21456116279561
collect_time: 1.4236357637814112
reward_mean: 1025.0
reward_std: 329.32861328125
reward_max: 1436.0
reward_min: 605.0
total_envstep_count: 1388978
total_train_sample_count: 1388932
total_episode_count: 9354
total_duration: 1758.5365424624504
[2024-11-19 23:29:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 873
train_sample_count: 873
avg_envstep_per_episode: 174.6
avg_sample_per_episode: 174.6
avg_envstep_per_sec: 793.3271974214862
avg_train_sample_per_sec: 793.3271974214862
avg_episode_per_sec: 4.543683834029131
collect_time: 1.1004286791597093
reward_mean: 1192.5999755859375
reward_std: 421.6489562988281
reward_max: 1909.0
reward_min: 639.0
total_envstep_count: 1389949
total_train_sample_count: 1389913
total_episode_count: 9359
total_duration: 1759.63697114161
[2024-11-19 23:29:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1366
train_sample_count: 1366
avg_envstep_per_episode: 170.75
avg_sample_per_episode: 170.75
avg_envstep_per_sec: 792.4903336698522
avg_train_sample_per_sec: 792.4903336698522
avg_episode_per_sec: 4.641231822371023
collect_time: 1.72368033017431
reward_mean: 1257.5
reward_std: 457.5846862792969
reward_max: 1697.0
reward_min: 233.0
total_envstep_count: 1390966
total_train_sample_count: 1390919
total_episode_count: 9367
total_duration: 1761.3606514717844
[2024-11-19 23:29:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 908
train_sample_count: 908
avg_envstep_per_episode: 181.6
avg_sample_per_episode: 181.6
avg_envstep_per_sec: 791.6984096066598
avg_train_sample_per_sec: 791.6984096066598
avg_episode_per_sec: 4.359572740124778
collect_time: 1.1469013818672724
reward_mean: 1291.0
reward_std: 415.7153015136719
reward_max: 1692.0
reward_min: 616.0
total_envstep_count: 1391977
total_train_sample_count: 1391935
total_episode_count: 9372
total_duration: 1762.5075528536518
[2024-11-19 23:29:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 874
train_sample_count: 874
avg_envstep_per_episode: 124.85714285714286
avg_sample_per_episode: 124.85714285714286
avg_envstep_per_sec: 804.470359457023
avg_train_sample_per_sec: 804.470359457023
avg_episode_per_sec: 6.443126448740459
collect_time: 1.086429089307785
reward_mean: 959.0
reward_std: 495.4637145996094
reward_max: 1585.0
reward_min: 251.0
total_envstep_count: 1392956
total_train_sample_count: 1392917
total_episode_count: 9379
total_duration: 1763.5939819429595
[2024-11-19 23:29:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1432
train_sample_count: 1432
avg_envstep_per_episode: 130.1818181818182
avg_sample_per_episode: 130.1818181818182
avg_envstep_per_sec: 795.5697159663708
avg_train_sample_per_sec: 795.5697159663708
avg_episode_per_sec: 6.111219885216536
collect_time: 1.7999679616519382
reward_mean: 942.0
reward_std: 323.1956787109375
reward_max: 1344.0
reward_min: 610.0
total_envstep_count: 1393994
total_train_sample_count: 1393965
total_episode_count: 9390
total_duration: 1765.3939499046114
[2024-11-19 23:29:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 621
train_sample_count: 621
avg_envstep_per_episode: 124.2
avg_sample_per_episode: 124.2
avg_envstep_per_sec: 789.5003465796651
avg_train_sample_per_sec: 789.5003465796651
avg_episode_per_sec: 6.356685560222746
collect_time: 0.7865734355790274
reward_mean: 962.7999877929688
reward_std: 350.573486328125
reward_max: 1440.0
reward_min: 626.0
total_envstep_count: 1394998
total_train_sample_count: 1394958
total_episode_count: 9395
total_duration: 1766.1805233401903
[2024-11-19 23:29:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 972
train_sample_count: 972
avg_envstep_per_episode: 162.0
avg_sample_per_episode: 162.0
avg_envstep_per_sec: 793.5941362333206
avg_train_sample_per_sec: 793.5941362333206
avg_episode_per_sec: 4.898729236008151
collect_time: 1.224807436977114
reward_mean: 1035.5
reward_std: 447.8436279296875
reward_max: 1854.0
reward_min: 602.0
total_envstep_count: 1395984
total_train_sample_count: 1395942
total_episode_count: 9401
total_duration: 1767.4053307771674
[2024-11-19 23:29:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1126
train_sample_count: 1126
avg_envstep_per_episode: 160.85714285714286
avg_sample_per_episode: 160.85714285714286
avg_envstep_per_sec: 794.5708238154033
avg_train_sample_per_sec: 794.5708238154033
avg_episode_per_sec: 4.939605476649932
collect_time: 1.4171172238531566
reward_mean: 973.5714111328125
reward_std: 341.6647644042969
reward_max: 1412.0
reward_min: 617.0
total_envstep_count: 1396970
total_train_sample_count: 1396924
total_episode_count: 9408
total_duration: 1768.8224480010206
[2024-11-19 23:29:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 736
train_sample_count: 736
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 800.7061309942255
avg_train_sample_per_sec: 800.7061309942255
avg_episode_per_sec: 4.3516637554034
collect_time: 0.9191886654921939
reward_mean: 1119.25
reward_std: 518.398681640625
reward_max: 1561.0
reward_min: 235.0
total_envstep_count: 1397958
total_train_sample_count: 1397924
total_episode_count: 9412
total_duration: 1769.7416366665127
[2024-11-19 23:29:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1158
train_sample_count: 1158
avg_envstep_per_episode: 165.42857142857142
avg_sample_per_episode: 165.42857142857142
avg_envstep_per_sec: 658.0108022108486
avg_train_sample_per_sec: 658.0108022108486
avg_episode_per_sec: 3.977612794020674
collect_time: 1.7598495284716287
reward_mean: 1075.142822265625
reward_std: 319.0049133300781
reward_max: 1441.0
reward_min: 614.0
total_envstep_count: 1398969
total_train_sample_count: 1398938
total_episode_count: 9419
total_duration: 1771.5014861949844
[2024-11-19 23:29:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1028
train_sample_count: 1028
avg_envstep_per_episode: 146.85714285714286
avg_sample_per_episode: 146.85714285714286
avg_envstep_per_sec: 806.3242441162262
avg_train_sample_per_sec: 806.3242441162262
avg_episode_per_sec: 5.490534736199984
collect_time: 1.2749213576316833
reward_mean: 1018.0
reward_std: 493.79693603515625
reward_max: 1580.0
reward_min: 236.0
total_envstep_count: 1399947
total_train_sample_count: 1399918
total_episode_count: 9426
total_duration: 1772.776407552616
[2024-11-19 23:30:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 912
train_sample_count: 912
avg_envstep_per_episode: 152.0
avg_sample_per_episode: 152.0
avg_envstep_per_sec: 794.9768453261589
avg_train_sample_per_sec: 794.9768453261589
avg_episode_per_sec: 5.230110824514203
collect_time: 1.1472032240458896
reward_mean: 1056.3333740234375
reward_std: 327.5157470703125
reward_max: 1423.0
reward_min: 619.0
total_envstep_count: 1400941
total_train_sample_count: 1400902
total_episode_count: 9432
total_duration: 1773.923610776662
[2024-11-19 23:30:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 477
train_sample_count: 477
avg_envstep_per_episode: 119.25
avg_sample_per_episode: 119.25
avg_envstep_per_sec: 783.1036664992002
avg_train_sample_per_sec: 783.1036664992002
avg_episode_per_sec: 6.566907056597066
collect_time: 0.6091147576059615
reward_mean: 1044.75
reward_std: 390.7629699707031
reward_max: 1440.0
reward_min: 654.0
total_envstep_count: 1401937
total_train_sample_count: 1401895
total_episode_count: 9436
total_duration: 1774.532725534268
[2024-11-19 23:30:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1714
train_sample_count: 1714
avg_envstep_per_episode: 214.25
avg_sample_per_episode: 214.25
avg_envstep_per_sec: 795.231352794084
avg_train_sample_per_sec: 795.231352794084
avg_episode_per_sec: 3.711698262749517
collect_time: 2.155347615480423
reward_mean: 1321.25
reward_std: 605.9867553710938
reward_max: 2586.0
reward_min: 634.0
total_envstep_count: 1402947
total_train_sample_count: 1402913
total_episode_count: 9444
total_duration: 1776.6880731497483
[2024-11-19 23:30:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 946
train_sample_count: 946
avg_envstep_per_episode: 135.14285714285714
avg_sample_per_episode: 135.14285714285714
avg_envstep_per_sec: 809.0773281221651
avg_train_sample_per_sec: 809.0773281221651
avg_episode_per_sec: 5.986830123525534
collect_time: 1.1692331092698232
reward_mean: 1009.2857055664062
reward_std: 272.306396484375
reward_max: 1356.0
reward_min: 622.0
total_envstep_count: 1403948
total_train_sample_count: 1403919
total_episode_count: 9451
total_duration: 1777.857306259018
[2024-11-19 23:30:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 793
train_sample_count: 793
avg_envstep_per_episode: 198.25
avg_sample_per_episode: 198.25
avg_envstep_per_sec: 798.6813238283984
avg_train_sample_per_sec: 798.6813238283984
avg_episode_per_sec: 4.028657371139462
collect_time: 0.9928866199084692
reward_mean: 1173.5
reward_std: 150.92630004882812
reward_max: 1340.0
reward_min: 1022.0
total_envstep_count: 1404944
total_train_sample_count: 1404892
total_episode_count: 9455
total_duration: 1778.8501928789265
[2024-11-19 23:30:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 781
train_sample_count: 781
avg_envstep_per_episode: 156.2
avg_sample_per_episode: 156.2
avg_envstep_per_sec: 796.5137640155947
avg_train_sample_per_sec: 796.5137640155947
avg_episode_per_sec: 5.099319872058865
collect_time: 0.980522917849677
reward_mean: 1065.800048828125
reward_std: 407.26422119140625
reward_max: 1684.0
reward_min: 630.0
total_envstep_count: 1405923
total_train_sample_count: 1405877
total_episode_count: 9460
total_duration: 1779.830715796776
[2024-11-19 23:30:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1600
train_sample_count: 1600
avg_envstep_per_episode: 160.0
avg_sample_per_episode: 160.0
avg_envstep_per_sec: 795.1288230002924
avg_train_sample_per_sec: 795.1288230002924
avg_episode_per_sec: 4.969555143751828
collect_time: 2.012252547911235
reward_mean: 949.0999755859375
reward_std: 276.7108459472656
reward_max: 1431.0
reward_min: 620.0
total_envstep_count: 1406900
total_train_sample_count: 1406865
total_episode_count: 9470
total_duration: 1781.8429683446873
[2024-11-19 23:30:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 510
train_sample_count: 510
avg_envstep_per_episode: 102.0
avg_sample_per_episode: 102.0
avg_envstep_per_sec: 799.1821452291697
avg_train_sample_per_sec: 799.1821452291697
avg_episode_per_sec: 7.835119070874213
collect_time: 0.6381523949759348
reward_mean: 783.7999877929688
reward_std: 280.9607849121094
reward_max: 1345.0
reward_min: 616.0
total_envstep_count: 1407904
total_train_sample_count: 1407855
total_episode_count: 9475
total_duration: 1782.4811207396633
[2024-11-19 23:30:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1540
train_sample_count: 1540
avg_envstep_per_episode: 171.11111111111111
avg_sample_per_episode: 171.11111111111111
avg_envstep_per_sec: 793.129960211807
avg_train_sample_per_sec: 793.129960211807
avg_episode_per_sec: 4.635175092146923
collect_time: 1.941674223967961
reward_mean: 1158.6666259765625
reward_std: 419.220703125
reward_max: 1633.0
reward_min: 234.0
total_envstep_count: 1408876
total_train_sample_count: 1408855
total_episode_count: 9484
total_duration: 1784.4227949636313
[2024-11-19 23:30:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 492
train_sample_count: 492
avg_envstep_per_episode: 123.0
avg_sample_per_episode: 123.0
avg_envstep_per_sec: 802.4862857935094
avg_train_sample_per_sec: 802.4862857935094
avg_episode_per_sec: 6.524278746288695
collect_time: 0.6130945895399367
reward_mean: 943.5
reward_std: 332.1268615722656
reward_max: 1434.0
reward_min: 626.0
total_envstep_count: 1409857
total_train_sample_count: 1409827
total_episode_count: 9488
total_duration: 1785.0358895531713
[2024-11-19 23:30:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1142
train_sample_count: 1142
avg_envstep_per_episode: 190.33333333333334
avg_sample_per_episode: 190.33333333333334
avg_envstep_per_sec: 796.7842546567279
avg_train_sample_per_sec: 796.7842546567279
avg_episode_per_sec: 4.186257029720111
collect_time: 1.43326125400407
reward_mean: 1369.3333740234375
reward_std: 362.8428039550781
reward_max: 1691.0
reward_min: 595.0
total_envstep_count: 1410867
total_train_sample_count: 1410825
total_episode_count: 9494
total_duration: 1786.4691508071753
[2024-11-19 23:30:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 166.66666666666666
avg_sample_per_episode: 166.66666666666666
avg_envstep_per_sec: 798.3334237040019
avg_train_sample_per_sec: 798.3334237040019
avg_episode_per_sec: 4.7900005422240115
collect_time: 1.2526094615459442
reward_mean: 1302.8333740234375
reward_std: 365.36895751953125
reward_max: 1710.0
reward_min: 625.0
total_envstep_count: 1411862
total_train_sample_count: 1411825
total_episode_count: 9500
total_duration: 1787.7217602687213
[2024-11-19 23:30:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1064
train_sample_count: 1064
avg_envstep_per_episode: 177.33333333333334
avg_sample_per_episode: 177.33333333333334
avg_envstep_per_sec: 794.8624272432185
avg_train_sample_per_sec: 794.8624272432185
avg_episode_per_sec: 4.482306920544465
collect_time: 1.338596420628684
reward_mean: 1371.6666259765625
reward_std: 358.9868469238281
reward_max: 1699.0
reward_min: 609.0
total_envstep_count: 1412888
total_train_sample_count: 1412829
total_episode_count: 9506
total_duration: 1789.0603566893499
[2024-11-19 23:30:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 879
train_sample_count: 879
avg_envstep_per_episode: 125.57142857142857
avg_sample_per_episode: 125.57142857142857
avg_envstep_per_sec: 789.3733001482177
avg_train_sample_per_sec: 789.3733001482177
avg_episode_per_sec: 6.286249261703668
collect_time: 1.113541590315955
reward_mean: 850.5714111328125
reward_std: 274.8266296386719
reward_max: 1338.0
reward_min: 608.0
total_envstep_count: 1413858
total_train_sample_count: 1413828
total_episode_count: 9513
total_duration: 1790.1738982796658
[2024-11-19 23:30:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 876
train_sample_count: 876
avg_envstep_per_episode: 146.0
avg_sample_per_episode: 146.0
avg_envstep_per_sec: 788.236877827718
avg_train_sample_per_sec: 788.236877827718
avg_episode_per_sec: 5.398882724847383
collect_time: 1.111341050692967
reward_mean: 1095.5
reward_std: 438.50836181640625
reward_max: 1847.0
reward_min: 608.0
total_envstep_count: 1414852
total_train_sample_count: 1414824
total_episode_count: 9519
total_duration: 1791.2852393303588
[2024-11-19 23:30:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1317
train_sample_count: 1317
avg_envstep_per_episode: 188.14285714285714
avg_sample_per_episode: 188.14285714285714
avg_envstep_per_sec: 794.6760712737854
avg_train_sample_per_sec: 794.6760712737854
avg_episode_per_sec: 4.223790811629839
collect_time: 1.657279044389725
reward_mean: 1288.7142333984375
reward_std: 327.61944580078125
reward_max: 1671.0
reward_min: 611.0
total_envstep_count: 1415838
total_train_sample_count: 1415805
total_episode_count: 9526
total_duration: 1792.9425183747485
[2024-11-19 23:30:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 970
train_sample_count: 970
avg_envstep_per_episode: 121.25
avg_sample_per_episode: 121.25
avg_envstep_per_sec: 793.340656935568
avg_train_sample_per_sec: 793.340656935568
avg_episode_per_sec: 6.543015727303653
collect_time: 1.2226777885641371
reward_mean: 963.375
reward_std: 434.1664123535156
reward_max: 1928.0
reward_min: 621.0
total_envstep_count: 1416817
total_train_sample_count: 1416799
total_episode_count: 9534
total_duration: 1794.1651961633127
[2024-11-19 23:31:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 718
train_sample_count: 718
avg_envstep_per_episode: 143.6
avg_sample_per_episode: 143.6
avg_envstep_per_sec: 798.037301856083
avg_train_sample_per_sec: 798.037301856083
avg_episode_per_sec: 5.557362826295842
collect_time: 0.8997073173522949
reward_mean: 1121.199951171875
reward_std: 393.5242614746094
reward_max: 1694.0
reward_min: 654.0
total_envstep_count: 1417807
total_train_sample_count: 1417769
total_episode_count: 9539
total_duration: 1795.064903480665
[2024-11-19 23:31:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1507
train_sample_count: 1507
avg_envstep_per_episode: 150.7
avg_sample_per_episode: 150.7
avg_envstep_per_sec: 792.1118388934748
avg_train_sample_per_sec: 792.1118388934748
avg_episode_per_sec: 5.256216581907596
collect_time: 1.9025091230869298
reward_mean: 1198.0
reward_std: 436.5031433105469
reward_max: 1864.0
reward_min: 654.0
total_envstep_count: 1418814
total_train_sample_count: 1418772
total_episode_count: 9549
total_duration: 1796.9674126037519
[2024-11-19 23:31:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 458
train_sample_count: 458
avg_envstep_per_episode: 114.5
avg_sample_per_episode: 114.5
avg_envstep_per_sec: 792.5563736953071
avg_train_sample_per_sec: 792.5563736953071
avg_episode_per_sec: 6.921889726596568
collect_time: 0.5778768743787492
reward_mean: 841.25
reward_std: 436.8508605957031
reward_max: 1429.0
reward_min: 252.0
total_envstep_count: 1419794
total_train_sample_count: 1419746
total_episode_count: 9553
total_duration: 1797.5452894781306
[2024-11-19 23:31:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1200
train_sample_count: 1200
avg_envstep_per_episode: 133.33333333333334
avg_sample_per_episode: 133.33333333333334
avg_envstep_per_sec: 789.0248558794252
avg_train_sample_per_sec: 789.0248558794252
avg_episode_per_sec: 5.917686419095689
collect_time: 1.5208646357059479
reward_mean: 1085.4444580078125
reward_std: 387.2619323730469
reward_max: 1440.0
reward_min: 650.0
total_envstep_count: 1420795
total_train_sample_count: 1420754
total_episode_count: 9562
total_duration: 1799.0661541138365
[2024-11-19 23:31:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 385
train_sample_count: 385
avg_envstep_per_episode: 128.33333333333334
avg_sample_per_episode: 128.33333333333334
avg_envstep_per_sec: 794.7638162456989
avg_train_sample_per_sec: 794.7638162456989
avg_episode_per_sec: 6.192964801914537
collect_time: 0.4844206443854741
reward_mean: 722.3333129882812
reward_std: 450.8187561035156
reward_max: 1322.0
reward_min: 235.0
total_envstep_count: 1421784
total_train_sample_count: 1421739
total_episode_count: 9565
total_duration: 1799.550574758222
[2024-11-19 23:31:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1556
train_sample_count: 1556
avg_envstep_per_episode: 194.5
avg_sample_per_episode: 194.5
avg_envstep_per_sec: 789.3759388406754
avg_train_sample_per_sec: 789.3759388406754
avg_episode_per_sec: 4.058488117432779
collect_time: 1.9711773863860538
reward_mean: 1293.375
reward_std: 390.7079772949219
reward_max: 1689.0
reward_min: 631.0
total_envstep_count: 1422745
total_train_sample_count: 1422719
total_episode_count: 9573
total_duration: 1801.521752144608
[2024-11-19 23:31:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1059
train_sample_count: 1059
avg_envstep_per_episode: 151.28571428571428
avg_sample_per_episode: 151.28571428571428
avg_envstep_per_sec: 793.929762552321
avg_train_sample_per_sec: 793.929762552321
avg_episode_per_sec: 5.247883227446882
collect_time: 1.3338711432048254
reward_mean: 1069.7142333984375
reward_std: 394.5890197753906
reward_max: 1707.0
reward_min: 613.0
total_envstep_count: 1423738
total_train_sample_count: 1423706
total_episode_count: 9580
total_duration: 1802.8556232878127
[2024-11-19 23:31:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 842
train_sample_count: 842
avg_envstep_per_episode: 140.33333333333334
avg_sample_per_episode: 140.33333333333334
avg_envstep_per_sec: 803.5271946500976
avg_train_sample_per_sec: 803.5271946500976
avg_episode_per_sec: 5.72584699275604
collect_time: 1.0478799045085907
reward_mean: 1052.8333740234375
reward_std: 447.63055419921875
reward_max: 1693.0
reward_min: 591.0
total_envstep_count: 1424733
total_train_sample_count: 1424692
total_episode_count: 9586
total_duration: 1803.9035031923213
[2024-11-19 23:31:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1063
train_sample_count: 1063
avg_envstep_per_episode: 151.85714285714286
avg_sample_per_episode: 151.85714285714286
avg_envstep_per_sec: 799.6318972148485
avg_train_sample_per_sec: 799.6318972148485
avg_episode_per_sec: 5.265685118065795
collect_time: 1.3293616771697998
reward_mean: 972.1428833007812
reward_std: 324.82012939453125
reward_max: 1432.0
reward_min: 597.0
total_envstep_count: 1425711
total_train_sample_count: 1425671
total_episode_count: 9593
total_duration: 1805.232864869491
[2024-11-19 23:31:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 557
train_sample_count: 557
avg_envstep_per_episode: 185.66666666666666
avg_sample_per_episode: 185.66666666666666
avg_envstep_per_sec: 808.5767392630961
avg_train_sample_per_sec: 808.5767392630961
avg_episode_per_sec: 4.354991414343426
collect_time: 0.6888647334916251
reward_mean: 1093.0
reward_std: 252.4532928466797
reward_max: 1426.0
reward_min: 815.0
total_envstep_count: 1426732
total_train_sample_count: 1426696
total_episode_count: 9596
total_duration: 1805.9217296029826
[2024-11-19 23:31:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1178
train_sample_count: 1178
avg_envstep_per_episode: 196.33333333333334
avg_sample_per_episode: 196.33333333333334
avg_envstep_per_sec: 792.7710899840672
avg_train_sample_per_sec: 792.7710899840672
avg_episode_per_sec: 4.037883310614943
collect_time: 1.4859270410878316
reward_mean: 1309.1666259765625
reward_std: 318.17730712890625
reward_max: 1614.0
reward_min: 622.0
total_envstep_count: 1427711
total_train_sample_count: 1427670
total_episode_count: 9602
total_duration: 1807.4076566440704
[2024-11-19 23:31:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1259
train_sample_count: 1259
avg_envstep_per_episode: 179.85714285714286
avg_sample_per_episode: 179.85714285714286
avg_envstep_per_sec: 800.125460405972
avg_train_sample_per_sec: 800.125460405972
avg_episode_per_sec: 4.448672138873554
collect_time: 1.5735032345567428
reward_mean: 1243.5714111328125
reward_std: 440.0473937988281
reward_max: 1578.0
reward_min: 246.0
total_envstep_count: 1428720
total_train_sample_count: 1428665
total_episode_count: 9609
total_duration: 1808.981159878627
[2024-11-19 23:31:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 865
train_sample_count: 865
avg_envstep_per_episode: 173.0
avg_sample_per_episode: 173.0
avg_envstep_per_sec: 793.7332128828753
avg_train_sample_per_sec: 793.7332128828753
avg_episode_per_sec: 4.588053253658239
collect_time: 1.0897868275642397
reward_mean: 1449.5999755859375
reward_std: 437.28643798828125
reward_max: 1913.0
reward_min: 633.0
total_envstep_count: 1429676
total_train_sample_count: 1429650
total_episode_count: 9614
total_duration: 1810.0709467061913
[2024-11-19 23:31:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 584
train_sample_count: 584
avg_envstep_per_episode: 146.0
avg_sample_per_episode: 146.0
avg_envstep_per_sec: 798.7173965104432
avg_train_sample_per_sec: 798.7173965104432
avg_episode_per_sec: 5.470667099386597
collect_time: 0.7311722551073347
reward_mean: 821.25
reward_std: 207.86097717285156
reward_max: 1035.0
reward_min: 606.0
total_envstep_count: 1430664
total_train_sample_count: 1430630
total_episode_count: 9618
total_duration: 1810.8021189612987
[2024-11-19 23:31:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1242
train_sample_count: 1242
avg_envstep_per_episode: 177.42857142857142
avg_sample_per_episode: 177.42857142857142
avg_envstep_per_sec: 799.9139301389606
avg_train_sample_per_sec: 799.9139301389606
avg_episode_per_sec: 4.50837158693456
collect_time: 1.5526670472962516
reward_mean: 1125.0
reward_std: 475.70880126953125
reward_max: 1833.0
reward_min: 630.0
total_envstep_count: 1431666
total_train_sample_count: 1431632
total_episode_count: 9625
total_duration: 1812.3547860085948
[2024-11-19 23:31:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1116
train_sample_count: 1116
avg_envstep_per_episode: 159.42857142857142
avg_sample_per_episode: 159.42857142857142
avg_envstep_per_sec: 795.9666348920391
avg_train_sample_per_sec: 795.9666348920391
avg_episode_per_sec: 4.992622261867629
collect_time: 1.402068819318499
reward_mean: 1068.0
reward_std: 382.6949462890625
reward_max: 1573.0
reward_min: 614.0
total_envstep_count: 1432707
total_train_sample_count: 1432652
total_episode_count: 9632
total_duration: 1813.7568548279132
[2024-11-19 23:32:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 935
train_sample_count: 935
avg_envstep_per_episode: 155.83333333333334
avg_sample_per_episode: 155.83333333333334
avg_envstep_per_sec: 792.0201219077029
avg_train_sample_per_sec: 792.0201219077029
avg_episode_per_sec: 5.082482065717879
collect_time: 1.180525562592915
reward_mean: 1040.1666259765625
reward_std: 385.7388916015625
reward_max: 1432.0
reward_min: 611.0
total_envstep_count: 1433693
total_train_sample_count: 1433659
total_episode_count: 9638
total_duration: 1814.9373803905062
[2024-11-19 23:32:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1446
train_sample_count: 1446
avg_envstep_per_episode: 160.66666666666666
avg_sample_per_episode: 160.66666666666666
avg_envstep_per_sec: 733.8632232662902
avg_train_sample_per_sec: 733.8632232662902
avg_episode_per_sec: 4.5676134228192335
collect_time: 1.970394419772284
reward_mean: 1135.4444580078125
reward_std: 385.8160705566406
reward_max: 1704.0
reward_min: 617.0
total_envstep_count: 1434700
total_train_sample_count: 1434661
total_episode_count: 9647
total_duration: 1816.9077748102784
[2024-11-19 23:32:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 863
train_sample_count: 863
avg_envstep_per_episode: 143.83333333333334
avg_sample_per_episode: 143.83333333333334
avg_envstep_per_sec: 698.7382945740525
avg_train_sample_per_sec: 698.7382945740525
avg_episode_per_sec: 4.857971920561199
collect_time: 1.2350833018620808
reward_mean: 1108.5
reward_std: 349.9436950683594
reward_max: 1434.0
reward_min: 654.0
total_envstep_count: 1435695
total_train_sample_count: 1435656
total_episode_count: 9653
total_duration: 1818.1428581121404
[2024-11-19 23:32:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1061
train_sample_count: 1061
avg_envstep_per_episode: 88.41666666666667
avg_sample_per_episode: 88.41666666666667
avg_envstep_per_sec: 792.8765380594293
avg_train_sample_per_sec: 792.8765380594293
avg_episode_per_sec: 8.96750090170891
collect_time: 1.3381654634362175
reward_mean: 773.9166870117188
reward_std: 411.1578063964844
reward_max: 1438.0
reward_min: 237.0
total_envstep_count: 1436707
total_train_sample_count: 1436657
total_episode_count: 9665
total_duration: 1819.4810235755767
[2024-11-19 23:32:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 860
train_sample_count: 860
avg_envstep_per_episode: 95.55555555555556
avg_sample_per_episode: 95.55555555555556
avg_envstep_per_sec: 793.1815969986984
avg_train_sample_per_sec: 793.1815969986984
avg_episode_per_sec: 8.300737643009635
collect_time: 1.0842409900256564
reward_mean: 823.4444580078125
reward_std: 500.01336669921875
reward_max: 1701.0
reward_min: 251.0
total_envstep_count: 1437716
total_train_sample_count: 1437673
total_episode_count: 9674
total_duration: 1820.5652645656023
[2024-11-19 23:32:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1113
train_sample_count: 1113
avg_envstep_per_episode: 139.125
avg_sample_per_episode: 139.125
avg_envstep_per_sec: 801.4090377759468
avg_train_sample_per_sec: 801.4090377759468
avg_episode_per_sec: 5.760352472783086
collect_time: 1.3888039035456523
reward_mean: 783.0
reward_std: 342.1114501953125
reward_max: 1674.0
reward_min: 608.0
total_envstep_count: 1438717
total_train_sample_count: 1438678
total_episode_count: 9682
total_duration: 1821.954068469148
[2024-11-19 23:32:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1084
train_sample_count: 1084
avg_envstep_per_episode: 135.5
avg_sample_per_episode: 135.5
avg_envstep_per_sec: 795.3059279763733
avg_train_sample_per_sec: 795.3059279763733
avg_episode_per_sec: 5.869416442630061
collect_time: 1.362997510603496
reward_mean: 966.25
reward_std: 447.3208312988281
reward_max: 1584.0
reward_min: 251.0
total_envstep_count: 1439742
total_train_sample_count: 1439702
total_episode_count: 9690
total_duration: 1823.3170659797515
[2024-11-19 23:32:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1140
train_sample_count: 1140
avg_envstep_per_episode: 142.5
avg_sample_per_episode: 142.5
avg_envstep_per_sec: 792.7999171185855
avg_train_sample_per_sec: 792.7999171185855
avg_episode_per_sec: 5.563508190305863
collect_time: 1.4379416235855647
reward_mean: 991.375
reward_std: 346.7203369140625
reward_max: 1438.0
reward_min: 613.0
total_envstep_count: 1440760
total_train_sample_count: 1440722
total_episode_count: 9698
total_duration: 1824.7550076033372
[2024-11-19 23:32:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 566
train_sample_count: 566
avg_envstep_per_episode: 113.2
avg_sample_per_episode: 113.2
avg_envstep_per_sec: 789.1281963029602
avg_train_sample_per_sec: 789.1281963029602
avg_episode_per_sec: 6.971097140485514
collect_time: 0.7172472136361259
reward_mean: 804.2000122070312
reward_std: 192.66281127929688
reward_max: 1041.0
reward_min: 634.0
total_envstep_count: 1441764
total_train_sample_count: 1441732
total_episode_count: 9703
total_duration: 1825.4722548169732
[2024-11-19 23:32:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1412
train_sample_count: 1412
avg_envstep_per_episode: 156.88888888888889
avg_sample_per_episode: 156.88888888888889
avg_envstep_per_sec: 794.8884994918832
avg_train_sample_per_sec: 794.8884994918832
avg_episode_per_sec: 5.066569755968094
collect_time: 1.7763497659138272
reward_mean: 1114.22216796875
reward_std: 610.85400390625
reward_max: 1919.0
reward_min: 241.0
total_envstep_count: 1442796
total_train_sample_count: 1442748
total_episode_count: 9712
total_duration: 1827.248604582887
[2024-11-19 23:32:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1024
train_sample_count: 1024
avg_envstep_per_episode: 146.28571428571428
avg_sample_per_episode: 146.28571428571428
avg_envstep_per_sec: 789.5685856118662
avg_train_sample_per_sec: 789.5685856118662
avg_episode_per_sec: 5.3974415032061165
collect_time: 1.29691076704434
reward_mean: 1021.5714111328125
reward_std: 323.2906188964844
reward_max: 1699.0
reward_min: 652.0
total_envstep_count: 1443813
total_train_sample_count: 1443772
total_episode_count: 9719
total_duration: 1828.5455153499315
[2024-11-19 23:32:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 990
train_sample_count: 990
avg_envstep_per_episode: 110.0
avg_sample_per_episode: 110.0
avg_envstep_per_sec: 795.1471440096558
avg_train_sample_per_sec: 795.1471440096558
avg_episode_per_sec: 7.22861040008778
collect_time: 1.2450525760650635
reward_mean: 794.7777709960938
reward_std: 359.38800048828125
reward_max: 1574.0
reward_min: 244.0
total_envstep_count: 1444805
total_train_sample_count: 1444774
total_episode_count: 9728
total_duration: 1829.7905679259966
[2024-11-19 23:32:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 627
train_sample_count: 627
avg_envstep_per_episode: 125.4
avg_sample_per_episode: 125.4
avg_envstep_per_sec: 799.4850718271616
avg_train_sample_per_sec: 799.4850718271616
avg_episode_per_sec: 6.375479041683905
collect_time: 0.7842547936098916
reward_mean: 627.4000244140625
reward_std: 457.56341552734375
reward_max: 1420.0
reward_min: 146.0
total_envstep_count: 1445809
total_train_sample_count: 1445773
total_episode_count: 9733
total_duration: 1830.5748227196066
[2024-11-19 23:32:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 860
train_sample_count: 860
avg_envstep_per_episode: 172.0
avg_sample_per_episode: 172.0
avg_envstep_per_sec: 809.702491926512
avg_train_sample_per_sec: 809.702491926512
avg_episode_per_sec: 4.707572627479721
collect_time: 1.0621185047285897
reward_mean: 791.0
reward_std: 489.53448486328125
reward_max: 1691.0
reward_min: 214.0
total_envstep_count: 1446796
total_train_sample_count: 1446753
total_episode_count: 9738
total_duration: 1831.6369412243353
[2024-11-19 23:32:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1082
train_sample_count: 1082
avg_envstep_per_episode: 154.57142857142858
avg_sample_per_episode: 154.57142857142858
avg_envstep_per_sec: 796.5406674309896
avg_train_sample_per_sec: 796.5406674309896
avg_episode_per_sec: 5.153220584119157
collect_time: 1.3583738335541315
reward_mean: 921.8571166992188
reward_std: 500.7050476074219
reward_max: 1670.0
reward_min: 248.0
total_envstep_count: 1447782
total_train_sample_count: 1447763
total_episode_count: 9745
total_duration: 1832.9953150578895
[2024-11-19 23:32:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 972
train_sample_count: 972
avg_envstep_per_episode: 162.0
avg_sample_per_episode: 162.0
avg_envstep_per_sec: 798.21041257891
avg_train_sample_per_sec: 798.21041257891
avg_episode_per_sec: 4.927224769005617
collect_time: 1.2177240295069558
reward_mean: 1092.8333740234375
reward_std: 296.55322265625
reward_max: 1425.0
reward_min: 611.0
total_envstep_count: 1448784
total_train_sample_count: 1448747
total_episode_count: 9751
total_duration: 1834.2130390873965
[2024-11-19 23:32:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1018
train_sample_count: 1018
avg_envstep_per_episode: 113.11111111111111
avg_sample_per_episode: 113.11111111111111
avg_envstep_per_sec: 794.5256490472129
avg_train_sample_per_sec: 794.5256490472129
avg_episode_per_sec: 7.024293557391863
collect_time: 1.2812676358790622
reward_mean: 958.0
reward_std: 391.7822570800781
reward_max: 1564.0
reward_min: 608.0
total_envstep_count: 1449791
total_train_sample_count: 1449753
total_episode_count: 9760
total_duration: 1835.4943067232755
[2024-11-19 23:33:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 456
train_sample_count: 456
avg_envstep_per_episode: 114.0
avg_sample_per_episode: 114.0
avg_envstep_per_sec: 796.1568536229418
avg_train_sample_per_sec: 796.1568536229418
avg_episode_per_sec: 6.983832049324051
collect_time: 0.5727514596212477
reward_mean: 772.0
reward_std: 177.53309631347656
reward_max: 1046.0
reward_min: 608.0
total_envstep_count: 1450756
total_train_sample_count: 1450725
total_episode_count: 9764
total_duration: 1836.0670581828967
[2024-11-19 23:33:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1557
train_sample_count: 1557
avg_envstep_per_episode: 311.4
avg_sample_per_episode: 311.4
avg_envstep_per_sec: 799.1286371647296
avg_train_sample_per_sec: 799.1286371647296
avg_episode_per_sec: 2.5662448206959847
collect_time: 1.9483721738769892
reward_mean: 1244.199951171875
reward_std: 318.4219970703125
reward_max: 1633.0
reward_min: 815.0
total_envstep_count: 1451736
total_train_sample_count: 1451706
total_episode_count: 9769
total_duration: 1838.0154303567738
[2024-11-19 23:33:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1262
train_sample_count: 1262
avg_envstep_per_episode: 180.28571428571428
avg_sample_per_episode: 180.28571428571428
avg_envstep_per_sec: 796.2302951552392
avg_train_sample_per_sec: 796.2302951552392
avg_episode_per_sec: 4.416491336043324
collect_time: 1.5849685796669553
reward_mean: 1247.4285888671875
reward_std: 274.7814025878906
reward_max: 1429.0
reward_min: 654.0
total_envstep_count: 1452746
total_train_sample_count: 1452692
total_episode_count: 9776
total_duration: 1839.6003989364408
[2024-11-19 23:33:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 703
train_sample_count: 703
avg_envstep_per_episode: 140.6
avg_sample_per_episode: 140.6
avg_envstep_per_sec: 796.7472399403708
avg_train_sample_per_sec: 796.7472399403708
avg_episode_per_sec: 5.666765575678314
collect_time: 0.8823375403881073
reward_mean: 1015.0
reward_std: 322.2738037109375
reward_max: 1415.0
reward_min: 654.0
total_envstep_count: 1453717
total_train_sample_count: 1453695
total_episode_count: 9781
total_duration: 1840.482736476829
[2024-11-19 23:33:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 488
train_sample_count: 488
avg_envstep_per_episode: 122.0
avg_sample_per_episode: 122.0
avg_envstep_per_sec: 810.235770321344
avg_train_sample_per_sec: 810.235770321344
avg_episode_per_sec: 6.641276805912656
collect_time: 0.6022938234465463
reward_mean: 747.75
reward_std: 335.7747497558594
reward_max: 1063.0
reward_min: 247.0
total_envstep_count: 1454737
total_train_sample_count: 1454687
total_episode_count: 9785
total_duration: 1841.0850303002755
[2024-11-19 23:33:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1943
train_sample_count: 1943
avg_envstep_per_episode: 176.63636363636363
avg_sample_per_episode: 176.63636363636363
avg_envstep_per_sec: 793.8864925101637
avg_train_sample_per_sec: 793.8864925101637
avg_episode_per_sec: 4.4944680481790025
collect_time: 2.4474531539848874
reward_mean: 965.5454711914062
reward_std: 348.140869140625
reward_max: 1587.0
reward_min: 608.0
total_envstep_count: 1455783
total_train_sample_count: 1455730
total_episode_count: 9796
total_duration: 1843.5324834542605
[2024-11-19 23:33:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 638
train_sample_count: 638
avg_envstep_per_episode: 127.6
avg_sample_per_episode: 127.6
avg_envstep_per_sec: 793.8816242996306
avg_train_sample_per_sec: 793.8816242996306
avg_episode_per_sec: 6.2216428236648165
collect_time: 0.803646262202944
reward_mean: 927.0
reward_std: 362.1800842285156
reward_max: 1587.0
reward_min: 617.0
total_envstep_count: 1456746
total_train_sample_count: 1456716
total_episode_count: 9801
total_duration: 1844.3361297164633
[2024-11-19 23:33:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 795
train_sample_count: 795
avg_envstep_per_episode: 198.75
avg_sample_per_episode: 198.75
avg_envstep_per_sec: 804.6206906340575
avg_train_sample_per_sec: 804.6206906340575
avg_episode_per_sec: 4.04840599061161
collect_time: 0.9880431975637164
reward_mean: 1028.5
reward_std: 420.2347412109375
reward_max: 1557.0
reward_min: 588.0
total_envstep_count: 1457726
total_train_sample_count: 1457691
total_episode_count: 9805
total_duration: 1845.324172914027
[2024-11-19 23:33:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1044
train_sample_count: 1044
avg_envstep_per_episode: 174.0
avg_sample_per_episode: 174.0
avg_envstep_per_sec: 804.8797632225088
avg_train_sample_per_sec: 804.8797632225088
avg_episode_per_sec: 4.625745765646602
collect_time: 1.297088146209717
reward_mean: 800.6666870117188
reward_std: 326.2757873535156
reward_max: 1298.0
reward_min: 251.0
total_envstep_count: 1458744
total_train_sample_count: 1458699
total_episode_count: 9811
total_duration: 1846.6212610602367
[2024-11-19 23:33:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1097
train_sample_count: 1097
avg_envstep_per_episode: 121.88888888888889
avg_sample_per_episode: 121.88888888888889
avg_envstep_per_sec: 805.0251218486925
avg_train_sample_per_sec: 805.0251218486925
avg_episode_per_sec: 6.604581674237221
collect_time: 1.3626903934138161
reward_mean: 769.5555419921875
reward_std: 402.1089172363281
reward_max: 1435.0
reward_min: 232.0
total_envstep_count: 1459753
total_train_sample_count: 1459712
total_episode_count: 9820
total_duration: 1847.9839514536507
[2024-11-19 23:33:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 427
train_sample_count: 427
avg_envstep_per_episode: 106.75
avg_sample_per_episode: 106.75
avg_envstep_per_sec: 805.0302197414977
avg_train_sample_per_sec: 805.0302197414977
avg_episode_per_sec: 7.541266695470704
collect_time: 0.5304148708071027
reward_mean: 616.75
reward_std: 314.81292724609375
reward_max: 1046.0
reward_min: 157.0
total_envstep_count: 1460757
total_train_sample_count: 1460727
total_episode_count: 9824
total_duration: 1848.5143663244578
[2024-11-19 23:33:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1070
train_sample_count: 1070
avg_envstep_per_episode: 152.85714285714286
avg_sample_per_episode: 152.85714285714286
avg_envstep_per_sec: 804.0666745334163
avg_train_sample_per_sec: 804.0666745334163
avg_episode_per_sec: 5.260249272648517
collect_time: 1.3307354152202608
reward_mean: 1018.7142944335938
reward_std: 320.0605773925781
reward_max: 1435.0
reward_min: 604.0
total_envstep_count: 1461774
total_train_sample_count: 1461725
total_episode_count: 9831
total_duration: 1849.845101739678
[2024-11-19 23:33:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 823
train_sample_count: 823
avg_envstep_per_episode: 164.6
avg_sample_per_episode: 164.6
avg_envstep_per_sec: 797.6229460476247
avg_train_sample_per_sec: 797.6229460476247
avg_episode_per_sec: 4.845825917664792
collect_time: 1.0318158524377006
reward_mean: 883.2000122070312
reward_std: 350.6225280761719
reward_max: 1561.0
reward_min: 592.0
total_envstep_count: 1462778
total_train_sample_count: 1462740
total_episode_count: 9836
total_duration: 1850.8769175921157
[2024-11-19 23:33:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 745
train_sample_count: 745
avg_envstep_per_episode: 248.33333333333334
avg_sample_per_episode: 248.33333333333334
avg_envstep_per_sec: 804.8986790247532
avg_train_sample_per_sec: 804.8986790247532
avg_episode_per_sec: 3.241202734327865
collect_time: 0.9255823365279606
reward_mean: 1407.0
reward_std: 329.37921142578125
reward_max: 1843.0
reward_min: 1047.0
total_envstep_count: 1463767
total_train_sample_count: 1463725
total_episode_count: 9839
total_duration: 1851.8024999286436
[2024-11-19 23:33:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 353
train_sample_count: 353
avg_envstep_per_episode: 176.5
avg_sample_per_episode: 176.5
avg_envstep_per_sec: 803.6032286835434
avg_train_sample_per_sec: 803.6032286835434
avg_episode_per_sec: 4.552992797073901
collect_time: 0.4392715053898948
reward_mean: 593.5
reward_std: 7.5
reward_max: 601.0
reward_min: 586.0
total_envstep_count: 1464750
total_train_sample_count: 1464702
total_episode_count: 9841
total_duration: 1852.2417714340334
[2024-11-19 23:33:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1342
train_sample_count: 1342
avg_envstep_per_episode: 191.71428571428572
avg_sample_per_episode: 191.71428571428572
avg_envstep_per_sec: 798.489541910777
avg_train_sample_per_sec: 798.489541910777
avg_episode_per_sec: 4.164997610562921
collect_time: 1.6806732331003462
reward_mean: 1032.7142333984375
reward_std: 484.1510314941406
reward_max: 1699.0
reward_min: 240.0
total_envstep_count: 1465752
total_train_sample_count: 1465732
total_episode_count: 9848
total_duration: 1853.9224446671337
[2024-11-19 23:34:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1167
train_sample_count: 1167
avg_envstep_per_episode: 194.5
avg_sample_per_episode: 194.5
avg_envstep_per_sec: 796.5891400415827
avg_train_sample_per_sec: 796.5891400415827
avg_episode_per_sec: 4.095573984789628
collect_time: 1.4649961207594187
reward_mean: 973.6666870117188
reward_std: 392.4061279296875
reward_max: 1576.0
reward_min: 573.0
total_envstep_count: 1466764
total_train_sample_count: 1466731
total_episode_count: 9854
total_duration: 1855.3874407878932
[2024-11-19 23:34:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 536
train_sample_count: 536
avg_envstep_per_episode: 134.0
avg_sample_per_episode: 134.0
avg_envstep_per_sec: 793.4554943753003
avg_train_sample_per_sec: 793.4554943753003
avg_episode_per_sec: 5.921309659517166
collect_time: 0.6755262315273285
reward_mean: 937.0
reward_std: 337.8905029296875
reward_max: 1429.0
reward_min: 605.0
total_envstep_count: 1467753
total_train_sample_count: 1467711
total_episode_count: 9858
total_duration: 1856.0629670194205
[2024-11-19 23:34:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1154
train_sample_count: 1154
avg_envstep_per_episode: 164.85714285714286
avg_sample_per_episode: 164.85714285714286
avg_envstep_per_sec: 799.1589037238879
avg_train_sample_per_sec: 799.1589037238879
avg_episode_per_sec: 4.847584338013185
collect_time: 1.4440181979111264
reward_mean: 1003.2857055664062
reward_std: 366.803466796875
reward_max: 1674.0
reward_min: 635.0
total_envstep_count: 1468756
total_train_sample_count: 1468709
total_episode_count: 9865
total_duration: 1857.5069852173317
[2024-11-19 23:34:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 903
train_sample_count: 903
avg_envstep_per_episode: 180.6
avg_sample_per_episode: 180.6
avg_envstep_per_sec: 792.5929809760553
avg_train_sample_per_sec: 792.5929809760553
avg_episode_per_sec: 4.388665453909498
collect_time: 1.1392985071454729
reward_mean: 1197.5999755859375
reward_std: 348.86993408203125
reward_max: 1579.0
reward_min: 735.0
total_envstep_count: 1469730
total_train_sample_count: 1469684
total_episode_count: 9870
total_duration: 1858.6462837244771
[2024-11-19 23:34:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 843
train_sample_count: 843
avg_envstep_per_episode: 105.375
avg_sample_per_episode: 105.375
avg_envstep_per_sec: 799.1117802324976
avg_train_sample_per_sec: 799.1117802324976
avg_episode_per_sec: 7.583504438742564
collect_time: 1.0549212523869105
reward_mean: 700.75
reward_std: 279.24261474609375
reward_max: 1325.0
reward_min: 246.0
total_envstep_count: 1470715
total_train_sample_count: 1470683
total_episode_count: 9878
total_duration: 1859.7012049768641
[2024-11-19 23:34:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 2975
train_sample_count: 2975
avg_envstep_per_episode: 270.45454545454544
avg_sample_per_episode: 270.45454545454544
avg_envstep_per_sec: 801.2821008136935
avg_train_sample_per_sec: 801.2821008136935
avg_episode_per_sec: 2.962723734101052
collect_time: 3.7127997704914644
reward_mean: 753.6363525390625
reward_std: 292.8025207519531
reward_max: 1643.0
reward_min: 516.0
total_envstep_count: 1471753
total_train_sample_count: 1471726
total_episode_count: 9889
total_duration: 1863.4140047473556
[2024-11-19 23:34:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 676
train_sample_count: 676
avg_envstep_per_episode: 96.57142857142857
avg_sample_per_episode: 96.57142857142857
avg_envstep_per_sec: 582.1716197427182
avg_train_sample_per_sec: 582.1716197427182
avg_episode_per_sec: 6.028404346448265
collect_time: 1.1611696226256234
reward_mean: 616.2857055664062
reward_std: 328.7637939453125
reward_max: 1302.0
reward_min: 231.0
total_envstep_count: 1472733
total_train_sample_count: 1472702
total_episode_count: 9896
total_duration: 1864.5751743699814
[2024-11-19 23:34:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 593
train_sample_count: 593
avg_envstep_per_episode: 197.66666666666666
avg_sample_per_episode: 197.66666666666666
avg_envstep_per_sec: 819.6263697137294
avg_train_sample_per_sec: 819.6263697137294
avg_episode_per_sec: 4.146507772582105
collect_time: 0.7235003922666823
reward_mean: 1298.0
reward_std: 181.73057556152344
reward_max: 1428.0
reward_min: 1041.0
total_envstep_count: 1473691
total_train_sample_count: 1473667
total_episode_count: 9899
total_duration: 1865.298674762248
[2024-11-19 23:34:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1189
train_sample_count: 1189
avg_envstep_per_episode: 198.16666666666666
avg_sample_per_episode: 198.16666666666666
avg_envstep_per_sec: 803.6034077302153
avg_train_sample_per_sec: 803.6034077302153
avg_episode_per_sec: 4.05518961007678
collect_time: 1.4795855624335152
reward_mean: 1101.5
reward_std: 367.5027160644531
reward_max: 1578.0
reward_min: 628.0
total_envstep_count: 1474678
total_train_sample_count: 1474640
total_episode_count: 9905
total_duration: 1866.7782603246817
[2024-11-19 23:34:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 618
train_sample_count: 618
avg_envstep_per_episode: 123.6
avg_sample_per_episode: 123.6
avg_envstep_per_sec: 818.0321619109154
avg_train_sample_per_sec: 818.0321619109154
avg_episode_per_sec: 6.618383186981516
collect_time: 0.7554715190614973
reward_mean: 933.0
reward_std: 410.6370544433594
reward_max: 1691.0
reward_min: 624.0
total_envstep_count: 1475651
total_train_sample_count: 1475630
total_episode_count: 9910
total_duration: 1867.5337318437432
[2024-11-19 23:34:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1114
train_sample_count: 1114
avg_envstep_per_episode: 159.14285714285714
avg_sample_per_episode: 159.14285714285714
avg_envstep_per_sec: 800.3909036743569
avg_train_sample_per_sec: 800.3909036743569
avg_episode_per_sec: 5.029386288797575
collect_time: 1.3918199156011855
reward_mean: 1117.7142333984375
reward_std: 255.46803283691406
reward_max: 1433.0
reward_min: 612.0
total_envstep_count: 1476669
total_train_sample_count: 1476636
total_episode_count: 9917
total_duration: 1868.9255517593444
[2024-11-19 23:34:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 338
train_sample_count: 338
avg_envstep_per_episode: 112.66666666666667
avg_sample_per_episode: 112.66666666666667
avg_envstep_per_sec: 815.2782980558071
avg_train_sample_per_sec: 815.2782980558071
avg_episode_per_sec: 7.236197911737933
collect_time: 0.41458235893930706
reward_mean: 518.6666870117188
reward_std: 226.2820281982422
reward_max: 760.0
reward_min: 216.0
total_envstep_count: 1477642
total_train_sample_count: 1477610
total_episode_count: 9920
total_duration: 1869.3401341182837
[2024-11-19 23:34:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 305
train_sample_count: 305
avg_envstep_per_episode: 152.5
avg_sample_per_episode: 152.5
avg_envstep_per_sec: 811.4071617256758
avg_train_sample_per_sec: 811.4071617256758
avg_episode_per_sec: 5.3207026998404965
collect_time: 0.37589019962719505
reward_mean: 642.0
reward_std: 62.0
reward_max: 704.0
reward_min: 580.0
total_envstep_count: 1478632
total_train_sample_count: 1478599
total_episode_count: 9922
total_duration: 1869.716024317911
[2024-11-19 23:34:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 2097
train_sample_count: 2097
avg_envstep_per_episode: 209.7
avg_sample_per_episode: 209.7
avg_envstep_per_sec: 811.5399474811966
avg_train_sample_per_sec: 811.5399474811966
avg_episode_per_sec: 3.870004518269893
collect_time: 2.5839763113430565
reward_mean: 1014.0999755859375
reward_std: 413.3445129394531
reward_max: 1570.0
reward_min: 609.0
total_envstep_count: 1479688
total_train_sample_count: 1479652
total_episode_count: 9932
total_duration: 1872.300000629254
[2024-11-19 23:34:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2124
train_sample_count: 2124
avg_envstep_per_episode: 303.42857142857144
avg_sample_per_episode: 303.42857142857144
avg_envstep_per_sec: 801.7085304689574
avg_train_sample_per_sec: 801.7085304689574
avg_episode_per_sec: 2.642165590057769
collect_time: 2.6493418983050754
reward_mean: 1012.8571166992188
reward_std: 361.7076416015625
reward_max: 1499.0
reward_min: 637.0
total_envstep_count: 1480729
total_train_sample_count: 1480684
total_episode_count: 9939
total_duration: 1874.949342527559
[2024-11-19 23:34:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 287
train_sample_count: 287
avg_envstep_per_episode: 95.66666666666667
avg_sample_per_episode: 95.66666666666667
avg_envstep_per_sec: 801.2044310263122
avg_train_sample_per_sec: 801.2044310263122
avg_episode_per_sec: 8.374959209334273
collect_time: 0.358210699898856
reward_mean: 624.3333129882812
reward_std: 327.7004089355469
reward_max: 1035.0
reward_min: 233.0
total_envstep_count: 1481694
total_train_sample_count: 1481655
total_episode_count: 9942
total_duration: 1875.307553227458
[2024-11-19 23:35:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1237
train_sample_count: 1237
avg_envstep_per_episode: 176.71428571428572
avg_sample_per_episode: 176.71428571428572
avg_envstep_per_sec: 800.5252330333847
avg_train_sample_per_sec: 800.5252330333847
avg_episode_per_sec: 4.530053865184877
collect_time: 1.5452354890959605
reward_mean: 838.8571166992188
reward_std: 270.947265625
reward_max: 1339.0
reward_min: 568.0
total_envstep_count: 1482681
total_train_sample_count: 1482640
total_episode_count: 9949
total_duration: 1876.852788716554
[2024-11-19 23:35:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1173
train_sample_count: 1173
avg_envstep_per_episode: 167.57142857142858
avg_sample_per_episode: 167.57142857142858
avg_envstep_per_sec: 789.0817267804221
avg_train_sample_per_sec: 789.0817267804221
avg_episode_per_sec: 4.7089276107953575
collect_time: 1.4865380355290003
reward_mean: 1204.857177734375
reward_std: 440.35650634765625
reward_max: 1853.0
reward_min: 581.0
total_envstep_count: 1483658
total_train_sample_count: 1483609
total_episode_count: 9956
total_duration: 1878.339326752083
[2024-11-19 23:35:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 1478
train_sample_count: 1478
avg_envstep_per_episode: 113.6923076923077
avg_sample_per_episode: 113.6923076923077
avg_envstep_per_sec: 804.1555460192062
avg_train_sample_per_sec: 804.1555460192062
avg_episode_per_sec: 7.0730866699930175
collect_time: 1.8379528777939933
reward_mean: 816.6153564453125
reward_std: 276.84417724609375
reward_max: 1424.0
reward_min: 609.0
total_envstep_count: 1484665
total_train_sample_count: 1484643
total_episode_count: 9969
total_duration: 1880.177279629877
[2024-11-19 23:35:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 374
train_sample_count: 374
avg_envstep_per_episode: 124.66666666666667
avg_sample_per_episode: 124.66666666666667
avg_envstep_per_sec: 808.2400856320155
avg_train_sample_per_sec: 808.2400856320155
avg_episode_per_sec: 6.483209243037558
collect_time: 0.462733792407172
reward_mean: 895.6666870117188
reward_std: 382.2829284667969
reward_max: 1436.0
reward_min: 610.0
total_envstep_count: 1485646
total_train_sample_count: 1485605
total_episode_count: 9972
total_duration: 1880.640013422284
[2024-11-19 23:35:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1042
train_sample_count: 1042
avg_envstep_per_episode: 148.85714285714286
avg_sample_per_episode: 148.85714285714286
avg_envstep_per_sec: 794.266887592951
avg_train_sample_per_sec: 794.266887592951
avg_episode_per_sec: 5.335766039491993
collect_time: 1.3119015991687775
reward_mean: 1152.2857666015625
reward_std: 410.24615478515625
reward_max: 1702.0
reward_min: 624.0
total_envstep_count: 1486631
total_train_sample_count: 1486575
total_episode_count: 9979
total_duration: 1881.9519150214528
[2024-11-19 23:35:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 940
train_sample_count: 940
avg_envstep_per_episode: 134.28571428571428
avg_sample_per_episode: 134.28571428571428
avg_envstep_per_sec: 802.3305323470863
avg_train_sample_per_sec: 802.3305323470863
avg_episode_per_sec: 5.974801836627239
collect_time: 1.171586973326547
reward_mean: 863.2857055664062
reward_std: 259.8866271972656
reward_max: 1426.0
reward_min: 654.0
total_envstep_count: 1487625
total_train_sample_count: 1487599
total_episode_count: 9986
total_duration: 1883.1235019947794
[2024-11-19 23:35:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 990
train_sample_count: 990
avg_envstep_per_episode: 198.0
avg_sample_per_episode: 198.0
avg_envstep_per_sec: 803.251779303374
avg_train_sample_per_sec: 803.251779303374
avg_episode_per_sec: 4.056827168198859
collect_time: 1.2324902670724052
reward_mean: 1229.4000244140625
reward_std: 481.3570861816406
reward_max: 1686.0
reward_min: 633.0
total_envstep_count: 1488605
total_train_sample_count: 1488565
total_episode_count: 9991
total_duration: 1884.3559922618517
[2024-11-19 23:35:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1417
train_sample_count: 1417
avg_envstep_per_episode: 141.7
avg_sample_per_episode: 141.7
avg_envstep_per_sec: 797.9849329095379
avg_train_sample_per_sec: 797.9849329095379
avg_episode_per_sec: 5.631509759418051
collect_time: 1.7757227505956377
reward_mean: 1091.300048828125
reward_std: 403.635009765625
reward_max: 1704.0
reward_min: 606.0
total_envstep_count: 1489596
total_train_sample_count: 1489562
total_episode_count: 10001
total_duration: 1886.1317150124473
[2024-11-19 23:35:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 878
train_sample_count: 878
avg_envstep_per_episode: 125.42857142857143
avg_sample_per_episode: 125.42857142857143
avg_envstep_per_sec: 803.0184224398517
avg_train_sample_per_sec: 803.0184224398517
avg_episode_per_sec: 6.402196989839364
collect_time: 1.0933746667135331
reward_mean: 967.7142944335938
reward_std: 407.12359619140625
reward_max: 1695.0
reward_min: 638.0
total_envstep_count: 1490598
total_train_sample_count: 1490560
total_episode_count: 10008
total_duration: 1887.2250896791609
[2024-11-19 23:35:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 818
train_sample_count: 818
avg_envstep_per_episode: 136.33333333333334
avg_sample_per_episode: 136.33333333333334
avg_envstep_per_sec: 806.2173919633257
avg_train_sample_per_sec: 806.2173919633257
avg_episode_per_sec: 5.913575002175983
collect_time: 1.0146146785645258
reward_mean: 1108.8333740234375
reward_std: 349.1501159667969
reward_max: 1433.0
reward_min: 653.0
total_envstep_count: 1491586
total_train_sample_count: 1491558
total_episode_count: 10014
total_duration: 1888.2397043577255
[2024-11-19 23:35:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1156
train_sample_count: 1156
avg_envstep_per_episode: 165.14285714285714
avg_sample_per_episode: 165.14285714285714
avg_envstep_per_sec: 801.4405436721185
avg_train_sample_per_sec: 801.4405436721185
avg_episode_per_sec: 4.853013672755043
collect_time: 1.4424026949065072
reward_mean: 1160.2857666015625
reward_std: 401.4554748535156
reward_max: 1695.0
reward_min: 585.0
total_envstep_count: 1492588
total_train_sample_count: 1492546
total_episode_count: 10021
total_duration: 1889.682107052632
[2024-11-19 23:35:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 712
train_sample_count: 712
avg_envstep_per_episode: 142.4
avg_sample_per_episode: 142.4
avg_envstep_per_sec: 801.2969814459162
avg_train_sample_per_sec: 801.2969814459162
avg_episode_per_sec: 5.627085543861772
collect_time: 0.8885594436100551
reward_mean: 861.0
reward_std: 84.0
reward_max: 1029.0
reward_min: 819.0
total_envstep_count: 1493552
total_train_sample_count: 1493522
total_episode_count: 10026
total_duration: 1890.5706664962422
[2024-11-19 23:35:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 988
train_sample_count: 988
avg_envstep_per_episode: 141.14285714285714
avg_sample_per_episode: 141.14285714285714
avg_envstep_per_sec: 803.5402729222745
avg_train_sample_per_sec: 803.5402729222745
avg_episode_per_sec: 5.693099099651743
collect_time: 1.2295587829181127
reward_mean: 936.1428833007812
reward_std: 384.5098876953125
reward_max: 1581.0
reward_min: 600.0
total_envstep_count: 1494569
total_train_sample_count: 1494534
total_episode_count: 10033
total_duration: 1891.8002252791603
[2024-11-19 23:35:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 970
train_sample_count: 970
avg_envstep_per_episode: 138.57142857142858
avg_sample_per_episode: 138.57142857142858
avg_envstep_per_sec: 804.1462107472994
avg_train_sample_per_sec: 804.1462107472994
avg_episode_per_sec: 5.803116984774325
collect_time: 1.2062483004161288
reward_mean: 926.7142944335938
reward_std: 310.13763427734375
reward_max: 1415.0
reward_min: 627.0
total_envstep_count: 1495546
total_train_sample_count: 1495516
total_episode_count: 10040
total_duration: 1893.0064735795763
[2024-11-19 23:35:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 795
train_sample_count: 795
avg_envstep_per_episode: 132.5
avg_sample_per_episode: 132.5
avg_envstep_per_sec: 796.5923162529923
avg_train_sample_per_sec: 796.5923162529923
avg_episode_per_sec: 6.012017481154659
collect_time: 0.9980010901178632
reward_mean: 833.0
reward_std: 311.82366943359375
reward_max: 1428.0
reward_min: 609.0
total_envstep_count: 1496566
total_train_sample_count: 1496527
total_episode_count: 10046
total_duration: 1894.0044746696942
[2024-11-19 23:35:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 516
train_sample_count: 516
avg_envstep_per_episode: 129.0
avg_sample_per_episode: 129.0
avg_envstep_per_sec: 802.0726084300957
avg_train_sample_per_sec: 802.0726084300957
avg_episode_per_sec: 6.217617119613145
collect_time: 0.6433332775320325
reward_mean: 852.0
reward_std: 398.28570556640625
reward_max: 1541.0
reward_min: 601.0
total_envstep_count: 1497563
total_train_sample_count: 1497535
total_episode_count: 10050
total_duration: 1894.6478079472263
[2024-11-19 23:35:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 792
train_sample_count: 792
avg_envstep_per_episode: 198.0
avg_sample_per_episode: 198.0
avg_envstep_per_sec: 807.7365184948318
avg_train_sample_per_sec: 807.7365184948318
avg_episode_per_sec: 4.079477366135515
collect_time: 0.9805177577904292
reward_mean: 1331.5
reward_std: 404.2156066894531
reward_max: 1691.0
reward_min: 652.0
total_envstep_count: 1498560
total_train_sample_count: 1498507
total_episode_count: 10054
total_duration: 1895.6283257050168
[2024-11-19 23:36:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 600
train_sample_count: 600
avg_envstep_per_episode: 150.0
avg_sample_per_episode: 150.0
avg_envstep_per_sec: 802.419880280373
avg_train_sample_per_sec: 802.419880280373
avg_episode_per_sec: 5.3494658685358205
collect_time: 0.7477382038320814
reward_mean: 925.0
reward_std: 328.087646484375
reward_max: 1415.0
reward_min: 626.0
total_envstep_count: 1499532
total_train_sample_count: 1499491
total_episode_count: 10058
total_duration: 1896.376063908849
[2024-11-19 23:36:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 939
train_sample_count: 939
avg_envstep_per_episode: 156.5
avg_sample_per_episode: 156.5
avg_envstep_per_sec: 805.3146747602235
avg_train_sample_per_sec: 805.3146747602235
avg_episode_per_sec: 5.1457806693944
collect_time: 1.1660038360527583
reward_mean: 1127.8333740234375
reward_std: 376.1087646484375
reward_max: 1580.0
reward_min: 651.0
total_envstep_count: 1500511
total_train_sample_count: 1500478
total_episode_count: 10064
total_duration: 1897.5420677449017
[2024-11-19 23:36:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 649
train_sample_count: 649
avg_envstep_per_episode: 129.8
avg_sample_per_episode: 129.8
avg_envstep_per_sec: 816.7770795903982
avg_train_sample_per_sec: 816.7770795903982
avg_episode_per_sec: 6.29258150685977
collect_time: 0.7945864498615265
reward_mean: 952.5999755859375
reward_std: 303.37078857421875
reward_max: 1436.0
reward_min: 603.0
total_envstep_count: 1501483
total_train_sample_count: 1501451
total_episode_count: 10069
total_duration: 1898.3366541947632
[2024-11-19 23:36:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 132
train_sample_count: 132
avg_envstep_per_episode: 132.0
avg_sample_per_episode: 132.0
avg_envstep_per_sec: 785.5306840378336
avg_train_sample_per_sec: 785.5306840378336
avg_episode_per_sec: 5.950990030589648
collect_time: 0.1680392665522439
reward_mean: 1042.0
reward_std: 0.0
reward_max: 1042.0
reward_min: 1042.0
total_envstep_count: 1502442
total_train_sample_count: 1502411
total_episode_count: 10070
total_duration: 1898.5046934613156
[2024-11-19 23:36:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1127
train_sample_count: 1127
avg_envstep_per_episode: 281.75
avg_sample_per_episode: 281.75
avg_envstep_per_sec: 809.4664975767905
avg_train_sample_per_sec: 809.4664975767905
avg_episode_per_sec: 2.8729955548422024
collect_time: 1.3922750396387917
reward_mean: 1567.5
reward_std: 127.72920227050781
reward_max: 1767.0
reward_min: 1421.0
total_envstep_count: 1503455
total_train_sample_count: 1503406
total_episode_count: 10074
total_duration: 1899.8969685009545
[2024-11-19 23:36:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 648
train_sample_count: 648
avg_envstep_per_episode: 129.6
avg_sample_per_episode: 129.6
avg_envstep_per_sec: 808.3410041607789
avg_train_sample_per_sec: 808.3410041607789
avg_episode_per_sec: 6.237199106178849
collect_time: 0.8016418772084373
reward_mean: 881.4000244140625
reward_std: 486.65618896484375
reward_max: 1571.0
reward_min: 249.0
total_envstep_count: 1504443
total_train_sample_count: 1504390
total_episode_count: 10079
total_duration: 1900.6986103781628
[2024-11-19 23:36:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 164
train_sample_count: 164
avg_envstep_per_episode: 82.0
avg_sample_per_episode: 82.0
avg_envstep_per_sec: 807.9707514936836
avg_train_sample_per_sec: 807.9707514936836
avg_episode_per_sec: 9.853301847483944
collect_time: 0.20297764454569134
reward_mean: 629.0
reward_std: 20.0
reward_max: 649.0
reward_min: 609.0
total_envstep_count: 1505402
total_train_sample_count: 1505358
total_episode_count: 10081
total_duration: 1900.9015880227084
[2024-11-19 23:36:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 891
train_sample_count: 891
avg_envstep_per_episode: 222.75
avg_sample_per_episode: 222.75
avg_envstep_per_sec: 811.9917054461696
avg_train_sample_per_sec: 811.9917054461696
avg_episode_per_sec: 3.645305074954746
collect_time: 1.0973018492971147
reward_mean: 1295.0
reward_std: 192.59413146972656
reward_max: 1577.0
reward_min: 1033.0
total_envstep_count: 1506382
total_train_sample_count: 1506333
total_episode_count: 10085
total_duration: 1901.9988898720055
[2024-11-19 23:36:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 521
train_sample_count: 521
avg_envstep_per_episode: 173.66666666666666
avg_sample_per_episode: 173.66666666666666
avg_envstep_per_sec: 806.3598972154654
avg_train_sample_per_sec: 806.3598972154654
avg_episode_per_sec: 4.643147200856807
collect_time: 0.6461134808404105
reward_mean: 1201.3333740234375
reward_std: 803.9275512695312
reward_max: 2338.0
reward_min: 612.0
total_envstep_count: 1507363
total_train_sample_count: 1507322
total_episode_count: 10088
total_duration: 1902.6450033528458
[2024-11-19 23:36:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2984
train_sample_count: 2984
avg_envstep_per_episode: 373.0
avg_sample_per_episode: 373.0
avg_envstep_per_sec: 807.7597291993895
avg_train_sample_per_sec: 807.7597291993895
avg_episode_per_sec: 2.165575681499704
collect_time: 3.6941678225994123
reward_mean: 1010.0
reward_std: 355.863037109375
reward_max: 1437.0
reward_min: 600.0
total_envstep_count: 1508366
total_train_sample_count: 1508326
total_episode_count: 10096
total_duration: 1906.3391711754452
[2024-11-19 23:36:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 320
train_sample_count: 320
avg_envstep_per_episode: 106.66666666666667
avg_sample_per_episode: 106.66666666666667
avg_envstep_per_sec: 801.8220616855464
avg_train_sample_per_sec: 801.8220616855464
avg_episode_per_sec: 7.517081828301998
collect_time: 0.39909103938511437
reward_mean: 667.6666870117188
reward_std: 38.17794418334961
reward_max: 720.0
reward_min: 630.0
total_envstep_count: 1509332
total_train_sample_count: 1509306
total_episode_count: 10099
total_duration: 1906.7382622148305
[2024-11-19 23:36:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 787
train_sample_count: 787
avg_envstep_per_episode: 196.75
avg_sample_per_episode: 196.75
avg_envstep_per_sec: 801.65040791865
avg_train_sample_per_sec: 801.65040791865
avg_episode_per_sec: 4.0744620478711555
collect_time: 0.981724692242486
reward_mean: 1404.0
reward_std: 44.64862823486328
reward_max: 1434.0
reward_min: 1327.0
total_envstep_count: 1510344
total_train_sample_count: 1510297
total_episode_count: 10103
total_duration: 1907.719986907073
[2024-11-19 23:36:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 908
train_sample_count: 908
avg_envstep_per_episode: 151.33333333333334
avg_sample_per_episode: 151.33333333333334
avg_envstep_per_sec: 796.7945066332613
avg_train_sample_per_sec: 796.7945066332613
avg_episode_per_sec: 5.265161938105251
collect_time: 1.1395660894257682
reward_mean: 900.0
reward_std: 383.1335754394531
reward_max: 1452.0
reward_min: 604.0
total_envstep_count: 1511339
total_train_sample_count: 1511289
total_episode_count: 10109
total_duration: 1908.8595529964987
[2024-11-19 23:36:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2556
train_sample_count: 2556
avg_envstep_per_episode: 511.2
avg_sample_per_episode: 511.2
avg_envstep_per_sec: 804.4280738982026
avg_train_sample_per_sec: 804.4280738982026
avg_episode_per_sec: 1.573607343306343
collect_time: 3.1774127270494197
reward_mean: 919.0
reward_std: 365.50677490234375
reward_max: 1474.0
reward_min: 605.0
total_envstep_count: 1512318
total_train_sample_count: 1512273
total_episode_count: 10114
total_duration: 1912.036965723548
[2024-11-19 23:36:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 959
train_sample_count: 959
avg_envstep_per_episode: 159.83333333333334
avg_sample_per_episode: 159.83333333333334
avg_envstep_per_sec: 800.3611144391748
avg_train_sample_per_sec: 800.3611144391748
avg_episode_per_sec: 5.007473083039676
collect_time: 1.198209136724472
reward_mean: 824.3333129882812
reward_std: 452.3396911621094
reward_max: 1479.0
reward_min: 141.0
total_envstep_count: 1513289
total_train_sample_count: 1513256
total_episode_count: 10120
total_duration: 1913.2351748602725
[2024-11-19 23:36:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 866
train_sample_count: 866
avg_envstep_per_episode: 173.2
avg_sample_per_episode: 173.2
avg_envstep_per_sec: 799.7337535484904
avg_train_sample_per_sec: 799.7337535484904
avg_episode_per_sec: 4.617400424644864
collect_time: 1.0828603846686229
reward_mean: 1307.0
reward_std: 354.297607421875
reward_max: 1582.0
reward_min: 623.0
total_envstep_count: 1514246
total_train_sample_count: 1514230
total_episode_count: 10125
total_duration: 1914.3180352449413
[2024-11-19 23:37:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 874
train_sample_count: 874
avg_envstep_per_episode: 145.66666666666666
avg_sample_per_episode: 145.66666666666666
avg_envstep_per_sec: 802.6703293657356
avg_train_sample_per_sec: 802.6703293657356
avg_episode_per_sec: 5.510322627224729
collect_time: 1.088865463222776
reward_mean: 707.6666870117188
reward_std: 353.708740234375
reward_max: 1422.0
reward_min: 239.0
total_envstep_count: 1515256
total_train_sample_count: 1515212
total_episode_count: 10131
total_duration: 1915.4069007081641
[2024-11-19 23:37:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 699
train_sample_count: 699
avg_envstep_per_episode: 139.8
avg_sample_per_episode: 139.8
avg_envstep_per_sec: 800.6489181363435
avg_train_sample_per_sec: 800.6489181363435
avg_episode_per_sec: 5.727102418714903
collect_time: 0.8730418341500419
reward_mean: 955.0
reward_std: 416.42816162109375
reward_max: 1725.0
reward_min: 584.0
total_envstep_count: 1516253
total_train_sample_count: 1516223
total_episode_count: 10136
total_duration: 1916.279942542314
[2024-11-19 23:37:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2843
train_sample_count: 2843
avg_envstep_per_episode: 473.8333333333333
avg_sample_per_episode: 473.8333333333333
avg_envstep_per_sec: 806.6497983487094
avg_train_sample_per_sec: 806.6497983487094
avg_episode_per_sec: 1.7023914140317469
collect_time: 3.5244538656302864
reward_mean: 985.6666870117188
reward_std: 321.818115234375
reward_max: 1538.0
reward_min: 650.0
total_envstep_count: 1517279
total_train_sample_count: 1517254
total_episode_count: 10142
total_duration: 1919.8043964079443
[2024-11-19 23:37:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1226
train_sample_count: 1226
avg_envstep_per_episode: 204.33333333333334
avg_sample_per_episode: 204.33333333333334
avg_envstep_per_sec: 799.1906615706921
avg_train_sample_per_sec: 799.1906615706921
avg_episode_per_sec: 3.9112104155172536
collect_time: 1.534051959003721
reward_mean: 1289.0
reward_std: 256.4832763671875
reward_max: 1434.0
reward_min: 722.0
total_envstep_count: 1518289
total_train_sample_count: 1518252
total_episode_count: 10148
total_duration: 1921.3384483669481
[2024-11-19 23:37:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 818
train_sample_count: 818
avg_envstep_per_episode: 136.33333333333334
avg_sample_per_episode: 136.33333333333334
avg_envstep_per_sec: 795.4625294778767
avg_train_sample_per_sec: 795.4625294778767
avg_episode_per_sec: 5.8346884802778245
collect_time: 1.0283325357096536
reward_mean: 931.5
reward_std: 444.20819091796875
reward_max: 1697.0
reward_min: 571.0
total_envstep_count: 1519268
total_train_sample_count: 1519238
total_episode_count: 10154
total_duration: 1922.3667809026579
[2024-11-19 23:37:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1242
train_sample_count: 1242
avg_envstep_per_episode: 177.42857142857142
avg_sample_per_episode: 177.42857142857142
avg_envstep_per_sec: 799.2682094348452
avg_train_sample_per_sec: 799.2682094348452
avg_episode_per_sec: 4.504732259294618
collect_time: 1.5539214313030243
reward_mean: 1325.142822265625
reward_std: 353.93316650390625
reward_max: 1687.0
reward_min: 749.0
total_envstep_count: 1520279
total_train_sample_count: 1520264
total_episode_count: 10161
total_duration: 1923.920702333961
[2024-11-19 23:37:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 530
train_sample_count: 530
avg_envstep_per_episode: 106.0
avg_sample_per_episode: 106.0
avg_envstep_per_sec: 812.1449842725491
avg_train_sample_per_sec: 812.1449842725491
avg_episode_per_sec: 7.66174513464669
collect_time: 0.6525928378105164
reward_mean: 784.5999755859375
reward_std: 326.4485168457031
reward_max: 1437.0
reward_min: 597.0
total_envstep_count: 1521298
total_train_sample_count: 1521250
total_episode_count: 10166
total_duration: 1924.5732951717714
[2024-11-19 23:37:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 974
train_sample_count: 974
avg_envstep_per_episode: 139.14285714285714
avg_sample_per_episode: 139.14285714285714
avg_envstep_per_sec: 802.1818384426439
avg_train_sample_per_sec: 802.1818384426439
avg_episode_per_sec: 5.76516721673358
collect_time: 1.2141885459423065
reward_mean: 885.8571166992188
reward_std: 380.6015625
reward_max: 1426.0
reward_min: 239.0
total_envstep_count: 1522262
total_train_sample_count: 1522224
total_episode_count: 10173
total_duration: 1925.7874837177137
[2024-11-19 23:37:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 619
train_sample_count: 619
avg_envstep_per_episode: 154.75
avg_sample_per_episode: 154.75
avg_envstep_per_sec: 799.8530133503626
avg_train_sample_per_sec: 799.8530133503626
avg_episode_per_sec: 5.168678600002344
collect_time: 0.7738921897751945
reward_mean: 771.5
reward_std: 170.13156127929688
reward_max: 1043.0
reward_min: 627.0
total_envstep_count: 1523242
total_train_sample_count: 1523215
total_episode_count: 10177
total_duration: 1926.5613759074888
[2024-11-19 23:37:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 797
train_sample_count: 797
avg_envstep_per_episode: 159.4
avg_sample_per_episode: 159.4
avg_envstep_per_sec: 807.0747177473316
avg_train_sample_per_sec: 807.0747177473316
avg_episode_per_sec: 5.063204000924289
collect_time: 0.9875169949872153
reward_mean: 1347.800048828125
reward_std: 564.2649536132812
reward_max: 1700.0
reward_min: 237.0
total_envstep_count: 1524261
total_train_sample_count: 1524228
total_episode_count: 10182
total_duration: 1927.548892902476
[2024-11-19 23:37:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1164
train_sample_count: 1164
avg_envstep_per_episode: 166.28571428571428
avg_sample_per_episode: 166.28571428571428
avg_envstep_per_sec: 799.8396419205013
avg_train_sample_per_sec: 799.8396419205013
avg_episode_per_sec: 4.810032210862121
collect_time: 1.4552917097296032
reward_mean: 1090.7142333984375
reward_std: 409.1746826171875
reward_max: 1571.0
reward_min: 612.0
total_envstep_count: 1525263
total_train_sample_count: 1525236
total_episode_count: 10189
total_duration: 1929.0041846122056
[2024-11-19 23:37:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 617
train_sample_count: 617
avg_envstep_per_episode: 123.4
avg_sample_per_episode: 123.4
avg_envstep_per_sec: 808.2477700830062
avg_train_sample_per_sec: 808.2477700830062
avg_episode_per_sec: 6.549819854805561
collect_time: 0.7633797739233289
reward_mean: 958.5999755859375
reward_std: 449.7890930175781
reward_max: 1580.0
reward_min: 586.0
total_envstep_count: 1526298
total_train_sample_count: 1526249
total_episode_count: 10194
total_duration: 1929.767564386129
[2024-11-19 23:38:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1118
train_sample_count: 1118
avg_envstep_per_episode: 223.6
avg_sample_per_episode: 223.6
avg_envstep_per_sec: 782.4114695711457
avg_train_sample_per_sec: 782.4114695711457
avg_episode_per_sec: 3.4991568406580758
collect_time: 1.4289156581674303
reward_mean: 1445.5999755859375
reward_std: 179.4130401611328
reward_max: 1795.0
reward_min: 1319.0
total_envstep_count: 1527256
total_train_sample_count: 1527223
total_episode_count: 10199
total_duration: 1931.1964800442963
[2024-11-19 23:38:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1008
train_sample_count: 1008
avg_envstep_per_episode: 144.0
avg_sample_per_episode: 144.0
avg_envstep_per_sec: 765.9784027738192
avg_train_sample_per_sec: 765.9784027738192
avg_episode_per_sec: 5.319294463707078
collect_time: 1.3159639963081906
reward_mean: 817.1428833007812
reward_std: 379.9460144042969
reward_max: 1419.0
reward_min: 248.0
total_envstep_count: 1528250
total_train_sample_count: 1528219
total_episode_count: 10206
total_duration: 1932.5124440406046
[2024-11-19 23:38:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 406
train_sample_count: 406
avg_envstep_per_episode: 101.5
avg_sample_per_episode: 101.5
avg_envstep_per_sec: 778.721790304436
avg_train_sample_per_sec: 778.721790304436
avg_episode_per_sec: 7.672135865068335
collect_time: 0.5213672007833209
reward_mean: 813.0
reward_std: 302.00909423828125
reward_max: 1336.0
reward_min: 633.0
total_envstep_count: 1529231
total_train_sample_count: 1529201
total_episode_count: 10210
total_duration: 1933.0338112413879
[2024-11-19 23:38:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1163
train_sample_count: 1163
avg_envstep_per_episode: 145.375
avg_sample_per_episode: 145.375
avg_envstep_per_sec: 798.382316404758
avg_train_sample_per_sec: 798.382316404758
avg_episode_per_sec: 5.491881798141069
collect_time: 1.456695590700422
reward_mean: 873.25
reward_std: 492.6679382324219
reward_max: 1534.0
reward_min: 235.0
total_envstep_count: 1530218
total_train_sample_count: 1530184
total_episode_count: 10218
total_duration: 1934.4905068320884
[2024-11-19 23:38:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 655
train_sample_count: 655
avg_envstep_per_episode: 131.0
avg_sample_per_episode: 131.0
avg_envstep_per_sec: 802.9050734786684
avg_train_sample_per_sec: 802.9050734786684
avg_episode_per_sec: 6.129046362432583
collect_time: 0.8157875963619777
reward_mean: 804.0
reward_std: 316.5912170410156
reward_max: 1429.0
reward_min: 604.0
total_envstep_count: 1531197
total_train_sample_count: 1531163
total_episode_count: 10223
total_duration: 1935.3062944284504
[2024-11-19 23:38:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 982
train_sample_count: 982
avg_envstep_per_episode: 163.66666666666666
avg_sample_per_episode: 163.66666666666666
avg_envstep_per_sec: 791.3090950433095
avg_train_sample_per_sec: 791.3090950433095
avg_episode_per_sec: 4.834882454439773
collect_time: 1.2409815660544805
reward_mean: 1010.0
reward_std: 360.3322448730469
reward_max: 1593.0
reward_min: 630.0
total_envstep_count: 1532192
total_train_sample_count: 1532157
total_episode_count: 10229
total_duration: 1936.5472759945048
[2024-11-19 23:38:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 2503
train_sample_count: 2503
avg_envstep_per_episode: 625.75
avg_sample_per_episode: 625.75
avg_envstep_per_sec: 794.70556777241
avg_train_sample_per_sec: 794.70556777241
avg_episode_per_sec: 1.2700049025527926
collect_time: 3.1495941409042905
reward_mean: 1216.75
reward_std: 374.6654357910156
reward_max: 1587.0
reward_min: 605.0
total_envstep_count: 1533180
total_train_sample_count: 1533136
total_episode_count: 10233
total_duration: 1939.6968701354092
[2024-11-19 23:38:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 890
train_sample_count: 890
avg_envstep_per_episode: 148.33333333333334
avg_sample_per_episode: 148.33333333333334
avg_envstep_per_sec: 800.9256814588724
avg_train_sample_per_sec: 800.9256814588724
avg_episode_per_sec: 5.39949897612723
collect_time: 1.1112142120088848
reward_mean: 1048.0
reward_std: 386.620849609375
reward_max: 1436.0
reward_min: 620.0
total_envstep_count: 1534192
total_train_sample_count: 1534134
total_episode_count: 10239
total_duration: 1940.8080843474181
[2024-11-19 23:38:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1091
train_sample_count: 1091
avg_envstep_per_episode: 272.75
avg_sample_per_episode: 272.75
avg_envstep_per_sec: 798.4656670372158
avg_train_sample_per_sec: 798.4656670372158
avg_episode_per_sec: 2.9274634905122485
collect_time: 1.3663705842835563
reward_mean: 1514.75
reward_std: 626.2457275390625
reward_max: 2341.0
reward_min: 594.0
total_envstep_count: 1535165
total_train_sample_count: 1535117
total_episode_count: 10243
total_duration: 1942.1744549317016
[2024-11-19 23:38:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 890
train_sample_count: 890
avg_envstep_per_episode: 148.33333333333334
avg_sample_per_episode: 148.33333333333334
avg_envstep_per_sec: 803.9169806062766
avg_train_sample_per_sec: 803.9169806062766
avg_episode_per_sec: 5.419665037795124
collect_time: 1.1070794888905116
reward_mean: 1117.8333740234375
reward_std: 350.6434326171875
reward_max: 1432.0
reward_min: 624.0
total_envstep_count: 1536137
total_train_sample_count: 1536103
total_episode_count: 10249
total_duration: 1943.2815344205922
[2024-11-19 23:38:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 958
train_sample_count: 958
avg_envstep_per_episode: 159.66666666666666
avg_sample_per_episode: 159.66666666666666
avg_envstep_per_sec: 797.2452517292365
avg_train_sample_per_sec: 797.2452517292365
avg_episode_per_sec: 4.9931852926674525
collect_time: 1.2016377619334628
reward_mean: 1232.1666259765625
reward_std: 327.5135498046875
reward_max: 1701.0
reward_min: 629.0
total_envstep_count: 1537115
total_train_sample_count: 1537085
total_episode_count: 10255
total_duration: 1944.4831721825255
[2024-11-19 23:39:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 374
train_sample_count: 374
avg_envstep_per_episode: 187.0
avg_sample_per_episode: 187.0
avg_envstep_per_sec: 802.9271054491396
avg_train_sample_per_sec: 802.9271054491396
avg_episode_per_sec: 4.293727836626416
collect_time: 0.46579570855413166
reward_mean: 1519.0
reward_std: 175.0
reward_max: 1694.0
reward_min: 1344.0
total_envstep_count: 1538097
total_train_sample_count: 1538059
total_episode_count: 10257
total_duration: 1944.9489678910797
[2024-11-19 23:39:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1101
train_sample_count: 1101
avg_envstep_per_episode: 183.5
avg_sample_per_episode: 183.5
avg_envstep_per_sec: 800.6045994968827
avg_train_sample_per_sec: 800.6045994968827
avg_episode_per_sec: 4.362967844669661
collect_time: 1.3752106853893824
reward_mean: 1171.3333740234375
reward_std: 427.58026123046875
reward_max: 1830.0
reward_min: 610.0
total_envstep_count: 1539099
total_train_sample_count: 1539040
total_episode_count: 10263
total_duration: 1946.3241785764692
[2024-11-19 23:39:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 423
train_sample_count: 423
avg_envstep_per_episode: 141.0
avg_sample_per_episode: 141.0
avg_envstep_per_sec: 803.3559012654357
avg_train_sample_per_sec: 803.3559012654357
avg_episode_per_sec: 5.697559583442807
collect_time: 0.526541224547795
reward_mean: 944.0
reward_std: 443.36065673828125
reward_max: 1571.0
reward_min: 628.0
total_envstep_count: 1540073
total_train_sample_count: 1540039
total_episode_count: 10266
total_duration: 1946.850719801017
[2024-11-19 23:39:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1408
train_sample_count: 1408
avg_envstep_per_episode: 201.14285714285714
avg_sample_per_episode: 201.14285714285714
avg_envstep_per_sec: 807.257196749718
avg_train_sample_per_sec: 807.257196749718
avg_episode_per_sec: 4.013352540659109
collect_time: 1.7441776990890505
reward_mean: 1380.5714111328125
reward_std: 626.5038452148438
reward_max: 2606.0
reward_min: 599.0
total_envstep_count: 1541066
total_train_sample_count: 1541027
total_episode_count: 10273
total_duration: 1948.594897500106
[2024-11-19 23:39:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1100
train_sample_count: 1100
avg_envstep_per_episode: 137.5
avg_sample_per_episode: 137.5
avg_envstep_per_sec: 800.5805150190258
avg_train_sample_per_sec: 800.5805150190258
avg_episode_per_sec: 5.822403745592915
collect_time: 1.3740029633045197
reward_mean: 1132.125
reward_std: 527.8942260742188
reward_max: 1721.0
reward_min: 236.0
total_envstep_count: 1542116
total_train_sample_count: 1542067
total_episode_count: 10281
total_duration: 1949.9689004634106
[2024-11-19 23:39:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 174
train_sample_count: 174
avg_envstep_per_episode: 87.0
avg_sample_per_episode: 87.0
avg_envstep_per_sec: 818.1203574400597
avg_train_sample_per_sec: 818.1203574400597
avg_episode_per_sec: 9.403682269425973
collect_time: 0.21268264310700552
reward_mean: 629.0
reward_std: 1.0
reward_max: 630.0
reward_min: 628.0
total_envstep_count: 1543074
total_train_sample_count: 1543033
total_episode_count: 10283
total_duration: 1950.1815831065176
[2024-11-19 23:39:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1232
train_sample_count: 1232
avg_envstep_per_episode: 246.4
avg_sample_per_episode: 246.4
avg_envstep_per_sec: 797.3130275404787
avg_train_sample_per_sec: 797.3130275404787
avg_episode_per_sec: 3.2358483260571376
collect_time: 1.5451898532254356
reward_mean: 1538.0
reward_std: 418.542724609375
reward_max: 1846.0
reward_min: 713.0
total_envstep_count: 1544055
total_train_sample_count: 1544013
total_episode_count: 10288
total_duration: 1951.726772959743
[2024-11-19 23:39:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 630
train_sample_count: 630
avg_envstep_per_episode: 126.0
avg_sample_per_episode: 126.0
avg_envstep_per_sec: 806.9707171070901
avg_train_sample_per_sec: 806.9707171070901
avg_episode_per_sec: 6.404529500849922
collect_time: 0.7806974734578814
reward_mean: 814.2000122070312
reward_std: 303.450439453125
reward_max: 1415.0
reward_min: 611.0
total_envstep_count: 1545026
total_train_sample_count: 1544991
total_episode_count: 10293
total_duration: 1952.5074704332008
[2024-11-19 23:39:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 825
train_sample_count: 825
avg_envstep_per_episode: 165.0
avg_sample_per_episode: 165.0
avg_envstep_per_sec: 805.8549421349884
avg_train_sample_per_sec: 805.8549421349884
avg_episode_per_sec: 4.883969346272657
collect_time: 1.023757449218205
reward_mean: 1498.0
reward_std: 239.3633270263672
reward_max: 1708.0
reward_min: 1062.0
total_envstep_count: 1546021
total_train_sample_count: 1545984
total_episode_count: 10298
total_duration: 1953.531227882419
[2024-11-19 23:39:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1306
train_sample_count: 1306
avg_envstep_per_episode: 217.66666666666666
avg_sample_per_episode: 217.66666666666666
avg_envstep_per_sec: 800.9005096937673
avg_train_sample_per_sec: 800.9005096937673
avg_episode_per_sec: 3.6794816678121007
collect_time: 1.6306644635541097
reward_mean: 1213.3333740234375
reward_std: 480.39276123046875
reward_max: 1902.0
reward_min: 624.0
total_envstep_count: 1546991
total_train_sample_count: 1546954
total_episode_count: 10304
total_duration: 1955.161892345973
[2024-11-19 23:39:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2756
train_sample_count: 2756
avg_envstep_per_episode: 459.3333333333333
avg_sample_per_episode: 459.3333333333333
avg_envstep_per_sec: 805.9260965940817
avg_train_sample_per_sec: 805.9260965940817
avg_episode_per_sec: 1.7545560883760851
collect_time: 3.4196683934756686
reward_mean: 1268.5
reward_std: 355.24908447265625
reward_max: 1702.0
reward_min: 620.0
total_envstep_count: 1547971
total_train_sample_count: 1547946
total_episode_count: 10310
total_duration: 1958.5815607394486
[2024-11-19 23:39:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1053
train_sample_count: 1053
avg_envstep_per_episode: 131.625
avg_sample_per_episode: 131.625
avg_envstep_per_sec: 806.5143235972241
avg_train_sample_per_sec: 806.5143235972241
avg_episode_per_sec: 6.127364281840259
collect_time: 1.305618473461696
reward_mean: 982.875
reward_std: 490.9972839355469
reward_max: 1685.0
reward_min: 228.0
total_envstep_count: 1549013
total_train_sample_count: 1548951
total_episode_count: 10318
total_duration: 1959.8871792129103
[2024-11-19 23:39:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1279
train_sample_count: 1279
avg_envstep_per_episode: 159.875
avg_sample_per_episode: 159.875
avg_envstep_per_sec: 802.3274238664454
avg_train_sample_per_sec: 802.3274238664454
avg_episode_per_sec: 5.018467076568854
collect_time: 1.5941122812884194
reward_mean: 1169.25
reward_std: 380.9654541015625
reward_max: 1576.0
reward_min: 607.0
total_envstep_count: 1549959
total_train_sample_count: 1549930
total_episode_count: 10326
total_duration: 1961.4812914941988
[2024-11-19 23:39:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 436
train_sample_count: 436
avg_envstep_per_episode: 145.33333333333334
avg_sample_per_episode: 145.33333333333334
avg_envstep_per_sec: 801.7829616727423
avg_train_sample_per_sec: 801.7829616727423
avg_episode_per_sec: 5.516855240867493
collect_time: 0.543788058417184
reward_mean: 1176.6666259765625
reward_std: 186.92303466796875
reward_max: 1441.0
reward_min: 1042.0
total_envstep_count: 1550957
total_train_sample_count: 1550918
total_episode_count: 10329
total_duration: 1962.025079552616
[2024-11-19 23:39:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1031
train_sample_count: 1031
avg_envstep_per_episode: 171.83333333333334
avg_sample_per_episode: 171.83333333333334
avg_envstep_per_sec: 806.8559123639252
avg_train_sample_per_sec: 806.8559123639252
avg_episode_per_sec: 4.695572719867654
collect_time: 1.2777993991261436
reward_mean: 1206.0
reward_std: 283.4654541015625
reward_max: 1701.0
reward_min: 817.0
total_envstep_count: 1551951
total_train_sample_count: 1551901
total_episode_count: 10335
total_duration: 1963.3028789517423
[2024-11-19 23:39:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1121
train_sample_count: 1121
avg_envstep_per_episode: 140.125
avg_sample_per_episode: 140.125
avg_envstep_per_sec: 799.1243186445049
avg_train_sample_per_sec: 799.1243186445049
avg_episode_per_sec: 5.702938937694951
collect_time: 1.4027854913756959
reward_mean: 891.0
reward_std: 358.4006042480469
reward_max: 1571.0
reward_min: 589.0
total_envstep_count: 1552929
total_train_sample_count: 1552902
total_episode_count: 10343
total_duration: 1964.705664443118
[2024-11-19 23:39:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1305
train_sample_count: 1305
avg_envstep_per_episode: 130.5
avg_sample_per_episode: 130.5
avg_envstep_per_sec: 810.5364078078618
avg_train_sample_per_sec: 810.5364078078618
avg_episode_per_sec: 6.211006956382083
collect_time: 1.6100448880876812
reward_mean: 922.7000122070312
reward_std: 413.7898254394531
reward_max: 1697.0
reward_min: 609.0
total_envstep_count: 1553947
total_train_sample_count: 1553907
total_episode_count: 10353
total_duration: 1966.3157093312057
[2024-11-19 23:40:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 609
train_sample_count: 609
avg_envstep_per_episode: 152.25
avg_sample_per_episode: 152.25
avg_envstep_per_sec: 812.0279893985908
avg_train_sample_per_sec: 812.0279893985908
avg_episode_per_sec: 5.333517171747722
collect_time: 0.7499741486140661
reward_mean: 1022.0
reward_std: 405.66796875
reward_max: 1428.0
reward_min: 600.0
total_envstep_count: 1554920
total_train_sample_count: 1554876
total_episode_count: 10357
total_duration: 1967.0656834798197
[2024-11-19 23:40:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 876
train_sample_count: 876
avg_envstep_per_episode: 146.0
avg_sample_per_episode: 146.0
avg_envstep_per_sec: 800.7019307636776
avg_train_sample_per_sec: 800.7019307636776
avg_episode_per_sec: 5.484259799751217
collect_time: 1.0940400745187489
reward_mean: 922.5
reward_std: 384.81109619140625
reward_max: 1583.0
reward_min: 606.0
total_envstep_count: 1555916
total_train_sample_count: 1555872
total_episode_count: 10363
total_duration: 1968.1597235543384
[2024-11-19 23:40:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 997
train_sample_count: 997
avg_envstep_per_episode: 124.625
avg_sample_per_episode: 124.625
avg_envstep_per_sec: 800.0965301008086
avg_train_sample_per_sec: 800.0965301008086
avg_episode_per_sec: 6.420032337819928
collect_time: 1.2460996423448836
reward_mean: 944.5
reward_std: 576.163818359375
reward_max: 1886.0
reward_min: 231.0
total_envstep_count: 1556948
total_train_sample_count: 1556905
total_episode_count: 10371
total_duration: 1969.4058231966833
[2024-11-19 23:40:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1646
train_sample_count: 1646
avg_envstep_per_episode: 164.6
avg_sample_per_episode: 164.6
avg_envstep_per_sec: 799.5784334860626
avg_train_sample_per_sec: 799.5784334860626
avg_episode_per_sec: 4.85770615726648
collect_time: 2.0585847880159105
reward_mean: 1116.4000244140625
reward_std: 465.22039794921875
reward_max: 1616.0
reward_min: 234.0
total_envstep_count: 1557931
total_train_sample_count: 1557903
total_episode_count: 10381
total_duration: 1971.4644079846992
[2024-11-19 23:40:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 671
train_sample_count: 671
avg_envstep_per_episode: 134.2
avg_sample_per_episode: 134.2
avg_envstep_per_sec: 799.4559328035897
avg_train_sample_per_sec: 799.4559328035897
avg_episode_per_sec: 5.9571977109060334
collect_time: 0.8393208086490631
reward_mean: 1099.4000244140625
reward_std: 397.2281799316406
reward_max: 1582.0
reward_min: 600.0
total_envstep_count: 1558903
total_train_sample_count: 1558874
total_episode_count: 10386
total_duration: 1972.3037287933482
[2024-11-19 23:40:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1198
train_sample_count: 1198
avg_envstep_per_episode: 119.8
avg_sample_per_episode: 119.8
avg_envstep_per_sec: 800.2871297372733
avg_train_sample_per_sec: 800.2871297372733
avg_episode_per_sec: 6.680193069593266
collect_time: 1.496962721858706
reward_mean: 1004.9000244140625
reward_std: 378.35919189453125
reward_max: 1439.0
reward_min: 621.0
total_envstep_count: 1559904
total_train_sample_count: 1559880
total_episode_count: 10396
total_duration: 1973.8006915152068
[2024-11-19 23:40:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 936
train_sample_count: 936
avg_envstep_per_episode: 133.71428571428572
avg_sample_per_episode: 133.71428571428572
avg_envstep_per_sec: 801.9042817412668
avg_train_sample_per_sec: 801.9042817412668
avg_episode_per_sec: 5.997147406184688
collect_time: 1.1672216015202659
reward_mean: 1138.857177734375
reward_std: 443.879150390625
reward_max: 1696.0
reward_min: 622.0
total_envstep_count: 1560906
total_train_sample_count: 1560864
total_episode_count: 10403
total_duration: 1974.967913116727
[2024-11-19 23:40:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 826
train_sample_count: 826
avg_envstep_per_episode: 137.66666666666666
avg_sample_per_episode: 137.66666666666666
avg_envstep_per_sec: 805.9132555271943
avg_train_sample_per_sec: 805.9132555271943
avg_episode_per_sec: 5.854091444507464
collect_time: 1.0249242016247342
reward_mean: 982.1666870117188
reward_std: 372.0198974609375
reward_max: 1502.0
reward_min: 614.0
total_envstep_count: 1561900
total_train_sample_count: 1561870
total_episode_count: 10409
total_duration: 1975.9928373183518
[2024-11-19 23:40:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1181
train_sample_count: 1181
avg_envstep_per_episode: 118.1
avg_sample_per_episode: 118.1
avg_envstep_per_sec: 799.0280024263742
avg_train_sample_per_sec: 799.0280024263742
avg_episode_per_sec: 6.765690113686488
collect_time: 1.4780458211898804
reward_mean: 979.5999755859375
reward_std: 430.3896484375
reward_max: 1689.0
reward_min: 621.0
total_envstep_count: 1562956
total_train_sample_count: 1562931
total_episode_count: 10419
total_duration: 1977.4708831395417
[2024-11-19 23:40:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 477
train_sample_count: 477
avg_envstep_per_episode: 159.0
avg_sample_per_episode: 159.0
avg_envstep_per_sec: 807.8613583827148
avg_train_sample_per_sec: 807.8613583827148
avg_episode_per_sec: 5.080889046432168
collect_time: 0.5904478473322732
reward_mean: 1208.0
reward_std: 429.718505859375
reward_max: 1581.0
reward_min: 606.0
total_envstep_count: 1563930
total_train_sample_count: 1563912
total_episode_count: 10422
total_duration: 1978.061330986874
[2024-11-19 23:40:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1496
train_sample_count: 1496
avg_envstep_per_episode: 166.22222222222223
avg_sample_per_episode: 166.22222222222223
avg_envstep_per_sec: 803.4301223613091
avg_train_sample_per_sec: 803.4301223613091
avg_episode_per_sec: 4.833469987467769
collect_time: 1.8620163202285767
reward_mean: 1305.22216796875
reward_std: 297.671630859375
reward_max: 1662.0
reward_min: 635.0
total_envstep_count: 1564906
total_train_sample_count: 1564892
total_episode_count: 10431
total_duration: 1979.9233473071026
[2024-11-19 23:40:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 945
train_sample_count: 945
avg_envstep_per_episode: 157.5
avg_sample_per_episode: 157.5
avg_envstep_per_sec: 808.1011534050594
avg_train_sample_per_sec: 808.1011534050594
avg_episode_per_sec: 5.130800974000377
collect_time: 1.1694080574171886
reward_mean: 1182.1666259765625
reward_std: 480.0268859863281
reward_max: 1863.0
reward_min: 627.0
total_envstep_count: 1565941
total_train_sample_count: 1565885
total_episode_count: 10437
total_duration: 1981.09275536452
[2024-11-19 23:40:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 590
train_sample_count: 590
avg_envstep_per_episode: 147.5
avg_sample_per_episode: 147.5
avg_envstep_per_sec: 804.4866907305551
avg_train_sample_per_sec: 804.4866907305551
avg_episode_per_sec: 5.454147055800374
collect_time: 0.7333868997437614
reward_mean: 1125.75
reward_std: 509.3502502441406
reward_max: 1681.0
reward_min: 612.0
total_envstep_count: 1566906
total_train_sample_count: 1566871
total_episode_count: 10441
total_duration: 1981.8261422642636
[2024-11-19 23:40:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 807
train_sample_count: 807
avg_envstep_per_episode: 134.5
avg_sample_per_episode: 134.5
avg_envstep_per_sec: 801.0442882830082
avg_train_sample_per_sec: 801.0442882830082
avg_episode_per_sec: 5.95571961548705
collect_time: 1.0074349343776703
reward_mean: 1075.6666259765625
reward_std: 471.3670349121094
reward_max: 1690.0
reward_min: 610.0
total_envstep_count: 1567901
total_train_sample_count: 1567858
total_episode_count: 10447
total_duration: 1982.8335771986413
[2024-11-19 23:40:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1422
train_sample_count: 1422
avg_envstep_per_episode: 177.75
avg_sample_per_episode: 177.75
avg_envstep_per_sec: 798.4562944966025
avg_train_sample_per_sec: 798.4562944966025
avg_episode_per_sec: 4.492018534439395
collect_time: 1.7809365519455502
reward_mean: 1253.5
reward_std: 639.5365600585938
reward_max: 2334.0
reward_min: 249.0
total_envstep_count: 1568894
total_train_sample_count: 1568848
total_episode_count: 10455
total_duration: 1984.6145137505869
[2024-11-19 23:40:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 758
train_sample_count: 758
avg_envstep_per_episode: 151.6
avg_sample_per_episode: 151.6
avg_envstep_per_sec: 801.4706966093019
avg_train_sample_per_sec: 801.4706966093019
avg_episode_per_sec: 5.286746019850276
collect_time: 0.9457613400050573
reward_mean: 1211.4000244140625
reward_std: 429.8612060546875
reward_max: 1686.0
reward_min: 626.0
total_envstep_count: 1569881
total_train_sample_count: 1569834
total_episode_count: 10460
total_duration: 1985.5602750905919
[2024-11-19 23:41:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1224
train_sample_count: 1224
avg_envstep_per_episode: 174.85714285714286
avg_sample_per_episode: 174.85714285714286
avg_envstep_per_sec: 798.5925268076508
avg_train_sample_per_sec: 798.5925268076508
avg_episode_per_sec: 4.567114123899963
collect_time: 1.5326965366091048
reward_mean: 1337.0
reward_std: 356.3088684082031
reward_max: 1688.0
reward_min: 610.0
total_envstep_count: 1570851
total_train_sample_count: 1570806
total_episode_count: 10467
total_duration: 1987.092971627201
[2024-11-19 23:41:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 988
train_sample_count: 988
avg_envstep_per_episode: 109.77777777777777
avg_sample_per_episode: 109.77777777777777
avg_envstep_per_sec: 797.6110105121896
avg_train_sample_per_sec: 797.6110105121896
avg_episode_per_sec: 7.265687342722376
collect_time: 1.238699048757553
reward_mean: 851.4444580078125
reward_std: 420.6154479980469
reward_max: 1438.0
reward_min: 249.0
total_envstep_count: 1571883
total_train_sample_count: 1571842
total_episode_count: 10476
total_duration: 1988.3316706759585
[2024-11-19 23:41:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 849
train_sample_count: 849
avg_envstep_per_episode: 169.8
avg_sample_per_episode: 169.8
avg_envstep_per_sec: 789.4986521602308
avg_train_sample_per_sec: 789.4986521602308
avg_episode_per_sec: 4.649579812486635
collect_time: 1.0753659904003146
reward_mean: 1296.4000244140625
reward_std: 352.78411865234375
reward_max: 1689.0
reward_min: 635.0
total_envstep_count: 1572878
total_train_sample_count: 1572835
total_episode_count: 10481
total_duration: 1989.4070366663589
[2024-11-19 23:41:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1216
train_sample_count: 1216
avg_envstep_per_episode: 173.71428571428572
avg_sample_per_episode: 173.71428571428572
avg_envstep_per_sec: 790.8829611071828
avg_train_sample_per_sec: 790.8829611071828
avg_episode_per_sec: 4.552780203742007
collect_time: 1.5375220605305264
reward_mean: 1182.142822265625
reward_std: 384.1065673828125
reward_max: 1569.0
reward_min: 627.0
total_envstep_count: 1573871
total_train_sample_count: 1573847
total_episode_count: 10488
total_duration: 1990.9445587268895
[2024-11-19 23:41:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 584
train_sample_count: 584
avg_envstep_per_episode: 116.8
avg_sample_per_episode: 116.8
avg_envstep_per_sec: 787.3756894698902
avg_train_sample_per_sec: 787.3756894698902
avg_episode_per_sec: 6.741230218064128
collect_time: 0.7417043830667223
reward_mean: 934.2000122070312
reward_std: 452.56573486328125
reward_max: 1437.0
reward_min: 236.0
total_envstep_count: 1574860
total_train_sample_count: 1574815
total_episode_count: 10493
total_duration: 1991.6862631099561
[2024-11-19 23:41:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 779
train_sample_count: 779
avg_envstep_per_episode: 155.8
avg_sample_per_episode: 155.8
avg_envstep_per_sec: 803.571164750033
avg_train_sample_per_sec: 803.571164750033
avg_episode_per_sec: 5.157709658215873
collect_time: 0.9694225404943739
reward_mean: 1151.199951171875
reward_std: 424.7626953125
reward_max: 1563.0
reward_min: 630.0
total_envstep_count: 1575816
total_train_sample_count: 1575798
total_episode_count: 10498
total_duration: 1992.6556856504506
[2024-11-19 23:41:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1568
train_sample_count: 1568
avg_envstep_per_episode: 196.0
avg_sample_per_episode: 196.0
avg_envstep_per_sec: 793.7337547324955
avg_train_sample_per_sec: 793.7337547324955
avg_episode_per_sec: 4.049662013941304
collect_time: 1.9754735018525804
reward_mean: 1118.25
reward_std: 593.9374389648438
reward_max: 2312.0
reward_min: 607.0
total_envstep_count: 1576817
total_train_sample_count: 1576778
total_episode_count: 10506
total_duration: 1994.631159152303
[2024-11-19 23:41:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1041
train_sample_count: 1041
avg_envstep_per_episode: 173.5
avg_sample_per_episode: 173.5
avg_envstep_per_sec: 802.0595701031369
avg_train_sample_per_sec: 802.0595701031369
avg_episode_per_sec: 4.622821729701077
collect_time: 1.2979085828576769
reward_mean: 1165.5
reward_std: 458.5654296875
reward_max: 1834.0
reward_min: 598.0
total_envstep_count: 1577803
total_train_sample_count: 1577759
total_episode_count: 10512
total_duration: 1995.9290677351607
[2024-11-19 23:41:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 425
train_sample_count: 425
avg_envstep_per_episode: 141.66666666666666
avg_sample_per_episode: 141.66666666666666
avg_envstep_per_sec: 798.5534457466158
avg_train_sample_per_sec: 798.5534457466158
avg_episode_per_sec: 5.636847852329053
collect_time: 0.5322123425347465
reward_mean: 938.3333129882812
reward_std: 442.48114013671875
reward_max: 1564.0
reward_min: 616.0
total_envstep_count: 1578776
total_train_sample_count: 1578748
total_episode_count: 10515
total_duration: 1996.4612800776954
[2024-11-19 23:41:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1436
train_sample_count: 1436
avg_envstep_per_episode: 179.5
avg_sample_per_episode: 179.5
avg_envstep_per_sec: 798.2329013142763
avg_train_sample_per_sec: 798.2329013142763
avg_episode_per_sec: 4.446979951611567
collect_time: 1.7989737050873893
reward_mean: 1376.125
reward_std: 520.3535766601562
reward_max: 2340.0
reward_min: 607.0
total_envstep_count: 1579809
total_train_sample_count: 1579764
total_episode_count: 10523
total_duration: 1998.2602537827827
[2024-11-19 23:41:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 567
train_sample_count: 567
avg_envstep_per_episode: 141.75
avg_sample_per_episode: 141.75
avg_envstep_per_sec: 804.9277076168136
avg_train_sample_per_sec: 804.9277076168136
avg_episode_per_sec: 5.678502346503095
collect_time: 0.7044110851628439
reward_mean: 1313.0
reward_std: 406.0818786621094
reward_max: 1699.0
reward_min: 631.0
total_envstep_count: 1580773
total_train_sample_count: 1580739
total_episode_count: 10527
total_duration: 1998.9646648679454
[2024-11-19 23:41:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 598
train_sample_count: 598
avg_envstep_per_episode: 119.6
avg_sample_per_episode: 119.6
avg_envstep_per_sec: 803.7913691238014
avg_train_sample_per_sec: 803.7913691238014
avg_episode_per_sec: 6.720663621436466
collect_time: 0.7439741492271423
reward_mean: 836.7999877929688
reward_std: 371.08673095703125
reward_max: 1576.0
reward_min: 609.0
total_envstep_count: 1581785
total_train_sample_count: 1581733
total_episode_count: 10532
total_duration: 1999.7086390171726
[2024-11-19 23:41:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1346
train_sample_count: 1346
avg_envstep_per_episode: 192.28571428571428
avg_sample_per_episode: 192.28571428571428
avg_envstep_per_sec: 795.3450012413451
avg_train_sample_per_sec: 795.3450012413451
avg_episode_per_sec: 4.136266722651869
collect_time: 1.6923473434788838
reward_mean: 1216.7142333984375
reward_std: 515.4977416992188
reward_max: 1849.0
reward_min: 625.0
total_envstep_count: 1582779
total_train_sample_count: 1582743
total_episode_count: 10539
total_duration: 2001.4009863606514
[2024-11-19 23:41:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1206
train_sample_count: 1206
avg_envstep_per_episode: 241.2
avg_sample_per_episode: 241.2
avg_envstep_per_sec: 795.696594883138
avg_train_sample_per_sec: 795.696594883138
avg_episode_per_sec: 3.2989079389848177
collect_time: 1.515653086560113
reward_mean: 1394.0
reward_std: 421.1964111328125
reward_max: 1855.0
reward_min: 619.0
total_envstep_count: 1583735
total_train_sample_count: 1583709
total_episode_count: 10544
total_duration: 2002.9166394472115
[2024-11-19 23:41:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 417
train_sample_count: 417
avg_envstep_per_episode: 139.0
avg_sample_per_episode: 139.0
avg_envstep_per_sec: 814.0486650157476
avg_train_sample_per_sec: 814.0486650157476
avg_episode_per_sec: 5.85646521594063
collect_time: 0.512254387140274
reward_mean: 1139.3333740234375
reward_std: 428.21051025390625
reward_max: 1695.0
reward_min: 653.0
total_envstep_count: 1584709
total_train_sample_count: 1584678
total_episode_count: 10547
total_duration: 2003.4288938343518
[2024-11-19 23:41:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 780
train_sample_count: 780
avg_envstep_per_episode: 195.0
avg_sample_per_episode: 195.0
avg_envstep_per_sec: 810.287172977829
avg_train_sample_per_sec: 810.287172977829
avg_episode_per_sec: 4.1553188357837385
collect_time: 0.9626216803278241
reward_mean: 1469.0
reward_std: 501.37908935546875
reward_max: 1852.0
reward_min: 624.0
total_envstep_count: 1585697
total_train_sample_count: 1585650
total_episode_count: 10551
total_duration: 2004.3915155146797
[2024-11-19 23:41:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 834
train_sample_count: 834
avg_envstep_per_episode: 166.8
avg_sample_per_episode: 166.8
avg_envstep_per_sec: 808.2442803038513
avg_train_sample_per_sec: 808.2442803038513
avg_episode_per_sec: 4.845589210454744
collect_time: 1.0318662566798074
reward_mean: 1091.4000244140625
reward_std: 434.8501281738281
reward_max: 1589.0
reward_min: 604.0
total_envstep_count: 1586662
total_train_sample_count: 1586640
total_episode_count: 10556
total_duration: 2005.4233817713596
[2024-11-19 23:42:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 360
train_sample_count: 360
avg_envstep_per_episode: 120.0
avg_sample_per_episode: 120.0
avg_envstep_per_sec: 813.9263284221079
avg_train_sample_per_sec: 813.9263284221079
avg_episode_per_sec: 6.782719403517566
collect_time: 0.4423004729407174
reward_mean: 727.3333129882812
reward_std: 447.0416259765625
reward_max: 1324.0
reward_min: 248.0
total_envstep_count: 1587659
total_train_sample_count: 1587612
total_episode_count: 10559
total_duration: 2005.8656822443004
[2024-11-19 23:42:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1061
train_sample_count: 1061
avg_envstep_per_episode: 212.2
avg_sample_per_episode: 212.2
avg_envstep_per_sec: 814.6061886475533
avg_train_sample_per_sec: 814.6061886475533
avg_episode_per_sec: 3.8388604554550105
collect_time: 1.3024698495864868
reward_mean: 1240.5999755859375
reward_std: 298.67010498046875
reward_max: 1436.0
reward_min: 648.0
total_envstep_count: 1588638
total_train_sample_count: 1588589
total_episode_count: 10564
total_duration: 2007.1681520938869
[2024-11-19 23:42:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1484
train_sample_count: 1484
avg_envstep_per_episode: 494.6666666666667
avg_sample_per_episode: 494.6666666666667
avg_envstep_per_sec: 800.5214831000516
avg_train_sample_per_sec: 800.5214831000516
avg_episode_per_sec: 1.61830488497315
collect_time: 1.8537915987627847
reward_mean: 1027.6666259765625
reward_std: 425.8828430175781
reward_max: 1622.0
reward_min: 646.0
total_envstep_count: 1589597
total_train_sample_count: 1589557
total_episode_count: 10567
total_duration: 2009.0219436926498
[2024-11-19 23:42:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 936
train_sample_count: 936
avg_envstep_per_episode: 187.2
avg_sample_per_episode: 187.2
avg_envstep_per_sec: 811.5165653999567
avg_train_sample_per_sec: 811.5165653999567
avg_episode_per_sec: 4.335024387820281
collect_time: 1.1533960487161363
reward_mean: 692.4000244140625
reward_std: 166.02963256835938
reward_max: 1024.0
reward_min: 601.0
total_envstep_count: 1590554
total_train_sample_count: 1590529
total_episode_count: 10572
total_duration: 2010.1753397413659
[2024-11-19 23:42:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1475
train_sample_count: 1475
avg_envstep_per_episode: 210.71428571428572
avg_sample_per_episode: 210.71428571428572
avg_envstep_per_sec: 810.2971183054947
avg_train_sample_per_sec: 810.2971183054947
avg_episode_per_sec: 3.8454778495853987
collect_time: 1.8203199378081731
reward_mean: 830.7142944335938
reward_std: 502.0909729003906
reward_max: 1804.0
reward_min: 229.0
total_envstep_count: 1591571
total_train_sample_count: 1591524
total_episode_count: 10579
total_duration: 2011.995659679174
[2024-11-19 23:42:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 837
train_sample_count: 837
avg_envstep_per_episode: 93.0
avg_sample_per_episode: 93.0
avg_envstep_per_sec: 810.7756437879831
avg_train_sample_per_sec: 810.7756437879831
avg_episode_per_sec: 8.718017675139603
collect_time: 1.032344775540488
reward_mean: 674.0
reward_std: 268.42132568359375
reward_max: 1344.0
reward_min: 249.0
total_envstep_count: 1592572
total_train_sample_count: 1592529
total_episode_count: 10588
total_duration: 2013.0280044547144
[2024-11-19 23:42:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 766
train_sample_count: 766
avg_envstep_per_episode: 127.66666666666667
avg_sample_per_episode: 127.66666666666667
avg_envstep_per_sec: 801.1679616395937
avg_train_sample_per_sec: 801.1679616395937
avg_episode_per_sec: 6.275467062451126
collect_time: 0.9561041338103157
reward_mean: 923.6666870117188
reward_std: 359.6872253417969
reward_max: 1492.0
reward_min: 621.0
total_envstep_count: 1593582
total_train_sample_count: 1593535
total_episode_count: 10594
total_duration: 2013.9841085885248
[2024-11-19 23:42:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 581
train_sample_count: 581
avg_envstep_per_episode: 193.66666666666666
avg_sample_per_episode: 193.66666666666666
avg_envstep_per_sec: 811.9358338658743
avg_train_sample_per_sec: 811.9358338658743
avg_episode_per_sec: 4.192439761785926
collect_time: 0.715573787689209
reward_mean: 1251.0
reward_std: 444.0750732421875
reward_max: 1569.0
reward_min: 623.0
total_envstep_count: 1594540
total_train_sample_count: 1594500
total_episode_count: 10597
total_duration: 2014.699682376214
[2024-11-19 23:42:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1114
train_sample_count: 1114
avg_envstep_per_episode: 159.14285714285714
avg_sample_per_episode: 159.14285714285714
avg_envstep_per_sec: 805.9628546146997
avg_train_sample_per_sec: 805.9628546146997
avg_episode_per_sec: 5.064398547848203
collect_time: 1.3821976951190402
reward_mean: 1093.2857666015625
reward_std: 429.8889465332031
reward_max: 1693.0
reward_min: 598.0
total_envstep_count: 1595528
total_train_sample_count: 1595482
total_episode_count: 10604
total_duration: 2016.081880071333
[2024-11-19 23:42:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 485
train_sample_count: 485
avg_envstep_per_episode: 80.83333333333333
avg_sample_per_episode: 80.83333333333333
avg_envstep_per_sec: 801.4066416069193
avg_train_sample_per_sec: 801.4066416069193
avg_episode_per_sec: 9.914308968333023
collect_time: 0.605185900415693
reward_mean: 569.5
reward_std: 144.30148315429688
reward_max: 650.0
reward_min: 248.0
total_envstep_count: 1596522
total_train_sample_count: 1596495
total_episode_count: 10610
total_duration: 2016.6870659717488
[2024-11-19 23:42:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1599
train_sample_count: 1599
avg_envstep_per_episode: 177.66666666666666
avg_sample_per_episode: 177.66666666666666
avg_envstep_per_sec: 805.5449872226959
avg_train_sample_per_sec: 805.5449872226959
avg_episode_per_sec: 4.534024318326618
collect_time: 1.984991558960506
reward_mean: 1182.4444580078125
reward_std: 516.6654052734375
reward_max: 2312.0
reward_min: 619.0
total_envstep_count: 1597546
total_train_sample_count: 1597494
total_episode_count: 10619
total_duration: 2018.6720575307093
[2024-11-19 23:43:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 636
train_sample_count: 636
avg_envstep_per_episode: 90.85714285714286
avg_sample_per_episode: 90.85714285714286
avg_envstep_per_sec: 804.6400783006612
avg_train_sample_per_sec: 804.6400783006612
avg_episode_per_sec: 8.856101490730548
collect_time: 0.7904155126639774
reward_mean: 684.5714111328125
reward_std: 302.5240783691406
reward_max: 1347.0
reward_min: 248.0
total_envstep_count: 1598500
total_train_sample_count: 1598466
total_episode_count: 10626
total_duration: 2019.4624730433732
[2024-11-19 23:43:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 648
train_sample_count: 648
avg_envstep_per_episode: 162.0
avg_sample_per_episode: 162.0
avg_envstep_per_sec: 767.9063854203816
avg_train_sample_per_sec: 767.9063854203816
avg_episode_per_sec: 4.7401628729653185
collect_time: 0.8438528605869838
reward_mean: 1378.25
reward_std: 461.4891052246094
reward_max: 1846.0
reward_min: 650.0
total_envstep_count: 1599504
total_train_sample_count: 1599450
total_episode_count: 10630
total_duration: 2020.3063259039602
[2024-11-19 23:43:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 3035
train_sample_count: 3035
avg_envstep_per_episode: 337.22222222222223
avg_sample_per_episode: 337.22222222222223
avg_envstep_per_sec: 785.1112236510082
avg_train_sample_per_sec: 785.1112236510082
avg_episode_per_sec: 2.3281716681578497
collect_time: 3.865694322756358
reward_mean: 898.3333129882812
reward_std: 299.71282958984375
reward_max: 1327.0
reward_min: 599.0
total_envstep_count: 1600459
total_train_sample_count: 1600433
total_episode_count: 10639
total_duration: 2024.1720202267165
[2024-11-19 23:43:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1159
train_sample_count: 1159
avg_envstep_per_episode: 128.77777777777777
avg_sample_per_episode: 128.77777777777777
avg_envstep_per_sec: 778.061814577076
avg_train_sample_per_sec: 778.061814577076
avg_episode_per_sec: 6.041895022600245
collect_time: 1.4895988702774048
reward_mean: 1018.888916015625
reward_std: 356.0606994628906
reward_max: 1346.0
reward_min: 613.0
total_envstep_count: 1601467
total_train_sample_count: 1601424
total_episode_count: 10648
total_duration: 2025.661619096994
[2024-11-19 23:43:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 471
train_sample_count: 471
avg_envstep_per_episode: 117.75
avg_sample_per_episode: 117.75
avg_envstep_per_sec: 756.8385485548979
avg_train_sample_per_sec: 756.8385485548979
avg_episode_per_sec: 6.4275035970691965
collect_time: 0.6223255949360984
reward_mean: 967.25
reward_std: 388.1297302246094
reward_max: 1570.0
reward_min: 624.0
total_envstep_count: 1602448
total_train_sample_count: 1602399
total_episode_count: 10652
total_duration: 2026.28394469193
[2024-11-19 23:43:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1260
train_sample_count: 1260
avg_envstep_per_episode: 126.0
avg_sample_per_episode: 126.0
avg_envstep_per_sec: 783.5835202356192
avg_train_sample_per_sec: 783.5835202356192
avg_episode_per_sec: 6.218916827266819
collect_time: 1.6079970640795573
reward_mean: 904.7000122070312
reward_std: 572.552001953125
reward_max: 1700.0
reward_min: 246.0
total_envstep_count: 1603432
total_train_sample_count: 1603395
total_episode_count: 10662
total_duration: 2027.8919417560096
[2024-11-19 23:43:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 833
train_sample_count: 833
avg_envstep_per_episode: 92.55555555555556
avg_sample_per_episode: 92.55555555555556
avg_envstep_per_sec: 797.8648718519584
avg_train_sample_per_sec: 797.8648718519584
avg_episode_per_sec: 8.620388771509754
collect_time: 1.0440364394869122
reward_mean: 672.888916015625
reward_std: 234.2237548828125
reward_max: 1057.0
reward_min: 240.0
total_envstep_count: 1604401
total_train_sample_count: 1604372
total_episode_count: 10671
total_duration: 2028.9359781954965
[2024-11-19 23:43:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 406
train_sample_count: 406
avg_envstep_per_episode: 81.2
avg_sample_per_episode: 81.2
avg_envstep_per_sec: 795.5054187837778
avg_train_sample_per_sec: 795.5054187837778
avg_episode_per_sec: 9.796864763347019
collect_time: 0.5103673594338554
reward_mean: 636.4000244140625
reward_std: 13.922643661499023
reward_max: 653.0
reward_min: 621.0
total_envstep_count: 1605389
total_train_sample_count: 1605366
total_episode_count: 10676
total_duration: 2029.4463455549303
[2024-11-19 23:43:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1219
train_sample_count: 1219
avg_envstep_per_episode: 304.75
avg_sample_per_episode: 304.75
avg_envstep_per_sec: 795.4574713069288
avg_train_sample_per_sec: 795.4574713069288
avg_episode_per_sec: 2.6101967885379125
collect_time: 1.5324515061719075
reward_mean: 1577.5
reward_std: 259.8638916015625
reward_max: 1909.0
reward_min: 1319.0
total_envstep_count: 1606386
total_train_sample_count: 1606345
total_episode_count: 10680
total_duration: 2030.9787970611021
[2024-11-19 23:43:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1309
train_sample_count: 1309
avg_envstep_per_episode: 261.8
avg_sample_per_episode: 261.8
avg_envstep_per_sec: 798.7699848328683
avg_train_sample_per_sec: 798.7699848328683
avg_episode_per_sec: 3.0510694607825375
collect_time: 1.6387696393898556
reward_mean: 1607.0
reward_std: 432.7401123046875
reward_max: 2321.0
reward_min: 1028.0
total_envstep_count: 1607374
total_train_sample_count: 1607330
total_episode_count: 10685
total_duration: 2032.617566700492
[2024-11-19 23:43:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 206.66666666666666
avg_sample_per_episode: 206.66666666666666
avg_envstep_per_sec: 793.8864944324374
avg_train_sample_per_sec: 793.8864944324374
avg_episode_per_sec: 3.8413862633827613
collect_time: 0.7809680657727378
reward_mean: 1421.3333740234375
reward_std: 91.14944458007812
reward_max: 1536.0
reward_min: 1313.0
total_envstep_count: 1608331
total_train_sample_count: 1608298
total_episode_count: 10688
total_duration: 2033.3985347662647
[2024-11-19 23:43:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1248
train_sample_count: 1248
avg_envstep_per_episode: 178.28571428571428
avg_sample_per_episode: 178.28571428571428
avg_envstep_per_sec: 804.8298225133055
avg_train_sample_per_sec: 804.8298225133055
avg_episode_per_sec: 4.514269837815014
collect_time: 1.5506383648940494
reward_mean: 1142.857177734375
reward_std: 713.42822265625
reward_max: 2326.0
reward_min: 245.0
total_envstep_count: 1609357
total_train_sample_count: 1609318
total_episode_count: 10695
total_duration: 2034.9491731311587
[2024-11-19 23:43:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 569
train_sample_count: 569
avg_envstep_per_episode: 142.25
avg_sample_per_episode: 142.25
avg_envstep_per_sec: 804.7780747364097
avg_train_sample_per_sec: 804.7780747364097
avg_episode_per_sec: 5.657490859306923
collect_time: 0.7070272139140539
reward_mean: 758.5
reward_std: 438.4840393066406
reward_max: 1338.0
reward_min: 103.0
total_envstep_count: 1610378
total_train_sample_count: 1610343
total_episode_count: 10699
total_duration: 2035.6562003450726
[2024-11-19 23:43:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 927
train_sample_count: 927
avg_envstep_per_episode: 185.4
avg_sample_per_episode: 185.4
avg_envstep_per_sec: 804.2000296845442
avg_train_sample_per_sec: 804.2000296845442
avg_episode_per_sec: 4.337648488050401
collect_time: 1.152698291199548
reward_mean: 810.4000244140625
reward_std: 650.807373046875
reward_max: 1757.0
reward_min: 113.0
total_envstep_count: 1611414
total_train_sample_count: 1611366
total_episode_count: 10704
total_duration: 2036.8088986362723
[2024-11-19 23:43:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 726
train_sample_count: 726
avg_envstep_per_episode: 181.5
avg_sample_per_episode: 181.5
avg_envstep_per_sec: 801.0128458366727
avg_train_sample_per_sec: 801.0128458366727
avg_episode_per_sec: 4.413293916455497
collect_time: 0.9063525057974315
reward_mean: 696.25
reward_std: 421.8852844238281
reward_max: 1323.0
reward_min: 136.0
total_envstep_count: 1612378
total_train_sample_count: 1612344
total_episode_count: 10708
total_duration: 2037.7152511420697
[2024-11-19 23:43:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 515
train_sample_count: 515
avg_envstep_per_episode: 257.5
avg_sample_per_episode: 257.5
avg_envstep_per_sec: 796.7310524502334
avg_train_sample_per_sec: 796.7310524502334
avg_episode_per_sec: 3.0941011745640132
collect_time: 0.646391273964019
reward_mean: 1119.0
reward_std: 329.0
reward_max: 1448.0
reward_min: 790.0
total_envstep_count: 1613345
total_train_sample_count: 1613327
total_episode_count: 10710
total_duration: 2038.3616424160339
[2024-11-19 23:44:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2095
train_sample_count: 2095
avg_envstep_per_episode: 419.0
avg_sample_per_episode: 419.0
avg_envstep_per_sec: 802.0812716755787
avg_train_sample_per_sec: 802.0812716755787
avg_episode_per_sec: 1.9142751113975627
collect_time: 2.6119547656604225
reward_mean: 1221.0
reward_std: 565.6094360351562
reward_max: 2223.0
reward_min: 587.0
total_envstep_count: 1614327
total_train_sample_count: 1614294
total_episode_count: 10715
total_duration: 2040.9735971816942
[2024-11-19 23:44:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1445
train_sample_count: 1445
avg_envstep_per_episode: 206.42857142857142
avg_sample_per_episode: 206.42857142857142
avg_envstep_per_sec: 806.03568789658
avg_train_sample_per_sec: 806.03568789658
avg_episode_per_sec: 3.90467115244018
collect_time: 1.7927245923451016
reward_mean: 1126.5714111328125
reward_std: 404.3127746582031
reward_max: 1583.0
reward_min: 619.0
total_envstep_count: 1615353
total_train_sample_count: 1615319
total_episode_count: 10722
total_duration: 2042.7663217740394
[2024-11-19 23:44:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 786
train_sample_count: 786
avg_envstep_per_episode: 196.5
avg_sample_per_episode: 196.5
avg_envstep_per_sec: 795.4738805689434
avg_train_sample_per_sec: 795.4738805689434
avg_episode_per_sec: 4.048213132666379
collect_time: 0.9880902682031905
reward_mean: 1495.75
reward_std: 503.7779235839844
reward_max: 1916.0
reward_min: 654.0
total_envstep_count: 1616351
total_train_sample_count: 1616309
total_episode_count: 10726
total_duration: 2043.7544120422426
[2024-11-19 23:44:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 866
train_sample_count: 866
avg_envstep_per_episode: 173.2
avg_sample_per_episode: 173.2
avg_envstep_per_sec: 788.5100131371969
avg_train_sample_per_sec: 788.5100131371969
avg_episode_per_sec: 4.5525982282748085
collect_time: 1.0982739414487566
reward_mean: 1357.0
reward_std: 454.3333435058594
reward_max: 1853.0
reward_min: 625.0
total_envstep_count: 1617307
total_train_sample_count: 1617283
total_episode_count: 10731
total_duration: 2044.8526859836913
[2024-11-19 23:44:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1570
train_sample_count: 1570
avg_envstep_per_episode: 174.44444444444446
avg_sample_per_episode: 174.44444444444446
avg_envstep_per_sec: 796.5309406756558
avg_train_sample_per_sec: 796.5309406756558
avg_episode_per_sec: 4.566100933809492
collect_time: 1.9710470991475242
reward_mean: 1239.111083984375
reward_std: 540.9126586914062
reward_max: 1898.0
reward_min: 621.0
total_envstep_count: 1618362
total_train_sample_count: 1618325
total_episode_count: 10740
total_duration: 2046.8237330828388
[2024-11-19 23:44:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 627
train_sample_count: 627
avg_envstep_per_episode: 156.75
avg_sample_per_episode: 156.75
avg_envstep_per_sec: 798.206750159926
avg_train_sample_per_sec: 798.206750159926
avg_episode_per_sec: 5.0922280711956995
collect_time: 0.785510771331333
reward_mean: 970.75
reward_std: 340.8536071777344
reward_max: 1316.0
reward_min: 619.0
total_envstep_count: 1619343
total_train_sample_count: 1619300
total_episode_count: 10744
total_duration: 2047.60924385417
[2024-11-19 23:44:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 858
train_sample_count: 858
avg_envstep_per_episode: 171.6
avg_sample_per_episode: 171.6
avg_envstep_per_sec: 802.847098957558
avg_train_sample_per_sec: 802.847098957558
avg_episode_per_sec: 4.678596147771317
collect_time: 1.068696643624987
reward_mean: 1099.0
reward_std: 479.6394348144531
reward_max: 1698.0
reward_min: 611.0
total_envstep_count: 1620316
total_train_sample_count: 1620290
total_episode_count: 10749
total_duration: 2048.677940497795
[2024-11-19 23:44:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1202
train_sample_count: 1202
avg_envstep_per_episode: 200.33333333333334
avg_sample_per_episode: 200.33333333333334
avg_envstep_per_sec: 805.8683641618193
avg_train_sample_per_sec: 805.8683641618193
avg_episode_per_sec: 4.022637425100595
collect_time: 1.4915587376980555
reward_mean: 1320.1666259765625
reward_std: 408.96795654296875
reward_max: 1850.0
reward_min: 612.0
total_envstep_count: 1621342
total_train_sample_count: 1621312
total_episode_count: 10755
total_duration: 2050.1694992354933
[2024-11-19 23:44:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1120
train_sample_count: 1120
avg_envstep_per_episode: 160.0
avg_sample_per_episode: 160.0
avg_envstep_per_sec: 798.0278015307769
avg_train_sample_per_sec: 798.0278015307769
avg_episode_per_sec: 4.987673759567355
collect_time: 1.4034598767757416
reward_mean: 1276.2857666015625
reward_std: 482.7438659667969
reward_max: 1859.0
reward_min: 608.0
total_envstep_count: 1622360
total_train_sample_count: 1622324
total_episode_count: 10762
total_duration: 2051.572959112269
[2024-11-19 23:44:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1008
train_sample_count: 1008
avg_envstep_per_episode: 144.0
avg_sample_per_episode: 144.0
avg_envstep_per_sec: 802.186234626649
avg_train_sample_per_sec: 802.186234626649
avg_episode_per_sec: 5.570737740462841
collect_time: 1.2565660646983554
reward_mean: 1072.142822265625
reward_std: 606.3519287109375
reward_max: 2345.0
reward_min: 588.0
total_envstep_count: 1623361
total_train_sample_count: 1623332
total_episode_count: 10769
total_duration: 2052.8295251769673
[2024-11-19 23:44:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 804
train_sample_count: 804
avg_envstep_per_episode: 100.5
avg_sample_per_episode: 100.5
avg_envstep_per_sec: 800.4332281064486
avg_train_sample_per_sec: 800.4332281064486
avg_episode_per_sec: 7.964509732402473
collect_time: 1.0044560517583574
reward_mean: 863.125
reward_std: 503.1188659667969
reward_max: 1917.0
reward_min: 249.0
total_envstep_count: 1624362
total_train_sample_count: 1624328
total_episode_count: 10777
total_duration: 2053.833981228726
[2024-11-19 23:44:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1020
train_sample_count: 1020
avg_envstep_per_episode: 170.0
avg_sample_per_episode: 170.0
avg_envstep_per_sec: 804.5917715084535
avg_train_sample_per_sec: 804.5917715084535
avg_episode_per_sec: 4.732892773579138
collect_time: 1.2677236284528461
reward_mean: 1205.5
reward_std: 455.1039123535156
reward_max: 1651.0
reward_min: 601.0
total_envstep_count: 1625389
total_train_sample_count: 1625348
total_episode_count: 10783
total_duration: 2055.101704857179
[2024-11-19 23:44:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1022
train_sample_count: 1022
avg_envstep_per_episode: 204.4
avg_sample_per_episode: 204.4
avg_envstep_per_sec: 802.0983799022171
avg_train_sample_per_sec: 802.0983799022171
avg_episode_per_sec: 3.924160371341571
collect_time: 1.2741579157965521
reward_mean: 1171.199951171875
reward_std: 525.7145385742188
reward_max: 1899.0
reward_min: 606.0
total_envstep_count: 1626368
total_train_sample_count: 1626334
total_episode_count: 10788
total_duration: 2056.3758627729753
[2024-11-19 23:44:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1277
train_sample_count: 1277
avg_envstep_per_episode: 212.83333333333334
avg_sample_per_episode: 212.83333333333334
avg_envstep_per_sec: 800.0942360420576
avg_train_sample_per_sec: 800.0942360420576
avg_episode_per_sec: 3.7592524794458457
collect_time: 1.5960619917937686
reward_mean: 1297.6666259765625
reward_std: 406.25921630859375
reward_max: 1892.0
reward_min: 601.0
total_envstep_count: 1627371
total_train_sample_count: 1627323
total_episode_count: 10794
total_duration: 2057.971924764769
[2024-11-19 23:44:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 554
train_sample_count: 554
avg_envstep_per_episode: 92.33333333333333
avg_sample_per_episode: 92.33333333333333
avg_envstep_per_sec: 806.1318270350677
avg_train_sample_per_sec: 806.1318270350677
avg_episode_per_sec: 8.730669606877989
collect_time: 0.6872325113841465
reward_mean: 690.0
reward_std: 159.3204345703125
reward_max: 1046.0
reward_min: 610.0
total_envstep_count: 1628358
total_train_sample_count: 1628321
total_episode_count: 10800
total_duration: 2058.659157276153
[2024-11-19 23:44:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1319
train_sample_count: 1319
avg_envstep_per_episode: 219.83333333333334
avg_sample_per_episode: 219.83333333333334
avg_envstep_per_sec: 804.5859045015848
avg_train_sample_per_sec: 804.5859045015848
avg_episode_per_sec: 3.6599813699844645
collect_time: 1.6393526068755557
reward_mean: 1397.6666259765625
reward_std: 604.2415771484375
reward_max: 2323.0
reward_min: 612.0
total_envstep_count: 1629360
total_train_sample_count: 1629304
total_episode_count: 10806
total_duration: 2060.2985098830286
[2024-11-19 23:44:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1153
train_sample_count: 1153
avg_envstep_per_episode: 144.125
avg_sample_per_episode: 144.125
avg_envstep_per_sec: 800.4722140460182
avg_train_sample_per_sec: 800.4722140460182
avg_episode_per_sec: 5.554013627379137
collect_time: 1.4403997787407465
reward_mean: 965.625
reward_std: 415.3350830078125
reward_max: 1581.0
reward_min: 609.0
total_envstep_count: 1630368
total_train_sample_count: 1630325
total_episode_count: 10814
total_duration: 2061.7389096617694
[2024-11-19 23:45:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 796
train_sample_count: 796
avg_envstep_per_episode: 132.66666666666666
avg_sample_per_episode: 132.66666666666666
avg_envstep_per_sec: 795.8000818506749
avg_train_sample_per_sec: 795.8000818506749
avg_episode_per_sec: 5.998493079276444
collect_time: 1.0002512165478297
reward_mean: 1017.8333129882812
reward_std: 428.3711242675781
reward_max: 1600.0
reward_min: 598.0
total_envstep_count: 1631355
total_train_sample_count: 1631313
total_episode_count: 10820
total_duration: 2062.7391608783173
[2024-11-19 23:45:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 400
train_sample_count: 400
avg_envstep_per_episode: 200.0
avg_sample_per_episode: 200.0
avg_envstep_per_sec: 802.8435193432899
avg_train_sample_per_sec: 802.8435193432899
avg_episode_per_sec: 4.01421759671645
collect_time: 0.49822909491402767
reward_mean: 1301.5
reward_std: 258.5
reward_max: 1560.0
reward_min: 1043.0
total_envstep_count: 1632313
total_train_sample_count: 1632277
total_episode_count: 10822
total_duration: 2063.2373899732315
[2024-11-19 23:45:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1554
train_sample_count: 1554
avg_envstep_per_episode: 194.25
avg_sample_per_episode: 194.25
avg_envstep_per_sec: 802.3440853137885
avg_train_sample_per_sec: 802.3440853137885
avg_episode_per_sec: 4.130471481666865
collect_time: 1.9368248965059007
reward_mean: 1260.625
reward_std: 388.267578125
reward_max: 1664.0
reward_min: 606.0
total_envstep_count: 1633354
total_train_sample_count: 1633303
total_episode_count: 10830
total_duration: 2065.1742148697376
[2024-11-19 23:45:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1165
train_sample_count: 1165
avg_envstep_per_episode: 129.44444444444446
avg_sample_per_episode: 129.44444444444446
avg_envstep_per_sec: 796.4617079061129
avg_train_sample_per_sec: 796.4617079061129
avg_episode_per_sec: 6.152923065369112
collect_time: 1.4627194106578825
reward_mean: 806.3333129882812
reward_std: 534.0193481445312
reward_max: 2316.0
reward_min: 590.0
total_envstep_count: 1634332
total_train_sample_count: 1634300
total_episode_count: 10839
total_duration: 2066.6369342803955
[2024-11-19 23:45:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 938
train_sample_count: 938
avg_envstep_per_episode: 117.25
avg_sample_per_episode: 117.25
avg_envstep_per_sec: 801.9490258687367
avg_train_sample_per_sec: 801.9490258687367
avg_episode_per_sec: 6.839650540458309
collect_time: 1.1696504013878959
reward_mean: 878.875
reward_std: 404.54400634765625
reward_max: 1575.0
reward_min: 603.0
total_envstep_count: 1635341
total_train_sample_count: 1635310
total_episode_count: 10847
total_duration: 2067.8065846817835
[2024-11-19 23:45:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1320
train_sample_count: 1320
avg_envstep_per_episode: 132.0
avg_sample_per_episode: 132.0
avg_envstep_per_sec: 801.2752666016224
avg_train_sample_per_sec: 801.2752666016224
avg_episode_per_sec: 6.070267171224413
collect_time: 1.647373948778425
reward_mean: 1063.5999755859375
reward_std: 441.3266906738281
reward_max: 1579.0
reward_min: 560.0
total_envstep_count: 1636356
total_train_sample_count: 1636318
total_episode_count: 10857
total_duration: 2069.453958630562
[2024-11-19 23:45:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 799
train_sample_count: 799
avg_envstep_per_episode: 99.875
avg_sample_per_episode: 99.875
avg_envstep_per_sec: 801.5653288963894
avg_train_sample_per_sec: 801.5653288963894
avg_episode_per_sec: 8.02568539570853
collect_time: 0.9967996009758539
reward_mean: 688.125
reward_std: 239.47674560546875
reward_max: 1046.0
reward_min: 252.0
total_envstep_count: 1637388
total_train_sample_count: 1637345
total_episode_count: 10865
total_duration: 2070.4507582315377
[2024-11-19 23:45:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 208
train_sample_count: 208
avg_envstep_per_episode: 104.0
avg_sample_per_episode: 104.0
avg_envstep_per_sec: 807.7530030259292
avg_train_sample_per_sec: 807.7530030259292
avg_episode_per_sec: 7.766855798326242
collect_time: 0.25750445893832613
reward_mean: 837.5
reward_std: 212.5
reward_max: 1050.0
reward_min: 625.0
total_envstep_count: 1638346
total_train_sample_count: 1638309
total_episode_count: 10867
total_duration: 2070.708262690476
[2024-11-19 23:45:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 844
train_sample_count: 844
avg_envstep_per_episode: 211.0
avg_sample_per_episode: 211.0
avg_envstep_per_sec: 796.2299599365437
avg_train_sample_per_sec: 796.2299599365437
avg_episode_per_sec: 3.7736017058603966
collect_time: 1.0599952808448245
reward_mean: 860.75
reward_std: 333.4001770019531
reward_max: 1435.0
reward_min: 612.0
total_envstep_count: 1639342
total_train_sample_count: 1639297
total_episode_count: 10871
total_duration: 2071.768257971321
[2024-11-19 23:45:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1778
train_sample_count: 1778
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 803.1126992808856
avg_train_sample_per_sec: 803.1126992808856
avg_episode_per_sec: 3.161861020790888
collect_time: 2.2138860481125966
reward_mean: 1154.7142333984375
reward_std: 400.5327453613281
reward_max: 1631.0
reward_min: 607.0
total_envstep_count: 1640329
total_train_sample_count: 1640283
total_episode_count: 10878
total_duration: 2073.9821440194337
[2024-11-19 23:45:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 939
train_sample_count: 939
avg_envstep_per_episode: 187.8
avg_sample_per_episode: 187.8
avg_envstep_per_sec: 804.081304808509
avg_train_sample_per_sec: 804.081304808509
avg_episode_per_sec: 4.2815830926970655
collect_time: 1.1677923543112618
reward_mean: 998.5999755859375
reward_std: 440.7065124511719
reward_max: 1540.0
reward_min: 610.0
total_envstep_count: 1641286
total_train_sample_count: 1641270
total_episode_count: 10883
total_duration: 2075.149936373745
[2024-11-19 23:45:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1054
train_sample_count: 1054
avg_envstep_per_episode: 175.66666666666666
avg_sample_per_episode: 175.66666666666666
avg_envstep_per_sec: 808.3583381628983
avg_train_sample_per_sec: 808.3583381628983
avg_episode_per_sec: 4.601660369048758
collect_time: 1.3038771918841772
reward_mean: 1268.3333740234375
reward_std: 406.3782043457031
reward_max: 1785.0
reward_min: 609.0
total_envstep_count: 1642313
total_train_sample_count: 1642264
total_episode_count: 10889
total_duration: 2076.453813565629
[2024-11-19 23:45:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 809
train_sample_count: 809
avg_envstep_per_episode: 134.83333333333334
avg_sample_per_episode: 134.83333333333334
avg_envstep_per_sec: 797.7519603712234
avg_train_sample_per_sec: 797.7519603712234
avg_episode_per_sec: 5.916578198056045
collect_time: 1.014099670307977
reward_mean: 881.0
reward_std: 332.8628234863281
reward_max: 1552.0
reward_min: 605.0
total_envstep_count: 1643269
total_train_sample_count: 1643241
total_episode_count: 10895
total_duration: 2077.467913235937
[2024-11-19 23:45:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 777
train_sample_count: 777
avg_envstep_per_episode: 155.4
avg_sample_per_episode: 155.4
avg_envstep_per_sec: 800.4980249468184
avg_train_sample_per_sec: 800.4980249468184
avg_episode_per_sec: 5.151209941742718
collect_time: 0.9706457427569799
reward_mean: 1300.4000244140625
reward_std: 438.89801025390625
reward_max: 1842.0
reward_min: 621.0
total_envstep_count: 1644248
total_train_sample_count: 1644234
total_episode_count: 10900
total_duration: 2078.438558978694
[2024-11-19 23:45:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1618
train_sample_count: 1618
avg_envstep_per_episode: 161.8
avg_sample_per_episode: 161.8
avg_envstep_per_sec: 791.6745305493681
avg_train_sample_per_sec: 791.6745305493681
avg_episode_per_sec: 4.892920460750112
collect_time: 2.0437691722597395
reward_mean: 1183.0
reward_std: 730.41552734375
reward_max: 2353.0
reward_min: 225.0
total_envstep_count: 1645272
total_train_sample_count: 1645240
total_episode_count: 10910
total_duration: 2080.4823281509534
[2024-11-19 23:45:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 717
train_sample_count: 717
avg_envstep_per_episode: 119.5
avg_sample_per_episode: 119.5
avg_envstep_per_sec: 789.7205230593794
avg_train_sample_per_sec: 789.7205230593794
avg_episode_per_sec: 6.608539941919493
collect_time: 0.9079161286354065
reward_mean: 1088.3333740234375
reward_std: 442.2053527832031
reward_max: 1577.0
reward_min: 638.0
total_envstep_count: 1646275
total_train_sample_count: 1646233
total_episode_count: 10916
total_duration: 2081.390244279589
[2024-11-19 23:46:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 564
train_sample_count: 564
avg_envstep_per_episode: 188.0
avg_sample_per_episode: 188.0
avg_envstep_per_sec: 794.6916784967477
avg_train_sample_per_sec: 794.6916784967477
avg_episode_per_sec: 4.227083396259296
collect_time: 0.7097092057977403
reward_mean: 1387.6666259765625
reward_std: 532.7615356445312
reward_max: 1903.0
reward_min: 654.0
total_envstep_count: 1647273
total_train_sample_count: 1647229
total_episode_count: 10919
total_duration: 2082.099953485387
[2024-11-19 23:46:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1616
train_sample_count: 1616
avg_envstep_per_episode: 230.85714285714286
avg_sample_per_episode: 230.85714285714286
avg_envstep_per_sec: 794.5703813802753
avg_train_sample_per_sec: 794.5703813802753
avg_episode_per_sec: 3.4418271470680244
collect_time: 2.033803471497127
reward_mean: 1507.5714111328125
reward_std: 371.8797302246094
reward_max: 1776.0
reward_min: 609.0
total_envstep_count: 1648275
total_train_sample_count: 1648233
total_episode_count: 10926
total_duration: 2084.133756956884
[2024-11-19 23:46:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 645
train_sample_count: 645
avg_envstep_per_episode: 107.5
avg_sample_per_episode: 107.5
avg_envstep_per_sec: 799.234931253374
avg_train_sample_per_sec: 799.234931253374
avg_episode_per_sec: 7.4347435465430145
collect_time: 0.8070217839309148
reward_mean: 871.5
reward_std: 290.5694274902344
reward_max: 1433.0
reward_min: 636.0
total_envstep_count: 1649255
total_train_sample_count: 1649214
total_episode_count: 10932
total_duration: 2084.940778740815
[2024-11-19 23:46:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1379
train_sample_count: 1379
avg_envstep_per_episode: 153.22222222222223
avg_sample_per_episode: 153.22222222222223
avg_envstep_per_sec: 794.4601676748123
avg_train_sample_per_sec: 794.4601676748123
avg_episode_per_sec: 5.185019223403415
collect_time: 1.735769842352186
reward_mean: 1031.5555419921875
reward_std: 535.3209228515625
reward_max: 2317.0
reward_min: 606.0
total_envstep_count: 1650254
total_train_sample_count: 1650209
total_episode_count: 10941
total_duration: 2086.676548583167
[2024-11-19 23:46:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 584
train_sample_count: 584
avg_envstep_per_episode: 116.8
avg_sample_per_episode: 116.8
avg_envstep_per_sec: 802.2911740729857
avg_train_sample_per_sec: 802.2911740729857
avg_episode_per_sec: 6.8689312848714525
collect_time: 0.7279152742453984
reward_mean: 813.7999877929688
reward_std: 309.1228942871094
reward_max: 1428.0
reward_min: 618.0
total_envstep_count: 1651258
total_train_sample_count: 1651213
total_episode_count: 10946
total_duration: 2087.4044638574123
[2024-11-19 23:46:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1145
train_sample_count: 1145
avg_envstep_per_episode: 229.0
avg_sample_per_episode: 229.0
avg_envstep_per_sec: 803.1102639351778
avg_train_sample_per_sec: 803.1102639351778
avg_episode_per_sec: 3.5070317202409513
collect_time: 1.4257070933069502
reward_mean: 1510.199951171875
reward_std: 465.42987060546875
reward_max: 1914.0
reward_min: 620.0
total_envstep_count: 1652245
total_train_sample_count: 1652214
total_episode_count: 10951
total_duration: 2088.830170950719
[2024-11-19 23:46:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 576
train_sample_count: 576
avg_envstep_per_episode: 115.2
avg_sample_per_episode: 115.2
avg_envstep_per_sec: 808.9364655741663
avg_train_sample_per_sec: 808.9364655741663
avg_episode_per_sec: 7.022017930331304
collect_time: 0.7120460314410072
reward_mean: 961.2000122070312
reward_std: 389.388427734375
reward_max: 1439.0
reward_min: 629.0
total_envstep_count: 1653209
total_train_sample_count: 1653186
total_episode_count: 10956
total_duration: 2089.54221698216
[2024-11-19 23:46:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1338
train_sample_count: 1338
avg_envstep_per_episode: 191.14285714285714
avg_sample_per_episode: 191.14285714285714
avg_envstep_per_sec: 799.2574483623594
avg_train_sample_per_sec: 799.2574483623594
avg_episode_per_sec: 4.1814664712530005
collect_time: 1.6740538392748152
reward_mean: 1252.4285888671875
reward_std: 526.49267578125
reward_max: 1903.0
reward_min: 654.0
total_envstep_count: 1654218
total_train_sample_count: 1654176
total_episode_count: 10963
total_duration: 2091.2162708214346
[2024-11-19 23:46:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 698
train_sample_count: 698
avg_envstep_per_episode: 139.6
avg_sample_per_episode: 139.6
avg_envstep_per_sec: 794.4865551236253
avg_train_sample_per_sec: 794.4865551236253
avg_episode_per_sec: 5.691164434982989
collect_time: 0.8785548295293536
reward_mean: 1132.4000244140625
reward_std: 602.0928344726562
reward_max: 1859.0
reward_min: 232.0
total_envstep_count: 1655205
total_train_sample_count: 1655162
total_episode_count: 10968
total_duration: 2092.094825650964
[2024-11-19 23:46:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1830
train_sample_count: 1830
avg_envstep_per_episode: 203.33333333333334
avg_sample_per_episode: 203.33333333333334
avg_envstep_per_sec: 712.5534738771632
avg_train_sample_per_sec: 712.5534738771632
avg_episode_per_sec: 3.504361346936869
collect_time: 2.568228304386139
reward_mean: 1236.4444580078125
reward_std: 527.9631958007812
reward_max: 2325.0
reward_min: 625.0
total_envstep_count: 1656181
total_train_sample_count: 1656164
total_episode_count: 10977
total_duration: 2094.6630539553503
[2024-11-19 23:46:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 930
train_sample_count: 930
avg_envstep_per_episode: 116.25
avg_sample_per_episode: 116.25
avg_envstep_per_sec: 816.5272576600794
avg_train_sample_per_sec: 816.5272576600794
avg_episode_per_sec: 7.023890388473801
collect_time: 1.1389699379603067
reward_mean: 790.125
reward_std: 283.6117248535156
reward_max: 1434.0
reward_min: 597.0
total_envstep_count: 1657205
total_train_sample_count: 1657154
total_episode_count: 10985
total_duration: 2095.8020238933104
[2024-11-19 23:46:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 556
train_sample_count: 556
avg_envstep_per_episode: 92.66666666666667
avg_sample_per_episode: 92.66666666666667
avg_envstep_per_sec: 810.8787870278188
avg_train_sample_per_sec: 810.8787870278188
avg_episode_per_sec: 8.750490507494447
collect_time: 0.6856758480980282
reward_mean: 759.3333129882812
reward_std: 251.80526733398438
reward_max: 1322.0
reward_min: 627.0
total_envstep_count: 1658193
total_train_sample_count: 1658166
total_episode_count: 10991
total_duration: 2096.4876997414085
[2024-11-19 23:46:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1269
train_sample_count: 1269
avg_envstep_per_episode: 141.0
avg_sample_per_episode: 141.0
avg_envstep_per_sec: 809.8565477886895
avg_train_sample_per_sec: 809.8565477886895
avg_episode_per_sec: 5.743663459494251
collect_time: 1.5669441748233068
reward_mean: 1183.3333740234375
reward_std: 553.6581420898438
reward_max: 1928.0
reward_min: 614.0
total_envstep_count: 1659178
total_train_sample_count: 1659147
total_episode_count: 11000
total_duration: 2098.0546439162317
[2024-11-19 23:46:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 870
train_sample_count: 870
avg_envstep_per_episode: 217.5
avg_sample_per_episode: 217.5
avg_envstep_per_sec: 811.245873894322
avg_train_sample_per_sec: 811.245873894322
avg_episode_per_sec: 3.7298660868704463
collect_time: 1.0724245607852936
reward_mean: 1075.5
reward_std: 376.41033935546875
reward_max: 1567.0
reward_min: 619.0
total_envstep_count: 1660150
total_train_sample_count: 1660113
total_episode_count: 11004
total_duration: 2099.127068477017
[2024-11-19 23:46:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 698
train_sample_count: 698
avg_envstep_per_episode: 139.6
avg_sample_per_episode: 139.6
avg_envstep_per_sec: 811.2870044401654
avg_train_sample_per_sec: 811.2870044401654
avg_episode_per_sec: 5.811511493124394
collect_time: 0.8603613717215401
reward_mean: 939.4000244140625
reward_std: 360.88702392578125
reward_max: 1437.0
reward_min: 632.0
total_envstep_count: 1661153
total_train_sample_count: 1661099
total_episode_count: 11009
total_duration: 2099.9874298487384
[2024-11-19 23:46:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1172
train_sample_count: 1172
avg_envstep_per_episode: 195.33333333333334
avg_sample_per_episode: 195.33333333333334
avg_envstep_per_sec: 807.7268390287134
avg_train_sample_per_sec: 807.7268390287134
avg_episode_per_sec: 4.135120336324471
collect_time: 1.4509855849402291
reward_mean: 1288.3333740234375
reward_std: 493.1841125488281
reward_max: 1894.0
reward_min: 617.0
total_envstep_count: 1662116
total_train_sample_count: 1662079
total_episode_count: 11015
total_duration: 2101.4384154336785
[2024-11-19 23:46:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 467
train_sample_count: 467
avg_envstep_per_episode: 116.75
avg_sample_per_episode: 116.75
avg_envstep_per_sec: 804.3214553410783
avg_train_sample_per_sec: 804.3214553410783
avg_episode_per_sec: 6.889263000780113
collect_time: 0.5806136301585606
reward_mean: 846.0
reward_std: 446.9613952636719
reward_max: 1431.0
reward_min: 238.0
total_envstep_count: 1663088
total_train_sample_count: 1663062
total_episode_count: 11019
total_duration: 2102.019029063837
[2024-11-19 23:47:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 830
train_sample_count: 830
avg_envstep_per_episode: 207.5
avg_sample_per_episode: 207.5
avg_envstep_per_sec: 809.6158755489794
avg_train_sample_per_sec: 809.6158755489794
avg_episode_per_sec: 3.901763255657732
collect_time: 1.0251775256225042
reward_mean: 1017.0
reward_std: 424.4590759277344
reward_max: 1566.0
reward_min: 601.0
total_envstep_count: 1664092
total_train_sample_count: 1664048
total_episode_count: 11023
total_duration: 2103.0442065894595
[2024-11-19 23:47:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 867
train_sample_count: 867
avg_envstep_per_episode: 144.5
avg_sample_per_episode: 144.5
avg_envstep_per_sec: 802.6196528680216
avg_train_sample_per_sec: 802.6196528680216
avg_episode_per_sec: 5.554461265522641
collect_time: 1.0802127718925476
reward_mean: 902.1666870117188
reward_std: 392.4166259765625
reward_max: 1572.0
reward_min: 606.0
total_envstep_count: 1665086
total_train_sample_count: 1665047
total_episode_count: 11029
total_duration: 2104.124419361352
[2024-11-19 23:47:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1832
train_sample_count: 1832
avg_envstep_per_episode: 261.7142857142857
avg_sample_per_episode: 261.7142857142857
avg_envstep_per_sec: 805.4147528089939
avg_train_sample_per_sec: 805.4147528089939
avg_episode_per_sec: 3.0774581166282515
collect_time: 2.2746044737952094
reward_mean: 1310.4285888671875
reward_std: 553.8341064453125
reward_max: 2319.0
reward_min: 650.0
total_envstep_count: 1666104
total_train_sample_count: 1666075
total_episode_count: 11036
total_duration: 2106.399023835147
[2024-11-19 23:47:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1129
train_sample_count: 1129
avg_envstep_per_episode: 141.125
avg_sample_per_episode: 141.125
avg_envstep_per_sec: 798.9354226073051
avg_train_sample_per_sec: 798.9354226073051
avg_episode_per_sec: 5.661189885614208
collect_time: 1.4131304834570204
reward_mean: 952.375
reward_std: 445.8783264160156
reward_max: 1691.0
reward_min: 610.0
total_envstep_count: 1667089
total_train_sample_count: 1667060
total_episode_count: 11044
total_duration: 2107.812154318604
[2024-11-19 23:47:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 553
train_sample_count: 553
avg_envstep_per_episode: 184.33333333333334
avg_sample_per_episode: 184.33333333333334
avg_envstep_per_sec: 813.3755391463808
avg_train_sample_per_sec: 813.3755391463808
avg_episode_per_sec: 4.412525528823043
collect_time: 0.6798827520438603
reward_mean: 1160.3333740234375
reward_std: 363.80975341796875
reward_max: 1429.0
reward_min: 646.0
total_envstep_count: 1668102
total_train_sample_count: 1668057
total_episode_count: 11047
total_duration: 2108.4920370706477
[2024-11-19 23:47:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1189
train_sample_count: 1189
avg_envstep_per_episode: 198.16666666666666
avg_sample_per_episode: 198.16666666666666
avg_envstep_per_sec: 799.0324851225015
avg_train_sample_per_sec: 799.0324851225015
avg_episode_per_sec: 4.032123558229612
collect_time: 1.4880496377036683
reward_mean: 1208.6666259765625
reward_std: 241.86886596679688
reward_max: 1419.0
reward_min: 751.0
total_envstep_count: 1669112
total_train_sample_count: 1669066
total_episode_count: 11053
total_duration: 2109.9800867083513
[2024-11-19 23:47:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1330
train_sample_count: 1330
avg_envstep_per_episode: 133.0
avg_sample_per_episode: 133.0
avg_envstep_per_sec: 799.2506414528655
avg_train_sample_per_sec: 799.2506414528655
avg_episode_per_sec: 6.009403319194477
collect_time: 1.6640587207816895
reward_mean: 1005.4000244140625
reward_std: 434.5984802246094
reward_max: 1920.0
reward_min: 619.0
total_envstep_count: 1670088
total_train_sample_count: 1670060
total_episode_count: 11063
total_duration: 2111.644145429133
[2024-11-19 23:47:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 877
train_sample_count: 877
avg_envstep_per_episode: 97.44444444444444
avg_sample_per_episode: 97.44444444444444
avg_envstep_per_sec: 800.3113913832011
avg_train_sample_per_sec: 800.3113913832011
avg_episode_per_sec: 8.213001735973558
collect_time: 1.095823462520327
reward_mean: 754.7777709960938
reward_std: 215.7893829345703
reward_max: 1345.0
reward_min: 591.0
total_envstep_count: 1671129
total_train_sample_count: 1671093
total_episode_count: 11072
total_duration: 2112.7399688916535
[2024-11-19 23:47:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 980
train_sample_count: 980
avg_envstep_per_episode: 122.5
avg_sample_per_episode: 122.5
avg_envstep_per_sec: 799.3104777091534
avg_train_sample_per_sec: 799.3104777091534
avg_episode_per_sec: 6.524983491503292
collect_time: 1.2260567418166568
reward_mean: 785.875
reward_std: 446.71728515625
reward_max: 1841.0
reward_min: 239.0
total_envstep_count: 1672129
total_train_sample_count: 1672097
total_episode_count: 11080
total_duration: 2113.96602563347
[2024-11-19 23:47:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 933
train_sample_count: 933
avg_envstep_per_episode: 186.6
avg_sample_per_episode: 186.6
avg_envstep_per_sec: 798.4323910442295
avg_train_sample_per_sec: 798.4323910442295
avg_episode_per_sec: 4.2788445393581425
collect_time: 1.1685397667544228
reward_mean: 1289.199951171875
reward_std: 347.5033264160156
reward_max: 1681.0
reward_min: 739.0
total_envstep_count: 1673109
total_train_sample_count: 1673078
total_episode_count: 11085
total_duration: 2115.1345654002243
[2024-11-19 23:47:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1212
train_sample_count: 1212
avg_envstep_per_episode: 134.66666666666666
avg_sample_per_episode: 134.66666666666666
avg_envstep_per_sec: 806.0738278131024
avg_train_sample_per_sec: 806.0738278131024
avg_episode_per_sec: 5.985696741186405
collect_time: 1.5035843593733653
reward_mean: 1029.111083984375
reward_std: 483.1630859375
reward_max: 1700.0
reward_min: 621.0
total_envstep_count: 1674092
total_train_sample_count: 1674062
total_episode_count: 11094
total_duration: 2116.6381497595976
[2024-11-19 23:47:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 646
train_sample_count: 646
avg_envstep_per_episode: 129.2
avg_sample_per_episode: 129.2
avg_envstep_per_sec: 800.8086215953342
avg_train_sample_per_sec: 800.8086215953342
avg_episode_per_sec: 6.198209145474723
collect_time: 0.8066846217427934
reward_mean: 1009.4000244140625
reward_std: 330.91363525390625
reward_max: 1436.0
reward_min: 619.0
total_envstep_count: 1675079
total_train_sample_count: 1675032
total_episode_count: 11099
total_duration: 2117.4448343813406
[2024-11-19 23:47:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1469
train_sample_count: 1469
avg_envstep_per_episode: 122.41666666666667
avg_sample_per_episode: 122.41666666666667
avg_envstep_per_sec: 805.976283761491
avg_train_sample_per_sec: 805.976283761491
avg_episode_per_sec: 6.5838770627215055
collect_time: 1.8226342754704612
reward_mean: 925.0833129882812
reward_std: 447.7578125
reward_max: 1680.0
reward_min: 233.0
total_envstep_count: 1676085
total_train_sample_count: 1676045
total_episode_count: 11111
total_duration: 2119.267468656811
[2024-11-19 23:47:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 724
train_sample_count: 724
avg_envstep_per_episode: 120.66666666666667
avg_sample_per_episode: 120.66666666666667
avg_envstep_per_sec: 813.6670129796631
avg_train_sample_per_sec: 813.6670129796631
avg_episode_per_sec: 6.743096792649142
collect_time: 0.8897988838808877
reward_mean: 1053.5
reward_std: 407.7629089355469
reward_max: 1575.0
reward_min: 650.0
total_envstep_count: 1677097
total_train_sample_count: 1677057
total_episode_count: 11117
total_duration: 2120.157267540692
[2024-11-19 23:47:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 335
train_sample_count: 335
avg_envstep_per_episode: 111.66666666666667
avg_sample_per_episode: 111.66666666666667
avg_envstep_per_sec: 809.1912673236778
avg_train_sample_per_sec: 809.1912673236778
avg_episode_per_sec: 7.246488961107562
collect_time: 0.41399359277316505
reward_mean: 642.0
reward_std: 4.966554641723633
reward_max: 649.0
reward_min: 638.0
total_envstep_count: 1678079
total_train_sample_count: 1678028
total_episode_count: 11120
total_duration: 2120.571261133465
[2024-11-19 23:47:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1552
train_sample_count: 1552
avg_envstep_per_episode: 221.71428571428572
avg_sample_per_episode: 221.71428571428572
avg_envstep_per_sec: 810.5709883687606
avg_train_sample_per_sec: 810.5709883687606
avg_episode_per_sec: 3.6559258496013687
collect_time: 1.9146996651376995
reward_mean: 1283.857177734375
reward_std: 431.5170593261719
reward_max: 1811.0
reward_min: 637.0
total_envstep_count: 1679049
total_train_sample_count: 1679004
total_episode_count: 11127
total_duration: 2122.4859607986027
[2024-11-19 23:48:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 761
train_sample_count: 761
avg_envstep_per_episode: 190.25
avg_sample_per_episode: 190.25
avg_envstep_per_sec: 805.5793122442432
avg_train_sample_per_sec: 805.5793122442432
avg_episode_per_sec: 4.23431964385936
collect_time: 0.9446617960929871
reward_mean: 1045.25
reward_std: 743.5557861328125
reward_max: 2333.0
reward_min: 607.0
total_envstep_count: 1680029
total_train_sample_count: 1679993
total_episode_count: 11131
total_duration: 2123.4306225946957
[2024-11-19 23:48:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1376
train_sample_count: 1376
avg_envstep_per_episode: 172.0
avg_sample_per_episode: 172.0
avg_envstep_per_sec: 803.1902671784949
avg_train_sample_per_sec: 803.1902671784949
avg_episode_per_sec: 4.669710855688924
collect_time: 1.713168169770922
reward_mean: 1139.625
reward_std: 318.0518493652344
reward_max: 1667.0
reward_min: 653.0
total_envstep_count: 1681013
total_train_sample_count: 1680997
total_episode_count: 11139
total_duration: 2125.1437907644668
[2024-11-19 23:48:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 276
train_sample_count: 276
avg_envstep_per_episode: 138.0
avg_sample_per_episode: 138.0
avg_envstep_per_sec: 806.8003618228009
avg_train_sample_per_sec: 806.8003618228009
avg_episode_per_sec: 5.846379433498557
collect_time: 0.3420920627457755
reward_mean: 844.5
reward_std: 192.5
reward_max: 1037.0
reward_min: 652.0
total_envstep_count: 1682027
total_train_sample_count: 1681969
total_episode_count: 11141
total_duration: 2125.4858828272127
[2024-11-19 23:48:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1570
train_sample_count: 1570
avg_envstep_per_episode: 196.25
avg_sample_per_episode: 196.25
avg_envstep_per_sec: 802.1711450707285
avg_train_sample_per_sec: 802.1711450707285
avg_episode_per_sec: 4.087496280615177
collect_time: 1.9571883252688813
reward_mean: 1256.375
reward_std: 571.4873046875
reward_max: 2328.0
reward_min: 620.0
total_envstep_count: 1682987
total_train_sample_count: 1682951
total_episode_count: 11149
total_duration: 2127.4430711524815
[2024-11-19 23:48:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 841
train_sample_count: 841
avg_envstep_per_episode: 168.2
avg_sample_per_episode: 168.2
avg_envstep_per_sec: 814.848887114753
avg_train_sample_per_sec: 814.848887114753
avg_episode_per_sec: 4.844523704606142
collect_time: 1.0320932056222643
reward_mean: 1128.800048828125
reward_std: 435.88275146484375
reward_max: 1685.0
reward_min: 615.0
total_envstep_count: 1683950
total_train_sample_count: 1683924
total_episode_count: 11154
total_duration: 2128.475164358104
[2024-11-19 23:48:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1034
train_sample_count: 1034
avg_envstep_per_episode: 172.33333333333334
avg_sample_per_episode: 172.33333333333334
avg_envstep_per_sec: 804.1380112416032
avg_train_sample_per_sec: 804.1380112416032
avg_episode_per_sec: 4.666178014941605
collect_time: 1.2858489283493586
reward_mean: 1323.6666259765625
reward_std: 482.67919921875
reward_max: 1857.0
reward_min: 649.0
total_envstep_count: 1684960
total_train_sample_count: 1684922
total_episode_count: 11160
total_duration: 2129.7610132864534
[2024-11-19 23:48:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 536
train_sample_count: 536
avg_envstep_per_episode: 178.66666666666666
avg_sample_per_episode: 178.66666666666666
avg_envstep_per_sec: 804.4416995171243
avg_train_sample_per_sec: 804.4416995171243
avg_episode_per_sec: 4.502472198789874
collect_time: 0.6663006160940443
reward_mean: 1218.0
reward_std: 432.9765319824219
reward_max: 1684.0
reward_min: 641.0
total_envstep_count: 1685917
total_train_sample_count: 1685890
total_episode_count: 11163
total_duration: 2130.427313902547
[2024-11-19 23:48:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1187
train_sample_count: 1187
avg_envstep_per_episode: 237.4
avg_sample_per_episode: 237.4
avg_envstep_per_sec: 802.444323661132
avg_train_sample_per_sec: 802.444323661132
avg_episode_per_sec: 3.3801361569550634
collect_time: 1.479230352810451
reward_mean: 1379.0
reward_std: 199.9169921875
reward_max: 1579.0
reward_min: 1034.0
total_envstep_count: 1686920
total_train_sample_count: 1686885
total_episode_count: 11168
total_duration: 2131.906544255358
[2024-11-19 23:48:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 809
train_sample_count: 809
avg_envstep_per_episode: 161.8
avg_sample_per_episode: 161.8
avg_envstep_per_sec: 804.710062354938
avg_train_sample_per_sec: 804.710062354938
avg_episode_per_sec: 4.97348617030246
collect_time: 1.0053310351712363
reward_mean: 824.0
reward_std: 253.51528930664062
reward_max: 1318.0
reward_min: 624.0
total_envstep_count: 1687939
total_train_sample_count: 1687898
total_episode_count: 11173
total_duration: 2132.911875290529
[2024-11-19 23:48:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 414
train_sample_count: 414
avg_envstep_per_episode: 138.0
avg_sample_per_episode: 138.0
avg_envstep_per_sec: 800.1770903760935
avg_train_sample_per_sec: 800.1770903760935
avg_episode_per_sec: 5.798384712870242
collect_time: 0.517385470015662
reward_mean: 977.6666870117188
reward_std: 470.4871826171875
reward_max: 1643.0
reward_min: 639.0
total_envstep_count: 1688912
total_train_sample_count: 1688876
total_episode_count: 11176
total_duration: 2133.429260760545
[2024-11-19 23:48:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 482
train_sample_count: 482
avg_envstep_per_episode: 160.66666666666666
avg_sample_per_episode: 160.66666666666666
avg_envstep_per_sec: 815.1864646763415
avg_train_sample_per_sec: 815.1864646763415
avg_episode_per_sec: 5.073774676408765
collect_time: 0.5912757643631527
reward_mean: 1307.0
reward_std: 465.6958923339844
reward_max: 1694.0
reward_min: 652.0
total_envstep_count: 1689885
total_train_sample_count: 1689850
total_episode_count: 11179
total_duration: 2134.020536524908
[2024-11-19 23:48:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1016
train_sample_count: 1016
avg_envstep_per_episode: 203.2
avg_sample_per_episode: 203.2
avg_envstep_per_sec: 807.5443996376271
avg_train_sample_per_sec: 807.5443996376271
avg_episode_per_sec: 3.974135824988322
collect_time: 1.2581351569720676
reward_mean: 1246.800048828125
reward_std: 742.2717895507812
reward_max: 2345.0
reward_min: 247.0
total_envstep_count: 1690872
total_train_sample_count: 1690818
total_episode_count: 11184
total_duration: 2135.27867168188
[2024-11-19 23:48:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 758
train_sample_count: 758
avg_envstep_per_episode: 189.5
avg_sample_per_episode: 189.5
avg_envstep_per_sec: 808.6147930233984
avg_train_sample_per_sec: 808.6147930233984
avg_episode_per_sec: 4.267096533105005
collect_time: 0.9374055564403534
reward_mean: 1040.75
reward_std: 392.82080078125
reward_max: 1673.0
reward_min: 639.0
total_envstep_count: 1691844
total_train_sample_count: 1691816
total_episode_count: 11188
total_duration: 2136.2160772383204
[2024-11-19 23:48:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 974
train_sample_count: 974
avg_envstep_per_episode: 324.6666666666667
avg_sample_per_episode: 324.6666666666667
avg_envstep_per_sec: 646.1541028475287
avg_train_sample_per_sec: 646.1541028475287
avg_episode_per_sec: 1.9902077089759613
collect_time: 1.5073803535529544
reward_mean: 1553.3333740234375
reward_std: 555.8088989257812
reward_max: 2326.0
reward_min: 1042.0
total_envstep_count: 1692810
total_train_sample_count: 1692790
total_episode_count: 11191
total_duration: 2137.7234575918733
[2024-11-19 23:49:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 892
train_sample_count: 892
avg_envstep_per_episode: 148.66666666666666
avg_sample_per_episode: 148.66666666666666
avg_envstep_per_sec: 808.0707609904945
avg_train_sample_per_sec: 808.0707609904945
avg_episode_per_sec: 5.435453549263416
collect_time: 1.1038637246404375
reward_mean: 964.6666870117188
reward_std: 489.7522277832031
reward_max: 1900.0
reward_min: 617.0
total_envstep_count: 1693845
total_train_sample_count: 1693790
total_episode_count: 11197
total_duration: 2138.827321316514
[2024-11-19 23:49:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 609
train_sample_count: 609
avg_envstep_per_episode: 152.25
avg_sample_per_episode: 152.25
avg_envstep_per_sec: 812.6673983459592
avg_train_sample_per_sec: 812.6673983459592
avg_episode_per_sec: 5.337716902108106
collect_time: 0.7493840668882643
reward_mean: 904.25
reward_std: 284.5780944824219
reward_max: 1312.0
reward_min: 625.0
total_envstep_count: 1694825
total_train_sample_count: 1694795
total_episode_count: 11201
total_duration: 2139.576705383402
[2024-11-19 23:49:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2313
train_sample_count: 2313
avg_envstep_per_episode: 289.125
avg_sample_per_episode: 289.125
avg_envstep_per_sec: 807.8929715481611
avg_train_sample_per_sec: 807.8929715481611
avg_episode_per_sec: 2.79426881642252
collect_time: 2.86300299848829
reward_mean: 906.125
reward_std: 446.61627197265625
reward_max: 1694.0
reward_min: 607.0
total_envstep_count: 1695843
total_train_sample_count: 1695788
total_episode_count: 11209
total_duration: 2142.4397083818903
[2024-11-19 23:49:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 213
train_sample_count: 213
avg_envstep_per_episode: 106.5
avg_sample_per_episode: 106.5
avg_envstep_per_sec: 807.2469962760052
avg_train_sample_per_sec: 807.2469962760052
avg_episode_per_sec: 7.579784002591598
collect_time: 0.2638597616127559
reward_mean: 703.5
reward_std: 53.5
reward_max: 757.0
reward_min: 650.0
total_envstep_count: 1696801
total_train_sample_count: 1696757
total_episode_count: 11211
total_duration: 2142.703568143503
[2024-11-19 23:49:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1093
train_sample_count: 1093
avg_envstep_per_episode: 136.625
avg_sample_per_episode: 136.625
avg_envstep_per_sec: 816.6988401004071
avg_train_sample_per_sec: 816.6988401004071
avg_episode_per_sec: 5.977667631110024
collect_time: 1.3383146226406097
reward_mean: 1186.75
reward_std: 454.3280029296875
reward_max: 1701.0
reward_min: 609.0
total_envstep_count: 1697795
total_train_sample_count: 1697766
total_episode_count: 11219
total_duration: 2144.0418827661438
[2024-11-19 23:49:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1220
train_sample_count: 1220
avg_envstep_per_episode: 203.33333333333334
avg_sample_per_episode: 203.33333333333334
avg_envstep_per_sec: 796.3772512294425
avg_train_sample_per_sec: 796.3772512294425
avg_episode_per_sec: 3.9166094322759473
collect_time: 1.531937279871532
reward_mean: 1271.8333740234375
reward_std: 652.9426879882812
reward_max: 2283.0
reward_min: 647.0
total_envstep_count: 1698805
total_train_sample_count: 1698746
total_episode_count: 11225
total_duration: 2145.5738200460155
[2024-11-19 23:49:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 599
train_sample_count: 599
avg_envstep_per_episode: 199.66666666666666
avg_sample_per_episode: 199.66666666666666
avg_envstep_per_sec: 803.9902951363255
avg_train_sample_per_sec: 803.9902951363255
avg_episode_per_sec: 4.026662579981597
collect_time: 0.7450338687215533
reward_mean: 1553.6666259765625
reward_std: 719.981689453125
reward_max: 2350.0
reward_min: 606.0
total_envstep_count: 1699778
total_train_sample_count: 1699753
total_episode_count: 11228
total_duration: 2146.3188539147372
[2024-11-19 23:49:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 867
train_sample_count: 867
avg_envstep_per_episode: 144.5
avg_sample_per_episode: 144.5
avg_envstep_per_sec: 793.8937006408556
avg_train_sample_per_sec: 793.8937006408556
avg_episode_per_sec: 5.4940740528778935
collect_time: 1.0920857531683785
reward_mean: 921.0
reward_std: 373.9830627441406
reward_max: 1556.0
reward_min: 616.0
total_envstep_count: 1700760
total_train_sample_count: 1700740
total_episode_count: 11234
total_duration: 2147.4109396679055
[2024-11-19 23:49:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 822
train_sample_count: 822
avg_envstep_per_episode: 205.5
avg_sample_per_episode: 205.5
avg_envstep_per_sec: 809.077272154273
avg_train_sample_per_sec: 809.077272154273
avg_episode_per_sec: 3.9371156795828375
collect_time: 1.0159721800259183
reward_mean: 1379.75
reward_std: 674.6511840820312
reward_max: 2342.0
reward_min: 739.0
total_envstep_count: 1701733
total_train_sample_count: 1701706
total_episode_count: 11238
total_duration: 2148.4269118479315
[2024-11-19 23:49:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2852
train_sample_count: 2852
avg_envstep_per_episode: 407.42857142857144
avg_sample_per_episode: 407.42857142857144
avg_envstep_per_sec: 808.9027030651584
avg_train_sample_per_sec: 808.9027030651584
avg_episode_per_sec: 1.9853853160785797
collect_time: 3.5257639629500246
reward_mean: 1183.857177734375
reward_std: 456.3011169433594
reward_max: 2036.0
reward_min: 587.0
total_envstep_count: 1702767
total_train_sample_count: 1702734
total_episode_count: 11245
total_duration: 2151.9526758108814
[2024-11-19 23:49:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1268
train_sample_count: 1268
avg_envstep_per_episode: 253.6
avg_sample_per_episode: 253.6
avg_envstep_per_sec: 809.5024419657805
avg_train_sample_per_sec: 809.5024419657805
avg_episode_per_sec: 3.192044329518062
collect_time: 1.5663942864962985
reward_mean: 1609.800048828125
reward_std: 434.1867980957031
reward_max: 2324.0
reward_min: 1042.0
total_envstep_count: 1703763
total_train_sample_count: 1703726
total_episode_count: 11250
total_duration: 2153.5190700973776
[2024-11-19 23:49:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 939
train_sample_count: 939
avg_envstep_per_episode: 187.8
avg_sample_per_episode: 187.8
avg_envstep_per_sec: 809.0187293394254
avg_train_sample_per_sec: 809.0187293394254
avg_episode_per_sec: 4.307873958143905
collect_time: 1.1606653417859758
reward_mean: 1193.5999755859375
reward_std: 299.6615295410156
reward_max: 1441.0
reward_min: 604.0
total_envstep_count: 1704744
total_train_sample_count: 1704713
total_episode_count: 11255
total_duration: 2154.679735439164
[2024-11-19 23:49:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 927
train_sample_count: 927
avg_envstep_per_episode: 154.5
avg_sample_per_episode: 154.5
avg_envstep_per_sec: 805.193526250936
avg_train_sample_per_sec: 805.193526250936
avg_episode_per_sec: 5.211608584148453
collect_time: 1.151276022195816
reward_mean: 1067.3333740234375
reward_std: 402.39935302734375
reward_max: 1696.0
reward_min: 636.0
total_envstep_count: 1705740
total_train_sample_count: 1705700
total_episode_count: 11261
total_duration: 2155.8310114613596
[2024-11-19 23:49:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1062
train_sample_count: 1062
avg_envstep_per_episode: 212.4
avg_sample_per_episode: 212.4
avg_envstep_per_sec: 794.6724322307467
avg_train_sample_per_sec: 794.6724322307467
avg_episode_per_sec: 3.7413956319715007
collect_time: 1.3363996999604362
reward_mean: 1632.199951171875
reward_std: 589.16259765625
reward_max: 2355.0
reward_min: 612.0
total_envstep_count: 1706720
total_train_sample_count: 1706678
total_episode_count: 11266
total_duration: 2157.16741116132
[2024-11-19 23:50:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1195
train_sample_count: 1195
avg_envstep_per_episode: 149.375
avg_sample_per_episode: 149.375
avg_envstep_per_sec: 801.6422444373568
avg_train_sample_per_sec: 801.6422444373568
avg_episode_per_sec: 5.366642640584816
collect_time: 1.4906899034976961
reward_mean: 1093.625
reward_std: 425.5977783203125
reward_max: 1689.0
reward_min: 651.0
total_envstep_count: 1707713
total_train_sample_count: 1707669
total_episode_count: 11274
total_duration: 2158.658101064818
[2024-11-19 23:50:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 755
train_sample_count: 755
avg_envstep_per_episode: 125.83333333333333
avg_sample_per_episode: 125.83333333333333
avg_envstep_per_sec: 803.2046909034619
avg_train_sample_per_sec: 803.2046909034619
avg_episode_per_sec: 6.383083636318903
collect_time: 0.93998455007871
reward_mean: 1047.8333740234375
reward_std: 633.182861328125
reward_max: 2352.0
reward_min: 651.0
total_envstep_count: 1708715
total_train_sample_count: 1708676
total_episode_count: 11280
total_duration: 2159.5980856148967
[2024-11-19 23:50:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 998
train_sample_count: 998
avg_envstep_per_episode: 166.33333333333334
avg_sample_per_episode: 166.33333333333334
avg_envstep_per_sec: 803.6899475708132
avg_train_sample_per_sec: 803.6899475708132
avg_episode_per_sec: 4.831803292008897
collect_time: 1.2417724061579931
reward_mean: 1347.0
reward_std: 583.1777954101562
reward_max: 1919.0
reward_min: 235.0
total_envstep_count: 1709709
total_train_sample_count: 1709662
total_episode_count: 11286
total_duration: 2160.8398580210546
[2024-11-19 23:50:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1058
train_sample_count: 1058
avg_envstep_per_episode: 176.33333333333334
avg_sample_per_episode: 176.33333333333334
avg_envstep_per_sec: 803.9804719780765
avg_train_sample_per_sec: 803.9804719780765
avg_episode_per_sec: 4.55943556887378
collect_time: 1.3159523606300356
reward_mean: 1198.5
reward_std: 589.1741943359375
reward_max: 2342.0
reward_min: 595.0
total_envstep_count: 1710719
total_train_sample_count: 1710684
total_episode_count: 11292
total_duration: 2162.1558103816847
[2024-11-19 23:50:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 709
train_sample_count: 709
avg_envstep_per_episode: 177.25
avg_sample_per_episode: 177.25
avg_envstep_per_sec: 804.2205357808174
avg_train_sample_per_sec: 804.2205357808174
avg_episode_per_sec: 4.537210357014485
collect_time: 0.8815989749772208
reward_mean: 1258.25
reward_std: 450.0179748535156
reward_max: 1687.0
reward_min: 616.0
total_envstep_count: 1711692
total_train_sample_count: 1711657
total_episode_count: 11296
total_duration: 2163.037409356662
[2024-11-19 23:50:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 382
train_sample_count: 382
avg_envstep_per_episode: 191.0
avg_sample_per_episode: 191.0
avg_envstep_per_sec: 809.6481263642493
avg_train_sample_per_sec: 809.6481263642493
avg_episode_per_sec: 4.238995425990834
collect_time: 0.47180989810398644
reward_mean: 1639.0
reward_std: 60.0
reward_max: 1699.0
reward_min: 1579.0
total_envstep_count: 1712675
total_train_sample_count: 1712639
total_episode_count: 11298
total_duration: 2163.509219254766
[2024-11-19 23:50:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1567
train_sample_count: 1567
avg_envstep_per_episode: 261.1666666666667
avg_sample_per_episode: 261.1666666666667
avg_envstep_per_sec: 810.9450587735748
avg_train_sample_per_sec: 810.9450587735748
avg_episode_per_sec: 3.1050863769249832
collect_time: 1.9323133953980036
reward_mean: 1265.6666259765625
reward_std: 608.1522827148438
reward_max: 2321.0
reward_min: 651.0
total_envstep_count: 1713671
total_train_sample_count: 1713642
total_episode_count: 11304
total_duration: 2165.441532650164
[2024-11-19 23:50:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 892
train_sample_count: 892
avg_envstep_per_episode: 178.4
avg_sample_per_episode: 178.4
avg_envstep_per_sec: 811.221550255177
avg_train_sample_per_sec: 811.221550255177
avg_episode_per_sec: 4.547205999188212
collect_time: 1.0995763114520483
reward_mean: 1060.0
reward_std: 465.28399658203125
reward_max: 1668.0
reward_min: 650.0
total_envstep_count: 1714683
total_train_sample_count: 1714618
total_episode_count: 11309
total_duration: 2166.541108961616
[2024-11-19 23:50:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1347
train_sample_count: 1347
avg_envstep_per_episode: 192.42857142857142
avg_sample_per_episode: 192.42857142857142
avg_envstep_per_sec: 804.4520690809802
avg_train_sample_per_sec: 804.4520690809802
avg_episode_per_sec: 4.180523001905613
collect_time: 1.674431643315724
reward_mean: 1051.142822265625
reward_std: 295.1219787597656
reward_max: 1404.0
reward_min: 607.0
total_envstep_count: 1715685
total_train_sample_count: 1715641
total_episode_count: 11316
total_duration: 2168.2155406049314
[2024-11-19 23:50:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 896
train_sample_count: 896
avg_envstep_per_episode: 149.33333333333334
avg_sample_per_episode: 149.33333333333334
avg_envstep_per_sec: 807.0433507276201
avg_train_sample_per_sec: 807.0433507276201
avg_episode_per_sec: 5.4043081521938845
collect_time: 1.1102253666945867
reward_mean: 1108.8333740234375
reward_std: 491.40118408203125
reward_max: 1835.0
reward_min: 614.0
total_envstep_count: 1716680
total_train_sample_count: 1716657
total_episode_count: 11322
total_duration: 2169.325765971626
[2024-11-19 23:50:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 853
train_sample_count: 853
avg_envstep_per_episode: 106.625
avg_sample_per_episode: 106.625
avg_envstep_per_sec: 800.2291098322412
avg_train_sample_per_sec: 800.2291098322412
avg_episode_per_sec: 7.5050795763867875
collect_time: 1.0659447269780296
reward_mean: 744.875
reward_std: 305.2357482910156
reward_max: 1333.0
reward_min: 236.0
total_envstep_count: 1717712
total_train_sample_count: 1717654
total_episode_count: 11330
total_duration: 2170.391710698604
[2024-11-19 23:50:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1170
train_sample_count: 1170
avg_envstep_per_episode: 234.0
avg_sample_per_episode: 234.0
avg_envstep_per_sec: 804.9839498131561
avg_train_sample_per_sec: 804.9839498131561
avg_episode_per_sec: 3.4401023496288725
collect_time: 1.4534451280321394
reward_mean: 1484.0
reward_std: 634.8628540039062
reward_max: 2318.0
reward_min: 738.0
total_envstep_count: 1718707
total_train_sample_count: 1718668
total_episode_count: 11335
total_duration: 2171.845155826636
[2024-11-19 23:50:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 797
train_sample_count: 797
avg_envstep_per_episode: 199.25
avg_sample_per_episode: 199.25
avg_envstep_per_sec: 799.5029971511242
avg_train_sample_per_sec: 799.5029971511242
avg_episode_per_sec: 4.012562093606646
collect_time: 0.9968693086079188
reward_mean: 1483.25
reward_std: 312.48309326171875
reward_max: 1861.0
reward_min: 1060.0
total_envstep_count: 1719695
total_train_sample_count: 1719657
total_episode_count: 11339
total_duration: 2172.842025135244
[2024-11-19 23:50:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1244
train_sample_count: 1244
avg_envstep_per_episode: 177.71428571428572
avg_sample_per_episode: 177.71428571428572
avg_envstep_per_sec: 798.2901202279173
avg_train_sample_per_sec: 798.2901202279173
avg_episode_per_sec: 4.4919862070702745
collect_time: 1.5583306976727076
reward_mean: 1256.857177734375
reward_std: 531.4068603515625
reward_max: 1850.0
reward_min: 638.0
total_envstep_count: 1720712
total_train_sample_count: 1720661
total_episode_count: 11346
total_duration: 2174.400355832917
[2024-11-19 23:50:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1206
train_sample_count: 1206
avg_envstep_per_episode: 150.75
avg_sample_per_episode: 150.75
avg_envstep_per_sec: 802.2602695746623
avg_train_sample_per_sec: 802.2602695746623
avg_episode_per_sec: 5.321792832999418
collect_time: 1.5032528042793272
reward_mean: 1111.75
reward_std: 403.8281555175781
reward_max: 1681.0
reward_min: 583.0
total_envstep_count: 1721697
total_train_sample_count: 1721663
total_episode_count: 11354
total_duration: 2175.903608637196
[2024-11-19 23:50:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 560
train_sample_count: 560
avg_envstep_per_episode: 186.66666666666666
avg_sample_per_episode: 186.66666666666666
avg_envstep_per_sec: 807.1217610897285
avg_train_sample_per_sec: 807.1217610897285
avg_episode_per_sec: 4.3238665772664024
collect_time: 0.6938234439917973
reward_mean: 630.0
reward_std: 4.966554641723633
reward_max: 637.0
reward_min: 626.0
total_envstep_count: 1722702
total_train_sample_count: 1722655
total_episode_count: 11357
total_duration: 2176.597432081188
[2024-11-19 23:50:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1218
train_sample_count: 1218
avg_envstep_per_episode: 243.6
avg_sample_per_episode: 243.6
avg_envstep_per_sec: 804.4650843433657
avg_train_sample_per_sec: 804.4650843433657
avg_episode_per_sec: 3.3024018240696456
collect_time: 1.51404955131667
reward_mean: 1099.5999755859375
reward_std: 418.4153747558594
reward_max: 1674.0
reward_min: 606.0
total_envstep_count: 1723658
total_train_sample_count: 1723633
total_episode_count: 11362
total_duration: 2178.1114816325044
[2024-11-19 23:51:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 965
train_sample_count: 965
avg_envstep_per_episode: 160.83333333333334
avg_sample_per_episode: 160.83333333333334
avg_envstep_per_sec: 796.0683771382361
avg_train_sample_per_sec: 796.0683771382361
avg_episode_per_sec: 4.949647940755872
collect_time: 1.2122074280466353
reward_mean: 1105.1666259765625
reward_std: 395.9959411621094
reward_max: 1693.0
reward_min: 595.0
total_envstep_count: 1724676
total_train_sample_count: 1724622
total_episode_count: 11368
total_duration: 2179.323689060551
[2024-11-19 23:51:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1006
train_sample_count: 1006
avg_envstep_per_episode: 143.71428571428572
avg_sample_per_episode: 143.71428571428572
avg_envstep_per_sec: 811.0614945132409
avg_train_sample_per_sec: 811.0614945132409
avg_episode_per_sec: 5.643569047308833
collect_time: 1.2403498462268285
reward_mean: 900.7142944335938
reward_std: 633.8516235351562
reward_max: 2353.0
reward_min: 243.0
total_envstep_count: 1725661
total_train_sample_count: 1725628
total_episode_count: 11375
total_duration: 2180.5640389067776
[2024-11-19 23:51:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1145
train_sample_count: 1145
avg_envstep_per_episode: 229.0
avg_sample_per_episode: 229.0
avg_envstep_per_sec: 805.6277989170917
avg_train_sample_per_sec: 805.6277989170917
avg_episode_per_sec: 3.5180253227820595
collect_time: 1.4212518504687717
reward_mean: 1457.800048828125
reward_std: 577.5875244140625
reward_max: 2330.0
reward_min: 654.0
total_envstep_count: 1726680
total_train_sample_count: 1726629
total_episode_count: 11380
total_duration: 2181.9852907572463
[2024-11-19 23:51:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1060
train_sample_count: 1060
avg_envstep_per_episode: 132.5
avg_sample_per_episode: 132.5
avg_envstep_per_sec: 801.8823106485781
avg_train_sample_per_sec: 801.8823106485781
avg_episode_per_sec: 6.05194196715908
collect_time: 1.3218897410801482
reward_mean: 993.375
reward_std: 435.8927307128906
reward_max: 1704.0
reward_min: 621.0
total_envstep_count: 1727643
total_train_sample_count: 1727617
total_episode_count: 11388
total_duration: 2183.3071804983265
[2024-11-19 23:51:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 790
train_sample_count: 790
avg_envstep_per_episode: 131.66666666666666
avg_sample_per_episode: 131.66666666666666
avg_envstep_per_sec: 819.2784161854325
avg_train_sample_per_sec: 819.2784161854325
avg_episode_per_sec: 6.222367717864044
collect_time: 0.9642631667000907
reward_mean: 837.8333129882812
reward_std: 395.9012451171875
reward_max: 1709.0
reward_min: 594.0
total_envstep_count: 1728653
total_train_sample_count: 1728599
total_episode_count: 11394
total_duration: 2184.2714436650267
[2024-11-19 23:51:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1063
train_sample_count: 1063
avg_envstep_per_episode: 177.16666666666666
avg_sample_per_episode: 177.16666666666666
avg_envstep_per_sec: 722.9109438217666
avg_train_sample_per_sec: 722.9109438217666
avg_episode_per_sec: 4.080400435494449
collect_time: 1.4704439171722958
reward_mean: 1441.8333740234375
reward_std: 616.16162109375
reward_max: 2345.0
reward_min: 624.0
total_envstep_count: 1729633
total_train_sample_count: 1729590
total_episode_count: 11400
total_duration: 2185.741887582199
[2024-11-19 23:51:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1056
train_sample_count: 1056
avg_envstep_per_episode: 150.85714285714286
avg_sample_per_episode: 150.85714285714286
avg_envstep_per_sec: 729.4400594001918
avg_train_sample_per_sec: 729.4400594001918
avg_episode_per_sec: 4.835303424054302
collect_time: 1.447685778141022
reward_mean: 984.8571166992188
reward_std: 624.6332397460938
reward_max: 2354.0
reward_min: 597.0
total_envstep_count: 1730619
total_train_sample_count: 1730574
total_episode_count: 11407
total_duration: 2187.18957336034
[2024-11-19 23:51:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1049
train_sample_count: 1049
avg_envstep_per_episode: 131.125
avg_sample_per_episode: 131.125
avg_envstep_per_sec: 801.9297873155904
avg_train_sample_per_sec: 801.9297873155904
avg_episode_per_sec: 6.115765775524045
collect_time: 1.3080945696149555
reward_mean: 843.75
reward_std: 358.63690185546875
reward_max: 1584.0
reward_min: 621.0
total_envstep_count: 1731589
total_train_sample_count: 1731551
total_episode_count: 11415
total_duration: 2188.4976679299552
[2024-11-19 23:51:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 860
train_sample_count: 860
avg_envstep_per_episode: 122.85714285714286
avg_sample_per_episode: 122.85714285714286
avg_envstep_per_sec: 808.8126476783224
avg_train_sample_per_sec: 808.8126476783224
avg_episode_per_sec: 6.583358760172391
collect_time: 1.0632870325020383
reward_mean: 839.1428833007812
reward_std: 369.9773864746094
reward_max: 1681.0
reward_min: 622.0
total_envstep_count: 1732598
total_train_sample_count: 1732543
total_episode_count: 11422
total_duration: 2189.5609549624573
[2024-11-19 23:51:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 747
train_sample_count: 747
avg_envstep_per_episode: 186.75
avg_sample_per_episode: 186.75
avg_envstep_per_sec: 807.5734077150673
avg_train_sample_per_sec: 807.5734077150673
avg_episode_per_sec: 4.32435559686783
collect_time: 0.9249933106558664
reward_mean: 1411.5
reward_std: 611.8351440429688
reward_max: 2348.0
reward_min: 632.0
total_envstep_count: 1733571
total_train_sample_count: 1733530
total_episode_count: 11426
total_duration: 2190.485948273113
[2024-11-19 23:51:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1013
train_sample_count: 1013
avg_envstep_per_episode: 168.83333333333334
avg_sample_per_episode: 168.83333333333334
avg_envstep_per_sec: 801.2395198122132
avg_train_sample_per_sec: 801.2395198122132
avg_episode_per_sec: 4.745742466804816
collect_time: 1.2642911076545715
reward_mean: 1310.3333740234375
reward_std: 454.7657470703125
reward_max: 1691.0
reward_min: 628.0
total_envstep_count: 1734581
total_train_sample_count: 1734543
total_episode_count: 11432
total_duration: 2191.7502393807677
[2024-11-19 23:52:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1405
train_sample_count: 1405
avg_envstep_per_episode: 200.71428571428572
avg_sample_per_episode: 200.71428571428572
avg_envstep_per_sec: 798.7153407465491
avg_train_sample_per_sec: 798.7153407465491
avg_episode_per_sec: 3.979364686993483
collect_time: 1.7590747645923068
reward_mean: 1490.7142333984375
reward_std: 578.9072875976562
reward_max: 2629.0
reward_min: 622.0
total_envstep_count: 1735598
total_train_sample_count: 1735552
total_episode_count: 11439
total_duration: 2193.50931414536
[2024-11-19 23:52:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 861
train_sample_count: 861
avg_envstep_per_episode: 123.0
avg_sample_per_episode: 123.0
avg_envstep_per_sec: 805.2648325281205
avg_train_sample_per_sec: 805.2648325281205
avg_episode_per_sec: 6.546868557139191
collect_time: 1.0692134627274106
reward_mean: 1011.5714111328125
reward_std: 453.1483154296875
reward_max: 1840.0
reward_min: 630.0
total_envstep_count: 1736584
total_train_sample_count: 1736557
total_episode_count: 11446
total_duration: 2194.5785276080874
[2024-11-19 23:52:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 898
train_sample_count: 898
avg_envstep_per_episode: 149.66666666666666
avg_sample_per_episode: 149.66666666666666
avg_envstep_per_sec: 805.318776519793
avg_train_sample_per_sec: 805.318776519793
avg_episode_per_sec: 5.380749063606634
collect_time: 1.1150863809244973
reward_mean: 1228.6666259765625
reward_std: 663.4462280273438
reward_max: 2354.0
reward_min: 609.0
total_envstep_count: 1737572
total_train_sample_count: 1737539
total_episode_count: 11452
total_duration: 2195.6936139890117
[2024-11-19 23:52:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1314
train_sample_count: 1314
avg_envstep_per_episode: 146.0
avg_sample_per_episode: 146.0
avg_envstep_per_sec: 813.1811720339074
avg_train_sample_per_sec: 813.1811720339074
avg_episode_per_sec: 5.569734055026763
collect_time: 1.6158760743481773
reward_mean: 1040.77783203125
reward_std: 326.872314453125
reward_max: 1425.0
reward_min: 637.0
total_envstep_count: 1738564
total_train_sample_count: 1738517
total_episode_count: 11461
total_duration: 2197.30949006336
[2024-11-19 23:52:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 760
train_sample_count: 760
avg_envstep_per_episode: 190.0
avg_sample_per_episode: 190.0
avg_envstep_per_sec: 801.0289301271956
avg_train_sample_per_sec: 801.0289301271956
avg_episode_per_sec: 4.215941737511556
collect_time: 0.9487797149590083
reward_mean: 1058.0
reward_std: 396.1249694824219
reward_max: 1689.0
reward_min: 705.0
total_envstep_count: 1739520
total_train_sample_count: 1739493
total_episode_count: 11465
total_duration: 2198.258269778319
[2024-11-19 23:52:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 381
train_sample_count: 381
avg_envstep_per_episode: 127.0
avg_sample_per_episode: 127.0
avg_envstep_per_sec: 815.3441514749379
avg_train_sample_per_sec: 815.3441514749379
avg_episode_per_sec: 6.420032688779038
collect_time: 0.46728734033448355
reward_mean: 468.6666564941406
reward_std: 411.74615478515625
reward_max: 1050.0
reward_min: 149.0
total_envstep_count: 1740509
total_train_sample_count: 1740474
total_episode_count: 11468
total_duration: 2198.725557118654
[2024-11-19 23:52:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1435
train_sample_count: 1435
avg_envstep_per_episode: 179.375
avg_sample_per_episode: 179.375
avg_envstep_per_sec: 812.0748447268957
avg_train_sample_per_sec: 812.0748447268957
avg_episode_per_sec: 4.527246521125551
collect_time: 1.7670785018375945
reward_mean: 961.375
reward_std: 410.0527038574219
reward_max: 1824.0
reward_min: 582.0
total_envstep_count: 1741478
total_train_sample_count: 1741453
total_episode_count: 11476
total_duration: 2200.4926356204915
[2024-11-19 23:52:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 673
train_sample_count: 673
avg_envstep_per_episode: 168.25
avg_sample_per_episode: 168.25
avg_envstep_per_sec: 799.5060805353924
avg_train_sample_per_sec: 799.5060805353924
avg_episode_per_sec: 4.751893495009762
collect_time: 0.8417697080544064
reward_mean: 1191.75
reward_std: 462.030517578125
reward_max: 1835.0
reward_min: 742.0
total_envstep_count: 1742466
total_train_sample_count: 1742438
total_episode_count: 11480
total_duration: 2201.334405328546
[2024-11-19 23:52:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1178
train_sample_count: 1178
avg_envstep_per_episode: 294.5
avg_sample_per_episode: 294.5
avg_envstep_per_sec: 808.3550574344927
avg_train_sample_per_sec: 808.3550574344927
avg_episode_per_sec: 2.7448389047011634
collect_time: 1.4572804229600091
reward_mean: 1717.0
reward_std: 35.049964904785156
reward_max: 1777.0
reward_min: 1689.0
total_envstep_count: 1743470
total_train_sample_count: 1743436
total_episode_count: 11484
total_duration: 2202.791685751506
[2024-11-19 23:52:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1064
train_sample_count: 1064
avg_envstep_per_episode: 177.33333333333334
avg_sample_per_episode: 177.33333333333334
avg_envstep_per_sec: 800.6623321131775
avg_train_sample_per_sec: 800.6623321131775
avg_episode_per_sec: 4.515013151014159
collect_time: 1.3288997837475367
reward_mean: 1160.1666259765625
reward_std: 358.4840393066406
reward_max: 1561.0
reward_min: 603.0
total_envstep_count: 1744481
total_train_sample_count: 1744440
total_episode_count: 11490
total_duration: 2204.1205855352537
[2024-11-19 23:52:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1252
train_sample_count: 1252
avg_envstep_per_episode: 156.5
avg_sample_per_episode: 156.5
avg_envstep_per_sec: 805.6140154831248
avg_train_sample_per_sec: 805.6140154831248
avg_episode_per_sec: 5.14769338966853
collect_time: 1.554094114473888
reward_mean: 1258.0
reward_std: 500.2511901855469
reward_max: 1847.0
reward_min: 614.0
total_envstep_count: 1745481
total_train_sample_count: 1745428
total_episode_count: 11498
total_duration: 2205.6746796497278
[2024-11-19 23:52:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 667
train_sample_count: 667
avg_envstep_per_episode: 133.4
avg_sample_per_episode: 133.4
avg_envstep_per_sec: 805.3684101738643
avg_train_sample_per_sec: 805.3684101738643
avg_episode_per_sec: 6.037244454076943
collect_time: 0.8281924043382916
reward_mean: 803.5999755859375
reward_std: 143.0169219970703
reward_max: 1045.0
reward_min: 602.0
total_envstep_count: 1746469
total_train_sample_count: 1746431
total_episode_count: 11503
total_duration: 2206.502872054066
[2024-11-19 23:52:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 955
train_sample_count: 955
avg_envstep_per_episode: 191.0
avg_sample_per_episode: 191.0
avg_envstep_per_sec: 815.6881698010661
avg_train_sample_per_sec: 815.6881698010661
avg_episode_per_sec: 4.270618690057938
collect_time: 1.170790548835482
reward_mean: 1385.0
reward_std: 481.6799621582031
reward_max: 1851.0
reward_min: 623.0
total_envstep_count: 1747457
total_train_sample_count: 1747410
total_episode_count: 11508
total_duration: 2207.6736626029015
[2024-11-19 23:52:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 397
train_sample_count: 397
avg_envstep_per_episode: 198.5
avg_sample_per_episode: 198.5
avg_envstep_per_sec: 820.9181624645377
avg_train_sample_per_sec: 820.9181624645377
avg_episode_per_sec: 4.135607871357872
collect_time: 0.4836048441273825
reward_mean: 1179.5
reward_std: 116.5
reward_max: 1296.0
reward_min: 1063.0
total_envstep_count: 1748431
total_train_sample_count: 1748383
total_episode_count: 11510
total_duration: 2208.157267447029
[2024-11-19 23:52:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1049
train_sample_count: 1049
avg_envstep_per_episode: 209.8
avg_sample_per_episode: 209.8
avg_envstep_per_sec: 810.6447410473104
avg_train_sample_per_sec: 810.6447410473104
avg_episode_per_sec: 3.863892950654482
collect_time: 1.294031709432602
reward_mean: 1315.800048828125
reward_std: 563.2883911132812
reward_max: 2341.0
reward_min: 780.0
total_envstep_count: 1749427
total_train_sample_count: 1749408
total_episode_count: 11515
total_duration: 2209.4512991564616
[2024-11-19 23:52:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 786
train_sample_count: 786
avg_envstep_per_episode: 131.0
avg_sample_per_episode: 131.0
avg_envstep_per_sec: 811.6432964927076
avg_train_sample_per_sec: 811.6432964927076
avg_episode_per_sec: 6.195750354906164
collect_time: 0.9684057065418787
reward_mean: 1067.0
reward_std: 401.392578125
reward_max: 1696.0
reward_min: 633.0
total_envstep_count: 1750470
total_train_sample_count: 1750434
total_episode_count: 11521
total_duration: 2210.4197048630035
[2024-11-19 23:52:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1265
train_sample_count: 1265
avg_envstep_per_episode: 253.0
avg_sample_per_episode: 253.0
avg_envstep_per_sec: 811.2344246684836
avg_train_sample_per_sec: 811.2344246684836
avg_episode_per_sec: 3.206460176555271
collect_time: 1.5593519721712386
reward_mean: 1335.800048828125
reward_std: 683.09423828125
reward_max: 2298.0
reward_min: 236.0
total_envstep_count: 1751449
total_train_sample_count: 1751411
total_episode_count: 11526
total_duration: 2211.9790568351746
[2024-11-19 23:53:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 674
train_sample_count: 674
avg_envstep_per_episode: 134.8
avg_sample_per_episode: 134.8
avg_envstep_per_sec: 806.0458048310312
avg_train_sample_per_sec: 806.0458048310312
avg_episode_per_sec: 5.97956828509667
collect_time: 0.8361807678427016
reward_mean: 1020.7999877929688
reward_std: 447.4815673828125
reward_max: 1678.0
reward_min: 612.0
total_envstep_count: 1752438
total_train_sample_count: 1752397
total_episode_count: 11531
total_duration: 2212.815237603017
[2024-11-19 23:53:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 2310
train_sample_count: 2310
avg_envstep_per_episode: 210.0
avg_sample_per_episode: 210.0
avg_envstep_per_sec: 799.4076413505178
avg_train_sample_per_sec: 799.4076413505178
avg_episode_per_sec: 3.8067030540500846
collect_time: 2.889639628784997
reward_mean: 1175.54541015625
reward_std: 563.187744140625
reward_max: 2349.0
reward_min: 623.0
total_envstep_count: 1753468
total_train_sample_count: 1753435
total_episode_count: 11542
total_duration: 2215.704877231802
[2024-11-19 23:53:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 546
train_sample_count: 546
avg_envstep_per_episode: 182.0
avg_sample_per_episode: 182.0
avg_envstep_per_sec: 781.1197324592185
avg_train_sample_per_sec: 781.1197324592185
avg_episode_per_sec: 4.291866661863838
collect_time: 0.6989965523992265
reward_mean: 1666.6666259765625
reward_std: 179.20069885253906
reward_max: 1870.0
reward_min: 1434.0
total_envstep_count: 1754457
total_train_sample_count: 1754425
total_episode_count: 11545
total_duration: 2216.4038737842016
[2024-11-19 23:53:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1222
train_sample_count: 1222
avg_envstep_per_episode: 203.66666666666666
avg_sample_per_episode: 203.66666666666666
avg_envstep_per_sec: 794.9597077453561
avg_train_sample_per_sec: 794.9597077453561
avg_episode_per_sec: 3.903239154232518
collect_time: 1.5371848259653365
reward_mean: 1449.8333740234375
reward_std: 556.870849609375
reward_max: 1909.0
reward_min: 610.0
total_envstep_count: 1755454
total_train_sample_count: 1755431
total_episode_count: 11551
total_duration: 2217.9410586101667
[2024-11-19 23:53:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1044
train_sample_count: 1044
avg_envstep_per_episode: 208.8
avg_sample_per_episode: 208.8
avg_envstep_per_sec: 796.3631315730132
avg_train_sample_per_sec: 796.3631315730132
avg_episode_per_sec: 3.813999672284546
collect_time: 1.310959735086986
reward_mean: 1557.800048828125
reward_std: 329.0953674316406
reward_max: 1921.0
reward_min: 1043.0
total_envstep_count: 1756452
total_train_sample_count: 1756427
total_episode_count: 11556
total_duration: 2219.252018345254
[2024-11-19 23:53:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 526
train_sample_count: 526
avg_envstep_per_episode: 105.2
avg_sample_per_episode: 105.2
avg_envstep_per_sec: 802.7840371255814
avg_train_sample_per_sec: 802.7840371255814
avg_episode_per_sec: 7.631026968874348
collect_time: 0.6552198046729678
reward_mean: 826.2000122070312
reward_std: 432.8036193847656
reward_max: 1340.0
reward_min: 247.0
total_envstep_count: 1757464
total_train_sample_count: 1757421
total_episode_count: 11561
total_duration: 2219.907238149927
[2024-11-19 23:53:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1384
train_sample_count: 1384
avg_envstep_per_episode: 197.71428571428572
avg_sample_per_episode: 197.71428571428572
avg_envstep_per_sec: 799.3063462005806
avg_train_sample_per_sec: 799.3063462005806
avg_episode_per_sec: 4.0427344099740345
collect_time: 1.7315013280936649
reward_mean: 1083.2857666015625
reward_std: 466.4001159667969
reward_max: 1689.0
reward_min: 237.0
total_envstep_count: 1758434
total_train_sample_count: 1758397
total_episode_count: 11568
total_duration: 2221.6387394780204
[2024-11-19 23:53:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1355
train_sample_count: 1355
avg_envstep_per_episode: 193.57142857142858
avg_sample_per_episode: 193.57142857142858
avg_envstep_per_sec: 813.3893675988262
avg_train_sample_per_sec: 813.3893675988262
avg_episode_per_sec: 4.202011493130467
collect_time: 1.665868837208975
reward_mean: 1359.0
reward_std: 475.74542236328125
reward_max: 2328.0
reward_min: 634.0
total_envstep_count: 1759437
total_train_sample_count: 1759380
total_episode_count: 11575
total_duration: 2223.3046083152294
[2024-11-19 23:53:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 430
train_sample_count: 430
avg_envstep_per_episode: 143.33333333333334
avg_sample_per_episode: 143.33333333333334
avg_envstep_per_sec: 796.9246963557769
avg_train_sample_per_sec: 796.9246963557769
avg_episode_per_sec: 5.559939742017048
collect_time: 0.5395741931029729
reward_mean: 1217.6666259765625
reward_std: 402.4776306152344
reward_max: 1568.0
reward_min: 654.0
total_envstep_count: 1760394
total_train_sample_count: 1760350
total_episode_count: 11578
total_duration: 2223.8441825083323
[2024-11-19 23:53:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1438
train_sample_count: 1438
avg_envstep_per_episode: 143.8
avg_sample_per_episode: 143.8
avg_envstep_per_sec: 799.2306077099021
avg_train_sample_per_sec: 799.2306077099021
avg_episode_per_sec: 5.557931903406829
collect_time: 1.7992303924901147
reward_mean: 1085.800048828125
reward_std: 419.88446044921875
reward_max: 1859.0
reward_min: 617.0
total_envstep_count: 1761369
total_train_sample_count: 1761320
total_episode_count: 11588
total_duration: 2225.6434129008226
[2024-11-19 23:53:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 858
train_sample_count: 858
avg_envstep_per_episode: 143.0
avg_sample_per_episode: 143.0
avg_envstep_per_sec: 802.4402981596808
avg_train_sample_per_sec: 802.4402981596808
avg_episode_per_sec: 5.611470616501264
collect_time: 1.0692384243011475
reward_mean: 1158.8333740234375
reward_std: 259.5286865234375
reward_max: 1326.0
reward_min: 623.0
total_envstep_count: 1762356
total_train_sample_count: 1762310
total_episode_count: 11594
total_duration: 2226.7126513251237
[2024-11-19 23:53:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 575
train_sample_count: 575
avg_envstep_per_episode: 115.0
avg_sample_per_episode: 115.0
avg_envstep_per_sec: 803.8754321832403
avg_train_sample_per_sec: 803.8754321832403
avg_episode_per_sec: 6.990221149419481
collect_time: 0.7152849520955766
reward_mean: 849.5999755859375
reward_std: 418.3656921386719
reward_max: 1686.0
reward_min: 621.0
total_envstep_count: 1763336
total_train_sample_count: 1763293
total_episode_count: 11599
total_duration: 2227.4279362772195
[2024-11-19 23:53:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1038
train_sample_count: 1038
avg_envstep_per_episode: 207.6
avg_sample_per_episode: 207.6
avg_envstep_per_sec: 799.3083790449253
avg_train_sample_per_sec: 799.3083790449253
avg_episode_per_sec: 3.85023303971544
collect_time: 1.2986226933343068
reward_mean: 1590.199951171875
reward_std: 548.2026977539062
reward_max: 2350.0
reward_min: 639.0
total_envstep_count: 1764332
total_train_sample_count: 1764295
total_episode_count: 11604
total_duration: 2228.726558970554
[2024-11-19 23:53:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1317
train_sample_count: 1317
avg_envstep_per_episode: 219.5
avg_sample_per_episode: 219.5
avg_envstep_per_sec: 807.4027734053228
avg_train_sample_per_sec: 807.4027734053228
avg_episode_per_sec: 3.6783725439878032
collect_time: 1.631156150783811
reward_mean: 1652.8333740234375
reward_std: 548.0880126953125
reward_max: 2363.0
reward_min: 606.0
total_envstep_count: 1765351
total_train_sample_count: 1765312
total_episode_count: 11610
total_duration: 2230.3577151213376
[2024-11-19 23:53:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 583
train_sample_count: 583
avg_envstep_per_episode: 145.75
avg_sample_per_episode: 145.75
avg_envstep_per_sec: 807.2772496528373
avg_train_sample_per_sec: 807.2772496528373
avg_episode_per_sec: 5.53878044358722
collect_time: 0.7221806389944894
reward_mean: 871.0
reward_std: 324.3570556640625
reward_max: 1419.0
reward_min: 628.0
total_envstep_count: 1766340
total_train_sample_count: 1766315
total_episode_count: 11614
total_duration: 2231.079895760332
[2024-11-19 23:53:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1159
train_sample_count: 1159
avg_envstep_per_episode: 165.57142857142858
avg_sample_per_episode: 165.57142857142858
avg_envstep_per_sec: 806.8619078528596
avg_train_sample_per_sec: 806.8619078528596
avg_episode_per_sec: 4.8731953019586
collect_time: 1.436429194041661
reward_mean: 1176.5714111328125
reward_std: 495.02606201171875
reward_max: 1688.0
reward_min: 602.0
total_envstep_count: 1767335
total_train_sample_count: 1767294
total_episode_count: 11621
total_duration: 2232.5163249543734
[2024-11-19 23:54:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 736
train_sample_count: 736
avg_envstep_per_episode: 147.2
avg_sample_per_episode: 147.2
avg_envstep_per_sec: 764.9993820793087
avg_train_sample_per_sec: 764.9993820793087
avg_episode_per_sec: 5.197006671734434
collect_time: 0.9620922803878784
reward_mean: 1036.199951171875
reward_std: 486.6926574707031
reward_max: 1855.0
reward_min: 588.0
total_envstep_count: 1768330
total_train_sample_count: 1768282
total_episode_count: 11626
total_duration: 2233.4784172347613
[2024-11-19 23:54:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 957
train_sample_count: 957
avg_envstep_per_episode: 136.71428571428572
avg_sample_per_episode: 136.71428571428572
avg_envstep_per_sec: 779.123494839255
avg_train_sample_per_sec: 779.123494839255
avg_episode_per_sec: 5.6989179350833705
collect_time: 1.2283033515725816
reward_mean: 1074.857177734375
reward_std: 381.5339050292969
reward_max: 1434.0
reward_min: 605.0
total_envstep_count: 1769315
total_train_sample_count: 1769263
total_episode_count: 11633
total_duration: 2234.706720586334
[2024-11-19 23:54:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1663
train_sample_count: 1663
avg_envstep_per_episode: 277.1666666666667
avg_sample_per_episode: 277.1666666666667
avg_envstep_per_sec: 788.1090610974472
avg_train_sample_per_sec: 788.1090610974472
avg_episode_per_sec: 2.843448206004019
collect_time: 2.1101140465055193
reward_mean: 1525.5
reward_std: 705.7962036132812
reward_max: 2347.0
reward_min: 618.0
total_envstep_count: 1770310
total_train_sample_count: 1770278
total_episode_count: 11639
total_duration: 2236.81683463284
[2024-11-19 23:54:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 840
train_sample_count: 840
avg_envstep_per_episode: 168.0
avg_sample_per_episode: 168.0
avg_envstep_per_sec: 803.0849563412136
avg_train_sample_per_sec: 803.0849563412136
avg_episode_per_sec: 4.780267597269128
collect_time: 1.0459665485790797
reward_mean: 1338.0
reward_std: 363.2283020019531
reward_max: 1690.0
reward_min: 653.0
total_envstep_count: 1771338
total_train_sample_count: 1771298
total_episode_count: 11644
total_duration: 2237.862801181419
[2024-11-19 23:54:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 636
train_sample_count: 636
avg_envstep_per_episode: 159.0
avg_sample_per_episode: 159.0
avg_envstep_per_sec: 808.1331480476639
avg_train_sample_per_sec: 808.1331480476639
avg_episode_per_sec: 5.082598415394112
collect_time: 0.7869990255151477
reward_mean: 1356.75
reward_std: 536.8995971679688
reward_max: 1878.0
reward_min: 619.0
total_envstep_count: 1772319
total_train_sample_count: 1772270
total_episode_count: 11648
total_duration: 2238.6498002069343
[2024-11-19 23:54:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1179
train_sample_count: 1179
avg_envstep_per_episode: 131.0
avg_sample_per_episode: 131.0
avg_envstep_per_sec: 806.5015569871181
avg_train_sample_per_sec: 806.5015569871181
avg_episode_per_sec: 6.156500435016169
collect_time: 1.4618694654532844
reward_mean: 1115.6666259765625
reward_std: 465.8166198730469
reward_max: 1882.0
reward_min: 615.0
total_envstep_count: 1773334
total_train_sample_count: 1773281
total_episode_count: 11657
total_duration: 2240.1116696723875
[2024-11-19 23:54:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1246
train_sample_count: 1246
avg_envstep_per_episode: 178.0
avg_sample_per_episode: 178.0
avg_envstep_per_sec: 796.0213053473223
avg_train_sample_per_sec: 796.0213053473223
avg_episode_per_sec: 4.472029805322035
collect_time: 1.5652847375188554
reward_mean: 1315.0
reward_std: 625.1326904296875
reward_max: 2315.0
reward_min: 608.0
total_envstep_count: 1774321
total_train_sample_count: 1774287
total_episode_count: 11664
total_duration: 2241.6769544099066
[2024-11-19 23:54:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 991
train_sample_count: 991
avg_envstep_per_episode: 165.16666666666666
avg_sample_per_episode: 165.16666666666666
avg_envstep_per_sec: 797.1579397399499
avg_train_sample_per_sec: 797.1579397399499
avg_episode_per_sec: 4.826385104379112
collect_time: 1.2431664424283166
reward_mean: 1234.5
reward_std: 470.0679931640625
reward_max: 1857.0
reward_min: 601.0
total_envstep_count: 1775316
total_train_sample_count: 1775266
total_episode_count: 11670
total_duration: 2242.920120852335
[2024-11-19 23:54:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 337
train_sample_count: 337
avg_envstep_per_episode: 112.33333333333333
avg_sample_per_episode: 112.33333333333333
avg_envstep_per_sec: 800.4943106382601
avg_train_sample_per_sec: 800.4943106382601
avg_episode_per_sec: 7.126062112506767
collect_time: 0.42098987528256004
reward_mean: 760.0
reward_std: 202.2391357421875
reward_max: 1046.0
reward_min: 615.0
total_envstep_count: 1776305
total_train_sample_count: 1776251
total_episode_count: 11673
total_duration: 2243.3411107276174
[2024-11-19 23:54:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1600
train_sample_count: 1600
avg_envstep_per_episode: 177.77777777777777
avg_sample_per_episode: 177.77777777777777
avg_envstep_per_sec: 807.7845616017034
avg_train_sample_per_sec: 807.7845616017034
avg_episode_per_sec: 4.543788159009582
collect_time: 1.980726144143513
reward_mean: 1045.0
reward_std: 412.9355773925781
reward_max: 1675.0
reward_min: 592.0
total_envstep_count: 1777272
total_train_sample_count: 1777239
total_episode_count: 11682
total_duration: 2245.3218368717608
[2024-11-19 23:54:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 778
train_sample_count: 778
avg_envstep_per_episode: 194.5
avg_sample_per_episode: 194.5
avg_envstep_per_sec: 803.2753445530972
avg_train_sample_per_sec: 803.2753445530972
avg_episode_per_sec: 4.129950357599471
collect_time: 0.9685346441609519
reward_mean: 1246.5
reward_std: 519.4658203125
reward_max: 1838.0
reward_min: 654.0
total_envstep_count: 1778269
total_train_sample_count: 1778233
total_episode_count: 11686
total_duration: 2246.290371515922
[2024-11-19 23:54:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1436
train_sample_count: 1436
avg_envstep_per_episode: 179.5
avg_sample_per_episode: 179.5
avg_envstep_per_sec: 809.8878808601959
avg_train_sample_per_sec: 809.8878808601959
avg_episode_per_sec: 4.51191019977825
collect_time: 1.7730849342686787
reward_mean: 1326.75
reward_std: 618.1471557617188
reward_max: 2348.0
reward_min: 596.0
total_envstep_count: 1779335
total_train_sample_count: 1779297
total_episode_count: 11694
total_duration: 2248.0634564501906
[2024-11-19 23:54:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 626
train_sample_count: 626
avg_envstep_per_episode: 104.33333333333333
avg_sample_per_episode: 104.33333333333333
avg_envstep_per_sec: 812.0037616844585
avg_train_sample_per_sec: 812.0037616844585
avg_episode_per_sec: 7.782783658317493
collect_time: 0.7709323891571591
reward_mean: 755.3333129882812
reward_std: 254.51040649414062
reward_max: 1324.0
reward_min: 626.0
total_envstep_count: 1780322
total_train_sample_count: 1780271
total_episode_count: 11700
total_duration: 2248.834388839348
[2024-11-19 23:54:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1010
train_sample_count: 1010
avg_envstep_per_episode: 168.33333333333334
avg_sample_per_episode: 168.33333333333334
avg_envstep_per_sec: 811.9008819019816
avg_train_sample_per_sec: 811.9008819019816
avg_episode_per_sec: 4.823173555853356
collect_time: 1.2439942147050584
reward_mean: 1349.1666259765625
reward_std: 361.3831787109375
reward_max: 1691.0
reward_min: 610.0
total_envstep_count: 1781269
total_train_sample_count: 1781245
total_episode_count: 11706
total_duration: 2250.078383054053
[2024-11-19 23:54:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 719
train_sample_count: 719
avg_envstep_per_episode: 143.8
avg_sample_per_episode: 143.8
avg_envstep_per_sec: 810.1911176189722
avg_train_sample_per_sec: 810.1911176189722
avg_episode_per_sec: 5.63415241737811
collect_time: 0.8874449304171972
reward_mean: 1121.4000244140625
reward_std: 403.0407409667969
reward_max: 1573.0
reward_min: 622.0
total_envstep_count: 1782267
total_train_sample_count: 1782240
total_episode_count: 11711
total_duration: 2250.9658279844703
[2024-11-19 23:54:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 375
train_sample_count: 375
avg_envstep_per_episode: 93.75
avg_sample_per_episode: 93.75
avg_envstep_per_sec: 817.0251644230467
avg_train_sample_per_sec: 817.0251644230467
avg_episode_per_sec: 8.714935087179166
collect_time: 0.4589821909155164
reward_mean: 679.5
reward_std: 73.61555480957031
reward_max: 761.0
reward_min: 588.0
total_envstep_count: 1783263
total_train_sample_count: 1783215
total_episode_count: 11715
total_duration: 2251.4248101753856
[2024-11-19 23:54:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1606
train_sample_count: 1606
avg_envstep_per_episode: 321.2
avg_sample_per_episode: 321.2
avg_envstep_per_sec: 813.229336919124
avg_train_sample_per_sec: 813.229336919124
avg_episode_per_sec: 2.5318472506822043
collect_time: 1.9748426760946
reward_mean: 1489.5999755859375
reward_std: 840.536865234375
reward_max: 2332.0
reward_min: 243.0
total_envstep_count: 1784250
total_train_sample_count: 1784209
total_episode_count: 11720
total_duration: 2253.3996528514804
[2024-11-19 23:55:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1173
train_sample_count: 1173
avg_envstep_per_episode: 167.57142857142858
avg_sample_per_episode: 167.57142857142858
avg_envstep_per_sec: 815.7200534619311
avg_train_sample_per_sec: 815.7200534619311
avg_episode_per_sec: 4.8678946071897
collect_time: 1.437993334872382
reward_mean: 786.1428833007812
reward_std: 240.61553955078125
reward_max: 1277.0
reward_min: 622.0
total_envstep_count: 1785259
total_train_sample_count: 1785202
total_episode_count: 11727
total_duration: 2254.8376461863527
[2024-11-19 23:55:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1018
train_sample_count: 1018
avg_envstep_per_episode: 203.6
avg_sample_per_episode: 203.6
avg_envstep_per_sec: 801.9911127592331
avg_train_sample_per_sec: 801.9911127592331
avg_episode_per_sec: 3.939052616695644
collect_time: 1.2693407492978233
reward_mean: 1379.4000244140625
reward_std: 451.01556396484375
reward_max: 1827.0
reward_min: 654.0
total_envstep_count: 1786254
total_train_sample_count: 1786220
total_episode_count: 11732
total_duration: 2256.1069869356506
[2024-11-19 23:55:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1102
train_sample_count: 1102
avg_envstep_per_episode: 122.44444444444444
avg_sample_per_episode: 122.44444444444444
avg_envstep_per_sec: 803.2431040744966
avg_train_sample_per_sec: 803.2431040744966
avg_episode_per_sec: 6.560061648521297
collect_time: 1.3719383265290943
reward_mean: 896.6666870117188
reward_std: 510.7541198730469
reward_max: 1854.0
reward_min: 583.0
total_envstep_count: 1787247
total_train_sample_count: 1787226
total_episode_count: 11741
total_duration: 2257.47892526218
[2024-11-19 23:55:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1210
train_sample_count: 1210
avg_envstep_per_episode: 151.25
avg_sample_per_episode: 151.25
avg_envstep_per_sec: 806.6187715964608
avg_train_sample_per_sec: 806.6187715964608
avg_episode_per_sec: 5.333016671712137
collect_time: 1.5000890663691928
reward_mean: 1066.625
reward_std: 630.9868774414062
reward_max: 2341.0
reward_min: 586.0
total_envstep_count: 1788217
total_train_sample_count: 1788196
total_episode_count: 11749
total_duration: 2258.979014328549
[2024-11-19 23:55:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 762
train_sample_count: 762
avg_envstep_per_episode: 190.5
avg_sample_per_episode: 190.5
avg_envstep_per_sec: 788.3302706382415
avg_train_sample_per_sec: 788.3302706382415
avg_episode_per_sec: 4.1382166437702965
collect_time: 0.9665999497686114
reward_mean: 1346.75
reward_std: 458.39794921875
reward_max: 1854.0
reward_min: 619.0
total_envstep_count: 1789191
total_train_sample_count: 1789162
total_episode_count: 11753
total_duration: 2259.945614278318
[2024-11-19 23:55:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1372
train_sample_count: 1372
avg_envstep_per_episode: 152.44444444444446
avg_sample_per_episode: 152.44444444444446
avg_envstep_per_sec: 793.5845947002296
avg_train_sample_per_sec: 793.5845947002296
avg_episode_per_sec: 5.205729848616666
collect_time: 1.7288642057350703
reward_mean: 1055.6666259765625
reward_std: 506.22174072265625
reward_max: 1856.0
reward_min: 611.0
total_envstep_count: 1790200
total_train_sample_count: 1790174
total_episode_count: 11762
total_duration: 2261.674478484053
[2024-11-19 23:55:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 915
train_sample_count: 915
avg_envstep_per_episode: 114.375
avg_sample_per_episode: 114.375
avg_envstep_per_sec: 792.4977308850358
avg_train_sample_per_sec: 792.4977308850358
avg_episode_per_sec: 6.928941909377362
collect_time: 1.1545774383204324
reward_mean: 794.0
reward_std: 275.48956298828125
reward_max: 1425.0
reward_min: 618.0
total_envstep_count: 1791185
total_train_sample_count: 1791161
total_episode_count: 11770
total_duration: 2262.8290559223733
[2024-11-19 23:55:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 845
train_sample_count: 845
avg_envstep_per_episode: 140.83333333333334
avg_sample_per_episode: 140.83333333333334
avg_envstep_per_sec: 806.1208228719946
avg_train_sample_per_sec: 806.1208228719946
avg_episode_per_sec: 5.723934836960908
collect_time: 1.0482299625873566
reward_mean: 1060.5
reward_std: 469.7973937988281
reward_max: 1700.0
reward_min: 637.0
total_envstep_count: 1792164
total_train_sample_count: 1792138
total_episode_count: 11776
total_duration: 2263.8772858849607
[2024-11-19 23:55:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 726
train_sample_count: 726
avg_envstep_per_episode: 145.2
avg_sample_per_episode: 145.2
avg_envstep_per_sec: 810.2982722110786
avg_train_sample_per_sec: 810.2982722110786
avg_episode_per_sec: 5.580566613023957
collect_time: 0.8959663680621556
reward_mean: 1055.800048828125
reward_std: 546.3809814453125
reward_max: 1860.0
reward_min: 588.0
total_envstep_count: 1793169
total_train_sample_count: 1793128
total_episode_count: 11781
total_duration: 2264.7732522530227
[2024-11-19 23:55:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 962
train_sample_count: 962
avg_envstep_per_episode: 160.33333333333334
avg_sample_per_episode: 160.33333333333334
avg_envstep_per_sec: 809.1622155707937
avg_train_sample_per_sec: 809.1622155707937
avg_episode_per_sec: 5.046749785264826
collect_time: 1.1888839857918878
reward_mean: 1127.1666259765625
reward_std: 354.42132568359375
reward_max: 1438.0
reward_min: 605.0
total_envstep_count: 1794156
total_train_sample_count: 1794126
total_episode_count: 11787
total_duration: 2265.9621362388148
[2024-11-19 23:55:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 978
train_sample_count: 978
avg_envstep_per_episode: 244.5
avg_sample_per_episode: 244.5
avg_envstep_per_sec: 807.8990001508892
avg_train_sample_per_sec: 807.8990001508892
avg_episode_per_sec: 3.3042903891651907
collect_time: 1.2105473577976227
reward_mean: 1270.5
reward_std: 700.0108642578125
reward_max: 2357.0
reward_min: 592.0
total_envstep_count: 1795129
total_train_sample_count: 1795104
total_episode_count: 11791
total_duration: 2267.1726835966124
[2024-11-19 23:55:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 989
train_sample_count: 989
avg_envstep_per_episode: 197.8
avg_sample_per_episode: 197.8
avg_envstep_per_sec: 801.2976187262044
avg_train_sample_per_sec: 801.2976187262044
avg_episode_per_sec: 4.051049639667363
collect_time: 1.2342480208192552
reward_mean: 1464.5999755859375
reward_std: 298.3330993652344
reward_max: 1907.0
reward_min: 1056.0
total_envstep_count: 1796125
total_train_sample_count: 1796081
total_episode_count: 11796
total_duration: 2268.406931617432
[2024-11-19 23:55:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1106
train_sample_count: 1106
avg_envstep_per_episode: 221.2
avg_sample_per_episode: 221.2
avg_envstep_per_sec: 804.2302725764741
avg_train_sample_per_sec: 804.2302725764741
avg_episode_per_sec: 3.6357607259334275
collect_time: 1.3752280133111137
reward_mean: 1102.0
reward_std: 444.6675109863281
reward_max: 1679.0
reward_min: 622.0
total_envstep_count: 1797136
total_train_sample_count: 1797103
total_episode_count: 11801
total_duration: 2269.782159630743
[2024-11-19 23:55:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 574
train_sample_count: 574
avg_envstep_per_episode: 191.33333333333334
avg_sample_per_episode: 191.33333333333334
avg_envstep_per_sec: 802.9274342946784
avg_train_sample_per_sec: 802.9274342946784
avg_episode_per_sec: 4.1964848482300265
collect_time: 0.7148840299674443
reward_mean: 1340.0
reward_std: 494.267822265625
reward_max: 1690.0
reward_min: 641.0
total_envstep_count: 1798117
total_train_sample_count: 1798073
total_episode_count: 11804
total_duration: 2270.4970436607105
[2024-11-19 23:55:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1819
train_sample_count: 1819
avg_envstep_per_episode: 227.375
avg_sample_per_episode: 227.375
avg_envstep_per_sec: 809.481658756781
avg_train_sample_per_sec: 809.481658756781
avg_episode_per_sec: 3.56011724576924
collect_time: 2.2471170042242323
reward_mean: 1564.25
reward_std: 265.8508605957031
reward_max: 1848.0
reward_min: 1046.0
total_envstep_count: 1799089
total_train_sample_count: 1799064
total_episode_count: 11812
total_duration: 2272.7441606649345
[2024-11-19 23:55:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 454
train_sample_count: 454
avg_envstep_per_episode: 113.5
avg_sample_per_episode: 113.5
avg_envstep_per_sec: 812.114772313901
avg_train_sample_per_sec: 812.114772313901
avg_episode_per_sec: 7.155196231840537
collect_time: 0.5590342836720603
reward_mean: 700.5
reward_std: 398.69818115234375
reward_max: 1336.0
reward_min: 235.0
total_envstep_count: 1800061
total_train_sample_count: 1800046
total_episode_count: 11816
total_duration: 2273.3031949486067
[2024-11-19 23:55:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1077
train_sample_count: 1077
avg_envstep_per_episode: 179.5
avg_sample_per_episode: 179.5
avg_envstep_per_sec: 807.6142434845295
avg_train_sample_per_sec: 807.6142434845295
avg_episode_per_sec: 4.499243696292644
collect_time: 1.3335574609892709
reward_mean: 1207.8333740234375
reward_std: 302.9056091308594
reward_max: 1553.0
reward_min: 610.0
total_envstep_count: 1801072
total_train_sample_count: 1801027
total_episode_count: 11822
total_duration: 2274.636752409596
[2024-11-19 23:56:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 720
train_sample_count: 720
avg_envstep_per_episode: 240.0
avg_sample_per_episode: 240.0
avg_envstep_per_sec: 804.2654723063987
avg_train_sample_per_sec: 804.2654723063987
avg_episode_per_sec: 3.351106134609995
collect_time: 0.8952267936297825
reward_mean: 1646.3333740234375
reward_std: 61.775577545166016
reward_max: 1692.0
reward_min: 1559.0
total_envstep_count: 1802054
total_train_sample_count: 1802023
total_episode_count: 11825
total_duration: 2275.5319792032255
[2024-11-19 23:56:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 771
train_sample_count: 771
avg_envstep_per_episode: 154.2
avg_sample_per_episode: 154.2
avg_envstep_per_sec: 771.9111357707498
avg_train_sample_per_sec: 771.9111357707498
avg_episode_per_sec: 5.005908792287611
collect_time: 0.9988196364470893
reward_mean: 1145.800048828125
reward_std: 465.1612243652344
reward_max: 1691.0
reward_min: 654.0
total_envstep_count: 1803050
total_train_sample_count: 1803010
total_episode_count: 11830
total_duration: 2276.5307988396726
[2024-11-19 23:56:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1054
train_sample_count: 1054
avg_envstep_per_episode: 263.5
avg_sample_per_episode: 263.5
avg_envstep_per_sec: 732.9497824416247
avg_train_sample_per_sec: 732.9497824416247
avg_episode_per_sec: 2.7815931022452554
collect_time: 1.4380248486995697
reward_mean: 1464.0
reward_std: 258.71124267578125
reward_max: 1912.0
reward_min: 1306.0
total_envstep_count: 1804054
total_train_sample_count: 1804004
total_episode_count: 11834
total_duration: 2277.968823688372
[2024-11-19 23:56:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1356
train_sample_count: 1356
avg_envstep_per_episode: 226.0
avg_sample_per_episode: 226.0
avg_envstep_per_sec: 760.1010683862999
avg_train_sample_per_sec: 760.1010683862999
avg_episode_per_sec: 3.363279063656194
collect_time: 1.783973285130092
reward_mean: 1100.1666259765625
reward_std: 598.9169311523438
reward_max: 2313.0
reward_min: 628.0
total_envstep_count: 1805025
total_train_sample_count: 1804988
total_episode_count: 11840
total_duration: 2279.7527969735024
[2024-11-19 23:56:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 959
train_sample_count: 959
avg_envstep_per_episode: 239.75
avg_sample_per_episode: 239.75
avg_envstep_per_sec: 815.3962160901873
avg_train_sample_per_sec: 815.3962160901873
avg_episode_per_sec: 3.401026970136339
collect_time: 1.1761153425489153
reward_mean: 1322.75
reward_std: 423.6415710449219
reward_max: 1671.0
reward_min: 627.0
total_envstep_count: 1805981
total_train_sample_count: 1805959
total_episode_count: 11844
total_duration: 2280.9289123160515
[2024-11-19 23:56:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1083
train_sample_count: 1083
avg_envstep_per_episode: 180.5
avg_sample_per_episode: 180.5
avg_envstep_per_sec: 809.021625814474
avg_train_sample_per_sec: 809.021625814474
avg_episode_per_sec: 4.482114270440299
collect_time: 1.3386539561407906
reward_mean: 980.8333129882812
reward_std: 513.6900634765625
reward_max: 1680.0
reward_min: 245.0
total_envstep_count: 1806999
total_train_sample_count: 1806958
total_episode_count: 11850
total_duration: 2282.267566272192
[2024-11-19 23:56:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 600
train_sample_count: 600
avg_envstep_per_episode: 200.0
avg_sample_per_episode: 200.0
avg_envstep_per_sec: 807.7374870572593
avg_train_sample_per_sec: 807.7374870572593
avg_episode_per_sec: 4.038687435286296
collect_time: 0.74281559245927
reward_mean: 1394.6666259765625
reward_std: 251.87608337402344
reward_max: 1681.0
reward_min: 1068.0
total_envstep_count: 1807964
total_train_sample_count: 1807930
total_episode_count: 11853
total_duration: 2283.0103818646517
[2024-11-19 23:56:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1251
train_sample_count: 1251
avg_envstep_per_episode: 208.5
avg_sample_per_episode: 208.5
avg_envstep_per_sec: 813.7321752316152
avg_train_sample_per_sec: 813.7321752316152
avg_episode_per_sec: 3.9027922073458763
collect_time: 1.537360864026206
reward_mean: 1190.3333740234375
reward_std: 604.737060546875
reward_max: 2339.0
reward_min: 610.0
total_envstep_count: 1808950
total_train_sample_count: 1808917
total_episode_count: 11859
total_duration: 2284.547742728678
[2024-11-19 23:56:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 331
train_sample_count: 331
avg_envstep_per_episode: 165.5
avg_sample_per_episode: 165.5
avg_envstep_per_sec: 817.8996074386665
avg_train_sample_per_sec: 817.8996074386665
avg_episode_per_sec: 4.941991585732124
collect_time: 0.40469514472143986
reward_mean: 1074.0
reward_std: 266.0
reward_max: 1340.0
reward_min: 808.0
total_envstep_count: 1809924
total_train_sample_count: 1809884
total_episode_count: 11861
total_duration: 2284.952437873399
[2024-11-19 23:56:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 874
train_sample_count: 874
avg_envstep_per_episode: 291.3333333333333
avg_sample_per_episode: 291.3333333333333
avg_envstep_per_sec: 820.2793935519043
avg_train_sample_per_sec: 820.2793935519043
avg_episode_per_sec: 2.815604325693035
collect_time: 1.0654906204768588
reward_mean: 1114.3333740234375
reward_std: 137.6525421142578
reward_max: 1309.0
reward_min: 1016.0
total_envstep_count: 1810883
total_train_sample_count: 1810854
total_episode_count: 11864
total_duration: 2286.017928493876
[2024-11-19 23:56:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1337
train_sample_count: 1337
avg_envstep_per_episode: 191.0
avg_sample_per_episode: 191.0
avg_envstep_per_sec: 817.2851998958888
avg_train_sample_per_sec: 817.2851998958888
avg_episode_per_sec: 4.278980104166957
collect_time: 1.63590384381158
reward_mean: 887.7142944335938
reward_std: 336.5186462402344
reward_max: 1412.0
reward_min: 598.0
total_envstep_count: 1811911
total_train_sample_count: 1811867
total_episode_count: 11871
total_duration: 2287.6538323376876
[2024-11-19 23:56:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 899
train_sample_count: 899
avg_envstep_per_episode: 128.42857142857142
avg_sample_per_episode: 128.42857142857142
avg_envstep_per_sec: 817.2204600324342
avg_train_sample_per_sec: 817.2204600324342
avg_episode_per_sec: 6.363229388461668
collect_time: 1.1000703530652183
reward_mean: 993.7142944335938
reward_std: 439.6634216308594
reward_max: 1708.0
reward_min: 609.0
total_envstep_count: 1812905
total_train_sample_count: 1812850
total_episode_count: 11878
total_duration: 2288.753902690753
[2024-11-19 23:56:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1026
train_sample_count: 1026
avg_envstep_per_episode: 128.25
avg_sample_per_episode: 128.25
avg_envstep_per_sec: 811.8079390707965
avg_train_sample_per_sec: 811.8079390707965
avg_episode_per_sec: 6.329886464489641
collect_time: 1.2638457332338606
reward_mean: 896.375
reward_std: 478.426025390625
reward_max: 1675.0
reward_min: 224.0
total_envstep_count: 1813915
total_train_sample_count: 1813888
total_episode_count: 11886
total_duration: 2290.0177484239866
[2024-11-19 23:56:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1698
train_sample_count: 1698
avg_envstep_per_episode: 242.57142857142858
avg_sample_per_episode: 242.57142857142858
avg_envstep_per_sec: 812.313668641813
avg_train_sample_per_sec: 812.313668641813
avg_episode_per_sec: 3.3487607070039407
collect_time: 2.0903255300862447
reward_mean: 936.5714111328125
reward_std: 368.40576171875
reward_max: 1513.0
reward_min: 616.0
total_envstep_count: 1814918
total_train_sample_count: 1814890
total_episode_count: 11893
total_duration: 2292.108073954073
[2024-11-19 23:56:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1254
train_sample_count: 1254
avg_envstep_per_episode: 139.33333333333334
avg_sample_per_episode: 139.33333333333334
avg_envstep_per_sec: 806.5695496377837
avg_train_sample_per_sec: 806.5695496377837
avg_episode_per_sec: 5.78877667204151
collect_time: 1.5547326334885188
reward_mean: 1131.111083984375
reward_std: 440.9498596191406
reward_max: 1696.0
reward_min: 617.0
total_envstep_count: 1815935
total_train_sample_count: 1815892
total_episode_count: 11902
total_duration: 2293.6628065875616
[2024-11-19 23:56:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 655
train_sample_count: 655
avg_envstep_per_episode: 131.0
avg_sample_per_episode: 131.0
avg_envstep_per_sec: 811.0217402668106
avg_train_sample_per_sec: 811.0217402668106
avg_episode_per_sec: 6.191005650891684
collect_time: 0.80762323311397
reward_mean: 947.2000122070312
reward_std: 319.349609375
reward_max: 1339.0
reward_min: 613.0
total_envstep_count: 1816931
total_train_sample_count: 1816883
total_episode_count: 11907
total_duration: 2294.4704298206757
[2024-11-19 23:57:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 946
train_sample_count: 946
avg_envstep_per_episode: 105.11111111111111
avg_sample_per_episode: 105.11111111111111
avg_envstep_per_sec: 801.1653068910842
avg_train_sample_per_sec: 801.1653068910842
avg_episode_per_sec: 7.622080086701647
collect_time: 1.1807800361088345
reward_mean: 745.0
reward_std: 248.9680938720703
reward_max: 1432.0
reward_min: 614.0
total_envstep_count: 1817909
total_train_sample_count: 1817877
total_episode_count: 11916
total_duration: 2295.6512098567846
[2024-11-19 23:57:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1458
train_sample_count: 1458
avg_envstep_per_episode: 182.25
avg_sample_per_episode: 182.25
avg_envstep_per_sec: 811.4974475710909
avg_train_sample_per_sec: 811.4974475710909
avg_episode_per_sec: 4.452660892022447
collect_time: 1.796678479228701
reward_mean: 1325.625
reward_std: 581.9432983398438
reward_max: 2341.0
reward_min: 653.0
total_envstep_count: 1818934
total_train_sample_count: 1818903
total_episode_count: 11924
total_duration: 2297.4478883360134
[2024-11-19 23:57:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 840
train_sample_count: 840
avg_envstep_per_episode: 140.0
avg_sample_per_episode: 140.0
avg_envstep_per_sec: 798.0329846306415
avg_train_sample_per_sec: 798.0329846306415
avg_episode_per_sec: 5.7002356045045826
collect_time: 1.0525880711419244
reward_mean: 1220.0
reward_std: 217.87228393554688
reward_max: 1432.0
reward_min: 818.0
total_envstep_count: 1819928
total_train_sample_count: 1819875
total_episode_count: 11930
total_duration: 2298.5004764071555
[2024-11-19 23:57:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 504
train_sample_count: 504
avg_envstep_per_episode: 168.0
avg_sample_per_episode: 168.0
avg_envstep_per_sec: 831.8012114037733
avg_train_sample_per_sec: 831.8012114037733
avg_episode_per_sec: 4.951197686927222
collect_time: 0.6059140009539468
reward_mean: 603.6666870117188
reward_std: 4.988876819610596
reward_max: 609.0
reward_min: 597.0
total_envstep_count: 1820902
total_train_sample_count: 1820859
total_episode_count: 11933
total_duration: 2299.1063904081093
[2024-11-19 23:57:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1531
train_sample_count: 1531
avg_envstep_per_episode: 255.16666666666666
avg_sample_per_episode: 255.16666666666666
avg_envstep_per_sec: 822.2439645381518
avg_train_sample_per_sec: 822.2439645381518
avg_episode_per_sec: 3.222380004721692
collect_time: 1.8619777900832037
reward_mean: 1269.6666259765625
reward_std: 402.7979736328125
reward_max: 1805.0
reward_min: 722.0
total_envstep_count: 1821920
total_train_sample_count: 1821886
total_episode_count: 11939
total_duration: 2300.9683681981924
[2024-11-19 23:57:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 737
train_sample_count: 737
avg_envstep_per_episode: 184.25
avg_sample_per_episode: 184.25
avg_envstep_per_sec: 809.3764127568604
avg_train_sample_per_sec: 809.3764127568604
avg_episode_per_sec: 4.392816351461929
collect_time: 0.9105775611741201
reward_mean: 1247.0
reward_std: 460.8600769042969
reward_max: 1899.0
reward_min: 607.0
total_envstep_count: 1822886
total_train_sample_count: 1822863
total_episode_count: 11943
total_duration: 2301.8789457593666
[2024-11-19 23:57:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1173
train_sample_count: 1173
avg_envstep_per_episode: 146.625
avg_sample_per_episode: 146.625
avg_envstep_per_sec: 805.2402447426064
avg_train_sample_per_sec: 805.2402447426064
avg_episode_per_sec: 5.49183457624966
collect_time: 1.456708116190774
reward_mean: 855.0
reward_std: 391.296875
reward_max: 1675.0
reward_min: 575.0
total_envstep_count: 1823903
total_train_sample_count: 1823856
total_episode_count: 11951
total_duration: 2303.3356538755575
[2024-11-19 23:57:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1201
train_sample_count: 1201
avg_envstep_per_episode: 150.125
avg_sample_per_episode: 150.125
avg_envstep_per_sec: 808.7539319957968
avg_train_sample_per_sec: 808.7539319957968
avg_episode_per_sec: 5.387203543685574
collect_time: 1.4850005081721713
reward_mean: 1064.375
reward_std: 425.2022705078125
reward_max: 1859.0
reward_min: 596.0
total_envstep_count: 1824887
total_train_sample_count: 1824841
total_episode_count: 11959
total_duration: 2304.8206543837296
[2024-11-19 23:57:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 931
train_sample_count: 931
avg_envstep_per_episode: 103.44444444444444
avg_sample_per_episode: 103.44444444444444
avg_envstep_per_sec: 807.6755091738333
avg_train_sample_per_sec: 807.6755091738333
avg_episode_per_sec: 7.807819100498926
collect_time: 1.1526906405176438
reward_mean: 899.4444580078125
reward_std: 418.6358947753906
reward_max: 1410.0
reward_min: 251.0
total_envstep_count: 1825889
total_train_sample_count: 1825844
total_episode_count: 11968
total_duration: 2305.973345024247
[2024-11-19 23:57:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 763
train_sample_count: 763
avg_envstep_per_episode: 95.375
avg_sample_per_episode: 95.375
avg_envstep_per_sec: 810.8670828178077
avg_train_sample_per_sec: 810.8670828178077
avg_episode_per_sec: 8.501882912899688
collect_time: 0.940968028136662
reward_mean: 736.75
reward_std: 393.2151794433594
reward_max: 1700.0
reward_min: 243.0
total_envstep_count: 1826883
total_train_sample_count: 1826847
total_episode_count: 11976
total_duration: 2306.9143130523835
[2024-11-19 23:57:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 877
train_sample_count: 877
avg_envstep_per_episode: 146.16666666666666
avg_sample_per_episode: 146.16666666666666
avg_envstep_per_sec: 803.9200907621673
avg_train_sample_per_sec: 803.9200907621673
avg_episode_per_sec: 5.500023425966937
collect_time: 1.0909044444561005
reward_mean: 847.0
reward_std: 329.9217224121094
reward_max: 1314.0
reward_min: 587.0
total_envstep_count: 1827909
total_train_sample_count: 1827856
total_episode_count: 11982
total_duration: 2308.0052174968396
[2024-11-19 23:57:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 987
train_sample_count: 987
avg_envstep_per_episode: 123.375
avg_sample_per_episode: 123.375
avg_envstep_per_sec: 813.0388297462963
avg_train_sample_per_sec: 813.0388297462963
avg_episode_per_sec: 6.589980382948704
collect_time: 1.213964159999575
reward_mean: 854.875
reward_std: 308.2622375488281
reward_max: 1346.0
reward_min: 605.0
total_envstep_count: 1828878
total_train_sample_count: 1828843
total_episode_count: 11990
total_duration: 2309.2191816568393
[2024-11-19 23:57:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1075
train_sample_count: 1075
avg_envstep_per_episode: 134.375
avg_sample_per_episode: 134.375
avg_envstep_per_sec: 810.2552446603111
avg_train_sample_per_sec: 810.2552446603111
avg_episode_per_sec: 6.029806471890687
collect_time: 1.3267424149172644
reward_mean: 1075.75
reward_std: 509.6728820800781
reward_max: 1706.0
reward_min: 242.0
total_envstep_count: 1829894
total_train_sample_count: 1829858
total_episode_count: 11998
total_duration: 2310.5459240717564
[2024-11-19 23:57:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1292
train_sample_count: 1292
avg_envstep_per_episode: 129.2
avg_sample_per_episode: 129.2
avg_envstep_per_sec: 806.8399484238255
avg_train_sample_per_sec: 806.8399484238255
avg_episode_per_sec: 6.244891241670476
collect_time: 1.601308912038803
reward_mean: 1036.9000244140625
reward_std: 486.5166931152344
reward_max: 1862.0
reward_min: 241.0
total_envstep_count: 1830887
total_train_sample_count: 1830850
total_episode_count: 12008
total_duration: 2312.147232983795
[2024-11-19 23:57:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 628
train_sample_count: 628
avg_envstep_per_episode: 125.6
avg_sample_per_episode: 125.6
avg_envstep_per_sec: 806.0819919748695
avg_train_sample_per_sec: 806.0819919748695
avg_episode_per_sec: 6.417850254576987
collect_time: 0.7790770743574416
reward_mean: 1039.0
reward_std: 535.9219970703125
reward_max: 1699.0
reward_min: 243.0
total_envstep_count: 1831874
total_train_sample_count: 1831850
total_episode_count: 12013
total_duration: 2312.9263100581525
[2024-11-19 23:57:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1327
train_sample_count: 1327
avg_envstep_per_episode: 147.44444444444446
avg_sample_per_episode: 147.44444444444446
avg_envstep_per_sec: 803.9322937434137
avg_train_sample_per_sec: 803.9322937434137
avg_episode_per_sec: 5.4524420826606805
collect_time: 1.6506365154470717
reward_mean: 1357.888916015625
reward_std: 409.7054443359375
reward_max: 1713.0
reward_min: 634.0
total_envstep_count: 1832915
total_train_sample_count: 1832877
total_episode_count: 12022
total_duration: 2314.5769465735993
[2024-11-19 23:57:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1060
train_sample_count: 1060
avg_envstep_per_episode: 132.5
avg_sample_per_episode: 132.5
avg_envstep_per_sec: 804.2816221626151
avg_train_sample_per_sec: 804.2816221626151
avg_episode_per_sec: 6.070049978585775
collect_time: 1.3179463148117065
reward_mean: 1005.875
reward_std: 498.7101745605469
reward_max: 1690.0
reward_min: 611.0
total_envstep_count: 1833901
total_train_sample_count: 1833865
total_episode_count: 12030
total_duration: 2315.894892888411
[2024-11-19 23:58:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 888
train_sample_count: 888
avg_envstep_per_episode: 126.85714285714286
avg_sample_per_episode: 126.85714285714286
avg_envstep_per_sec: 806.7914530132533
avg_train_sample_per_sec: 806.7914530132533
avg_episode_per_sec: 6.359842535014384
collect_time: 1.1006561815738678
reward_mean: 1061.7142333984375
reward_std: 440.8209228515625
reward_max: 1862.0
reward_min: 607.0
total_envstep_count: 1834896
total_train_sample_count: 1834849
total_episode_count: 12037
total_duration: 2316.995549069985
[2024-11-19 23:58:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 650
train_sample_count: 650
avg_envstep_per_episode: 130.0
avg_sample_per_episode: 130.0
avg_envstep_per_sec: 807.7019786956306
avg_train_sample_per_sec: 807.7019786956306
avg_episode_per_sec: 6.213092143812544
collect_time: 0.8047522689614977
reward_mean: 956.4000244140625
reward_std: 255.2336883544922
reward_max: 1329.0
reward_min: 610.0
total_envstep_count: 1835875
total_train_sample_count: 1835835
total_episode_count: 12042
total_duration: 2317.8003013389466
[2024-11-19 23:58:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 795
train_sample_count: 795
avg_envstep_per_episode: 132.5
avg_sample_per_episode: 132.5
avg_envstep_per_sec: 805.2023263098714
avg_train_sample_per_sec: 805.2023263098714
avg_episode_per_sec: 6.076998689131105
collect_time: 0.9873294872897012
reward_mean: 751.1666870117188
reward_std: 378.85284423828125
reward_max: 1424.0
reward_min: 243.0
total_envstep_count: 1836877
total_train_sample_count: 1836822
total_episode_count: 12048
total_duration: 2318.787630826236
[2024-11-19 23:58:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1409
train_sample_count: 1409
avg_envstep_per_episode: 201.28571428571428
avg_sample_per_episode: 201.28571428571428
avg_envstep_per_sec: 811.1775306577791
avg_train_sample_per_sec: 811.1775306577791
avg_episode_per_sec: 4.029980634921543
collect_time: 1.7369810513087685
reward_mean: 1212.857177734375
reward_std: 608.4508056640625
reward_max: 2330.0
reward_min: 582.0
total_envstep_count: 1837823
total_train_sample_count: 1837799
total_episode_count: 12055
total_duration: 2320.524611877545
[2024-11-19 23:58:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1236
train_sample_count: 1236
avg_envstep_per_episode: 123.6
avg_sample_per_episode: 123.6
avg_envstep_per_sec: 803.3541083230128
avg_train_sample_per_sec: 803.3541083230128
avg_episode_per_sec: 6.49962870811499
collect_time: 1.5385494232177734
reward_mean: 918.4000244140625
reward_std: 336.96917724609375
reward_max: 1330.0
reward_min: 596.0
total_envstep_count: 1838830
total_train_sample_count: 1838807
total_episode_count: 12065
total_duration: 2322.0631613007627
[2024-11-19 23:58:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 721
train_sample_count: 721
avg_envstep_per_episode: 120.16666666666667
avg_sample_per_episode: 120.16666666666667
avg_envstep_per_sec: 596.7203068279155
avg_train_sample_per_sec: 596.7203068279155
avg_episode_per_sec: 4.965772317569338
collect_time: 1.2082712650299074
reward_mean: 969.8333129882812
reward_std: 358.59051513671875
reward_max: 1341.0
reward_min: 606.0
total_envstep_count: 1839826
total_train_sample_count: 1839780
total_episode_count: 12071
total_duration: 2323.2714325657926
[2024-11-19 23:58:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 923
train_sample_count: 923
avg_envstep_per_episode: 184.6
avg_sample_per_episode: 184.6
avg_envstep_per_sec: 798.8246211970948
avg_train_sample_per_sec: 798.8246211970948
avg_episode_per_sec: 4.327327308759993
collect_time: 1.155447610786983
reward_mean: 1347.199951171875
reward_std: 392.4178466796875
reward_max: 1695.0
reward_min: 616.0
total_envstep_count: 1840805
total_train_sample_count: 1840775
total_episode_count: 12076
total_duration: 2324.4268801765797
[2024-11-19 23:58:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 942
train_sample_count: 942
avg_envstep_per_episode: 188.4
avg_sample_per_episode: 188.4
avg_envstep_per_sec: 817.2994725170058
avg_train_sample_per_sec: 817.2994725170058
avg_episode_per_sec: 4.338107603593449
collect_time: 1.1525762975215912
reward_mean: 1343.800048828125
reward_std: 408.8732604980469
reward_max: 1688.0
reward_min: 625.0
total_envstep_count: 1841776
total_train_sample_count: 1841741
total_episode_count: 12081
total_duration: 2325.5794564741013
[2024-11-19 23:58:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 918
train_sample_count: 918
avg_envstep_per_episode: 183.6
avg_sample_per_episode: 183.6
avg_envstep_per_sec: 810.9425260761533
avg_train_sample_per_sec: 810.9425260761533
avg_episode_per_sec: 4.416898290175126
collect_time: 1.1320161053112576
reward_mean: 1010.5999755859375
reward_std: 353.4162292480469
reward_max: 1563.0
reward_min: 650.0
total_envstep_count: 1842772
total_train_sample_count: 1842719
total_episode_count: 12086
total_duration: 2326.7114725794127
[2024-11-19 23:58:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1025
train_sample_count: 1025
avg_envstep_per_episode: 170.83333333333334
avg_sample_per_episode: 170.83333333333334
avg_envstep_per_sec: 809.5930602353448
avg_train_sample_per_sec: 809.5930602353448
avg_episode_per_sec: 4.739081328206896
collect_time: 1.2660681647913798
reward_mean: 1176.6666259765625
reward_std: 451.4645080566406
reward_max: 1869.0
reward_min: 625.0
total_envstep_count: 1843767
total_train_sample_count: 1843720
total_episode_count: 12092
total_duration: 2327.977540744204
[2024-11-19 23:58:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1171
train_sample_count: 1171
avg_envstep_per_episode: 146.375
avg_sample_per_episode: 146.375
avg_envstep_per_sec: 807.9381595798428
avg_train_sample_per_sec: 807.9381595798428
avg_episode_per_sec: 5.519645838290985
collect_time: 1.4493683534009119
reward_mean: 1059.0
reward_std: 469.0338439941406
reward_max: 1900.0
reward_min: 609.0
total_envstep_count: 1844753
total_train_sample_count: 1844735
total_episode_count: 12100
total_duration: 2329.426909097605
[2024-11-19 23:58:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1183
train_sample_count: 1183
avg_envstep_per_episode: 147.875
avg_sample_per_episode: 147.875
avg_envstep_per_sec: 812.6462081790381
avg_train_sample_per_sec: 812.6462081790381
avg_episode_per_sec: 5.495494222681577
collect_time: 1.4557380420821053
reward_mean: 870.75
reward_std: 331.4256286621094
reward_max: 1325.0
reward_min: 251.0
total_envstep_count: 1845764
total_train_sample_count: 1845738
total_episode_count: 12108
total_duration: 2330.882647139687
[2024-11-19 23:58:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 355
train_sample_count: 355
avg_envstep_per_episode: 118.33333333333333
avg_sample_per_episode: 118.33333333333333
avg_envstep_per_sec: 818.2777557180931
avg_train_sample_per_sec: 818.2777557180931
avg_episode_per_sec: 6.915023287758533
collect_time: 0.4338380183492388
reward_mean: 606.3333129882812
reward_std: 6.018490314483643
reward_max: 612.0
reward_min: 598.0
total_envstep_count: 1846761
total_train_sample_count: 1846729
total_episode_count: 12111
total_duration: 2331.3164851580364
[2024-11-19 23:58:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1392
train_sample_count: 1392
avg_envstep_per_episode: 278.4
avg_sample_per_episode: 278.4
avg_envstep_per_sec: 816.2080976952566
avg_train_sample_per_sec: 816.2080976952566
avg_episode_per_sec: 2.931781960112272
collect_time: 1.705447426864079
reward_mean: 1460.0
reward_std: 354.86334228515625
reward_max: 1846.0
reward_min: 787.0
total_envstep_count: 1847757
total_train_sample_count: 1847713
total_episode_count: 12116
total_duration: 2333.0219325849002
[2024-11-19 23:58:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 887
train_sample_count: 887
avg_envstep_per_episode: 177.4
avg_sample_per_episode: 177.4
avg_envstep_per_sec: 815.488236010053
avg_train_sample_per_sec: 815.488236010053
avg_episode_per_sec: 4.5968897182077395
collect_time: 1.0876919627189636
reward_mean: 1025.0
reward_std: 385.5992736816406
reward_max: 1569.0
reward_min: 639.0
total_envstep_count: 1848753
total_train_sample_count: 1848720
total_episode_count: 12121
total_duration: 2334.109624547619
[2024-11-19 23:58:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 830
train_sample_count: 830
avg_envstep_per_episode: 207.5
avg_sample_per_episode: 207.5
avg_envstep_per_sec: 816.929367956088
avg_train_sample_per_sec: 816.929367956088
avg_episode_per_sec: 3.9370090021980144
collect_time: 1.015999708856855
reward_mean: 1086.25
reward_std: 407.1132507324219
reward_max: 1576.0
reward_min: 625.0
total_envstep_count: 1849749
total_train_sample_count: 1849706
total_episode_count: 12125
total_duration: 2335.125624256476
[2024-11-19 23:58:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 457
train_sample_count: 457
avg_envstep_per_episode: 152.33333333333334
avg_sample_per_episode: 152.33333333333334
avg_envstep_per_sec: 810.3973658238314
avg_train_sample_per_sec: 810.3973658238314
avg_episode_per_sec: 5.3198951804627885
collect_time: 0.5639208853244781
reward_mean: 975.3333129882812
reward_std: 592.1510620117188
reward_max: 1681.0
reward_min: 232.0
total_envstep_count: 1850707
total_train_sample_count: 1850679
total_episode_count: 12128
total_duration: 2335.6895451418004
[2024-11-19 23:58:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 974
train_sample_count: 974
avg_envstep_per_episode: 194.8
avg_sample_per_episode: 194.8
avg_envstep_per_sec: 817.2387577091338
avg_train_sample_per_sec: 817.2387577091338
avg_episode_per_sec: 4.195270830129023
collect_time: 1.1918181691850935
reward_mean: 1260.4000244140625
reward_std: 415.8425598144531
reward_max: 1682.0
reward_min: 740.0
total_envstep_count: 1851711
total_train_sample_count: 1851677
total_episode_count: 12133
total_duration: 2336.8813633109853
[2024-11-19 23:59:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 963
train_sample_count: 963
avg_envstep_per_episode: 240.75
avg_sample_per_episode: 240.75
avg_envstep_per_sec: 812.6381360956677
avg_train_sample_per_sec: 812.6381360956677
avg_episode_per_sec: 3.3754439713215687
collect_time: 1.1850292980670931
reward_mean: 1133.25
reward_std: 521.4193725585938
reward_max: 1687.0
reward_min: 595.0
total_envstep_count: 1852691
total_train_sample_count: 1852652
total_episode_count: 12137
total_duration: 2338.0663926090524
[2024-11-19 23:59:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1314
train_sample_count: 1314
avg_envstep_per_episode: 164.25
avg_sample_per_episode: 164.25
avg_envstep_per_sec: 806.9206556705818
avg_train_sample_per_sec: 806.9206556705818
avg_episode_per_sec: 4.912758938633679
collect_time: 1.628412893840245
reward_mean: 1200.75
reward_std: 388.8392028808594
reward_max: 1685.0
reward_min: 573.0
total_envstep_count: 1853724
total_train_sample_count: 1853690
total_episode_count: 12145
total_duration: 2339.6948055028925
[2024-11-19 23:59:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1760
train_sample_count: 1760
avg_envstep_per_episode: 251.42857142857142
avg_sample_per_episode: 251.42857142857142
avg_envstep_per_sec: 817.0895016288052
avg_train_sample_per_sec: 817.0895016288052
avg_episode_per_sec: 3.2497877905691115
collect_time: 2.153986798865455
reward_mean: 1209.4285888671875
reward_std: 514.672119140625
reward_max: 2244.0
reward_min: 606.0
total_envstep_count: 1854727
total_train_sample_count: 1854694
total_episode_count: 12152
total_duration: 2341.848792301758
[2024-11-19 23:59:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 766
train_sample_count: 766
avg_envstep_per_episode: 127.66666666666667
avg_sample_per_episode: 127.66666666666667
avg_envstep_per_sec: 815.9151567681668
avg_train_sample_per_sec: 815.9151567681668
avg_episode_per_sec: 6.3909803402206276
collect_time: 0.9388231039047242
reward_mean: 940.5
reward_std: 482.2716369628906
reward_max: 1853.0
reward_min: 609.0
total_envstep_count: 1855722
total_train_sample_count: 1855688
total_episode_count: 12158
total_duration: 2342.7876154056626
[2024-11-19 23:59:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 842
train_sample_count: 842
avg_envstep_per_episode: 168.4
avg_sample_per_episode: 168.4
avg_envstep_per_sec: 810.1341827391215
avg_train_sample_per_sec: 810.1341827391215
avg_episode_per_sec: 4.810773056645615
collect_time: 1.039333999156952
reward_mean: 1469.0
reward_std: 458.2850646972656
reward_max: 1865.0
reward_min: 618.0
total_envstep_count: 1856725
total_train_sample_count: 1856686
total_episode_count: 12163
total_duration: 2343.8269494048195
[2024-11-19 23:59:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1039
train_sample_count: 1039
avg_envstep_per_episode: 207.8
avg_sample_per_episode: 207.8
avg_envstep_per_sec: 803.5895894986097
avg_train_sample_per_sec: 803.5895894986097
avg_episode_per_sec: 3.8671298820914806
collect_time: 1.292948556797845
reward_mean: 1263.800048828125
reward_std: 405.3533630371094
reward_max: 1858.0
reward_min: 608.0
total_envstep_count: 1857720
total_train_sample_count: 1857689
total_episode_count: 12168
total_duration: 2345.1198979616174
[2024-11-19 23:59:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 858
train_sample_count: 858
avg_envstep_per_episode: 171.6
avg_sample_per_episode: 171.6
avg_envstep_per_sec: 807.3971281060692
avg_train_sample_per_sec: 807.3971281060692
avg_episode_per_sec: 4.705111469149587
collect_time: 1.0626740796225411
reward_mean: 1135.5999755859375
reward_std: 506.72186279296875
reward_max: 1847.0
reward_min: 596.0
total_envstep_count: 1858732
total_train_sample_count: 1858691
total_episode_count: 12173
total_duration: 2346.18257204124
[2024-11-19 23:59:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 478
train_sample_count: 478
avg_envstep_per_episode: 159.33333333333334
avg_sample_per_episode: 159.33333333333334
avg_envstep_per_sec: 812.0062475655227
avg_train_sample_per_sec: 812.0062475655227
avg_episode_per_sec: 5.096273520285707
collect_time: 0.5886654215199607
reward_mean: 941.0
reward_std: 340.9173889160156
reward_max: 1420.0
reward_min: 654.0
total_envstep_count: 1859713
total_train_sample_count: 1859661
total_episode_count: 12176
total_duration: 2346.77123746276
[2024-11-19 23:59:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1692
train_sample_count: 1692
avg_envstep_per_episode: 169.2
avg_sample_per_episode: 169.2
avg_envstep_per_sec: 800.6337816429876
avg_train_sample_per_sec: 800.6337816429876
avg_episode_per_sec: 4.731878142098036
collect_time: 2.113325766154698
reward_mean: 1251.5
reward_std: 654.3690185546875
reward_max: 2340.0
reward_min: 251.0
total_envstep_count: 1860727
total_train_sample_count: 1860681
total_episode_count: 12186
total_duration: 2348.8845632289144
[2024-11-19 23:59:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1008
train_sample_count: 1008
avg_envstep_per_episode: 201.6
avg_sample_per_episode: 201.6
avg_envstep_per_sec: 812.9793975198869
avg_train_sample_per_sec: 812.9793975198869
avg_episode_per_sec: 4.032635900396264
collect_time: 1.2398838187967027
reward_mean: 1231.5999755859375
reward_std: 483.479736328125
reward_max: 1863.0
reward_min: 605.0
total_envstep_count: 1861698
total_train_sample_count: 1861677
total_episode_count: 12191
total_duration: 2350.1244470477113
[2024-11-19 23:59:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 698
train_sample_count: 698
avg_envstep_per_episode: 174.5
avg_sample_per_episode: 174.5
avg_envstep_per_sec: 802.8467282477299
avg_train_sample_per_sec: 802.8467282477299
avg_episode_per_sec: 4.600840849557191
collect_time: 0.8694062956741877
reward_mean: 1433.75
reward_std: 514.6141357421875
reward_max: 1860.0
reward_min: 595.0
total_envstep_count: 1862702
total_train_sample_count: 1862651
total_episode_count: 12195
total_duration: 2350.9938533433856
[2024-11-20 00:00:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1458
train_sample_count: 1458
avg_envstep_per_episode: 145.8
avg_sample_per_episode: 145.8
avg_envstep_per_sec: 801.7487134285684
avg_train_sample_per_sec: 801.7487134285684
avg_episode_per_sec: 5.498962369194571
collect_time: 1.8185249013560159
reward_mean: 840.9000244140625
reward_std: 359.9353942871094
reward_max: 1430.0
reward_min: 578.0
total_envstep_count: 1863724
total_train_sample_count: 1863689
total_episode_count: 12205
total_duration: 2352.8123782447415
[2024-11-20 00:00:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 792
train_sample_count: 792
avg_envstep_per_episode: 198.0
avg_sample_per_episode: 198.0
avg_envstep_per_sec: 811.225232349708
avg_train_sample_per_sec: 811.225232349708
avg_episode_per_sec: 4.097097133079333
collect_time: 0.9763009931359972
reward_mean: 1118.75
reward_std: 329.1423645019531
reward_max: 1422.0
reward_min: 611.0
total_envstep_count: 1864730
total_train_sample_count: 1864673
total_episode_count: 12209
total_duration: 2353.7886792378777
[2024-11-20 00:00:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1069
train_sample_count: 1069
avg_envstep_per_episode: 178.16666666666666
avg_sample_per_episode: 178.16666666666666
avg_envstep_per_sec: 816.937680178924
avg_train_sample_per_sec: 816.937680178924
avg_episode_per_sec: 4.585244229254952
collect_time: 1.3085453467709678
reward_mean: 997.8333129882812
reward_std: 434.5508728027344
reward_max: 1694.0
reward_min: 593.0
total_envstep_count: 1865748
total_train_sample_count: 1865706
total_episode_count: 12215
total_duration: 2355.0972245846488
[2024-11-20 00:00:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 875
train_sample_count: 875
avg_envstep_per_episode: 125.0
avg_sample_per_episode: 125.0
avg_envstep_per_sec: 810.4066868954103
avg_train_sample_per_sec: 810.4066868954103
avg_episode_per_sec: 6.483253495163282
collect_time: 1.0797048125948225
reward_mean: 940.4285888671875
reward_std: 445.1882019042969
reward_max: 1665.0
reward_min: 248.0
total_envstep_count: 1866744
total_train_sample_count: 1866689
total_episode_count: 12222
total_duration: 2356.1769293972434
[2024-11-20 00:00:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 985
train_sample_count: 985
avg_envstep_per_episode: 109.44444444444444
avg_sample_per_episode: 109.44444444444444
avg_envstep_per_sec: 821.6635691865728
avg_train_sample_per_sec: 821.6635691865728
avg_episode_per_sec: 7.507585911349397
collect_time: 1.1987874805927277
reward_mean: 819.4444580078125
reward_std: 519.9553833007812
reward_max: 1707.0
reward_min: 248.0
total_envstep_count: 1867699
total_train_sample_count: 1867674
total_episode_count: 12231
total_duration: 2357.375716877836
[2024-11-20 00:00:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1141
train_sample_count: 1141
avg_envstep_per_episode: 228.2
avg_sample_per_episode: 228.2
avg_envstep_per_sec: 821.1481610657589
avg_train_sample_per_sec: 821.1481610657589
avg_episode_per_sec: 3.5983705568175237
collect_time: 1.389517816759291
reward_mean: 1263.0
reward_std: 615.2153930664062
reward_max: 2295.0
reward_min: 612.0
total_envstep_count: 1868702
total_train_sample_count: 1868671
total_episode_count: 12236
total_duration: 2358.7652346945956
[2024-11-20 00:00:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1192
train_sample_count: 1192
avg_envstep_per_episode: 108.36363636363636
avg_sample_per_episode: 108.36363636363636
avg_envstep_per_sec: 808.8866601186169
avg_train_sample_per_sec: 808.8866601186169
avg_episode_per_sec: 7.464558105121465
collect_time: 1.473630433990842
reward_mean: 795.3636474609375
reward_std: 454.2170715332031
reward_max: 1691.0
reward_min: 245.0
total_envstep_count: 1869741
total_train_sample_count: 1869683
total_episode_count: 12247
total_duration: 2360.2388651285864
[2024-11-20 00:00:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 952
train_sample_count: 952
avg_envstep_per_episode: 136.0
avg_sample_per_episode: 136.0
avg_envstep_per_sec: 815.3303228374556
avg_train_sample_per_sec: 815.3303228374556
avg_episode_per_sec: 5.995075903216585
collect_time: 1.1676249163491383
reward_mean: 1030.4285888671875
reward_std: 501.3216552734375
reward_max: 1847.0
reward_min: 603.0
total_envstep_count: 1870719
total_train_sample_count: 1870695
total_episode_count: 12254
total_duration: 2361.4064900449357
[2024-11-20 00:00:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 917
train_sample_count: 917
avg_envstep_per_episode: 131.0
avg_sample_per_episode: 131.0
avg_envstep_per_sec: 814.156736490734
avg_train_sample_per_sec: 814.156736490734
avg_episode_per_sec: 6.214936919776596
collect_time: 1.1263187527656555
reward_mean: 953.4285888671875
reward_std: 530.5194091796875
reward_max: 1703.0
reward_min: 178.0
total_envstep_count: 1871729
total_train_sample_count: 1871684
total_episode_count: 12261
total_duration: 2362.5328087977014
[2024-11-20 00:00:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 284
train_sample_count: 284
avg_envstep_per_episode: 142.0
avg_sample_per_episode: 142.0
avg_envstep_per_sec: 832.1453182156129
avg_train_sample_per_sec: 832.1453182156129
avg_episode_per_sec: 5.860178297293048
collect_time: 0.34128654428890776
reward_mean: 754.0
reward_std: 586.0
reward_max: 1340.0
reward_min: 168.0
total_envstep_count: 1872695
total_train_sample_count: 1872652
total_episode_count: 12263
total_duration: 2362.87409534199
[2024-11-20 00:00:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1710
train_sample_count: 1710
avg_envstep_per_episode: 190.0
avg_sample_per_episode: 190.0
avg_envstep_per_sec: 819.3371290492988
avg_train_sample_per_sec: 819.3371290492988
avg_episode_per_sec: 4.312300679206836
collect_time: 2.0870529838970726
reward_mean: 973.7777709960938
reward_std: 334.3540344238281
reward_max: 1431.0
reward_min: 609.0
total_envstep_count: 1873719
total_train_sample_count: 1873678
total_episode_count: 12272
total_duration: 2364.9611483258873
[2024-11-20 00:00:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 989
train_sample_count: 989
avg_envstep_per_episode: 164.83333333333334
avg_sample_per_episode: 164.83333333333334
avg_envstep_per_sec: 818.2539379759493
avg_train_sample_per_sec: 818.2539379759493
avg_episode_per_sec: 4.964129047376841
collect_time: 1.208671237741198
reward_mean: 1048.5
reward_std: 476.9391174316406
reward_max: 1827.0
reward_min: 586.0
total_envstep_count: 1874691
total_train_sample_count: 1874667
total_episode_count: 12278
total_duration: 2366.1698195636286
[2024-11-20 00:01:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 785
train_sample_count: 785
avg_envstep_per_episode: 112.14285714285714
avg_sample_per_episode: 112.14285714285714
avg_envstep_per_sec: 806.7114864692783
avg_train_sample_per_sec: 806.7114864692783
avg_episode_per_sec: 7.193605611827959
collect_time: 0.9730864294937679
reward_mean: 924.7142944335938
reward_std: 523.2026977539062
reward_max: 1930.0
reward_min: 249.0
total_envstep_count: 1875701
total_train_sample_count: 1875680
total_episode_count: 12285
total_duration: 2367.1429059931224
[2024-11-20 00:01:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 465
train_sample_count: 465
avg_envstep_per_episode: 155.0
avg_sample_per_episode: 155.0
avg_envstep_per_sec: 816.7630193136685
avg_train_sample_per_sec: 816.7630193136685
avg_episode_per_sec: 5.269438834281732
collect_time: 0.5693205850464957
reward_mean: 982.6666870117188
reward_std: 302.8138427734375
reward_max: 1327.0
reward_min: 590.0
total_envstep_count: 1876730
total_train_sample_count: 1876685
total_episode_count: 12288
total_duration: 2367.712226578169
[2024-11-20 00:01:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1856
train_sample_count: 1856
avg_envstep_per_episode: 206.22222222222223
avg_sample_per_episode: 206.22222222222223
avg_envstep_per_sec: 717.7461316853479
avg_train_sample_per_sec: 717.7461316853479
avg_episode_per_sec: 3.4804499920086918
collect_time: 2.5858725224222456
reward_mean: 1332.3333740234375
reward_std: 621.4569091796875
reward_max: 2334.0
reward_min: 649.0
total_envstep_count: 1877723
total_train_sample_count: 1877689
total_episode_count: 12297
total_duration: 2370.298099100591
[2024-11-20 00:01:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1005
train_sample_count: 1005
avg_envstep_per_episode: 167.5
avg_sample_per_episode: 167.5
avg_envstep_per_sec: 818.6094409648939
avg_train_sample_per_sec: 818.6094409648939
avg_episode_per_sec: 4.887220543073994
collect_time: 1.2276916801929474
reward_mean: 1278.0
reward_std: 605.1198120117188
reward_max: 2346.0
reward_min: 609.0
total_envstep_count: 1878725
total_train_sample_count: 1878694
total_episode_count: 12303
total_duration: 2371.525790780784
[2024-11-20 00:01:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 759
train_sample_count: 759
avg_envstep_per_episode: 126.5
avg_sample_per_episode: 126.5
avg_envstep_per_sec: 815.4500658538512
avg_train_sample_per_sec: 815.4500658538512
avg_episode_per_sec: 6.4462455798723415
collect_time: 0.9307743438652583
reward_mean: 978.6666870117188
reward_std: 452.9049377441406
reward_max: 1846.0
reward_min: 606.0
total_envstep_count: 1879736
total_train_sample_count: 1879693
total_episode_count: 12309
total_duration: 2372.4565651246494
[2024-11-20 00:01:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 744
train_sample_count: 744
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 815.2383948229744
avg_train_sample_per_sec: 815.2383948229744
avg_episode_per_sec: 6.574503184056246
collect_time: 0.9126164870602744
reward_mean: 1083.6666259765625
reward_std: 449.958740234375
reward_max: 1582.0
reward_min: 604.0
total_envstep_count: 1880722
total_train_sample_count: 1880689
total_episode_count: 12315
total_duration: 2373.36918161171
[2024-11-20 00:01:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 569
train_sample_count: 569
avg_envstep_per_episode: 113.8
avg_sample_per_episode: 113.8
avg_envstep_per_sec: 812.6056485284649
avg_train_sample_per_sec: 812.6056485284649
avg_episode_per_sec: 7.140647175118321
collect_time: 0.7002166438670385
reward_mean: 849.7999877929688
reward_std: 287.2576599121094
reward_max: 1325.0
reward_min: 602.0
total_envstep_count: 1881710
total_train_sample_count: 1881666
total_episode_count: 12320
total_duration: 2374.0693982555767
[2024-11-20 00:01:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1033
train_sample_count: 1033
avg_envstep_per_episode: 172.16666666666666
avg_sample_per_episode: 172.16666666666666
avg_envstep_per_sec: 811.087325555973
avg_train_sample_per_sec: 811.087325555973
avg_episode_per_sec: 4.711059006133435
collect_time: 1.273598991689228
reward_mean: 986.3333129882812
reward_std: 705.542236328125
reward_max: 2314.0
reward_min: 143.0
total_envstep_count: 1882689
total_train_sample_count: 1882651
total_episode_count: 12326
total_duration: 2375.342997247266
[2024-11-20 00:01:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1606
train_sample_count: 1606
avg_envstep_per_episode: 267.6666666666667
avg_sample_per_episode: 267.6666666666667
avg_envstep_per_sec: 815.5255693260793
avg_train_sample_per_sec: 815.5255693260793
avg_episode_per_sec: 3.046795402214493
collect_time: 1.9692822155498324
reward_mean: 1042.6666259765625
reward_std: 730.5556640625
reward_max: 2599.0
reward_min: 593.0
total_envstep_count: 1883692
total_train_sample_count: 1883645
total_episode_count: 12332
total_duration: 2377.3122794628157
[2024-11-20 00:01:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1330
train_sample_count: 1330
avg_envstep_per_episode: 147.77777777777777
avg_sample_per_episode: 147.77777777777777
avg_envstep_per_sec: 811.7713407671408
avg_train_sample_per_sec: 811.7713407671408
avg_episode_per_sec: 5.493189523988171
collect_time: 1.6383924058505468
reward_mean: 929.4444580078125
reward_std: 459.13348388671875
reward_max: 1900.0
reward_min: 585.0
total_envstep_count: 1884675
total_train_sample_count: 1884627
total_episode_count: 12341
total_duration: 2378.950671868666
[2024-11-20 00:01:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 819
train_sample_count: 819
avg_envstep_per_episode: 136.5
avg_sample_per_episode: 136.5
avg_envstep_per_sec: 813.7840611881666
avg_train_sample_per_sec: 813.7840611881666
avg_episode_per_sec: 5.961787994052503
collect_time: 1.0064094875540053
reward_mean: 1056.3333740234375
reward_std: 475.0661926269531
reward_max: 1841.0
reward_min: 608.0
total_envstep_count: 1885661
total_train_sample_count: 1885626
total_episode_count: 12347
total_duration: 2379.95708135622
[2024-11-20 00:01:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1175
train_sample_count: 1175
avg_envstep_per_episode: 130.55555555555554
avg_sample_per_episode: 130.55555555555554
avg_envstep_per_sec: 812.2820953379636
avg_train_sample_per_sec: 812.2820953379636
avg_episode_per_sec: 6.221735198333338
collect_time: 1.446541794708797
reward_mean: 969.888916015625
reward_std: 439.9051513671875
reward_max: 1841.0
reward_min: 586.0
total_envstep_count: 1886668
total_train_sample_count: 1886633
total_episode_count: 12356
total_duration: 2381.403623150929
[2024-11-20 00:01:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1053
train_sample_count: 1053
avg_envstep_per_episode: 117.0
avg_sample_per_episode: 117.0
avg_envstep_per_sec: 808.2443642252005
avg_train_sample_per_sec: 808.2443642252005
avg_episode_per_sec: 6.908071489104278
collect_time: 1.3028238075120107
reward_mean: 894.4444580078125
reward_std: 375.28155517578125
reward_max: 1575.0
reward_min: 593.0
total_envstep_count: 1887677
total_train_sample_count: 1887638
total_episode_count: 12365
total_duration: 2382.706446958441
[2024-11-20 00:01:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1004
train_sample_count: 1004
avg_envstep_per_episode: 100.4
avg_sample_per_episode: 100.4
avg_envstep_per_sec: 815.3680176915433
avg_train_sample_per_sec: 815.3680176915433
avg_episode_per_sec: 8.121195395334096
collect_time: 1.2313458195754459
reward_mean: 767.5
reward_std: 280.5709228515625
reward_max: 1334.0
reward_min: 592.0
total_envstep_count: 1888700
total_train_sample_count: 1888642
total_episode_count: 12375
total_duration: 2383.9377927780165
[2024-11-20 00:01:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 694
train_sample_count: 694
avg_envstep_per_episode: 99.14285714285714
avg_sample_per_episode: 99.14285714285714
avg_envstep_per_sec: 814.6523074566959
avg_train_sample_per_sec: 814.6523074566959
avg_episode_per_sec: 8.216954109793763
collect_time: 0.8518971758229392
reward_mean: 795.1428833007812
reward_std: 395.3737487792969
reward_max: 1434.0
reward_min: 246.0
total_envstep_count: 1889717
total_train_sample_count: 1889672
total_episode_count: 12382
total_duration: 2384.7896899538396
[2024-11-20 00:01:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1012
train_sample_count: 1012
avg_envstep_per_episode: 202.4
avg_sample_per_episode: 202.4
avg_envstep_per_sec: 817.8233084339489
avg_train_sample_per_sec: 817.8233084339489
avg_episode_per_sec: 4.040628994238878
collect_time: 1.2374311046940938
reward_mean: 1353.4000244140625
reward_std: 622.7434692382812
reward_max: 2344.0
reward_min: 652.0
total_envstep_count: 1890698
total_train_sample_count: 1890672
total_episode_count: 12387
total_duration: 2386.027121058534
[2024-11-20 00:01:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1211
train_sample_count: 1211
avg_envstep_per_episode: 173.0
avg_sample_per_episode: 173.0
avg_envstep_per_sec: 812.1122329422712
avg_train_sample_per_sec: 812.1122329422712
avg_episode_per_sec: 4.6942903638281575
collect_time: 1.4911732035023828
reward_mean: 1218.4285888671875
reward_std: 609.7816772460938
reward_max: 2353.0
reward_min: 597.0
total_envstep_count: 1891687
total_train_sample_count: 1891667
total_episode_count: 12394
total_duration: 2387.5182942620363
[2024-11-20 00:02:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 931
train_sample_count: 931
avg_envstep_per_episode: 133.0
avg_sample_per_episode: 133.0
avg_envstep_per_sec: 816.8182720835517
avg_train_sample_per_sec: 816.8182720835517
avg_episode_per_sec: 6.141490767545502
collect_time: 1.1397884104933058
reward_mean: 939.0
reward_std: 393.9303894042969
reward_max: 1695.0
reward_min: 605.0
total_envstep_count: 1892729
total_train_sample_count: 1892706
total_episode_count: 12401
total_duration: 2388.6580826725294
[2024-11-20 00:02:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1162
train_sample_count: 1162
avg_envstep_per_episode: 129.11111111111111
avg_sample_per_episode: 129.11111111111111
avg_envstep_per_sec: 812.771143561667
avg_train_sample_per_sec: 812.771143561667
avg_episode_per_sec: 6.295129339117903
collect_time: 1.429676741361618
reward_mean: 1011.5555419921875
reward_std: 415.4818115234375
reward_max: 1691.0
reward_min: 620.0
total_envstep_count: 1893738
total_train_sample_count: 1893700
total_episode_count: 12410
total_duration: 2390.087759413891
[2024-11-20 00:02:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 532
train_sample_count: 532
avg_envstep_per_episode: 177.33333333333334
avg_sample_per_episode: 177.33333333333334
avg_envstep_per_sec: 814.3399238714162
avg_train_sample_per_sec: 814.3399238714162
avg_episode_per_sec: 4.5921424278463325
collect_time: 0.6532898417540959
reward_mean: 1318.3333740234375
reward_std: 3.399346113204956
reward_max: 1323.0
reward_min: 1315.0
total_envstep_count: 1894696
total_train_sample_count: 1894676
total_episode_count: 12413
total_duration: 2390.741049255645
[2024-11-20 00:02:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1213
train_sample_count: 1213
avg_envstep_per_episode: 173.28571428571428
avg_sample_per_episode: 173.28571428571428
avg_envstep_per_sec: 815.6138948773797
avg_train_sample_per_sec: 815.6138948773797
avg_episode_per_sec: 4.706757843480345
collect_time: 1.4872233143874576
reward_mean: 1095.4285888671875
reward_std: 380.44329833984375
reward_max: 1674.0
reward_min: 622.0
total_envstep_count: 1895713
total_train_sample_count: 1895661
total_episode_count: 12420
total_duration: 2392.2282725700325
[2024-11-20 00:02:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1205
train_sample_count: 1205
avg_envstep_per_episode: 150.625
avg_sample_per_episode: 150.625
avg_envstep_per_sec: 811.9649029845389
avg_train_sample_per_sec: 811.9649029845389
avg_episode_per_sec: 5.3906383600633285
collect_time: 1.4840542929513114
reward_mean: 1233.5
reward_std: 455.95751953125
reward_max: 1850.0
reward_min: 246.0
total_envstep_count: 1896707
total_train_sample_count: 1896662
total_episode_count: 12428
total_duration: 2393.712326862984
[2024-11-20 00:02:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 994
train_sample_count: 994
avg_envstep_per_episode: 110.44444444444444
avg_sample_per_episode: 110.44444444444444
avg_envstep_per_sec: 815.9034856998716
avg_train_sample_per_sec: 815.9034856998716
avg_episode_per_sec: 7.387456107946523
collect_time: 1.2182813499655043
reward_mean: 970.5555419921875
reward_std: 403.08258056640625
reward_max: 1642.0
reward_min: 608.0
total_envstep_count: 1897707
total_train_sample_count: 1897680
total_episode_count: 12437
total_duration: 2394.930608212949
[2024-11-20 00:02:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 610
train_sample_count: 610
avg_envstep_per_episode: 122.0
avg_sample_per_episode: 122.0
avg_envstep_per_sec: 802.2285817859977
avg_train_sample_per_sec: 802.2285817859977
avg_episode_per_sec: 6.575644112999981
collect_time: 0.7603817837578909
reward_mean: 1121.800048828125
reward_std: 426.8598937988281
reward_max: 1705.0
reward_min: 627.0
total_envstep_count: 1898703
total_train_sample_count: 1898674
total_episode_count: 12442
total_duration: 2395.6909899967072
[2024-11-20 00:02:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 830
train_sample_count: 830
avg_envstep_per_episode: 207.5
avg_sample_per_episode: 207.5
avg_envstep_per_sec: 813.7520396264607
avg_train_sample_per_sec: 813.7520396264607
avg_episode_per_sec: 3.921696576513064
collect_time: 1.019966721534729
reward_mean: 1474.75
reward_std: 634.5519409179688
reward_max: 2350.0
reward_min: 581.0
total_envstep_count: 1899692
total_train_sample_count: 1899660
total_episode_count: 12446
total_duration: 2396.710956718242
[2024-11-20 00:02:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 493
train_sample_count: 493
avg_envstep_per_episode: 164.33333333333334
avg_sample_per_episode: 164.33333333333334
avg_envstep_per_sec: 818.5108207930759
avg_train_sample_per_sec: 818.5108207930759
avg_episode_per_sec: 4.980796069734742
collect_time: 0.6023133567401342
reward_mean: 1418.3333740234375
reward_std: 562.7938232421875
reward_max: 1923.0
reward_min: 633.0
total_envstep_count: 1900705
total_train_sample_count: 1900693
total_episode_count: 12449
total_duration: 2397.313270074982
[2024-11-20 00:02:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1678
train_sample_count: 1678
avg_envstep_per_episode: 239.71428571428572
avg_sample_per_episode: 239.71428571428572
avg_envstep_per_sec: 807.2606155073844
avg_train_sample_per_sec: 807.2606155073844
avg_episode_per_sec: 3.367594939542128
collect_time: 2.0786347900118143
reward_mean: 1494.5714111328125
reward_std: 401.30426025390625
reward_max: 2325.0
reward_min: 1050.0
total_envstep_count: 1901748
total_train_sample_count: 1901699
total_episode_count: 12456
total_duration: 2399.3919048649936
[2024-11-20 00:02:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 955
train_sample_count: 955
avg_envstep_per_episode: 159.16666666666666
avg_sample_per_episode: 159.16666666666666
avg_envstep_per_sec: 809.6035036043213
avg_train_sample_per_sec: 809.6035036043213
avg_episode_per_sec: 5.086514158770605
collect_time: 1.1795897568975178
reward_mean: 1260.5
reward_std: 324.7515869140625
reward_max: 1704.0
reward_min: 609.0
total_envstep_count: 1902742
total_train_sample_count: 1902702
total_episode_count: 12462
total_duration: 2400.5714946218914
[2024-11-20 00:02:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 538
train_sample_count: 538
avg_envstep_per_episode: 134.5
avg_sample_per_episode: 134.5
avg_envstep_per_sec: 819.9035653207329
avg_train_sample_per_sec: 819.9035653207329
avg_episode_per_sec: 6.095937288629985
collect_time: 0.6561747292677562
reward_mean: 895.0
reward_std: 293.4808349609375
reward_max: 1302.0
reward_min: 602.0
total_envstep_count: 1903747
total_train_sample_count: 1903684
total_episode_count: 12466
total_duration: 2401.227669351159
[2024-11-20 00:02:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 772
train_sample_count: 772
avg_envstep_per_episode: 154.4
avg_sample_per_episode: 154.4
avg_envstep_per_sec: 815.4424626712487
avg_train_sample_per_sec: 815.4424626712487
avg_episode_per_sec: 5.281363100202388
collect_time: 0.9467252876077379
reward_mean: 1007.5999755859375
reward_std: 315.60772705078125
reward_max: 1318.0
reward_min: 618.0
total_envstep_count: 1904711
total_train_sample_count: 1904660
total_episode_count: 12471
total_duration: 2402.174394638767
[2024-11-20 00:02:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1082
train_sample_count: 1082
avg_envstep_per_episode: 180.33333333333334
avg_sample_per_episode: 180.33333333333334
avg_envstep_per_sec: 810.0042532118628
avg_train_sample_per_sec: 810.0042532118628
avg_episode_per_sec: 4.491705655518647
collect_time: 1.3357954550357092
reward_mean: 1273.3333740234375
reward_std: 279.67938232421875
reward_max: 1831.0
reward_min: 1040.0
total_envstep_count: 1905673
total_train_sample_count: 1905634
total_episode_count: 12477
total_duration: 2403.5101900938025
[2024-11-20 00:02:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 842
train_sample_count: 842
avg_envstep_per_episode: 140.33333333333334
avg_sample_per_episode: 140.33333333333334
avg_envstep_per_sec: 810.2543203162188
avg_train_sample_per_sec: 810.2543203162188
avg_episode_per_sec: 5.773783755222462
collect_time: 1.0391798956053597
reward_mean: 1114.6666259765625
reward_std: 343.65228271484375
reward_max: 1429.0
reward_min: 609.0
total_envstep_count: 1906660
total_train_sample_count: 1906620
total_episode_count: 12483
total_duration: 2404.5493699894078
[2024-11-20 00:02:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 582
train_sample_count: 582
avg_envstep_per_episode: 145.5
avg_sample_per_episode: 145.5
avg_envstep_per_sec: 813.7970494013391
avg_train_sample_per_sec: 813.7970494013391
avg_episode_per_sec: 5.593106868737726
collect_time: 0.7151660237993513
reward_mean: 1349.75
reward_std: 533.8189697265625
reward_max: 1863.0
reward_min: 627.0
total_envstep_count: 1907681
total_train_sample_count: 1907634
total_episode_count: 12487
total_duration: 2405.264536013207
[2024-11-20 00:03:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 965
train_sample_count: 965
avg_envstep_per_episode: 120.625
avg_sample_per_episode: 120.625
avg_envstep_per_sec: 811.6768413863658
avg_train_sample_per_sec: 811.6768413863658
avg_episode_per_sec: 6.728927182477644
collect_time: 1.1888968007905143
reward_mean: 972.875
reward_std: 362.7528076171875
reward_max: 1357.0
reward_min: 604.0
total_envstep_count: 1908683
total_train_sample_count: 1908635
total_episode_count: 12495
total_duration: 2406.4534328139976
[2024-11-20 00:03:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 701
train_sample_count: 701
avg_envstep_per_episode: 116.83333333333333
avg_sample_per_episode: 116.83333333333333
avg_envstep_per_sec: 817.4738872329722
avg_train_sample_per_sec: 817.4738872329722
avg_episode_per_sec: 6.9969234285275785
collect_time: 0.8575197458267212
reward_mean: 983.3333129882812
reward_std: 345.1225280761719
reward_max: 1335.0
reward_min: 630.0
total_envstep_count: 1909655
total_train_sample_count: 1909624
total_episode_count: 12501
total_duration: 2407.3109525598243
[2024-11-20 00:03:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2501
train_sample_count: 2501
avg_envstep_per_episode: 312.625
avg_sample_per_episode: 312.625
avg_envstep_per_sec: 815.0998739507712
avg_train_sample_per_sec: 815.0998739507712
avg_episode_per_sec: 2.6072766859680807
collect_time: 3.068335648093905
reward_mean: 937.875
reward_std: 330.08160400390625
reward_max: 1329.0
reward_min: 591.0
total_envstep_count: 1910671
total_train_sample_count: 1910625
total_episode_count: 12509
total_duration: 2410.3792882079183
[2024-11-20 00:03:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 771
train_sample_count: 771
avg_envstep_per_episode: 128.5
avg_sample_per_episode: 128.5
avg_envstep_per_sec: 809.5735613900832
avg_train_sample_per_sec: 809.5735613900832
avg_episode_per_sec: 6.300183357121271
collect_time: 0.9523532348019736
reward_mean: 1047.1666259765625
reward_std: 484.1223449707031
reward_max: 1695.0
reward_min: 600.0
total_envstep_count: 1911620
total_train_sample_count: 1911600
total_episode_count: 12515
total_duration: 2411.3316414427204
[2024-11-20 00:03:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 450
train_sample_count: 450
avg_envstep_per_episode: 112.5
avg_sample_per_episode: 112.5
avg_envstep_per_sec: 825.9423730009543
avg_train_sample_per_sec: 825.9423730009543
avg_episode_per_sec: 7.341709982230705
collect_time: 0.5448321998119354
reward_mean: 727.0
reward_std: 185.03378295898438
reward_max: 1047.0
reward_min: 612.0
total_envstep_count: 1912609
total_train_sample_count: 1912578
total_episode_count: 12519
total_duration: 2411.8764736425323
[2024-11-20 00:03:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 998
train_sample_count: 998
avg_envstep_per_episode: 166.33333333333334
avg_sample_per_episode: 166.33333333333334
avg_envstep_per_sec: 815.2765452193217
avg_train_sample_per_sec: 815.2765452193217
avg_episode_per_sec: 4.901462195707345
collect_time: 1.2241245082446508
reward_mean: 1129.8333740234375
reward_std: 517.4738159179688
reward_max: 1855.0
reward_min: 618.0
total_envstep_count: 1913604
total_train_sample_count: 1913564
total_episode_count: 12525
total_duration: 2413.100598150777
[2024-11-20 00:03:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 373
train_sample_count: 373
avg_envstep_per_episode: 186.5
avg_sample_per_episode: 186.5
avg_envstep_per_sec: 756.1433640402519
avg_train_sample_per_sec: 756.1433640402519
avg_episode_per_sec: 4.054388010939689
collect_time: 0.49329269783837454
reward_mean: 967.0
reward_std: 339.0
reward_max: 1306.0
reward_min: 628.0
total_envstep_count: 1914586
total_train_sample_count: 1914549
total_episode_count: 12527
total_duration: 2413.5938908486155
[2024-11-20 00:03:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2654
train_sample_count: 2654
avg_envstep_per_episode: 379.14285714285717
avg_sample_per_episode: 379.14285714285717
avg_envstep_per_sec: 756.660778970258
avg_train_sample_per_sec: 756.660778970258
avg_episode_per_sec: 1.9957141871860609
collect_time: 3.5075162791070484
reward_mean: 1469.5714111328125
reward_std: 475.0768127441406
reward_max: 2189.0
reward_min: 613.0
total_envstep_count: 1915604
total_train_sample_count: 1915559
total_episode_count: 12534
total_duration: 2417.1014071277227
[2024-11-20 00:03:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 964
train_sample_count: 964
avg_envstep_per_episode: 192.8
avg_sample_per_episode: 192.8
avg_envstep_per_sec: 821.5264548411939
avg_train_sample_per_sec: 821.5264548411939
avg_episode_per_sec: 4.26102933008918
collect_time: 1.1734253891876765
reward_mean: 984.0
reward_std: 316.9088134765625
reward_max: 1333.0
reward_min: 596.0
total_envstep_count: 1916584
total_train_sample_count: 1916535
total_episode_count: 12539
total_duration: 2418.2748325169105
[2024-11-20 00:03:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 945
train_sample_count: 945
avg_envstep_per_episode: 157.5
avg_sample_per_episode: 157.5
avg_envstep_per_sec: 822.0357019426502
avg_train_sample_per_sec: 822.0357019426502
avg_episode_per_sec: 5.219274298048573
collect_time: 1.1495851065431322
reward_mean: 912.8333129882812
reward_std: 456.64697265625
reward_max: 1839.0
reward_min: 585.0
total_envstep_count: 1917555
total_train_sample_count: 1917516
total_episode_count: 12545
total_duration: 2419.424417623454
[2024-11-20 00:03:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 726
train_sample_count: 726
avg_envstep_per_episode: 145.2
avg_sample_per_episode: 145.2
avg_envstep_per_sec: 807.5469054590659
avg_train_sample_per_sec: 807.5469054590659
avg_episode_per_sec: 5.561617806191914
collect_time: 0.8990189858845302
reward_mean: 1029.0
reward_std: 327.20941162109375
reward_max: 1316.0
reward_min: 626.0
total_envstep_count: 1918590
total_train_sample_count: 1918530
total_episode_count: 12550
total_duration: 2420.3234366093384
[2024-11-20 00:03:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1442
train_sample_count: 1442
avg_envstep_per_episode: 160.22222222222223
avg_sample_per_episode: 160.22222222222223
avg_envstep_per_sec: 812.602415147098
avg_train_sample_per_sec: 812.602415147098
avg_episode_per_sec: 5.071721037672595
collect_time: 1.7745455503463745
reward_mean: 1060.22216796875
reward_std: 473.1567077636719
reward_max: 1843.0
reward_min: 611.0
total_envstep_count: 1919559
total_train_sample_count: 1919516
total_episode_count: 12559
total_duration: 2422.0979821596848
[2024-11-20 00:03:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 966
train_sample_count: 966
avg_envstep_per_episode: 120.75
avg_sample_per_episode: 120.75
avg_envstep_per_sec: 808.8331071361658
avg_train_sample_per_sec: 808.8331071361658
avg_episode_per_sec: 6.698410825144231
collect_time: 1.1943131302084242
reward_mean: 976.25
reward_std: 473.29107666015625
reward_max: 1914.0
reward_min: 617.0
total_envstep_count: 1920576
total_train_sample_count: 1920518
total_episode_count: 12567
total_duration: 2423.292295289893
[2024-11-20 00:03:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 74
train_sample_count: 74
avg_envstep_per_episode: 74.0
avg_sample_per_episode: 74.0
avg_envstep_per_sec: 817.6770065897505
avg_train_sample_per_sec: 817.6770065897505
avg_episode_per_sec: 11.049689278239871
collect_time: 0.09050028238977705
reward_mean: 653.0
reward_std: 0.0
reward_max: 653.0
reward_min: 653.0
total_envstep_count: 1921535
total_train_sample_count: 1921480
total_episode_count: 12568
total_duration: 2423.3827955722827
[2024-11-20 00:03:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1123
train_sample_count: 1123
avg_envstep_per_episode: 224.6
avg_sample_per_episode: 224.6
avg_envstep_per_sec: 812.7115725367814
avg_train_sample_per_sec: 812.7115725367814
avg_episode_per_sec: 3.6184842944647437
collect_time: 1.3817940311772485
reward_mean: 1370.4000244140625
reward_std: 508.25762939453125
reward_max: 1835.0
reward_min: 736.0
total_envstep_count: 1922538
total_train_sample_count: 1922495
total_episode_count: 12573
total_duration: 2424.76458960346
[2024-11-20 00:03:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1494
train_sample_count: 1494
avg_envstep_per_episode: 249.0
avg_sample_per_episode: 249.0
avg_envstep_per_sec: 814.7617874588335
avg_train_sample_per_sec: 814.7617874588335
avg_episode_per_sec: 3.2721356926057568
collect_time: 1.8336647876671384
reward_mean: 1109.1666259765625
reward_std: 371.3190002441406
reward_max: 1624.0
reward_min: 603.0
total_envstep_count: 1923494
total_train_sample_count: 1923473
total_episode_count: 12579
total_duration: 2426.5982543911273
[2024-11-20 00:03:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 694
train_sample_count: 694
avg_envstep_per_episode: 138.8
avg_sample_per_episode: 138.8
avg_envstep_per_sec: 827.4917229268549
avg_train_sample_per_sec: 827.4917229268549
avg_episode_per_sec: 5.961755928867831
collect_time: 0.8386790837560381
reward_mean: 787.7999877929688
reward_std: 265.6813049316406
reward_max: 1314.0
reward_min: 609.0
total_envstep_count: 1924513
total_train_sample_count: 1924467
total_episode_count: 12584
total_duration: 2427.4369334748835
[2024-11-20 00:04:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 815
train_sample_count: 815
avg_envstep_per_episode: 135.83333333333334
avg_sample_per_episode: 135.83333333333334
avg_envstep_per_sec: 811.2876051378481
avg_train_sample_per_sec: 811.2876051378481
avg_episode_per_sec: 5.97266948567741
collect_time: 1.0045759294714247
reward_mean: 718.8333129882812
reward_std: 360.6953430175781
reward_max: 1425.0
reward_min: 230.0
total_envstep_count: 1925524
total_train_sample_count: 1925498
total_episode_count: 12590
total_duration: 2428.4415094043547
[2024-11-20 00:04:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1168
train_sample_count: 1168
avg_envstep_per_episode: 166.85714285714286
avg_sample_per_episode: 166.85714285714286
avg_envstep_per_sec: 818.4371518371762
avg_train_sample_per_sec: 818.4371518371762
avg_episode_per_sec: 4.905017177106364
collect_time: 1.4271101909024377
reward_mean: 1187.4285888671875
reward_std: 421.27386474609375
reward_max: 1696.0
reward_min: 603.0
total_envstep_count: 1926528
total_train_sample_count: 1926510
total_episode_count: 12597
total_duration: 2429.8686195952573
[2024-11-20 00:04:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 499
train_sample_count: 499
avg_envstep_per_episode: 83.16666666666667
avg_sample_per_episode: 83.16666666666667
avg_envstep_per_sec: 809.9036491482422
avg_train_sample_per_sec: 809.9036491482422
avg_episode_per_sec: 9.738320430640186
collect_time: 0.6161226715360368
reward_mean: 599.3333129882812
reward_std: 175.23382568359375
reward_max: 817.0
reward_min: 237.0
total_envstep_count: 1927546
total_train_sample_count: 1927513
total_episode_count: 12603
total_duration: 2430.4847422667935
[2024-11-20 00:04:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1016
train_sample_count: 1016
avg_envstep_per_episode: 203.2
avg_sample_per_episode: 203.2
avg_envstep_per_sec: 807.2802918119277
avg_train_sample_per_sec: 807.2802918119277
avg_episode_per_sec: 3.972836081751612
collect_time: 1.2585467653615132
reward_mean: 1422.199951171875
reward_std: 594.4891967773438
reward_max: 2360.0
reward_min: 609.0
total_envstep_count: 1928541
total_train_sample_count: 1928493
total_episode_count: 12608
total_duration: 2431.743289032155
[2024-11-20 00:04:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 770
train_sample_count: 770
avg_envstep_per_episode: 256.6666666666667
avg_sample_per_episode: 256.6666666666667
avg_envstep_per_sec: 812.9721944355356
avg_train_sample_per_sec: 812.9721944355356
avg_episode_per_sec: 3.1674241341644245
collect_time: 0.9471418644700731
reward_mean: 1899.3333740234375
reward_std: 29.555971145629883
reward_max: 1929.0
reward_min: 1859.0
total_envstep_count: 1929595
total_train_sample_count: 1929551
total_episode_count: 12611
total_duration: 2432.6904308966255
[2024-11-20 00:04:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 999
train_sample_count: 999
avg_envstep_per_episode: 199.8
avg_sample_per_episode: 199.8
avg_envstep_per_sec: 815.6556617759186
avg_train_sample_per_sec: 815.6556617759186
avg_episode_per_sec: 4.082360669549142
collect_time: 1.2247815430164337
reward_mean: 1427.199951171875
reward_std: 462.4320068359375
reward_max: 1917.0
reward_min: 624.0
total_envstep_count: 1930575
total_train_sample_count: 1930538
total_episode_count: 12616
total_duration: 2433.915212439642
[2024-11-20 00:04:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 822
train_sample_count: 822
avg_envstep_per_episode: 137.0
avg_sample_per_episode: 137.0
avg_envstep_per_sec: 819.5932021956714
avg_train_sample_per_sec: 819.5932021956714
avg_episode_per_sec: 5.98243213281512
collect_time: 1.0029365760939462
reward_mean: 701.8333129882812
reward_std: 322.1559753417969
reward_max: 1332.0
reward_min: 245.0
total_envstep_count: 1931545
total_train_sample_count: 1931516
total_episode_count: 12622
total_duration: 2434.9181490157357
[2024-11-20 00:04:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 837
train_sample_count: 837
avg_envstep_per_episode: 167.4
avg_sample_per_episode: 167.4
avg_envstep_per_sec: 821.0218546245271
avg_train_sample_per_sec: 821.0218546245271
avg_episode_per_sec: 4.904551102894427
collect_time: 1.0194612911769323
reward_mean: 983.4000244140625
reward_std: 301.5404357910156
reward_max: 1319.0
reward_min: 620.0
total_envstep_count: 1932532
total_train_sample_count: 1932485
total_episode_count: 12627
total_duration: 2435.9376103069126
[2024-11-20 00:04:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 789
train_sample_count: 789
avg_envstep_per_episode: 131.5
avg_sample_per_episode: 131.5
avg_envstep_per_sec: 813.2677548376355
avg_train_sample_per_sec: 813.2677548376355
avg_episode_per_sec: 6.184545664164529
collect_time: 0.9701601905482157
reward_mean: 750.1666870117188
reward_std: 254.9950408935547
reward_max: 1311.0
reward_min: 603.0
total_envstep_count: 1933518
total_train_sample_count: 1933478
total_episode_count: 12633
total_duration: 2436.9077704974607
[2024-11-20 00:04:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 695
train_sample_count: 695
avg_envstep_per_episode: 139.0
avg_sample_per_episode: 139.0
avg_envstep_per_sec: 807.1905062726155
avg_train_sample_per_sec: 807.1905062726155
avg_episode_per_sec: 5.807125944407305
collect_time: 0.8610111176967622
reward_mean: 979.0
reward_std: 326.89874267578125
reward_max: 1335.0
reward_min: 597.0
total_envstep_count: 1934505
total_train_sample_count: 1934461
total_episode_count: 12638
total_duration: 2437.7687816151574
[2024-11-20 00:04:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1082
train_sample_count: 1082
avg_envstep_per_episode: 270.5
avg_sample_per_episode: 270.5
avg_envstep_per_sec: 815.9946926896289
avg_train_sample_per_sec: 815.9946926896289
avg_episode_per_sec: 3.016616239148351
collect_time: 1.3259890164647783
reward_mean: 1558.0
reward_std: 141.1612548828125
reward_max: 1678.0
reward_min: 1319.0
total_envstep_count: 1935501
total_train_sample_count: 1935459
total_episode_count: 12642
total_duration: 2439.0947706316224
[2024-11-20 00:04:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2839
train_sample_count: 2839
avg_envstep_per_episode: 473.1666666666667
avg_sample_per_episode: 473.1666666666667
avg_envstep_per_sec: 819.0052091124292
avg_train_sample_per_sec: 819.0052091124292
avg_episode_per_sec: 1.730902167902281
collect_time: 3.466400418962751
reward_mean: 1022.5
reward_std: 466.4757080078125
reward_max: 1680.0
reward_min: 502.0
total_envstep_count: 1936512
total_train_sample_count: 1936462
total_episode_count: 12648
total_duration: 2442.561171050585
[2024-11-20 00:05:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 721
train_sample_count: 721
avg_envstep_per_episode: 144.2
avg_sample_per_episode: 144.2
avg_envstep_per_sec: 801.3181439304152
avg_train_sample_per_sec: 801.3181439304152
avg_episode_per_sec: 5.556991289392616
collect_time: 0.8997674712112973
reward_mean: 921.2000122070312
reward_std: 243.28370666503906
reward_max: 1330.0
reward_min: 626.0
total_envstep_count: 1937491
total_train_sample_count: 1937471
total_episode_count: 12653
total_duration: 2443.4609385217964
[2024-11-20 00:05:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 800
train_sample_count: 800
avg_envstep_per_episode: 133.33333333333334
avg_sample_per_episode: 133.33333333333334
avg_envstep_per_sec: 820.1164312000673
avg_train_sample_per_sec: 820.1164312000673
avg_episode_per_sec: 6.150873234000504
collect_time: 0.9754712496485028
reward_mean: 992.0
reward_std: 365.47320556640625
reward_max: 1427.0
reward_min: 597.0
total_envstep_count: 1938526
total_train_sample_count: 1938487
total_episode_count: 12659
total_duration: 2444.4364097714447
[2024-11-20 00:05:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 529
train_sample_count: 529
avg_envstep_per_episode: 132.25
avg_sample_per_episode: 132.25
avg_envstep_per_sec: 815.9904100750377
avg_train_sample_per_sec: 815.9904100750377
avg_episode_per_sec: 6.170059811531477
collect_time: 0.6482919326850344
reward_mean: 926.0
reward_std: 445.4542541503906
reward_max: 1684.0
reward_min: 602.0
total_envstep_count: 1939498
total_train_sample_count: 1939472
total_episode_count: 12663
total_duration: 2445.0847017041297
[2024-11-20 00:05:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1495
train_sample_count: 1495
avg_envstep_per_episode: 299.0
avg_sample_per_episode: 299.0
avg_envstep_per_sec: 819.4642266205657
avg_train_sample_per_sec: 819.4642266205657
avg_episode_per_sec: 2.740683032175805
collect_time: 1.824362737791879
reward_mean: 1436.5999755859375
reward_std: 645.4569091796875
reward_max: 2530.0
reward_min: 797.0
total_envstep_count: 1940511
total_train_sample_count: 1940451
total_episode_count: 12668
total_duration: 2446.9090644419216
[2024-11-20 00:05:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1413
train_sample_count: 1413
avg_envstep_per_episode: 282.6
avg_sample_per_episode: 282.6
avg_envstep_per_sec: 820.8378165124439
avg_train_sample_per_sec: 820.8378165124439
avg_episode_per_sec: 2.9045924151183433
collect_time: 1.7214119178908214
reward_mean: 1435.800048828125
reward_std: 558.8911743164062
reward_max: 2290.0
reward_min: 582.0
total_envstep_count: 1941491
total_train_sample_count: 1941444
total_episode_count: 12673
total_duration: 2448.6304763598123
[2024-11-20 00:05:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1135
train_sample_count: 1135
avg_envstep_per_episode: 189.16666666666666
avg_sample_per_episode: 189.16666666666666
avg_envstep_per_sec: 798.314994365259
avg_train_sample_per_sec: 798.314994365259
avg_episode_per_sec: 4.220167371093881
collect_time: 1.4217445594923837
reward_mean: 1275.6666259765625
reward_std: 428.23773193359375
reward_max: 1885.0
reward_min: 638.0
total_envstep_count: 1942469
total_train_sample_count: 1942423
total_episode_count: 12679
total_duration: 2450.0522209193045
[2024-11-20 00:05:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1216
train_sample_count: 1216
avg_envstep_per_episode: 110.54545454545455
avg_sample_per_episode: 110.54545454545455
avg_envstep_per_sec: 778.5160240924588
avg_train_sample_per_sec: 778.5160240924588
avg_episode_per_sec: 7.0424969284679655
collect_time: 1.5619460131440845
reward_mean: 851.4545288085938
reward_std: 340.60491943359375
reward_max: 1691.0
reward_min: 630.0
total_envstep_count: 1943445
total_train_sample_count: 1943423
total_episode_count: 12690
total_duration: 2451.614166932449
[2024-11-20 00:05:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 308
train_sample_count: 308
avg_envstep_per_episode: 154.0
avg_sample_per_episode: 154.0
avg_envstep_per_sec: 816.5240941314482
avg_train_sample_per_sec: 816.5240941314482
avg_episode_per_sec: 5.3021045073470665
collect_time: 0.3772087097167969
reward_mean: 1325.0
reward_std: 4.0
reward_max: 1329.0
reward_min: 1321.0
total_envstep_count: 1944443
total_train_sample_count: 1944391
total_episode_count: 12692
total_duration: 2451.9913756421656
[2024-11-20 00:05:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1575
train_sample_count: 1575
avg_envstep_per_episode: 196.875
avg_sample_per_episode: 196.875
avg_envstep_per_sec: 808.0106792643465
avg_train_sample_per_sec: 808.0106792643465
avg_episode_per_sec: 4.104181228009379
collect_time: 1.9492316629205433
reward_mean: 1333.75
reward_std: 513.3660278320312
reward_max: 1900.0
reward_min: 636.0
total_envstep_count: 1945460
total_train_sample_count: 1945438
total_episode_count: 12700
total_duration: 2453.9406073050864
[2024-11-20 00:05:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 906
train_sample_count: 906
avg_envstep_per_episode: 129.42857142857142
avg_sample_per_episode: 129.42857142857142
avg_envstep_per_sec: 806.951452669893
avg_train_sample_per_sec: 806.951452669893
avg_episode_per_sec: 6.23472424800138
collect_time: 1.1227441217218128
reward_mean: 1151.7142333984375
reward_std: 317.0496826171875
reward_max: 1438.0
reward_min: 654.0
total_envstep_count: 1946487
total_train_sample_count: 1946428
total_episode_count: 12707
total_duration: 2455.0633514268084
[2024-11-20 00:05:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1096
train_sample_count: 1096
avg_envstep_per_episode: 137.0
avg_sample_per_episode: 137.0
avg_envstep_per_sec: 816.3032745975747
avg_train_sample_per_sec: 816.3032745975747
avg_episode_per_sec: 5.95841806275602
collect_time: 1.3426382499081748
reward_mean: 1172.0
reward_std: 352.7109375
reward_max: 1698.0
reward_min: 598.0
total_envstep_count: 1947427
total_train_sample_count: 1947404
total_episode_count: 12715
total_duration: 2456.4059896767167
[2024-11-20 00:05:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 830
train_sample_count: 830
avg_envstep_per_episode: 138.33333333333334
avg_sample_per_episode: 138.33333333333334
avg_envstep_per_sec: 815.5149578539804
avg_train_sample_per_sec: 815.5149578539804
avg_episode_per_sec: 5.895288851956485
collect_time: 1.017761835030147
reward_mean: 892.8333129882812
reward_std: 406.9420166015625
reward_max: 1693.0
reward_min: 604.0
total_envstep_count: 1948430
total_train_sample_count: 1948390
total_episode_count: 12721
total_duration: 2457.423751511747
[2024-11-20 00:05:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 889
train_sample_count: 889
avg_envstep_per_episode: 222.25
avg_sample_per_episode: 222.25
avg_envstep_per_sec: 819.3956533382382
avg_train_sample_per_sec: 819.3956533382382
avg_episode_per_sec: 3.6868195875736247
collect_time: 1.0849459554467882
reward_mean: 1265.75
reward_std: 90.65697479248047
reward_max: 1326.0
reward_min: 1109.0
total_envstep_count: 1949402
total_train_sample_count: 1949363
total_episode_count: 12725
total_duration: 2458.508697467194
[2024-11-20 00:05:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1149
train_sample_count: 1149
avg_envstep_per_episode: 229.8
avg_sample_per_episode: 229.8
avg_envstep_per_sec: 824.1612065341811
avg_train_sample_per_sec: 824.1612065341811
avg_episode_per_sec: 3.5864282268676293
collect_time: 1.3941447266510554
reward_mean: 1168.0
reward_std: 274.21014404296875
reward_max: 1317.0
reward_min: 620.0
total_envstep_count: 1950381
total_train_sample_count: 1950356
total_episode_count: 12730
total_duration: 2459.902842193845
[2024-11-20 00:05:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 235
train_sample_count: 235
avg_envstep_per_episode: 117.5
avg_sample_per_episode: 117.5
avg_envstep_per_sec: 823.102453491286
avg_train_sample_per_sec: 823.102453491286
avg_episode_per_sec: 7.005127263755626
collect_time: 0.28550516281809124
reward_mean: 759.5
reward_std: 542.5
reward_max: 1302.0
reward_min: 217.0
total_envstep_count: 1951355
total_train_sample_count: 1951323
total_episode_count: 12732
total_duration: 2460.188347356663
[2024-11-20 00:05:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1578
train_sample_count: 1578
avg_envstep_per_episode: 197.25
avg_sample_per_episode: 197.25
avg_envstep_per_sec: 816.0400167172696
avg_train_sample_per_sec: 816.0400167172696
avg_episode_per_sec: 4.137085002368921
collect_time: 1.9337286991732463
reward_mean: 1060.25
reward_std: 320.7544860839844
reward_max: 1323.0
reward_min: 637.0
total_envstep_count: 1952333
total_train_sample_count: 1952289
total_episode_count: 12740
total_duration: 2462.1220760558363
[2024-11-20 00:05:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 929
train_sample_count: 929
avg_envstep_per_episode: 154.83333333333334
avg_sample_per_episode: 154.83333333333334
avg_envstep_per_sec: 812.1017900128235
avg_train_sample_per_sec: 812.1017900128235
avg_episode_per_sec: 5.245006178769581
collect_time: 1.143945268222264
reward_mean: 1074.5
reward_std: 465.24462890625
reward_max: 1695.0
reward_min: 594.0
total_envstep_count: 1953329
total_train_sample_count: 1953290
total_episode_count: 12746
total_duration: 2463.2660213240583
[2024-11-20 00:06:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 611
train_sample_count: 611
avg_envstep_per_episode: 203.66666666666666
avg_sample_per_episode: 203.66666666666666
avg_envstep_per_sec: 824.3124655455447
avg_train_sample_per_sec: 824.3124655455447
avg_episode_per_sec: 4.047360714626242
collect_time: 0.7412237780434745
reward_mean: 1496.0
reward_std: 655.5166015625
reward_max: 2360.0
reward_min: 773.0
total_envstep_count: 1954295
total_train_sample_count: 1954261
total_episode_count: 12749
total_duration: 2464.007245102102
[2024-11-20 00:06:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1647
train_sample_count: 1647
avg_envstep_per_episode: 164.7
avg_sample_per_episode: 164.7
avg_envstep_per_sec: 810.8785974326717
avg_train_sample_per_sec: 810.8785974326717
avg_episode_per_sec: 4.923367318959755
collect_time: 2.031130190406527
reward_mean: 1120.800048828125
reward_std: 524.8875732421875
reward_max: 1947.0
reward_min: 234.0
total_envstep_count: 1955286
total_train_sample_count: 1955260
total_episode_count: 12759
total_duration: 2466.0383752925086
[2024-11-20 00:06:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 933
train_sample_count: 933
avg_envstep_per_episode: 155.5
avg_sample_per_episode: 155.5
avg_envstep_per_sec: 816.2584187853419
avg_train_sample_per_sec: 816.2584187853419
avg_episode_per_sec: 5.249250281577761
collect_time: 1.1430203701768602
reward_mean: 1013.8333129882812
reward_std: 343.8140869140625
reward_max: 1425.0
reward_min: 605.0
total_envstep_count: 1956272
total_train_sample_count: 1956241
total_episode_count: 12765
total_duration: 2467.1813956626856
[2024-11-20 00:06:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1010
train_sample_count: 1010
avg_envstep_per_episode: 126.25
avg_sample_per_episode: 126.25
avg_envstep_per_sec: 820.2351139229158
avg_train_sample_per_sec: 820.2351139229158
avg_episode_per_sec: 6.496911793448839
collect_time: 1.2313542578901564
reward_mean: 951.125
reward_std: 418.4075012207031
reward_max: 1690.0
reward_min: 618.0
total_envstep_count: 1957289
total_train_sample_count: 1957263
total_episode_count: 12773
total_duration: 2468.4127499205756
[2024-11-20 00:06:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 964
train_sample_count: 964
avg_envstep_per_episode: 120.5
avg_sample_per_episode: 120.5
avg_envstep_per_sec: 808.9536238850961
avg_train_sample_per_sec: 808.9536238850961
avg_episode_per_sec: 6.713308082033993
collect_time: 1.1916628735406056
reward_mean: 885.375
reward_std: 336.6593017578125
reward_max: 1329.0
reward_min: 608.0
total_envstep_count: 1958305
total_train_sample_count: 1958263
total_episode_count: 12781
total_duration: 2469.6044127941163
[2024-11-20 00:06:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 827
train_sample_count: 827
avg_envstep_per_episode: 118.14285714285714
avg_sample_per_episode: 118.14285714285714
avg_envstep_per_sec: 789.9633609121781
avg_train_sample_per_sec: 789.9633609121781
avg_episode_per_sec: 6.686509705423515
collect_time: 1.0468839960438865
reward_mean: 1002.4285888671875
reward_std: 551.8102416992188
reward_max: 1709.0
reward_min: 236.0
total_envstep_count: 1959308
total_train_sample_count: 1959282
total_episode_count: 12788
total_duration: 2470.6512967901604
[2024-11-20 00:06:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1088
train_sample_count: 1088
avg_envstep_per_episode: 155.42857142857142
avg_sample_per_episode: 155.42857142857142
avg_envstep_per_sec: 800.8351923982399
avg_train_sample_per_sec: 800.8351923982399
avg_episode_per_sec: 5.152432304032793
collect_time: 1.3585816536630906
reward_mean: 1211.2857666015625
reward_std: 677.5115966796875
reward_max: 2344.0
reward_min: 621.0
total_envstep_count: 1960280
total_train_sample_count: 1960250
total_episode_count: 12795
total_duration: 2472.0098784438233
[2024-11-20 00:06:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 851
train_sample_count: 851
avg_envstep_per_episode: 121.57142857142857
avg_sample_per_episode: 121.57142857142857
avg_envstep_per_sec: 816.3188010594498
avg_train_sample_per_sec: 816.3188010594498
avg_episode_per_sec: 6.714725743144711
collect_time: 1.0424848709787642
reward_mean: 964.1428833007812
reward_std: 471.343505859375
reward_max: 1929.0
reward_min: 600.0
total_envstep_count: 1961297
total_train_sample_count: 1961257
total_episode_count: 12802
total_duration: 2473.052363314802
[2024-11-20 00:06:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1158
train_sample_count: 1158
avg_envstep_per_episode: 144.75
avg_sample_per_episode: 144.75
avg_envstep_per_sec: 804.3755738792291
avg_train_sample_per_sec: 804.3755738792291
avg_episode_per_sec: 5.556998783276194
collect_time: 1.4396260125296456
reward_mean: 1068.125
reward_std: 670.341796875
reward_max: 2343.0
reward_min: 228.0
total_envstep_count: 1962299
total_train_sample_count: 1962235
total_episode_count: 12810
total_duration: 2474.4919893273313
[2024-11-20 00:06:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 960
train_sample_count: 960
avg_envstep_per_episode: 160.0
avg_sample_per_episode: 160.0
avg_envstep_per_sec: 824.2772622712354
avg_train_sample_per_sec: 824.2772622712354
avg_episode_per_sec: 5.151732889195221
collect_time: 1.1646566561290197
reward_mean: 1275.6666259765625
reward_std: 485.2197570800781
reward_max: 1860.0
reward_min: 620.0
total_envstep_count: 1963254
total_train_sample_count: 1963219
total_episode_count: 12816
total_duration: 2475.6566459834603
[2024-11-20 00:06:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 842
train_sample_count: 842
avg_envstep_per_episode: 93.55555555555556
avg_sample_per_episode: 93.55555555555556
avg_envstep_per_sec: 817.4514328363348
avg_train_sample_per_sec: 817.4514328363348
avg_episode_per_sec: 8.737604388986952
collect_time: 1.0300306124346597
reward_mean: 621.5555419921875
reward_std: 383.6624755859375
reward_max: 1424.0
reward_min: 140.0
total_envstep_count: 1964229
total_train_sample_count: 1964193
total_episode_count: 12825
total_duration: 2476.686676595895
[2024-11-20 00:06:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 312
train_sample_count: 312
avg_envstep_per_episode: 104.0
avg_sample_per_episode: 104.0
avg_envstep_per_sec: 811.885360574887
avg_train_sample_per_sec: 811.885360574887
avg_episode_per_sec: 7.80659000552776
collect_time: 0.3842907079628536
reward_mean: 878.0
reward_std: 318.1990966796875
reward_max: 1328.0
reward_min: 652.0
total_envstep_count: 1965202
total_train_sample_count: 1965177
total_episode_count: 12828
total_duration: 2477.0709673038577
[2024-11-20 00:06:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 822
train_sample_count: 822
avg_envstep_per_episode: 205.5
avg_sample_per_episode: 205.5
avg_envstep_per_sec: 818.9374668525936
avg_train_sample_per_sec: 818.9374668525936
avg_episode_per_sec: 3.9850971622997258
collect_time: 1.0037396422454288
reward_mean: 1716.0
reward_std: 128.5709991455078
reward_max: 1921.0
reward_min: 1566.0
total_envstep_count: 1966207
total_train_sample_count: 1966155
total_episode_count: 12832
total_duration: 2478.074706946103
[2024-11-20 00:06:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1279
train_sample_count: 1279
avg_envstep_per_episode: 213.16666666666666
avg_sample_per_episode: 213.16666666666666
avg_envstep_per_sec: 822.0377533064159
avg_train_sample_per_sec: 822.0377533064159
avg_episode_per_sec: 3.8563147144945233
collect_time: 1.555889610733305
reward_mean: 1212.3333740234375
reward_std: 642.817138671875
reward_max: 2294.0
reward_min: 606.0
total_envstep_count: 1967209
total_train_sample_count: 1967170
total_episode_count: 12838
total_duration: 2479.6305965568363
[2024-11-20 00:06:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 990
train_sample_count: 990
avg_envstep_per_episode: 141.42857142857142
avg_sample_per_episode: 141.42857142857142
avg_envstep_per_sec: 813.5750944477938
avg_train_sample_per_sec: 813.5750944477938
avg_episode_per_sec: 5.752551172863188
collect_time: 1.2168514089924949
reward_mean: 1080.2857666015625
reward_std: 411.3853454589844
reward_max: 1692.0
reward_min: 615.0
total_envstep_count: 1968211
total_train_sample_count: 1968172
total_episode_count: 12845
total_duration: 2480.847447965829
[2024-11-20 00:06:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 736
train_sample_count: 736
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 820.541101071294
avg_train_sample_per_sec: 820.541101071294
avg_episode_per_sec: 4.45946250582225
collect_time: 0.8969690842287881
reward_mean: 1328.25
reward_std: 434.60406494140625
reward_max: 1688.0
reward_min: 621.0
total_envstep_count: 1969185
total_train_sample_count: 1969160
total_episode_count: 12849
total_duration: 2481.7444170500576
[2024-11-20 00:06:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 768
train_sample_count: 768
avg_envstep_per_episode: 153.6
avg_sample_per_episode: 153.6
avg_envstep_per_sec: 821.3713951087765
avg_train_sample_per_sec: 821.3713951087765
avg_episode_per_sec: 5.34747002023943
collect_time: 0.9350216048104423
reward_mean: 854.0
reward_std: 365.76055908203125
reward_max: 1570.0
reward_min: 604.0
total_envstep_count: 1970173
total_train_sample_count: 1970132
total_episode_count: 12854
total_duration: 2482.679438654868
[2024-11-20 00:07:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1087
train_sample_count: 1087
avg_envstep_per_episode: 181.16666666666666
avg_sample_per_episode: 181.16666666666666
avg_envstep_per_sec: 827.4089849939553
avg_train_sample_per_sec: 827.4089849939553
avg_episode_per_sec: 4.567114912570131
collect_time: 1.3137396616595132
reward_mean: 1200.0
reward_std: 605.2490234375
reward_max: 2340.0
reward_min: 593.0
total_envstep_count: 1971151
total_train_sample_count: 1971111
total_episode_count: 12860
total_duration: 2483.9931783165275
[2024-11-20 00:07:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 833
train_sample_count: 833
avg_envstep_per_episode: 166.6
avg_sample_per_episode: 166.6
avg_envstep_per_sec: 827.330241248152
avg_train_sample_per_sec: 827.330241248152
avg_episode_per_sec: 4.965967834622761
collect_time: 1.0068530780928475
reward_mean: 1211.0
reward_std: 642.8579711914062
reward_max: 2351.0
reward_min: 616.0
total_envstep_count: 1972138
total_train_sample_count: 1972100
total_episode_count: 12865
total_duration: 2485.0000313946202
[2024-11-20 00:07:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2264
train_sample_count: 2264
avg_envstep_per_episode: 377.3333333333333
avg_sample_per_episode: 377.3333333333333
avg_envstep_per_sec: 821.0001864968303
avg_train_sample_per_sec: 821.0001864968303
avg_episode_per_sec: 2.175795547253084
collect_time: 2.757612041064671
reward_mean: 1318.3333740234375
reward_std: 738.5582275390625
reward_max: 2343.0
reward_min: 602.0
total_envstep_count: 1973134
total_train_sample_count: 1973092
total_episode_count: 12871
total_duration: 2487.7576434356847
[2024-11-20 00:07:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 972
train_sample_count: 972
avg_envstep_per_episode: 121.5
avg_sample_per_episode: 121.5
avg_envstep_per_sec: 815.0709001334205
avg_train_sample_per_sec: 815.0709001334205
avg_episode_per_sec: 6.7084024702339144
collect_time: 1.192534293447222
reward_mean: 886.625
reward_std: 338.6742248535156
reward_max: 1337.0
reward_min: 613.0
total_envstep_count: 1974135
total_train_sample_count: 1974076
total_episode_count: 12879
total_duration: 2488.950177729132
[2024-11-20 00:07:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1153
train_sample_count: 1153
avg_envstep_per_episode: 128.11111111111111
avg_sample_per_episode: 128.11111111111111
avg_envstep_per_sec: 810.1670684677334
avg_train_sample_per_sec: 810.1670684677334
avg_episode_per_sec: 6.3239406905547275
collect_time: 1.4231632522174291
reward_mean: 993.5555419921875
reward_std: 437.45452880859375
reward_max: 1843.0
reward_min: 608.0
total_envstep_count: 1975191
total_train_sample_count: 1975145
total_episode_count: 12888
total_duration: 2490.3733409813494
[2024-11-20 00:07:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 807
train_sample_count: 807
avg_envstep_per_episode: 100.875
avg_sample_per_episode: 100.875
avg_envstep_per_sec: 814.3597965822748
avg_train_sample_per_sec: 814.3597965822748
avg_episode_per_sec: 8.072959569588846
collect_time: 0.990962475538254
reward_mean: 842.375
reward_std: 254.49505615234375
reward_max: 1333.0
reward_min: 610.0
total_envstep_count: 1976217
total_train_sample_count: 1976192
total_episode_count: 12896
total_duration: 2491.3643034568877
[2024-11-20 00:07:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1317
train_sample_count: 1317
avg_envstep_per_episode: 188.14285714285714
avg_sample_per_episode: 188.14285714285714
avg_envstep_per_sec: 818.8666526760961
avg_train_sample_per_sec: 818.8666526760961
avg_episode_per_sec: 4.352366415134908
collect_time: 1.608320470367159
reward_mean: 1206.142822265625
reward_std: 631.921875
reward_max: 2622.0
reward_min: 616.0
total_envstep_count: 1977226
total_train_sample_count: 1977197
total_episode_count: 12903
total_duration: 2492.972623927255
[2024-11-20 00:07:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 507
train_sample_count: 507
avg_envstep_per_episode: 126.75
avg_sample_per_episode: 126.75
avg_envstep_per_sec: 810.5638757773771
avg_train_sample_per_sec: 810.5638757773771
avg_episode_per_sec: 6.394981268460569
collect_time: 0.6254904951368059
reward_mean: 971.5
reward_std: 721.5
reward_max: 1693.0
reward_min: 250.0
total_envstep_count: 1978215
total_train_sample_count: 1978172
total_episode_count: 12907
total_duration: 2493.598114422392
[2024-11-20 00:07:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1154
train_sample_count: 1154
avg_envstep_per_episode: 164.85714285714286
avg_sample_per_episode: 164.85714285714286
avg_envstep_per_sec: 814.7308117484196
avg_train_sample_per_sec: 814.7308117484196
avg_episode_per_sec: 4.942041319097866
collect_time: 1.4164187524999892
reward_mean: 1049.5714111328125
reward_std: 494.4110107421875
reward_max: 1915.0
reward_min: 605.0
total_envstep_count: 1979177
total_train_sample_count: 1979146
total_episode_count: 12914
total_duration: 2495.0145331748918
[2024-11-20 00:07:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1081
train_sample_count: 1081
avg_envstep_per_episode: 154.42857142857142
avg_sample_per_episode: 154.42857142857142
avg_envstep_per_sec: 815.9537739204055
avg_train_sample_per_sec: 815.9537739204055
avg_episode_per_sec: 5.283696963406881
collect_time: 1.3248299530574255
reward_mean: 907.5714111328125
reward_std: 356.9785461425781
reward_max: 1435.0
reward_min: 611.0
total_envstep_count: 1980194
total_train_sample_count: 1980155
total_episode_count: 12921
total_duration: 2496.339363127949
[2024-11-20 00:07:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1251
train_sample_count: 1251
avg_envstep_per_episode: 156.375
avg_sample_per_episode: 156.375
avg_envstep_per_sec: 807.2563786099682
avg_train_sample_per_sec: 807.2563786099682
avg_episode_per_sec: 5.162310974324337
collect_time: 1.549693546124867
reward_mean: 1092.875
reward_std: 389.39166259765625
reward_max: 1697.0
reward_min: 610.0
total_envstep_count: 1981210
total_train_sample_count: 1981166
total_episode_count: 12929
total_duration: 2497.889056674074
[2024-11-20 00:07:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 836
train_sample_count: 836
avg_envstep_per_episode: 139.33333333333334
avg_sample_per_episode: 139.33333333333334
avg_envstep_per_sec: 807.4055318739817
avg_train_sample_per_sec: 807.4055318739817
avg_episode_per_sec: 5.794776544550108
collect_time: 1.0354152492114475
reward_mean: 958.3333129882812
reward_std: 340.2076110839844
reward_max: 1435.0
reward_min: 593.0
total_envstep_count: 1982220
total_train_sample_count: 1982182
total_episode_count: 12935
total_duration: 2498.924471923285
[2024-11-20 00:07:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 614
train_sample_count: 614
avg_envstep_per_episode: 122.8
avg_sample_per_episode: 122.8
avg_envstep_per_sec: 817.0390657122075
avg_train_sample_per_sec: 817.0390657122075
avg_episode_per_sec: 6.65341258723296
collect_time: 0.7514940542834145
reward_mean: 802.2000122070312
reward_std: 318.032958984375
reward_max: 1431.0
reward_min: 605.0
total_envstep_count: 1983202
total_train_sample_count: 1983168
total_episode_count: 12940
total_duration: 2499.6759659775685
[2024-11-20 00:07:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 398
train_sample_count: 398
avg_envstep_per_episode: 132.66666666666666
avg_sample_per_episode: 132.66666666666666
avg_envstep_per_sec: 818.0919601909243
avg_train_sample_per_sec: 818.0919601909243
avg_episode_per_sec: 6.166522312996917
collect_time: 0.4864978747708457
reward_mean: 953.0
reward_std: 347.71539306640625
reward_max: 1430.0
reward_min: 611.0
total_envstep_count: 1984199
total_train_sample_count: 1984142
total_episode_count: 12943
total_duration: 2500.1624638523394
[2024-11-20 00:07:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1742
train_sample_count: 1742
avg_envstep_per_episode: 174.2
avg_sample_per_episode: 174.2
avg_envstep_per_sec: 816.7290551007821
avg_train_sample_per_sec: 816.7290551007821
avg_episode_per_sec: 4.688456114241
collect_time: 2.1328982838562562
reward_mean: 1180.800048828125
reward_std: 534.2229614257812
reward_max: 2317.0
reward_min: 604.0
total_envstep_count: 1985222
total_train_sample_count: 1985176
total_episode_count: 12953
total_duration: 2502.2953621361958
[2024-11-20 00:07:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 515
train_sample_count: 515
avg_envstep_per_episode: 128.75
avg_sample_per_episode: 128.75
avg_envstep_per_sec: 816.0833478237186
avg_train_sample_per_sec: 816.0833478237186
avg_episode_per_sec: 6.338511439407523
collect_time: 0.631062992981502
reward_mean: 815.5
reward_std: 273.4323425292969
reward_max: 1282.0
reward_min: 620.0
total_envstep_count: 1986210
total_train_sample_count: 1986171
total_episode_count: 12957
total_duration: 2502.9264251291775
[2024-11-20 00:07:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1251
train_sample_count: 1251
avg_envstep_per_episode: 312.75
avg_sample_per_episode: 312.75
avg_envstep_per_sec: 812.6891469201422
avg_train_sample_per_sec: 812.6891469201422
avg_episode_per_sec: 2.598526448985267
collect_time: 1.5393339565822057
reward_mean: 1356.75
reward_std: 326.7080993652344
reward_max: 1853.0
reward_min: 935.0
total_envstep_count: 1987182
total_train_sample_count: 1987146
total_episode_count: 12961
total_duration: 2504.4657590857596
[2024-11-20 00:08:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1127
train_sample_count: 1127
avg_envstep_per_episode: 187.83333333333334
avg_sample_per_episode: 187.83333333333334
avg_envstep_per_sec: 744.0744469450568
avg_train_sample_per_sec: 744.0744469450568
avg_episode_per_sec: 3.9613546421209764
collect_time: 1.5146333873271942
reward_mean: 1172.0
reward_std: 728.6560668945312
reward_max: 2644.0
reward_min: 608.0
total_envstep_count: 1988169
total_train_sample_count: 1988129
total_episode_count: 12967
total_duration: 2505.980392473087
[2024-11-20 00:08:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 902
train_sample_count: 902
avg_envstep_per_episode: 180.4
avg_sample_per_episode: 180.4
avg_envstep_per_sec: 708.973450394948
avg_train_sample_per_sec: 708.973450394948
avg_episode_per_sec: 3.9300080398833037
collect_time: 1.2722620282854353
reward_mean: 1341.199951171875
reward_std: 420.2163391113281
reward_max: 1919.0
reward_min: 613.0
total_envstep_count: 1989172
total_train_sample_count: 1989115
total_episode_count: 12972
total_duration: 2507.252654501372
[2024-11-20 00:08:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 632
train_sample_count: 632
avg_envstep_per_episode: 210.66666666666666
avg_sample_per_episode: 210.66666666666666
avg_envstep_per_sec: 807.6737356668602
avg_train_sample_per_sec: 807.6737356668602
avg_episode_per_sec: 3.8338943148743367
collect_time: 0.7824941830975669
reward_mean: 1620.0
reward_std: 78.05553436279297
reward_max: 1702.0
reward_min: 1515.0
total_envstep_count: 1990169
total_train_sample_count: 1990131
total_episode_count: 12975
total_duration: 2508.0351486844697
[2024-11-20 00:08:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1014
train_sample_count: 1014
avg_envstep_per_episode: 169.0
avg_sample_per_episode: 169.0
avg_envstep_per_sec: 808.4607124408396
avg_train_sample_per_sec: 808.4607124408396
avg_episode_per_sec: 4.783791197874791
collect_time: 1.2542353442737033
reward_mean: 1244.1666259765625
reward_std: 577.1757202148438
reward_max: 1923.0
reward_min: 610.0
total_envstep_count: 1991163
total_train_sample_count: 1991109
total_episode_count: 12981
total_duration: 2509.2893840287434
[2024-11-20 00:08:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 868
train_sample_count: 868
avg_envstep_per_episode: 289.3333333333333
avg_sample_per_episode: 289.3333333333333
avg_envstep_per_sec: 810.8380804704802
avg_train_sample_per_sec: 810.8380804704802
avg_episode_per_sec: 2.8024357619947473
collect_time: 1.0704973297459737
reward_mean: 1843.6666259765625
reward_std: 915.1544189453125
reward_max: 3029.0
reward_min: 801.0
total_envstep_count: 1992152
total_train_sample_count: 1992097
total_episode_count: 12984
total_duration: 2510.3598813584895
[2024-11-20 00:08:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 530
train_sample_count: 530
avg_envstep_per_episode: 132.5
avg_sample_per_episode: 132.5
avg_envstep_per_sec: 798.1967166770446
avg_train_sample_per_sec: 798.1967166770446
avg_episode_per_sec: 6.024126163600337
collect_time: 0.6639967177595412
reward_mean: 1275.25
reward_std: 397.3092956542969
reward_max: 1582.0
reward_min: 610.0
total_envstep_count: 1993117
total_train_sample_count: 1993071
total_episode_count: 12988
total_duration: 2511.023878076249
[2024-11-20 00:08:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1436
train_sample_count: 1436
avg_envstep_per_episode: 205.14285714285714
avg_sample_per_episode: 205.14285714285714
avg_envstep_per_sec: 788.8427194529827
avg_train_sample_per_sec: 788.8427194529827
avg_episode_per_sec: 3.8453335906482446
collect_time: 1.8203882277011871
reward_mean: 1487.0
reward_std: 680.9839477539062
reward_max: 2356.0
reward_min: 612.0
total_envstep_count: 1994103
total_train_sample_count: 1994063
total_episode_count: 12995
total_duration: 2512.84426630395
[2024-11-20 00:08:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 793
train_sample_count: 793
avg_envstep_per_episode: 158.6
avg_sample_per_episode: 158.6
avg_envstep_per_sec: 783.2468716028479
avg_train_sample_per_sec: 783.2468716028479
avg_episode_per_sec: 4.938504865087314
collect_time: 1.0124521766390118
reward_mean: 986.2000122070312
reward_std: 270.0425109863281
reward_max: 1425.0
reward_min: 616.0
total_envstep_count: 1995091
total_train_sample_count: 1995036
total_episode_count: 13000
total_duration: 2513.856718480589
[2024-11-20 00:08:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 727
train_sample_count: 727
avg_envstep_per_episode: 121.16666666666667
avg_sample_per_episode: 121.16666666666667
avg_envstep_per_sec: 794.1015338761654
avg_train_sample_per_sec: 794.1015338761654
avg_episode_per_sec: 6.553795327726262
collect_time: 0.9155000575951168
reward_mean: 852.0
reward_std: 356.4524230957031
reward_max: 1564.0
reward_min: 602.0
total_envstep_count: 1996071
total_train_sample_count: 1996027
total_episode_count: 13006
total_duration: 2514.772218538184
[2024-11-20 00:08:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 440
train_sample_count: 440
avg_envstep_per_episode: 146.66666666666666
avg_sample_per_episode: 146.66666666666666
avg_envstep_per_sec: 809.375119852502
avg_train_sample_per_sec: 809.375119852502
avg_episode_per_sec: 5.518466726267059
collect_time: 0.5436292631285531
reward_mean: 1291.6666259765625
reward_std: 517.3021850585938
reward_max: 1920.0
reward_min: 653.0
total_envstep_count: 1997028
total_train_sample_count: 1996995
total_episode_count: 13009
total_duration: 2515.3158478013124
[2024-11-20 00:08:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 774
train_sample_count: 774
avg_envstep_per_episode: 154.8
avg_sample_per_episode: 154.8
avg_envstep_per_sec: 810.5658867797843
avg_train_sample_per_sec: 810.5658867797843
avg_episode_per_sec: 5.2362137388874945
collect_time: 0.9548884459904263
reward_mean: 1302.0
reward_std: 775.9878540039062
reward_max: 2349.0
reward_min: 238.0
total_envstep_count: 1998031
total_train_sample_count: 1997997
total_episode_count: 13014
total_duration: 2516.270736247303
[2024-11-20 00:09:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1130
train_sample_count: 1130
avg_envstep_per_episode: 226.0
avg_sample_per_episode: 226.0
avg_envstep_per_sec: 806.9319267556709
avg_train_sample_per_sec: 806.9319267556709
avg_episode_per_sec: 3.5704952511312875
collect_time: 1.4003659571920124
reward_mean: 1333.5999755859375
reward_std: 648.90478515625
reward_max: 2306.0
reward_min: 610.0
total_envstep_count: 1999034
total_train_sample_count: 1998995
total_episode_count: 13019
total_duration: 2517.671102204495
[2024-11-20 00:09:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 685
train_sample_count: 685
avg_envstep_per_episode: 137.0
avg_sample_per_episode: 137.0
avg_envstep_per_sec: 816.6057432014102
avg_train_sample_per_sec: 816.6057432014102
avg_episode_per_sec: 5.960625862784016
collect_time: 0.8388380876609258
reward_mean: 1256.800048828125
reward_std: 494.55975341796875
reward_max: 1862.0
reward_min: 651.0
total_envstep_count: 1999990
total_train_sample_count: 1999968
total_episode_count: 13024
total_duration: 2518.509940292156
[2024-11-20 00:09:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1588
train_sample_count: 1588
avg_envstep_per_episode: 226.85714285714286
avg_sample_per_episode: 226.85714285714286
avg_envstep_per_sec: 811.4880915567073
avg_train_sample_per_sec: 811.4880915567073
avg_episode_per_sec: 3.577088564796569
collect_time: 1.9568987105573927
reward_mean: 1212.857177734375
reward_std: 661.2691650390625
reward_max: 2588.0
reward_min: 604.0
total_envstep_count: 2001033
total_train_sample_count: 2000992
total_episode_count: 13031
total_duration: 2520.466839002713
[2024-11-20 00:09:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 754
train_sample_count: 754
avg_envstep_per_episode: 125.66666666666667
avg_sample_per_episode: 125.66666666666667
avg_envstep_per_sec: 813.0372026387902
avg_train_sample_per_sec: 813.0372026387902
avg_episode_per_sec: 6.469792063438649
collect_time: 0.9273868373462133
reward_mean: 986.0
reward_std: 456.3960266113281
reward_max: 1911.0
reward_min: 616.0
total_envstep_count: 2002012
total_train_sample_count: 2001986
total_episode_count: 13037
total_duration: 2521.3942258400593
[2024-11-20 00:09:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2706
train_sample_count: 2706
avg_envstep_per_episode: 338.25
avg_sample_per_episode: 338.25
avg_envstep_per_sec: 796.7181351461174
avg_train_sample_per_sec: 796.7181351461174
avg_episode_per_sec: 2.355412077298204
collect_time: 3.396433293819428
reward_mean: 871.375
reward_std: 473.4891357421875
reward_max: 1771.0
reward_min: 245.0
total_envstep_count: 2003037
total_train_sample_count: 2003000
total_episode_count: 13045
total_duration: 2524.7906591338788
[2024-11-20 00:09:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 965
train_sample_count: 965
avg_envstep_per_episode: 193.0
avg_sample_per_episode: 193.0
avg_envstep_per_sec: 807.8497991983818
avg_train_sample_per_sec: 807.8497991983818
avg_episode_per_sec: 4.185750254913895
collect_time: 1.1945289841720035
reward_mean: 1110.4000244140625
reward_std: 479.843994140625
reward_max: 1698.0
reward_min: 636.0
total_envstep_count: 2004033
total_train_sample_count: 2003989
total_episode_count: 13050
total_duration: 2525.9851881180507
[2024-11-20 00:09:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1106
train_sample_count: 1106
avg_envstep_per_episode: 221.2
avg_sample_per_episode: 221.2
avg_envstep_per_sec: 806.8468380849514
avg_train_sample_per_sec: 806.8468380849514
avg_episode_per_sec: 3.6475896839283517
collect_time: 1.3707682149750846
reward_mean: 885.0
reward_std: 304.54620361328125
reward_max: 1411.0
reward_min: 601.0
total_envstep_count: 2005013
total_train_sample_count: 2004975
total_episode_count: 13055
total_duration: 2527.355956333026
[2024-11-20 00:09:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 983
train_sample_count: 983
avg_envstep_per_episode: 140.42857142857142
avg_sample_per_episode: 140.42857142857142
avg_envstep_per_sec: 799.1268922034878
avg_train_sample_per_sec: 799.1268922034878
avg_episode_per_sec: 5.690628937359527
collect_time: 1.2300925041948045
reward_mean: 1059.142822265625
reward_std: 483.9573669433594
reward_max: 1863.0
reward_min: 616.0
total_envstep_count: 2006030
total_train_sample_count: 2005982
total_episode_count: 13062
total_duration: 2528.586048837221
[2024-11-20 00:09:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1216
train_sample_count: 1216
avg_envstep_per_episode: 152.0
avg_sample_per_episode: 152.0
avg_envstep_per_sec: 806.0396731984775
avg_train_sample_per_sec: 806.0396731984775
avg_episode_per_sec: 5.302892586832089
collect_time: 1.5086106061935425
reward_mean: 1247.375
reward_std: 648.4810791015625
reward_max: 2362.0
reward_min: 596.0
total_envstep_count: 2007078
total_train_sample_count: 2007054
total_episode_count: 13070
total_duration: 2530.0946594434145
[2024-11-20 00:09:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1237
train_sample_count: 1237
avg_envstep_per_episode: 137.44444444444446
avg_sample_per_episode: 137.44444444444446
avg_envstep_per_sec: 807.0368413921118
avg_train_sample_per_sec: 807.0368413921118
avg_episode_per_sec: 5.87173126316007
collect_time: 1.5327676960400172
reward_mean: 1064.4444580078125
reward_std: 528.2457275390625
reward_max: 1702.0
reward_min: 243.0
total_envstep_count: 2008079
total_train_sample_count: 2008051
total_episode_count: 13079
total_duration: 2531.6274271394545
[2024-11-20 00:09:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 378
train_sample_count: 378
avg_envstep_per_episode: 94.5
avg_sample_per_episode: 94.5
avg_envstep_per_sec: 804.8997421411516
avg_train_sample_per_sec: 804.8997421411516
avg_episode_per_sec: 8.517457588795255
collect_time: 0.4696237061704908
reward_mean: 566.25
reward_std: 208.92747497558594
reward_max: 813.0
reward_min: 235.0
total_envstep_count: 2009075
total_train_sample_count: 2009041
total_episode_count: 13083
total_duration: 2532.097050845625
[2024-11-20 00:09:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1046
train_sample_count: 1046
avg_envstep_per_episode: 174.33333333333334
avg_sample_per_episode: 174.33333333333334
avg_envstep_per_sec: 812.526864791107
avg_train_sample_per_sec: 812.526864791107
avg_episode_per_sec: 4.660765954824705
collect_time: 1.2873420502458301
reward_mean: 1319.5
reward_std: 507.7784118652344
reward_max: 1853.0
reward_min: 622.0
total_envstep_count: 2010061
total_train_sample_count: 2010027
total_episode_count: 13089
total_duration: 2533.384392895871
[2024-11-20 00:09:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1136
train_sample_count: 1136
avg_envstep_per_episode: 162.28571428571428
avg_sample_per_episode: 162.28571428571428
avg_envstep_per_sec: 813.2131692864891
avg_train_sample_per_sec: 813.2131692864891
avg_episode_per_sec: 5.010996641730126
collect_time: 1.3969276973179408
reward_mean: 1094.2857666015625
reward_std: 579.8526000976562
reward_max: 1832.0
reward_min: 156.0
total_envstep_count: 2011063
total_train_sample_count: 2011019
total_episode_count: 13096
total_duration: 2534.781320593189
[2024-11-20 00:09:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 925
train_sample_count: 925
avg_envstep_per_episode: 154.16666666666666
avg_sample_per_episode: 154.16666666666666
avg_envstep_per_sec: 810.0005492339305
avg_train_sample_per_sec: 810.0005492339305
avg_episode_per_sec: 5.254057616652522
collect_time: 1.1419745343072074
reward_mean: 1101.6666259765625
reward_std: 401.9393310546875
reward_max: 1699.0
reward_min: 579.0
total_envstep_count: 2012034
total_train_sample_count: 2012004
total_episode_count: 13102
total_duration: 2535.923295127496
[2024-11-20 00:09:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 888
train_sample_count: 888
avg_envstep_per_episode: 177.6
avg_sample_per_episode: 177.6
avg_envstep_per_sec: 809.1455355056495
avg_train_sample_per_sec: 809.1455355056495
avg_episode_per_sec: 4.555999636856135
collect_time: 1.0974539944103787
reward_mean: 1169.800048828125
reward_std: 633.1298217773438
reward_max: 2343.0
reward_min: 633.0
total_envstep_count: 2013005
total_train_sample_count: 2012964
total_episode_count: 13107
total_duration: 2537.0207491219066
[2024-11-20 00:09:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1212
train_sample_count: 1212
avg_envstep_per_episode: 173.14285714285714
avg_sample_per_episode: 173.14285714285714
avg_envstep_per_sec: 806.6572164837739
avg_train_sample_per_sec: 806.6572164837739
avg_episode_per_sec: 4.658911316325427
collect_time: 1.502496940749032
reward_mean: 1380.4285888671875
reward_std: 781.1469116210938
reward_max: 2356.0
reward_min: 243.0
total_envstep_count: 2014030
total_train_sample_count: 2013996
total_episode_count: 13114
total_duration: 2538.5232460626557
[2024-11-20 00:09:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 803
train_sample_count: 803
avg_envstep_per_episode: 133.83333333333334
avg_sample_per_episode: 133.83333333333334
avg_envstep_per_sec: 823.2702855690552
avg_train_sample_per_sec: 823.2702855690552
avg_episode_per_sec: 6.1514591698808605
collect_time: 0.9753783345222473
reward_mean: 1045.3333740234375
reward_std: 466.1636657714844
reward_max: 1916.0
reward_min: 612.0
total_envstep_count: 2014992
total_train_sample_count: 2014979
total_episode_count: 13120
total_duration: 2539.498624397178
[2024-11-20 00:10:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1176
train_sample_count: 1176
avg_envstep_per_episode: 168.0
avg_sample_per_episode: 168.0
avg_envstep_per_sec: 819.4862880615657
avg_train_sample_per_sec: 819.4862880615657
avg_episode_per_sec: 4.877894571795034
collect_time: 1.4350453657763342
reward_mean: 1300.5714111328125
reward_std: 655.143798828125
reward_max: 2358.0
reward_min: 604.0
total_envstep_count: 2016026
total_train_sample_count: 2015975
total_episode_count: 13127
total_duration: 2540.933669762954
[2024-11-20 00:10:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 780
train_sample_count: 780
avg_envstep_per_episode: 260.0
avg_sample_per_episode: 260.0
avg_envstep_per_sec: 809.9827777547289
avg_train_sample_per_sec: 809.9827777547289
avg_episode_per_sec: 3.1153183759797267
collect_time: 0.9629834379468646
reward_mean: 1592.6666259765625
reward_std: 654.619140625
reward_max: 2346.0
reward_min: 750.0
total_envstep_count: 2017000
total_train_sample_count: 2016959
total_episode_count: 13130
total_duration: 2541.8966532009013
[2024-11-20 00:10:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1286
train_sample_count: 1286
avg_envstep_per_episode: 142.88888888888889
avg_sample_per_episode: 142.88888888888889
avg_envstep_per_sec: 809.7536661052942
avg_train_sample_per_sec: 809.7536661052942
avg_episode_per_sec: 5.667016325775776
collect_time: 1.588137298822403
reward_mean: 988.888916015625
reward_std: 446.44757080078125
reward_max: 1853.0
reward_min: 590.0
total_envstep_count: 2017992
total_train_sample_count: 2017957
total_episode_count: 13139
total_duration: 2543.4847904997237
[2024-11-20 00:10:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 917
train_sample_count: 917
avg_envstep_per_episode: 131.0
avg_sample_per_episode: 131.0
avg_envstep_per_sec: 816.5271912598605
avg_train_sample_per_sec: 816.5271912598605
avg_episode_per_sec: 6.23303199435008
collect_time: 1.1230489441326688
reward_mean: 983.5714111328125
reward_std: 657.3309326171875
reward_max: 2342.0
reward_min: 244.0
total_envstep_count: 2019041
total_train_sample_count: 2018994
total_episode_count: 13146
total_duration: 2544.6078394438564
[2024-11-20 00:10:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 792
train_sample_count: 792
avg_envstep_per_episode: 198.0
avg_sample_per_episode: 198.0
avg_envstep_per_sec: 812.2636700560005
avg_train_sample_per_sec: 812.2636700560005
avg_episode_per_sec: 4.102341767959598
collect_time: 0.9750528420720781
reward_mean: 1560.5
reward_std: 134.0606231689453
reward_max: 1696.0
reward_min: 1421.0
total_envstep_count: 2020037
total_train_sample_count: 2020002
total_episode_count: 13150
total_duration: 2545.5828922859287
[2024-11-20 00:10:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1163
train_sample_count: 1163
avg_envstep_per_episode: 193.83333333333334
avg_sample_per_episode: 193.83333333333334
avg_envstep_per_sec: 817.4081485534841
avg_train_sample_per_sec: 817.4081485534841
avg_episode_per_sec: 4.217066974480572
collect_time: 1.4227898291179113
reward_mean: 1047.5
reward_std: 395.6103820800781
reward_max: 1561.0
reward_min: 582.0
total_envstep_count: 2021048
total_train_sample_count: 2021009
total_episode_count: 13156
total_duration: 2547.0056821150465
[2024-11-20 00:10:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 430
train_sample_count: 430
avg_envstep_per_episode: 143.33333333333334
avg_sample_per_episode: 143.33333333333334
avg_envstep_per_sec: 806.8353150248367
avg_train_sample_per_sec: 806.8353150248367
avg_episode_per_sec: 5.629083593196536
collect_time: 0.5329464290823256
reward_mean: 943.0
reward_std: 449.4952697753906
reward_max: 1578.0
reward_min: 600.0
total_envstep_count: 2022021
total_train_sample_count: 2021979
total_episode_count: 13159
total_duration: 2547.5386285441286
[2024-11-20 00:10:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1607
train_sample_count: 1607
avg_envstep_per_episode: 160.7
avg_sample_per_episode: 160.7
avg_envstep_per_sec: 825.2698927684039
avg_train_sample_per_sec: 825.2698927684039
avg_episode_per_sec: 5.135469152261381
collect_time: 1.9472417618547166
reward_mean: 897.7000122070312
reward_std: 420.8605651855469
reward_max: 1558.0
reward_min: 248.0
total_envstep_count: 2023021
total_train_sample_count: 2022986
total_episode_count: 13169
total_duration: 2549.4858703059836
[2024-11-20 00:10:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 752
train_sample_count: 752
avg_envstep_per_episode: 188.0
avg_sample_per_episode: 188.0
avg_envstep_per_sec: 818.0717839046824
avg_train_sample_per_sec: 818.0717839046824
avg_episode_per_sec: 4.35144565906746
collect_time: 0.9192347356251309
reward_mean: 1392.75
reward_std: 653.8884887695312
reward_max: 2353.0
reward_min: 593.0
total_envstep_count: 2024001
total_train_sample_count: 2023966
total_episode_count: 13173
total_duration: 2550.4051050416087
[2024-11-20 00:10:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1484
train_sample_count: 1484
avg_envstep_per_episode: 185.5
avg_sample_per_episode: 185.5
avg_envstep_per_sec: 814.4755353682663
avg_train_sample_per_sec: 814.4755353682663
avg_episode_per_sec: 4.390703694707635
collect_time: 1.822031400033406
reward_mean: 1323.75
reward_std: 730.3352661132812
reward_max: 2366.0
reward_min: 611.0
total_envstep_count: 2025002
total_train_sample_count: 2024958
total_episode_count: 13181
total_duration: 2552.227136441642
[2024-11-20 00:10:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 665
train_sample_count: 665
avg_envstep_per_episode: 110.83333333333333
avg_sample_per_episode: 110.83333333333333
avg_envstep_per_sec: 812.0740152509754
avg_train_sample_per_sec: 812.0740152509754
avg_episode_per_sec: 7.326983596249402
collect_time: 0.8188908738749368
reward_mean: 910.5
reward_std: 573.4197998046875
reward_max: 1707.0
reward_min: 244.0
total_envstep_count: 2025989
total_train_sample_count: 2025947
total_episode_count: 13187
total_duration: 2553.0460273155168
[2024-11-20 00:10:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 745
train_sample_count: 745
avg_envstep_per_episode: 149.0
avg_sample_per_episode: 149.0
avg_envstep_per_sec: 814.8636134715928
avg_train_sample_per_sec: 814.8636134715928
avg_episode_per_sec: 5.4688833118898845
collect_time: 0.9142634272575378
reward_mean: 1219.0
reward_std: 520.3333740234375
reward_max: 1849.0
reward_min: 614.0
total_envstep_count: 2026985
total_train_sample_count: 2026944
total_episode_count: 13192
total_duration: 2553.9602907427743
[2024-11-20 00:10:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 860
train_sample_count: 860
avg_envstep_per_episode: 172.0
avg_sample_per_episode: 172.0
avg_envstep_per_sec: 814.5534296649797
avg_train_sample_per_sec: 814.5534296649797
avg_episode_per_sec: 4.735775753866161
collect_time: 1.0557932342801775
reward_mean: 1415.4000244140625
reward_std: 588.0345458984375
reward_max: 2355.0
reward_min: 616.0
total_envstep_count: 2027959
total_train_sample_count: 2027924
total_episode_count: 13197
total_duration: 2555.0160839770547
[2024-11-20 00:10:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1457
train_sample_count: 1457
avg_envstep_per_episode: 182.125
avg_sample_per_episode: 182.125
avg_envstep_per_sec: 697.9168540110886
avg_train_sample_per_sec: 697.9168540110886
avg_episode_per_sec: 3.832076068695064
collect_time: 2.0876412306513106
reward_mean: 1181.875
reward_std: 899.6255493164062
reward_max: 3018.0
reward_min: 173.0
total_envstep_count: 2028959
total_train_sample_count: 2028913
total_episode_count: 13205
total_duration: 2557.103725207706
[2024-11-20 00:10:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1136
train_sample_count: 1136
avg_envstep_per_episode: 162.28571428571428
avg_sample_per_episode: 162.28571428571428
avg_envstep_per_sec: 814.4316253596085
avg_train_sample_per_sec: 814.4316253596085
avg_episode_per_sec: 5.018504733729982
collect_time: 1.3948377796581812
reward_mean: 1067.142822265625
reward_std: 400.6471252441406
reward_max: 1851.0
reward_min: 582.0
total_envstep_count: 2029960
total_train_sample_count: 2029917
total_episode_count: 13212
total_duration: 2558.498562987364
[2024-11-20 00:10:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 446
train_sample_count: 446
avg_envstep_per_episode: 148.66666666666666
avg_sample_per_episode: 148.66666666666666
avg_envstep_per_sec: 817.7881134284985
avg_train_sample_per_sec: 817.7881134284985
avg_episode_per_sec: 5.50081690646972
collect_time: 0.5453735419682094
reward_mean: 820.0
reward_std: 181.3118896484375
reward_max: 1045.0
reward_min: 601.0
total_envstep_count: 2030933
total_train_sample_count: 2030891
total_episode_count: 13215
total_duration: 2559.0439365293323
[2024-11-20 00:11:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1092
train_sample_count: 1092
avg_envstep_per_episode: 136.5
avg_sample_per_episode: 136.5
avg_envstep_per_sec: 818.869765132894
avg_train_sample_per_sec: 818.869765132894
avg_episode_per_sec: 5.999045898409481
collect_time: 1.333545389629546
reward_mean: 974.375
reward_std: 388.72125244140625
reward_max: 1563.0
reward_min: 598.0
total_envstep_count: 2031949
total_train_sample_count: 2031911
total_episode_count: 13223
total_duration: 2560.377481918962
[2024-11-20 00:11:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 696
train_sample_count: 696
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 814.2944106462259
avg_train_sample_per_sec: 814.2944106462259
avg_episode_per_sec: 7.019779402122637
collect_time: 0.8547277138346717
reward_mean: 793.5
reward_std: 395.0201416015625
reward_max: 1676.0
reward_min: 599.0
total_envstep_count: 2032954
total_train_sample_count: 2032919
total_episode_count: 13229
total_duration: 2561.2322096327966
[2024-11-20 00:11:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1666
train_sample_count: 1666
avg_envstep_per_episode: 208.25
avg_sample_per_episode: 208.25
avg_envstep_per_sec: 811.0220396349118
avg_train_sample_per_sec: 811.0220396349118
avg_episode_per_sec: 3.894463575677848
collect_time: 2.054198182764507
reward_mean: 1180.375
reward_std: 704.8623657226562
reward_max: 2280.0
reward_min: 226.0
total_envstep_count: 2033940
total_train_sample_count: 2033901
total_episode_count: 13237
total_duration: 2563.2864078155612
[2024-11-20 00:11:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 792
train_sample_count: 792
avg_envstep_per_episode: 198.0
avg_sample_per_episode: 198.0
avg_envstep_per_sec: 825.8790949093438
avg_train_sample_per_sec: 825.8790949093438
avg_episode_per_sec: 4.171106539946181
collect_time: 0.9589781420571462
reward_mean: 1346.5
reward_std: 230.1765594482422
reward_max: 1703.0
reward_min: 1062.0
total_envstep_count: 2034920
total_train_sample_count: 2034885
total_episode_count: 13241
total_duration: 2564.2453859576185
[2024-11-20 00:11:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 899
train_sample_count: 899
avg_envstep_per_episode: 149.83333333333334
avg_sample_per_episode: 149.83333333333334
avg_envstep_per_sec: 817.6649128063955
avg_train_sample_per_sec: 817.6649128063955
avg_episode_per_sec: 5.457162933079392
collect_time: 1.099472395011357
reward_mean: 1225.8333740234375
reward_std: 622.2921142578125
reward_max: 1918.0
reward_min: 604.0
total_envstep_count: 2035946
total_train_sample_count: 2035892
total_episode_count: 13247
total_duration: 2565.3448583526297
[2024-11-20 00:11:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1187
train_sample_count: 1187
avg_envstep_per_episode: 169.57142857142858
avg_sample_per_episode: 169.57142857142858
avg_envstep_per_sec: 817.4264644051042
avg_train_sample_per_sec: 817.4264644051042
avg_episode_per_sec: 4.8205435980081965
collect_time: 1.452118388244084
reward_mean: 1349.857177734375
reward_std: 604.2164916992188
reward_max: 2351.0
reward_min: 610.0
total_envstep_count: 2036932
total_train_sample_count: 2036887
total_episode_count: 13254
total_duration: 2566.7969767408736
[2024-11-20 00:11:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 351
train_sample_count: 351
avg_envstep_per_episode: 117.0
avg_sample_per_episode: 117.0
avg_envstep_per_sec: 813.2535411834588
avg_train_sample_per_sec: 813.2535411834588
avg_episode_per_sec: 6.950884967379989
collect_time: 0.4315997191837856
reward_mean: 648.3333129882812
reward_std: 62.023292541503906
reward_max: 736.0
reward_min: 602.0
total_envstep_count: 2037914
total_train_sample_count: 2037862
total_episode_count: 13257
total_duration: 2567.2285764600574
[2024-11-20 00:11:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1701
train_sample_count: 1701
avg_envstep_per_episode: 212.625
avg_sample_per_episode: 212.625
avg_envstep_per_sec: 815.476101633924
avg_train_sample_per_sec: 815.476101633924
avg_episode_per_sec: 3.8352785497186317
collect_time: 2.0858980374676843
reward_mean: 1388.75
reward_std: 533.9100341796875
reward_max: 2328.0
reward_min: 611.0
total_envstep_count: 2038923
total_train_sample_count: 2038879
total_episode_count: 13265
total_duration: 2569.314474497525
[2024-11-20 00:11:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1081
train_sample_count: 1081
avg_envstep_per_episode: 154.42857142857142
avg_sample_per_episode: 154.42857142857142
avg_envstep_per_sec: 824.0536412646421
avg_train_sample_per_sec: 824.0536412646421
avg_episode_per_sec: 5.336147538253926
collect_time: 1.3118078070027488
reward_mean: 951.7142944335938
reward_std: 759.3660278320312
reward_max: 2342.0
reward_min: 192.0
total_envstep_count: 2039925
total_train_sample_count: 2039888
total_episode_count: 13272
total_duration: 2570.626282304528
[2024-11-20 00:11:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 580
train_sample_count: 580
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 824.3975969859813
avg_train_sample_per_sec: 824.3975969859813
avg_episode_per_sec: 7.106875836086045
collect_time: 0.703544020652771
reward_mean: 838.0
reward_std: 425.4771423339844
reward_max: 1322.0
reward_min: 208.0
total_envstep_count: 2040888
total_train_sample_count: 2040864
total_episode_count: 13277
total_duration: 2571.329826325181
[2024-11-20 00:11:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1285
train_sample_count: 1285
avg_envstep_per_episode: 214.16666666666666
avg_sample_per_episode: 214.16666666666666
avg_envstep_per_sec: 820.1652605382121
avg_train_sample_per_sec: 820.1652605382121
avg_episode_per_sec: 3.829565418855465
collect_time: 1.5667574107646942
reward_mean: 1423.8333740234375
reward_std: 425.78729248046875
reward_max: 1923.0
reward_min: 610.0
total_envstep_count: 2041890
total_train_sample_count: 2041861
total_episode_count: 13283
total_duration: 2572.8965837359456
[2024-11-20 00:11:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1193
train_sample_count: 1193
avg_envstep_per_episode: 170.42857142857142
avg_sample_per_episode: 170.42857142857142
avg_envstep_per_sec: 814.1878823557303
avg_train_sample_per_sec: 814.1878823557303
avg_episode_per_sec: 4.777296878868492
collect_time: 1.465263762644359
reward_mean: 1381.4285888671875
reward_std: 600.6904907226562
reward_max: 2348.0
reward_min: 652.0
total_envstep_count: 2042907
total_train_sample_count: 2042862
total_episode_count: 13290
total_duration: 2574.36184749859
[2024-11-20 00:12:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 763
train_sample_count: 763
avg_envstep_per_episode: 152.6
avg_sample_per_episode: 152.6
avg_envstep_per_sec: 811.8851924340715
avg_train_sample_per_sec: 811.8851924340715
avg_episode_per_sec: 5.320348574273076
collect_time: 0.9397880477564675
reward_mean: 1180.199951171875
reward_std: 722.0906982421875
reward_max: 2361.0
reward_min: 607.0
total_envstep_count: 2043894
total_train_sample_count: 2043853
total_episode_count: 13295
total_duration: 2575.3016355463465
[2024-11-20 00:12:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1138
train_sample_count: 1138
avg_envstep_per_episode: 162.57142857142858
avg_sample_per_episode: 162.57142857142858
avg_envstep_per_sec: 816.3880210473783
avg_train_sample_per_sec: 816.3880210473783
avg_episode_per_sec: 5.0217189343863335
collect_time: 1.3939450000013625
reward_mean: 1030.7142333984375
reward_std: 476.9794006347656
reward_max: 1907.0
reward_min: 579.0
total_envstep_count: 2044866
total_train_sample_count: 2044835
total_episode_count: 13302
total_duration: 2576.6955805463476
[2024-11-20 00:12:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 745
train_sample_count: 745
avg_envstep_per_episode: 124.16666666666667
avg_sample_per_episode: 124.16666666666667
avg_envstep_per_sec: 808.4545567044898
avg_train_sample_per_sec: 808.4545567044898
avg_episode_per_sec: 6.51104340970059
collect_time: 0.9215112882001059
reward_mean: 806.3333129882812
reward_std: 176.98931884765625
reward_max: 1042.0
reward_min: 615.0
total_envstep_count: 2045876
total_train_sample_count: 2045832
total_episode_count: 13308
total_duration: 2577.617091834548
[2024-11-20 00:12:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1078
train_sample_count: 1078
avg_envstep_per_episode: 215.6
avg_sample_per_episode: 215.6
avg_envstep_per_sec: 816.5831462082407
avg_train_sample_per_sec: 816.5831462082407
avg_episode_per_sec: 3.7874914017079813
collect_time: 1.320135010140283
reward_mean: 1383.800048828125
reward_std: 679.2188110351562
reward_max: 2333.0
reward_min: 243.0
total_envstep_count: 2046855
total_train_sample_count: 2046814
total_episode_count: 13313
total_duration: 2578.937226844688
[2024-11-20 00:12:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 785
train_sample_count: 785
avg_envstep_per_episode: 196.25
avg_sample_per_episode: 196.25
avg_envstep_per_sec: 808.4667748214329
avg_train_sample_per_sec: 808.4667748214329
avg_episode_per_sec: 4.119575922656983
collect_time: 0.9709737300872803
reward_mean: 1017.75
reward_std: 339.7877197265625
reward_max: 1392.0
reward_min: 629.0
total_envstep_count: 2047836
total_train_sample_count: 2047791
total_episode_count: 13317
total_duration: 2579.9082005747755
[2024-11-20 00:12:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1196
train_sample_count: 1196
avg_envstep_per_episode: 170.85714285714286
avg_sample_per_episode: 170.85714285714286
avg_envstep_per_sec: 814.2005878546131
avg_train_sample_per_sec: 814.2005878546131
avg_episode_per_sec: 4.765388056005261
collect_time: 1.4689254931041176
reward_mean: 1336.7142333984375
reward_std: 627.4459838867188
reward_max: 2348.0
reward_min: 609.0
total_envstep_count: 2048815
total_train_sample_count: 2048771
total_episode_count: 13324
total_duration: 2581.3771260678795
[2024-11-20 00:12:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 870
train_sample_count: 870
avg_envstep_per_episode: 145.0
avg_sample_per_episode: 145.0
avg_envstep_per_sec: 798.5732327989939
avg_train_sample_per_sec: 798.5732327989939
avg_episode_per_sec: 5.507401605510303
collect_time: 1.0894429768834797
reward_mean: 1148.8333740234375
reward_std: 910.3471069335938
reward_max: 2369.0
reward_min: 180.0
total_envstep_count: 2049801
total_train_sample_count: 2049761
total_episode_count: 13330
total_duration: 2582.466569044763
[2024-11-20 00:12:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 960
train_sample_count: 960
avg_envstep_per_episode: 240.0
avg_sample_per_episode: 240.0
avg_envstep_per_sec: 831.1333132836351
avg_train_sample_per_sec: 831.1333132836351
avg_episode_per_sec: 3.4630554720151463
collect_time: 1.1550493580954413
reward_mean: 1375.0
reward_std: 768.2743530273438
reward_max: 2330.0
reward_min: 599.0
total_envstep_count: 2050765
total_train_sample_count: 2050733
total_episode_count: 13334
total_duration: 2583.6216184028585
[2024-11-20 00:12:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 974
train_sample_count: 974
avg_envstep_per_episode: 162.33333333333334
avg_sample_per_episode: 162.33333333333334
avg_envstep_per_sec: 816.9283205096965
avg_train_sample_per_sec: 816.9283205096965
avg_episode_per_sec: 5.032412652010451
collect_time: 1.19227106656347
reward_mean: 859.8333129882812
reward_std: 533.5601806640625
reward_max: 1848.0
reward_min: 235.0
total_envstep_count: 2051799
total_train_sample_count: 2051767
total_episode_count: 13340
total_duration: 2584.813889469422
[2024-11-20 00:12:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1013
train_sample_count: 1013
avg_envstep_per_episode: 202.6
avg_sample_per_episode: 202.6
avg_envstep_per_sec: 813.0297493205445
avg_train_sample_per_sec: 813.0297493205445
avg_episode_per_sec: 4.012980006517989
collect_time: 1.2459568679332733
reward_mean: 1149.800048828125
reward_std: 985.5409545898438
reward_max: 2360.0
reward_min: 201.0
total_envstep_count: 2052810
total_train_sample_count: 2052756
total_episode_count: 13345
total_duration: 2586.0598463373553
[2024-11-20 00:12:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 904
train_sample_count: 904
avg_envstep_per_episode: 180.8
avg_sample_per_episode: 180.8
avg_envstep_per_sec: 805.7720655442279
avg_train_sample_per_sec: 805.7720655442279
avg_episode_per_sec: 4.456703902346393
collect_time: 1.1219053609030587
reward_mean: 983.0
reward_std: 404.7473449707031
reward_max: 1694.0
reward_min: 589.0
total_envstep_count: 2053798
total_train_sample_count: 2053744
total_episode_count: 13350
total_duration: 2587.1817516982583
[2024-11-20 00:12:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 574
train_sample_count: 574
avg_envstep_per_episode: 143.5
avg_sample_per_episode: 143.5
avg_envstep_per_sec: 803.3143451540616
avg_train_sample_per_sec: 803.3143451540616
avg_episode_per_sec: 5.598009373895899
collect_time: 0.7145397109644754
reward_mean: 1034.25
reward_std: 421.4038391113281
reward_max: 1569.0
reward_min: 606.0
total_envstep_count: 2054763
total_train_sample_count: 2054714
total_episode_count: 13354
total_duration: 2587.8962914092226
[2024-11-20 00:12:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 848
train_sample_count: 848
avg_envstep_per_episode: 212.0
avg_sample_per_episode: 212.0
avg_envstep_per_sec: 775.0690916094715
avg_train_sample_per_sec: 775.0690916094715
avg_episode_per_sec: 3.655986281176752
collect_time: 1.0940960092203957
reward_mean: 1366.25
reward_std: 353.545166015625
reward_max: 1688.0
reward_min: 776.0
total_envstep_count: 2055721
total_train_sample_count: 2055694
total_episode_count: 13358
total_duration: 2588.990387418443
[2024-11-20 00:12:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1366
train_sample_count: 1366
avg_envstep_per_episode: 341.5
avg_sample_per_episode: 341.5
avg_envstep_per_sec: 790.921194556611
avg_train_sample_per_sec: 790.921194556611
avg_episode_per_sec: 2.3160210675156985
collect_time: 1.7271000061716353
reward_mean: 1497.75
reward_std: 593.9884033203125
reward_max: 2296.0
reward_min: 620.0
total_envstep_count: 2056701
total_train_sample_count: 2056664
total_episode_count: 13362
total_duration: 2590.7174874246143
[2024-11-20 00:12:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 825
train_sample_count: 825
avg_envstep_per_episode: 275.0
avg_sample_per_episode: 275.0
avg_envstep_per_sec: 810.9619466838703
avg_train_sample_per_sec: 810.9619466838703
avg_episode_per_sec: 2.948952533395892
collect_time: 1.0173103724207198
reward_mean: 1160.3333740234375
reward_std: 356.614013671875
reward_max: 1649.0
reward_min: 808.0
total_envstep_count: 2057658
total_train_sample_count: 2057633
total_episode_count: 13365
total_duration: 2591.734797797035
[2024-11-20 00:12:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1040
train_sample_count: 1040
avg_envstep_per_episode: 260.0
avg_sample_per_episode: 260.0
avg_envstep_per_sec: 809.310958686194
avg_train_sample_per_sec: 809.310958686194
avg_episode_per_sec: 3.1127344564853616
collect_time: 1.285043763262885
reward_mean: 1529.75
reward_std: 353.5882873535156
reward_max: 1890.0
reward_min: 1053.0
total_envstep_count: 2058654
total_train_sample_count: 2058613
total_episode_count: 13369
total_duration: 2593.0198415602977
[2024-11-20 00:12:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1873
train_sample_count: 1873
avg_envstep_per_episode: 187.3
avg_sample_per_episode: 187.3
avg_envstep_per_sec: 815.5090367905088
avg_train_sample_per_sec: 815.5090367905088
avg_episode_per_sec: 4.354025823761393
collect_time: 2.296725009168897
reward_mean: 1248.800048828125
reward_std: 558.4811401367188
reward_max: 2310.0
reward_min: 605.0
total_envstep_count: 2059669
total_train_sample_count: 2059634
total_episode_count: 13379
total_duration: 2595.3165665694664
[2024-11-20 00:13:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 625
train_sample_count: 625
avg_envstep_per_episode: 125.0
avg_sample_per_episode: 125.0
avg_envstep_per_sec: 799.437655785854
avg_train_sample_per_sec: 799.437655785854
avg_episode_per_sec: 6.395501246286832
collect_time: 0.7817995505673544
reward_mean: 850.7999877929688
reward_std: 417.4284973144531
reward_max: 1678.0
reward_min: 601.0
total_envstep_count: 2060648
total_train_sample_count: 2060619
total_episode_count: 13384
total_duration: 2596.098366120034
[2024-11-20 00:13:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 608
train_sample_count: 608
avg_envstep_per_episode: 202.66666666666666
avg_sample_per_episode: 202.66666666666666
avg_envstep_per_sec: 814.1027048787037
avg_train_sample_per_sec: 814.1027048787037
avg_episode_per_sec: 4.016954135914656
collect_time: 0.7468345165252686
reward_mean: 1413.0
reward_std: 551.7432861328125
reward_max: 1912.0
reward_min: 644.0
total_envstep_count: 2061638
total_train_sample_count: 2061599
total_episode_count: 13387
total_duration: 2596.845200636559
[2024-11-20 00:13:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1483
train_sample_count: 1483
avg_envstep_per_episode: 211.85714285714286
avg_sample_per_episode: 211.85714285714286
avg_envstep_per_sec: 820.1804688747653
avg_train_sample_per_sec: 820.1804688747653
avg_episode_per_sec: 3.871384546273336
collect_time: 1.808138642992292
reward_mean: 1539.0
reward_std: 490.7981872558594
reward_max: 2360.0
reward_min: 654.0
total_envstep_count: 2062632
total_train_sample_count: 2062578
total_episode_count: 13394
total_duration: 2598.6533392795513
[2024-11-20 00:13:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 983
train_sample_count: 983
avg_envstep_per_episode: 163.83333333333334
avg_sample_per_episode: 163.83333333333334
avg_envstep_per_sec: 819.6309605032227
avg_train_sample_per_sec: 819.6309605032227
avg_episode_per_sec: 5.0028339399993245
collect_time: 1.199320239680154
reward_mean: 1033.5
reward_std: 381.30596923828125
reward_max: 1567.0
reward_min: 604.0
total_envstep_count: 2063588
total_train_sample_count: 2063561
total_episode_count: 13400
total_duration: 2599.8526595192316
[2024-11-20 00:13:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 718
train_sample_count: 718
avg_envstep_per_episode: 119.66666666666667
avg_sample_per_episode: 119.66666666666667
avg_envstep_per_sec: 791.7057664783165
avg_train_sample_per_sec: 791.7057664783165
avg_episode_per_sec: 6.615925625166991
collect_time: 0.9069025771958487
reward_mean: 776.1666870117188
reward_std: 339.7697448730469
reward_max: 1316.0
reward_min: 234.0
total_envstep_count: 2064567
total_train_sample_count: 2064531
total_episode_count: 13406
total_duration: 2600.7595620964275
[2024-11-20 00:13:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1070
train_sample_count: 1070
avg_envstep_per_episode: 133.75
avg_sample_per_episode: 133.75
avg_envstep_per_sec: 797.4267787261167
avg_train_sample_per_sec: 797.4267787261167
avg_episode_per_sec: 5.962069373653208
collect_time: 1.3418159868035997
reward_mean: 1050.0
reward_std: 537.7643432617188
reward_max: 1850.0
reward_min: 582.0
total_envstep_count: 2065592
total_train_sample_count: 2065541
total_episode_count: 13414
total_duration: 2602.1013780832313
[2024-11-20 00:13:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 666
train_sample_count: 666
avg_envstep_per_episode: 111.0
avg_sample_per_episode: 111.0
avg_envstep_per_sec: 823.6160979744467
avg_train_sample_per_sec: 823.6160979744467
avg_episode_per_sec: 7.419964846616637
collect_time: 0.8086291679314204
reward_mean: 879.1666870117188
reward_std: 362.93359375
reward_max: 1435.0
reward_min: 594.0
total_envstep_count: 2066557
total_train_sample_count: 2066519
total_episode_count: 13420
total_duration: 2602.910007251163
[2024-11-20 00:13:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1781
train_sample_count: 1781
avg_envstep_per_episode: 178.1
avg_sample_per_episode: 178.1
avg_envstep_per_sec: 820.7757209781944
avg_train_sample_per_sec: 820.7757209781944
avg_episode_per_sec: 4.6085105052116475
collect_time: 2.1698984929493497
reward_mean: 1127.300048828125
reward_std: 406.04559326171875
reward_max: 1568.0
reward_min: 613.0
total_envstep_count: 2067564
total_train_sample_count: 2067520
total_episode_count: 13430
total_duration: 2605.0799057441122
[2024-11-20 00:13:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 645
train_sample_count: 645
avg_envstep_per_episode: 92.14285714285714
avg_sample_per_episode: 92.14285714285714
avg_envstep_per_sec: 828.5650669937824
avg_train_sample_per_sec: 828.5650669937824
avg_episode_per_sec: 8.992179021637948
collect_time: 0.7784542526517596
reward_mean: 639.1428833007812
reward_std: 342.69122314453125
reward_max: 1332.0
reward_min: 248.0
total_envstep_count: 2068543
total_train_sample_count: 2068513
total_episode_count: 13437
total_duration: 2605.858359996764
[2024-11-20 00:13:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 973
train_sample_count: 973
avg_envstep_per_episode: 139.0
avg_sample_per_episode: 139.0
avg_envstep_per_sec: 802.2511224585212
avg_train_sample_per_sec: 802.2511224585212
avg_episode_per_sec: 5.771590809054109
collect_time: 1.2128371936934337
reward_mean: 1038.7142333984375
reward_std: 439.7602233886719
reward_max: 1692.0
reward_min: 617.0
total_envstep_count: 2069552
total_train_sample_count: 2069522
total_episode_count: 13444
total_duration: 2607.0711971904575
[2024-11-20 00:13:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1277
train_sample_count: 1277
avg_envstep_per_episode: 141.88888888888889
avg_sample_per_episode: 141.88888888888889
avg_envstep_per_sec: 760.4590808769854
avg_train_sample_per_sec: 760.4590808769854
avg_episode_per_sec: 5.359539332727383
collect_time: 1.6792488012995037
reward_mean: 1174.0
reward_std: 539.5679321289062
reward_max: 1925.0
reward_min: 230.0
total_envstep_count: 2070520
total_train_sample_count: 2070487
total_episode_count: 13453
total_duration: 2608.750445991757
[2024-11-20 00:14:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 389
train_sample_count: 389
avg_envstep_per_episode: 129.66666666666666
avg_sample_per_episode: 129.66666666666666
avg_envstep_per_sec: 723.3811314377965
avg_train_sample_per_sec: 723.3811314377965
avg_episode_per_sec: 5.578774792579408
collect_time: 0.5377524835722787
reward_mean: 1008.3333129882812
reward_std: 274.5545959472656
reward_max: 1323.0
reward_min: 654.0
total_envstep_count: 2071495
total_train_sample_count: 2071464
total_episode_count: 13456
total_duration: 2609.288198475329
[2024-11-20 00:14:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1364
train_sample_count: 1364
avg_envstep_per_episode: 151.55555555555554
avg_sample_per_episode: 151.55555555555554
avg_envstep_per_sec: 713.4551871634909
avg_train_sample_per_sec: 713.4551871634909
avg_episode_per_sec: 4.707548888908664
collect_time: 1.9118229491370065
reward_mean: 1273.3333740234375
reward_std: 461.7709655761719
reward_max: 1707.0
reward_min: 610.0
total_envstep_count: 2072504
total_train_sample_count: 2072480
total_episode_count: 13465
total_duration: 2611.200021424466
[2024-11-20 00:14:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1181
train_sample_count: 1181
avg_envstep_per_episode: 168.71428571428572
avg_sample_per_episode: 168.71428571428572
avg_envstep_per_sec: 685.1441023233201
avg_train_sample_per_sec: 685.1441023233201
avg_episode_per_sec: 4.060972664067096
collect_time: 1.7237249740532468
reward_mean: 1310.2857666015625
reward_std: 328.77423095703125
reward_max: 1699.0
reward_min: 579.0
total_envstep_count: 2073505
total_train_sample_count: 2073457
total_episode_count: 13472
total_duration: 2612.923746398519
[2024-11-20 00:14:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 955
train_sample_count: 955
avg_envstep_per_episode: 136.42857142857142
avg_sample_per_episode: 136.42857142857142
avg_envstep_per_sec: 669.9088188350527
avg_train_sample_per_sec: 669.9088188350527
avg_episode_per_sec: 4.910326420780491
collect_time: 1.4255671416010176
reward_mean: 1128.857177734375
reward_std: 494.49005126953125
reward_max: 1864.0
reward_min: 612.0
total_envstep_count: 2074532
total_train_sample_count: 2074496
total_episode_count: 13479
total_duration: 2614.34931354012
[2024-11-20 00:14:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 851
train_sample_count: 851
avg_envstep_per_episode: 141.83333333333334
avg_sample_per_episode: 141.83333333333334
avg_envstep_per_sec: 664.7650780967407
avg_train_sample_per_sec: 664.7650780967407
avg_episode_per_sec: 4.686945321481133
collect_time: 1.280151482139315
reward_mean: 1048.1666259765625
reward_std: 318.47210693359375
reward_max: 1340.0
reward_min: 610.0
total_envstep_count: 2075526
total_train_sample_count: 2075503
total_episode_count: 13485
total_duration: 2615.6294650222594
[2024-11-20 00:14:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 660
train_sample_count: 660
avg_envstep_per_episode: 165.0
avg_sample_per_episode: 165.0
avg_envstep_per_sec: 668.8590172865834
avg_train_sample_per_sec: 668.8590172865834
avg_episode_per_sec: 4.0536910138580815
collect_time: 0.98675503049578
reward_mean: 1330.5
reward_std: 421.1475524902344
reward_max: 1692.0
reward_min: 618.0
total_envstep_count: 2076508
total_train_sample_count: 2076475
total_episode_count: 13489
total_duration: 2616.616220052755
[2024-11-20 00:14:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1591
train_sample_count: 1591
avg_envstep_per_episode: 176.77777777777777
avg_sample_per_episode: 176.77777777777777
avg_envstep_per_sec: 662.6549036510783
avg_train_sample_per_sec: 662.6549036510783
avg_episode_per_sec: 3.748519253840166
collect_time: 2.4009480518954147
reward_mean: 1357.888916015625
reward_std: 570.8347778320312
reward_max: 2336.0
reward_min: 619.0
total_envstep_count: 2077532
total_train_sample_count: 2077490
total_episode_count: 13498
total_duration: 2619.0171681046504
[2024-11-20 00:14:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 815
train_sample_count: 815
avg_envstep_per_episode: 116.42857142857143
avg_sample_per_episode: 116.42857142857143
avg_envstep_per_sec: 664.2853104685158
avg_train_sample_per_sec: 664.2853104685158
avg_episode_per_sec: 5.7055180040240625
collect_time: 1.2268824662481037
reward_mean: 1015.2857055664062
reward_std: 296.9630432128906
reward_max: 1441.0
reward_min: 601.0
total_envstep_count: 2078541
total_train_sample_count: 2078497
total_episode_count: 13505
total_duration: 2620.2440505708987
[2024-11-20 00:14:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1126
train_sample_count: 1126
avg_envstep_per_episode: 125.11111111111111
avg_sample_per_episode: 125.11111111111111
avg_envstep_per_sec: 666.2408600722146
avg_train_sample_per_sec: 666.2408600722146
avg_episode_per_sec: 5.325193375355179
collect_time: 1.6900794704755149
reward_mean: 1056.888916015625
reward_std: 478.6317138671875
reward_max: 1708.0
reward_min: 625.0
total_envstep_count: 2079551
total_train_sample_count: 2079515
total_episode_count: 13514
total_duration: 2621.9341300413744
[2024-11-20 00:14:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 784
train_sample_count: 784
avg_envstep_per_episode: 130.66666666666666
avg_sample_per_episode: 130.66666666666666
avg_envstep_per_sec: 665.7612030021198
avg_train_sample_per_sec: 665.7612030021198
avg_episode_per_sec: 5.095111247465202
collect_time: 1.1775994102160137
reward_mean: 1004.6666870117188
reward_std: 425.5297546386719
reward_max: 1698.0
reward_min: 601.0
total_envstep_count: 2080537
total_train_sample_count: 2080491
total_episode_count: 13520
total_duration: 2623.1117294515902
[2024-11-20 00:14:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1161
train_sample_count: 1161
avg_envstep_per_episode: 129.0
avg_sample_per_episode: 129.0
avg_envstep_per_sec: 662.3597040737175
avg_train_sample_per_sec: 662.3597040737175
avg_episode_per_sec: 5.134571349408663
collect_time: 1.7528240212372372
reward_mean: 1142.5555419921875
reward_std: 375.8797302246094
reward_max: 1587.0
reward_min: 652.0
total_envstep_count: 2081530
total_train_sample_count: 2081484
total_episode_count: 13529
total_duration: 2624.8645534728275
[2024-11-20 00:14:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1009
train_sample_count: 1009
avg_envstep_per_episode: 126.125
avg_sample_per_episode: 126.125
avg_envstep_per_sec: 667.7116526292798
avg_train_sample_per_sec: 667.7116526292798
avg_episode_per_sec: 5.2940467998357175
collect_time: 1.5111313334533145
reward_mean: 1034.5
reward_std: 405.0030822753906
reward_max: 1689.0
reward_min: 627.0
total_envstep_count: 2082538
total_train_sample_count: 2082505
total_episode_count: 13537
total_duration: 2626.375684806281
[2024-11-20 00:14:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 867
train_sample_count: 867
avg_envstep_per_episode: 173.4
avg_sample_per_episode: 173.4
avg_envstep_per_sec: 706.0589457668021
avg_train_sample_per_sec: 706.0589457668021
avg_episode_per_sec: 4.071850898309124
collect_time: 1.2279428016571772
reward_mean: 1354.800048828125
reward_std: 429.2064208984375
reward_max: 1916.0
reward_min: 606.0
total_envstep_count: 2083510
total_train_sample_count: 2083480
total_episode_count: 13542
total_duration: 2627.603627607938
[2024-11-20 00:14:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 957
train_sample_count: 957
avg_envstep_per_episode: 95.7
avg_sample_per_episode: 95.7
avg_envstep_per_sec: 714.5009005633492
avg_train_sample_per_sec: 714.5009005633492
avg_episode_per_sec: 7.466049117694349
collect_time: 1.3393964923563455
reward_mean: 855.5999755859375
reward_std: 422.2056579589844
reward_max: 1703.0
reward_min: 610.0
total_envstep_count: 2084517
total_train_sample_count: 2084473
total_episode_count: 13552
total_duration: 2628.943024100294
[2024-11-20 00:15:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 858
train_sample_count: 858
avg_envstep_per_episode: 143.0
avg_sample_per_episode: 143.0
avg_envstep_per_sec: 734.6394147863149
avg_train_sample_per_sec: 734.6394147863149
avg_episode_per_sec: 5.137338564939265
collect_time: 1.1679199110893976
reward_mean: 999.8333129882812
reward_std: 506.2869567871094
reward_max: 1839.0
reward_min: 606.0
total_envstep_count: 2085497
total_train_sample_count: 2085451
total_episode_count: 13558
total_duration: 2630.1109440113837
[2024-11-20 00:15:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1421
train_sample_count: 1421
avg_envstep_per_episode: 129.1818181818182
avg_sample_per_episode: 129.1818181818182
avg_envstep_per_sec: 733.6385372896287
avg_train_sample_per_sec: 733.6385372896287
avg_episode_per_sec: 5.679116052206838
collect_time: 1.9369211509114221
reward_mean: 1056.3636474609375
reward_std: 597.384033203125
reward_max: 2355.0
reward_min: 607.0
total_envstep_count: 2086495
total_train_sample_count: 2086464
total_episode_count: 13569
total_duration: 2632.0478651622952
[2024-11-20 00:15:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 742
train_sample_count: 742
avg_envstep_per_episode: 106.0
avg_sample_per_episode: 106.0
avg_envstep_per_sec: 728.2634682355758
avg_train_sample_per_sec: 728.2634682355758
avg_episode_per_sec: 6.870410077694112
collect_time: 1.0188620360124678
reward_mean: 675.4285888671875
reward_std: 304.80010986328125
reward_max: 1332.0
reward_min: 243.0
total_envstep_count: 2087513
total_train_sample_count: 2087458
total_episode_count: 13576
total_duration: 2633.0667271983075
[2024-11-20 00:15:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1406
train_sample_count: 1406
avg_envstep_per_episode: 127.81818181818181
avg_sample_per_episode: 127.81818181818181
avg_envstep_per_sec: 726.5065854688825
avg_train_sample_per_sec: 726.5065854688825
avg_episode_per_sec: 5.6839064296996495
collect_time: 1.935288720187687
reward_mean: 882.727294921875
reward_std: 408.2196350097656
reward_max: 1697.0
reward_min: 605.0
total_envstep_count: 2088488
total_train_sample_count: 2088468
total_episode_count: 13587
total_duration: 2635.002015918495
[2024-11-20 00:15:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 600
train_sample_count: 600
avg_envstep_per_episode: 120.0
avg_sample_per_episode: 120.0
avg_envstep_per_sec: 728.6998892001261
avg_train_sample_per_sec: 728.6998892001261
avg_episode_per_sec: 6.072499076667718
collect_time: 0.823384233883449
reward_mean: 1018.5999755859375
reward_std: 449.814453125
reward_max: 1573.0
reward_min: 650.0
total_envstep_count: 2089483
total_train_sample_count: 2089440
total_episode_count: 13592
total_duration: 2635.8254001523787
[2024-11-20 00:15:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 690
train_sample_count: 690
avg_envstep_per_episode: 138.0
avg_sample_per_episode: 138.0
avg_envstep_per_sec: 734.9608626584744
avg_train_sample_per_sec: 734.9608626584744
avg_episode_per_sec: 5.3258033525976405
collect_time: 0.938825500862939
reward_mean: 941.0
reward_std: 408.9777526855469
reward_max: 1695.0
reward_min: 604.0
total_envstep_count: 2090464
total_train_sample_count: 2090430
total_episode_count: 13597
total_duration: 2636.7642256532417
[2024-11-20 00:15:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1311
train_sample_count: 1311
avg_envstep_per_episode: 187.28571428571428
avg_sample_per_episode: 187.28571428571428
avg_envstep_per_sec: 750.4456937614881
avg_train_sample_per_sec: 750.4456937614881
avg_episode_per_sec: 4.0069564121513475
collect_time: 1.7469618533338818
reward_mean: 1275.2857666015625
reward_std: 404.7304992675781
reward_max: 1694.0
reward_min: 605.0
total_envstep_count: 2091458
total_train_sample_count: 2091417
total_episode_count: 13604
total_duration: 2638.5111875065754
[2024-11-20 00:15:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 960
train_sample_count: 960
avg_envstep_per_episode: 160.0
avg_sample_per_episode: 160.0
avg_envstep_per_sec: 773.2351796550842
avg_train_sample_per_sec: 773.2351796550842
avg_episode_per_sec: 4.832719872844276
collect_time: 1.241536889757429
reward_mean: 1049.1666259765625
reward_std: 371.15289306640625
reward_max: 1575.0
reward_min: 610.0
total_envstep_count: 2092436
total_train_sample_count: 2092401
total_episode_count: 13610
total_duration: 2639.7527243963327
[2024-11-20 00:15:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1097
train_sample_count: 1097
avg_envstep_per_episode: 121.88888888888889
avg_sample_per_episode: 121.88888888888889
avg_envstep_per_sec: 752.11718962358
avg_train_sample_per_sec: 752.11718962358
avg_episode_per_sec: 6.170514773575405
collect_time: 1.4585492994104112
reward_mean: 865.888916015625
reward_std: 564.8823852539062
reward_max: 1695.0
reward_min: 235.0
total_envstep_count: 2093435
total_train_sample_count: 2093402
total_episode_count: 13619
total_duration: 2641.2112736957433
[2024-11-20 00:15:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 831
train_sample_count: 831
avg_envstep_per_episode: 138.5
avg_sample_per_episode: 138.5
avg_envstep_per_sec: 747.8829794318909
avg_train_sample_per_sec: 747.8829794318909
avg_episode_per_sec: 5.399877107811487
collect_time: 1.1111363981451305
reward_mean: 1108.3333740234375
reward_std: 619.8216552734375
reward_max: 1855.0
reward_min: 243.0
total_envstep_count: 2094422
total_train_sample_count: 2094389
total_episode_count: 13625
total_duration: 2642.3224100938883
[2024-11-20 00:16:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 890
train_sample_count: 890
avg_envstep_per_episode: 222.5
avg_sample_per_episode: 222.5
avg_envstep_per_sec: 751.7197052012086
avg_train_sample_per_sec: 751.7197052012086
avg_episode_per_sec: 3.378515528994196
collect_time: 1.1839519355978285
reward_mean: 1444.0
reward_std: 559.5520629882812
reward_max: 2347.0
reward_min: 812.0
total_envstep_count: 2095403
total_train_sample_count: 2095375
total_episode_count: 13629
total_duration: 2643.506362029486
[2024-11-20 00:16:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 605
train_sample_count: 605
avg_envstep_per_episode: 151.25
avg_sample_per_episode: 151.25
avg_envstep_per_sec: 759.4623512021872
avg_train_sample_per_sec: 759.4623512021872
avg_episode_per_sec: 5.021238685634295
collect_time: 0.7966161838599612
reward_mean: 847.25
reward_std: 326.0938415527344
reward_max: 1409.0
reward_min: 627.0
total_envstep_count: 2096399
total_train_sample_count: 2096352
total_episode_count: 13633
total_duration: 2644.302978213346
[2024-11-20 00:16:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1213
train_sample_count: 1213
avg_envstep_per_episode: 202.16666666666666
avg_sample_per_episode: 202.16666666666666
avg_envstep_per_sec: 746.328467784225
avg_train_sample_per_sec: 746.328467784225
avg_episode_per_sec: 3.6916494696664057
collect_time: 1.6252897381782532
reward_mean: 1215.1666259765625
reward_std: 686.4957885742188
reward_max: 2617.0
reward_min: 609.0
total_envstep_count: 2097385
total_train_sample_count: 2097337
total_episode_count: 13639
total_duration: 2645.928267951524
[2024-11-20 00:16:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1210
train_sample_count: 1210
avg_envstep_per_episode: 121.0
avg_sample_per_episode: 121.0
avg_envstep_per_sec: 753.2419127695385
avg_train_sample_per_sec: 753.2419127695385
avg_episode_per_sec: 6.225139774954864
collect_time: 1.6063896332468304
reward_mean: 737.5
reward_std: 280.97979736328125
reward_max: 1341.0
reward_min: 237.0
total_envstep_count: 2098401
total_train_sample_count: 2098355
total_episode_count: 13649
total_duration: 2647.5346575847707
[2024-11-20 00:16:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 493
train_sample_count: 493
avg_envstep_per_episode: 123.25
avg_sample_per_episode: 123.25
avg_envstep_per_sec: 488.68690537761086
avg_train_sample_per_sec: 488.68690537761086
avg_episode_per_sec: 3.9650053174654025
collect_time: 1.0088258853980472
reward_mean: 1009.0
reward_std: 255.57679748535156
reward_max: 1332.0
reward_min: 616.0
total_envstep_count: 2099373
total_train_sample_count: 2099340
total_episode_count: 13653
total_duration: 2648.5434834701687
[2024-11-20 00:16:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 810
train_sample_count: 810
avg_envstep_per_episode: 135.0
avg_sample_per_episode: 135.0
avg_envstep_per_sec: 738.8553742228555
avg_train_sample_per_sec: 738.8553742228555
avg_episode_per_sec: 5.473002772021152
collect_time: 1.0962903272537958
reward_mean: 992.6666870117188
reward_std: 550.9049072265625
reward_max: 1853.0
reward_min: 249.0
total_envstep_count: 2100351
total_train_sample_count: 2100318
total_episode_count: 13659
total_duration: 2649.6397737974225
[2024-11-20 00:16:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 557
train_sample_count: 557
avg_envstep_per_episode: 185.66666666666666
avg_sample_per_episode: 185.66666666666666
avg_envstep_per_sec: 735.5246322616629
avg_train_sample_per_sec: 735.5246322616629
avg_episode_per_sec: 3.9615330283392973
collect_time: 0.7572825920014155
reward_mean: 1139.0
reward_std: 137.9009246826172
reward_max: 1334.0
reward_min: 1039.0
total_envstep_count: 2101310
total_train_sample_count: 2101283
total_episode_count: 13662
total_duration: 2650.397056389424
[2024-11-20 00:16:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 713
train_sample_count: 713
avg_envstep_per_episode: 237.66666666666666
avg_sample_per_episode: 237.66666666666666
avg_envstep_per_sec: 731.3591041217741
avg_train_sample_per_sec: 731.3591041217741
avg_episode_per_sec: 3.0772472824198065
collect_time: 0.974897278206689
reward_mean: 1556.6666259765625
reward_std: 3.399346113204956
reward_max: 1560.0
reward_min: 1552.0
total_envstep_count: 2102284
total_train_sample_count: 2102260
total_episode_count: 13665
total_duration: 2651.371953667631
[2024-11-20 00:16:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 546
train_sample_count: 546
avg_envstep_per_episode: 136.5
avg_sample_per_episode: 136.5
avg_envstep_per_sec: 747.7320386898344
avg_train_sample_per_sec: 747.7320386898344
avg_episode_per_sec: 5.47789039333212
collect_time: 0.7302081116608211
reward_mean: 1008.0
reward_std: 550.0440673828125
reward_max: 1693.0
reward_min: 246.0
total_envstep_count: 2103312
total_train_sample_count: 2103262
total_episode_count: 13669
total_duration: 2652.1021617792917
[2024-11-20 00:16:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 868
train_sample_count: 868
avg_envstep_per_episode: 173.6
avg_sample_per_episode: 173.6
avg_envstep_per_sec: 744.5881059242732
avg_train_sample_per_sec: 744.5881059242732
avg_episode_per_sec: 4.289101992651344
collect_time: 1.1657451859542303
reward_mean: 1101.800048828125
reward_std: 484.06915283203125
reward_max: 1705.0
reward_min: 635.0
total_envstep_count: 2104292
total_train_sample_count: 2104262
total_episode_count: 13674
total_duration: 2653.267906965246
[2024-11-20 00:16:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1284
train_sample_count: 1284
avg_envstep_per_episode: 256.8
avg_sample_per_episode: 256.8
avg_envstep_per_sec: 732.9070964823164
avg_train_sample_per_sec: 732.9070964823164
avg_episode_per_sec: 2.8539995968937557
collect_time: 1.7519273672785078
reward_mean: 1311.5999755859375
reward_std: 631.6975708007812
reward_max: 2284.0
reward_min: 626.0
total_envstep_count: 2105328
total_train_sample_count: 2105282
total_episode_count: 13679
total_duration: 2655.019834332524
[2024-11-20 00:16:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 572
train_sample_count: 572
avg_envstep_per_episode: 143.0
avg_sample_per_episode: 143.0
avg_envstep_per_sec: 761.7463655274116
avg_train_sample_per_sec: 761.7463655274116
avg_episode_per_sec: 5.32689766103085
collect_time: 0.7509061098098754
reward_mean: 927.25
reward_std: 263.8269958496094
reward_max: 1303.0
reward_min: 632.0
total_envstep_count: 2106284
total_train_sample_count: 2106250
total_episode_count: 13683
total_duration: 2655.770740442334
[2024-11-20 00:16:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 610
train_sample_count: 610
avg_envstep_per_episode: 122.0
avg_sample_per_episode: 122.0
avg_envstep_per_sec: 736.2134886488077
avg_train_sample_per_sec: 736.2134886488077
avg_episode_per_sec: 6.034536792203342
collect_time: 0.828564009496144
reward_mean: 894.2000122070312
reward_std: 312.8407897949219
reward_max: 1435.0
reward_min: 619.0
total_envstep_count: 2107287
total_train_sample_count: 2107244
total_episode_count: 13688
total_duration: 2656.59930445183
[2024-11-20 00:16:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 471
train_sample_count: 471
avg_envstep_per_episode: 78.5
avg_sample_per_episode: 78.5
avg_envstep_per_sec: 760.8143700813652
avg_train_sample_per_sec: 760.8143700813652
avg_episode_per_sec: 9.691902803584268
collect_time: 0.6190734803676605
reward_mean: 617.8333129882812
reward_std: 8.193832397460938
reward_max: 627.0
reward_min: 603.0
total_envstep_count: 2108289
total_train_sample_count: 2108255
total_episode_count: 13694
total_duration: 2657.2183779321977
[2024-11-20 00:16:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 967
train_sample_count: 967
avg_envstep_per_episode: 138.14285714285714
avg_sample_per_episode: 138.14285714285714
avg_envstep_per_sec: 746.3528579049361
avg_train_sample_per_sec: 746.3528579049361
avg_episode_per_sec: 5.402761122372857
collect_time: 1.2956338141645705
reward_mean: 813.5714111328125
reward_std: 317.95770263671875
reward_max: 1348.0
reward_min: 603.0
total_envstep_count: 2109252
total_train_sample_count: 2109234
total_episode_count: 13701
total_duration: 2658.514011746362
[2024-11-20 00:17:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 3086
train_sample_count: 3086
avg_envstep_per_episode: 514.3333333333334
avg_sample_per_episode: 514.3333333333334
avg_envstep_per_sec: 745.1054380274495
avg_train_sample_per_sec: 745.1054380274495
avg_episode_per_sec: 1.4486819922763114
collect_time: 4.141695715132215
reward_mean: 1543.0
reward_std: 784.33154296875
reward_max: 2723.0
reward_min: 605.0
total_envstep_count: 2110280
total_train_sample_count: 2110220
total_episode_count: 13707
total_duration: 2662.6557074614943
[2024-11-20 00:17:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2177
train_sample_count: 2177
avg_envstep_per_episode: 272.125
avg_sample_per_episode: 272.125
avg_envstep_per_sec: 742.8507320020115
avg_train_sample_per_sec: 742.8507320020115
avg_episode_per_sec: 2.7298143573799227
collect_time: 2.930602214166096
reward_mean: 1033.625
reward_std: 293.19573974609375
reward_max: 1351.0
reward_min: 606.0
total_envstep_count: 2111241
total_train_sample_count: 2111209
total_episode_count: 13715
total_duration: 2665.5863096756602
[2024-11-20 00:17:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 754
train_sample_count: 754
avg_envstep_per_episode: 94.25
avg_sample_per_episode: 94.25
avg_envstep_per_sec: 740.8652153415741
avg_train_sample_per_sec: 740.8652153415741
avg_episode_per_sec: 7.860638889565773
collect_time: 1.0177289800984517
reward_mean: 800.75
reward_std: 342.5133972167969
reward_max: 1571.0
reward_min: 607.0
total_envstep_count: 2112236
total_train_sample_count: 2112215
total_episode_count: 13723
total_duration: 2666.604038655759
[2024-11-20 00:17:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1208
train_sample_count: 1208
avg_envstep_per_episode: 120.8
avg_sample_per_episode: 120.8
avg_envstep_per_sec: 755.177653900473
avg_train_sample_per_sec: 755.177653900473
avg_episode_per_sec: 6.251470644871465
collect_time: 1.5996236034802027
reward_mean: 938.2000122070312
reward_std: 494.39129638671875
reward_max: 1699.0
reward_min: 249.0
total_envstep_count: 2113277
total_train_sample_count: 2113207
total_episode_count: 13733
total_duration: 2668.203662259239
[2024-11-20 00:17:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 774
train_sample_count: 774
avg_envstep_per_episode: 96.75
avg_sample_per_episode: 96.75
avg_envstep_per_sec: 753.1817065143241
avg_train_sample_per_sec: 753.1817065143241
avg_episode_per_sec: 7.7848238399413345
collect_time: 1.0276404661791663
reward_mean: 791.125
reward_std: 560.6138305664062
reward_max: 1846.0
reward_min: 245.0
total_envstep_count: 2114253
total_train_sample_count: 2114221
total_episode_count: 13741
total_duration: 2669.231302725418
[2024-11-20 00:17:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1204
train_sample_count: 1204
avg_envstep_per_episode: 150.5
avg_sample_per_episode: 150.5
avg_envstep_per_sec: 754.2152807850648
avg_train_sample_per_sec: 754.2152807850648
avg_episode_per_sec: 5.011397214518704
collect_time: 1.5963611858231683
reward_mean: 1251.5
reward_std: 426.72357177734375
reward_max: 1700.0
reward_min: 606.0
total_envstep_count: 2115239
total_train_sample_count: 2115209
total_episode_count: 13749
total_duration: 2670.8276639112414
[2024-11-20 00:17:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 850
train_sample_count: 850
avg_envstep_per_episode: 121.42857142857143
avg_sample_per_episode: 121.42857142857143
avg_envstep_per_sec: 762.6156475070533
avg_train_sample_per_sec: 762.6156475070533
avg_episode_per_sec: 6.280364155940439
collect_time: 1.114585050514766
reward_mean: 1006.2857055664062
reward_std: 432.09051513671875
reward_max: 1701.0
reward_min: 614.0
total_envstep_count: 2116265
total_train_sample_count: 2116227
total_episode_count: 13756
total_duration: 2671.9422489617564
[2024-11-20 00:17:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1110
train_sample_count: 1110
avg_envstep_per_episode: 138.75
avg_sample_per_episode: 138.75
avg_envstep_per_sec: 749.1120347231691
avg_train_sample_per_sec: 749.1120347231691
avg_episode_per_sec: 5.399005655662481
collect_time: 1.4817543285233634
reward_mean: 933.625
reward_std: 554.2377319335938
reward_max: 1852.0
reward_min: 238.0
total_envstep_count: 2117268
total_train_sample_count: 2117229
total_episode_count: 13764
total_duration: 2673.42400329028
[2024-11-20 00:17:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 603
train_sample_count: 603
avg_envstep_per_episode: 150.75
avg_sample_per_episode: 150.75
avg_envstep_per_sec: 746.3716134891539
avg_train_sample_per_sec: 746.3716134891539
avg_episode_per_sec: 4.951055479198367
collect_time: 0.8079085392611367
reward_mean: 1263.5
reward_std: 123.51618957519531
reward_max: 1343.0
reward_min: 1050.0
total_envstep_count: 2118225
total_train_sample_count: 2118192
total_episode_count: 13768
total_duration: 2674.231911829541
[2024-11-20 00:17:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 996
train_sample_count: 996
avg_envstep_per_episode: 199.2
avg_sample_per_episode: 199.2
avg_envstep_per_sec: 752.3945562374066
avg_train_sample_per_sec: 752.3945562374066
avg_episode_per_sec: 3.777081105609471
collect_time: 1.3237735331058502
reward_mean: 1354.800048828125
reward_std: 428.77191162109375
reward_max: 1835.0
reward_min: 591.0
total_envstep_count: 2119228
total_train_sample_count: 2119188
total_episode_count: 13773
total_duration: 2675.5556853626467
[2024-11-20 00:17:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1203
train_sample_count: 1203
avg_envstep_per_episode: 150.375
avg_sample_per_episode: 150.375
avg_envstep_per_sec: 738.9394232243089
avg_train_sample_per_sec: 738.9394232243089
avg_episode_per_sec: 4.913977876803385
collect_time: 1.6280089574200767
reward_mean: 1039.625
reward_std: 550.8763427734375
reward_max: 1855.0
reward_min: 250.0
total_envstep_count: 2120238
total_train_sample_count: 2120187
total_episode_count: 13781
total_duration: 2677.183694320067
[2024-11-20 00:17:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 717
train_sample_count: 717
avg_envstep_per_episode: 143.4
avg_sample_per_episode: 143.4
avg_envstep_per_sec: 746.7534984928398
avg_train_sample_per_sec: 746.7534984928398
avg_episode_per_sec: 5.207486042488422
collect_time: 0.9601561980588096
reward_mean: 884.4000244140625
reward_std: 276.5918273925781
reward_max: 1341.0
reward_min: 605.0
total_envstep_count: 2121217
total_train_sample_count: 2121180
total_episode_count: 13786
total_duration: 2678.143850518126
[2024-11-20 00:17:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 978
train_sample_count: 978
avg_envstep_per_episode: 163.0
avg_sample_per_episode: 163.0
avg_envstep_per_sec: 742.9746305338172
avg_train_sample_per_sec: 742.9746305338172
avg_episode_per_sec: 4.55812656769213
collect_time: 1.3163302753652844
reward_mean: 939.8333129882812
reward_std: 458.1780700683594
reward_max: 1419.0
reward_min: 248.0
total_envstep_count: 2122188
total_train_sample_count: 2122158
total_episode_count: 13792
total_duration: 2679.460180793491
[2024-11-20 00:17:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1344
train_sample_count: 1344
avg_envstep_per_episode: 168.0
avg_sample_per_episode: 168.0
avg_envstep_per_sec: 743.5623146889628
avg_train_sample_per_sec: 743.5623146889628
avg_episode_per_sec: 4.425966158862874
collect_time: 1.80751494992347
reward_mean: 911.375
reward_std: 573.422607421875
reward_max: 2296.0
reward_min: 575.0
total_envstep_count: 2123212
total_train_sample_count: 2123178
total_episode_count: 13800
total_duration: 2681.2676957434146
[2024-11-20 00:17:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 430
train_sample_count: 430
avg_envstep_per_episode: 107.5
avg_sample_per_episode: 107.5
avg_envstep_per_sec: 743.4925349891361
avg_train_sample_per_sec: 743.4925349891361
avg_episode_per_sec: 6.916209627805916
collect_time: 0.5783514692669822
reward_mean: 970.0
reward_std: 344.4379577636719
reward_max: 1437.0
reward_min: 626.0
total_envstep_count: 2124192
total_train_sample_count: 2124160
total_episode_count: 13804
total_duration: 2681.8460472126817
[2024-11-20 00:17:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 912
train_sample_count: 912
avg_envstep_per_episode: 228.0
avg_sample_per_episode: 228.0
avg_envstep_per_sec: 746.0103634178366
avg_train_sample_per_sec: 746.0103634178366
avg_episode_per_sec: 3.2719752781484064
collect_time: 1.222503124248414
reward_mean: 1756.25
reward_std: 703.6619262695312
reward_max: 2360.0
reward_min: 625.0
total_envstep_count: 2125196
total_train_sample_count: 2125144
total_episode_count: 13808
total_duration: 2683.06855033693
[2024-11-20 00:18:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1501
train_sample_count: 1501
avg_envstep_per_episode: 136.45454545454547
avg_sample_per_episode: 136.45454545454547
avg_envstep_per_sec: 754.6106099668203
avg_train_sample_per_sec: 754.6106099668203
avg_episode_per_sec: 5.53012439016324
collect_time: 1.9891053480761394
reward_mean: 986.272705078125
reward_std: 555.5616455078125
reward_max: 2317.0
reward_min: 250.0
total_envstep_count: 2126178
total_train_sample_count: 2126129
total_episode_count: 13819
total_duration: 2685.057655685006
[2024-11-20 00:18:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 646
train_sample_count: 646
avg_envstep_per_episode: 161.5
avg_sample_per_episode: 161.5
avg_envstep_per_sec: 747.0742246276766
avg_train_sample_per_sec: 747.0742246276766
avg_episode_per_sec: 4.625846592121836
collect_time: 0.864706582966305
reward_mean: 1027.75
reward_std: 932.8803100585938
reward_max: 2617.0
reward_min: 223.0
total_envstep_count: 2127166
total_train_sample_count: 2127135
total_episode_count: 13823
total_duration: 2685.9223622679724
[2024-11-20 00:18:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1285
train_sample_count: 1285
avg_envstep_per_episode: 257.0
avg_sample_per_episode: 257.0
avg_envstep_per_sec: 750.0236013740621
avg_train_sample_per_sec: 750.0236013740621
avg_episode_per_sec: 2.91837977188351
collect_time: 1.713279419002079
reward_mean: 1172.199951171875
reward_std: 630.49072265625
reward_max: 2304.0
reward_min: 606.0
total_envstep_count: 2128162
total_train_sample_count: 2128132
total_episode_count: 13828
total_duration: 2687.6356416869744
[2024-11-20 00:18:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1587
train_sample_count: 1587
avg_envstep_per_episode: 144.27272727272728
avg_sample_per_episode: 144.27272727272728
avg_envstep_per_sec: 751.2991168908771
avg_train_sample_per_sec: 751.2991168908771
avg_episode_per_sec: 5.207492303591461
collect_time: 2.11234109600385
reward_mean: 837.8181762695312
reward_std: 429.1331481933594
reward_max: 1690.0
reward_min: 247.0
total_envstep_count: 2129193
total_train_sample_count: 2129143
total_episode_count: 13839
total_duration: 2689.7479827829784
[2024-11-20 00:18:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 503
train_sample_count: 503
avg_envstep_per_episode: 100.6
avg_sample_per_episode: 100.6
avg_envstep_per_sec: 726.9626865178013
avg_train_sample_per_sec: 726.9626865178013
avg_episode_per_sec: 7.226269249679934
collect_time: 0.6919199696608952
reward_mean: 784.7999877929688
reward_std: 276.7709655761719
reward_max: 1328.0
reward_min: 591.0
total_envstep_count: 2130165
total_train_sample_count: 2130126
total_episode_count: 13844
total_duration: 2690.4399027526392
[2024-11-20 00:18:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 966
train_sample_count: 966
avg_envstep_per_episode: 161.0
avg_sample_per_episode: 161.0
avg_envstep_per_sec: 740.5337315369937
avg_train_sample_per_sec: 740.5337315369937
avg_episode_per_sec: 4.599588394639713
collect_time: 1.3044645488262177
reward_mean: 1400.5
reward_std: 378.8468322753906
reward_max: 1695.0
reward_min: 626.0
total_envstep_count: 2131143
total_train_sample_count: 2131116
total_episode_count: 13850
total_duration: 2691.7443673014654
[2024-11-20 00:18:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1265
train_sample_count: 1265
avg_envstep_per_episode: 140.55555555555554
avg_sample_per_episode: 140.55555555555554
avg_envstep_per_sec: 730.7298923184107
avg_train_sample_per_sec: 730.7298923184107
avg_episode_per_sec: 5.198868799103318
collect_time: 1.7311458218665352
reward_mean: 1014.3333129882812
reward_std: 589.7604370117188
reward_max: 2350.0
reward_min: 609.0
total_envstep_count: 2132190
total_train_sample_count: 2132153
total_episode_count: 13859
total_duration: 2693.475513123332
[2024-11-20 00:18:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 832
train_sample_count: 832
avg_envstep_per_episode: 166.4
avg_sample_per_episode: 166.4
avg_envstep_per_sec: 727.9013648572829
avg_train_sample_per_sec: 727.9013648572829
avg_episode_per_sec: 4.374407240728864
collect_time: 1.143012007077535
reward_mean: 1509.0
reward_std: 457.2679748535156
reward_max: 1856.0
reward_min: 603.0
total_envstep_count: 2133193
total_train_sample_count: 2133153
total_episode_count: 13864
total_duration: 2694.6185251304096
[2024-11-20 00:18:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 452
train_sample_count: 452
avg_envstep_per_episode: 113.0
avg_sample_per_episode: 113.0
avg_envstep_per_sec: 732.996920502513
avg_train_sample_per_sec: 732.996920502513
avg_episode_per_sec: 6.486698411526664
collect_time: 0.6166465197290694
reward_mean: 728.75
reward_std: 181.6099853515625
reward_max: 1043.0
reward_min: 616.0
total_envstep_count: 2134157
total_train_sample_count: 2134121
total_episode_count: 13868
total_duration: 2695.2351716501385
[2024-11-20 00:18:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1456
train_sample_count: 1456
avg_envstep_per_episode: 208.0
avg_sample_per_episode: 208.0
avg_envstep_per_sec: 737.4415465349481
avg_train_sample_per_sec: 737.4415465349481
avg_episode_per_sec: 3.545392050648789
collect_time: 1.9743937764848982
reward_mean: 1527.142822265625
reward_std: 554.7412109375
reward_max: 2620.0
reward_min: 628.0
total_envstep_count: 2135150
total_train_sample_count: 2135109
total_episode_count: 13875
total_duration: 2697.209565426623
[2024-11-20 00:18:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1093
train_sample_count: 1093
avg_envstep_per_episode: 182.16666666666666
avg_sample_per_episode: 182.16666666666666
avg_envstep_per_sec: 746.1015840405397
avg_train_sample_per_sec: 746.1015840405397
avg_episode_per_sec: 4.095708604065177
collect_time: 1.4649479687213898
reward_mean: 975.5
reward_std: 678.5697631835938
reward_max: 2309.0
reward_min: 242.0
total_envstep_count: 2136129
total_train_sample_count: 2136094
total_episode_count: 13881
total_duration: 2698.6745133953445
[2024-11-20 00:18:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 480
train_sample_count: 480
avg_envstep_per_episode: 80.0
avg_sample_per_episode: 80.0
avg_envstep_per_sec: 761.6038628227334
avg_train_sample_per_sec: 761.6038628227334
avg_episode_per_sec: 9.520048285284167
collect_time: 0.6302489042282104
reward_mean: 749.5
reward_std: 476.31597900390625
reward_max: 1441.0
reward_min: 234.0
total_envstep_count: 2137147
total_train_sample_count: 2137102
total_episode_count: 13887
total_duration: 2699.3047622995728
[2024-11-20 00:18:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 628
train_sample_count: 628
avg_envstep_per_episode: 157.0
avg_sample_per_episode: 157.0
avg_envstep_per_sec: 767.0301654775291
avg_train_sample_per_sec: 767.0301654775291
avg_episode_per_sec: 4.885542455270886
collect_time: 0.8187422454357147
reward_mean: 643.5
reward_std: 48.649253845214844
reward_max: 726.0
reward_min: 606.0
total_envstep_count: 2138152
total_train_sample_count: 2138114
total_episode_count: 13891
total_duration: 2700.1235045450085
[2024-11-20 00:18:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 799
train_sample_count: 799
avg_envstep_per_episode: 266.3333333333333
avg_sample_per_episode: 266.3333333333333
avg_envstep_per_sec: 757.0177353174694
avg_train_sample_per_sec: 757.0177353174694
avg_episode_per_sec: 2.8423694692771067
collect_time: 1.0554574387414115
reward_mean: 824.0
reward_std: 307.7109069824219
reward_max: 1259.0
reward_min: 596.0
total_envstep_count: 2139133
total_train_sample_count: 2139093
total_episode_count: 13894
total_duration: 2701.17896198375
[2024-11-20 00:18:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1367
train_sample_count: 1367
avg_envstep_per_episode: 227.83333333333334
avg_sample_per_episode: 227.83333333333334
avg_envstep_per_sec: 757.7029456967507
avg_train_sample_per_sec: 757.7029456967507
avg_episode_per_sec: 3.3256895934019783
collect_time: 1.8041371064526694
reward_mean: 1068.6666259765625
reward_std: 641.1834716796875
reward_max: 2301.0
reward_min: 605.0
total_envstep_count: 2140138
total_train_sample_count: 2140088
total_episode_count: 13900
total_duration: 2702.983099090203
[2024-11-20 00:18:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 864
train_sample_count: 864
avg_envstep_per_episode: 123.42857142857143
avg_sample_per_episode: 123.42857142857143
avg_envstep_per_sec: 730.8247730668512
avg_train_sample_per_sec: 730.8247730668512
avg_episode_per_sec: 5.921034041050878
collect_time: 1.1822259340967451
reward_mean: 868.5714111328125
reward_std: 536.6703491210938
reward_max: 1903.0
reward_min: 251.0
total_envstep_count: 2141108
total_train_sample_count: 2141072
total_episode_count: 13907
total_duration: 2704.1653250242994
[2024-11-20 00:19:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 954
train_sample_count: 954
avg_envstep_per_episode: 318.0
avg_sample_per_episode: 318.0
avg_envstep_per_sec: 748.2293442271994
avg_train_sample_per_sec: 748.2293442271994
avg_episode_per_sec: 2.3529224661232684
collect_time: 1.2750101387500763
reward_mean: 1229.3333740234375
reward_std: 753.6517333984375
reward_max: 2292.0
reward_min: 627.0
total_envstep_count: 2142065
total_train_sample_count: 2142038
total_episode_count: 13910
total_duration: 2705.4403351630494
[2024-11-20 00:19:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1054
train_sample_count: 1054
avg_envstep_per_episode: 131.75
avg_sample_per_episode: 131.75
avg_envstep_per_sec: 738.5542757663118
avg_train_sample_per_sec: 738.5542757663118
avg_episode_per_sec: 5.605725053254738
collect_time: 1.4271124473639896
reward_mean: 1039.375
reward_std: 438.2575988769531
reward_max: 1696.0
reward_min: 601.0
total_envstep_count: 2143051
total_train_sample_count: 2143032
total_episode_count: 13918
total_duration: 2706.8674476104134
[2024-11-20 00:19:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 938
train_sample_count: 938
avg_envstep_per_episode: 117.25
avg_sample_per_episode: 117.25
avg_envstep_per_sec: 739.3092909584515
avg_train_sample_per_sec: 739.3092909584515
avg_episode_per_sec: 6.3054097309889245
collect_time: 1.2687518085752216
reward_mean: 918.25
reward_std: 499.2924499511719
reward_max: 1708.0
reward_min: 246.0
total_envstep_count: 2144117
total_train_sample_count: 2144078
total_episode_count: 13926
total_duration: 2708.136199418989
[2024-11-20 00:19:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 555
train_sample_count: 555
avg_envstep_per_episode: 138.75
avg_sample_per_episode: 138.75
avg_envstep_per_sec: 733.4090271899822
avg_train_sample_per_sec: 733.4090271899822
avg_episode_per_sec: 5.2858308265944665
collect_time: 0.756740071943828
reward_mean: 891.5
reward_std: 444.4066162109375
reward_max: 1661.0
reward_min: 620.0
total_envstep_count: 2145081
total_train_sample_count: 2145053
total_episode_count: 13930
total_duration: 2708.892939490933
[2024-11-20 00:19:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 970
train_sample_count: 970
avg_envstep_per_episode: 138.57142857142858
avg_sample_per_episode: 138.57142857142858
avg_envstep_per_sec: 742.7285520191302
avg_train_sample_per_sec: 742.7285520191302
avg_episode_per_sec: 5.359896767148363
collect_time: 1.3059953025409154
reward_mean: 1044.7142333984375
reward_std: 581.5272216796875
reward_max: 1699.0
reward_min: 247.0
total_envstep_count: 2146115
total_train_sample_count: 2146083
total_episode_count: 13937
total_duration: 2710.1989347934737
[2024-11-20 00:19:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 796
train_sample_count: 796
avg_envstep_per_episode: 159.2
avg_sample_per_episode: 159.2
avg_envstep_per_sec: 761.9203573302011
avg_train_sample_per_sec: 761.9203573302011
avg_episode_per_sec: 4.785931892777645
collect_time: 1.0447286154542652
reward_mean: 1220.0
reward_std: 455.1228332519531
reward_max: 1697.0
reward_min: 635.0
total_envstep_count: 2147119
total_train_sample_count: 2147083
total_episode_count: 13942
total_duration: 2711.243663408928
[2024-11-20 00:19:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 292
train_sample_count: 292
avg_envstep_per_episode: 146.0
avg_sample_per_episode: 146.0
avg_envstep_per_sec: 765.1012069176356
avg_train_sample_per_sec: 765.1012069176356
avg_episode_per_sec: 5.240419225463258
collect_time: 0.38164885554994854
reward_mean: 818.0
reward_std: 216.0
reward_max: 1034.0
reward_min: 602.0
total_envstep_count: 2148093
total_train_sample_count: 2148047
total_episode_count: 13944
total_duration: 2711.625312264478
[2024-11-20 00:19:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 590
train_sample_count: 590
avg_envstep_per_episode: 196.66666666666666
avg_sample_per_episode: 196.66666666666666
avg_envstep_per_sec: 761.7406042560681
avg_train_sample_per_sec: 761.7406042560681
avg_episode_per_sec: 3.8732573097766174
collect_time: 0.7745418804032462
reward_mean: 1277.0
reward_std: 358.6902160644531
reward_max: 1561.0
reward_min: 771.0
total_envstep_count: 2149066
total_train_sample_count: 2149033
total_episode_count: 13947
total_duration: 2712.3998541448814
[2024-11-20 00:19:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2272
train_sample_count: 2272
avg_envstep_per_episode: 757.3333333333334
avg_sample_per_episode: 757.3333333333334
avg_envstep_per_sec: 758.6108297361183
avg_train_sample_per_sec: 758.6108297361183
avg_episode_per_sec: 1.0016868350388886
collect_time: 2.9949480167457034
reward_mean: 1368.0
reward_std: 264.7803955078125
reward_max: 1665.0
reward_min: 1022.0
total_envstep_count: 2150031
total_train_sample_count: 2150009
total_episode_count: 13950
total_duration: 2715.394802161627
[2024-11-20 00:19:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1697
train_sample_count: 1697
avg_envstep_per_episode: 242.42857142857142
avg_sample_per_episode: 242.42857142857142
avg_envstep_per_sec: 758.0227139220832
avg_train_sample_per_sec: 758.0227139220832
avg_episode_per_sec: 3.1267878594311034
collect_time: 2.2387191951274876
reward_mean: 1099.0
reward_std: 468.12725830078125
reward_max: 1922.0
reward_min: 609.0
total_envstep_count: 2151049
total_train_sample_count: 2151010
total_episode_count: 13957
total_duration: 2717.6335213567545
[2024-11-20 00:19:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1557
train_sample_count: 1557
avg_envstep_per_episode: 222.42857142857142
avg_sample_per_episode: 222.42857142857142
avg_envstep_per_sec: 735.2433239827166
avg_train_sample_per_sec: 735.2433239827166
avg_episode_per_sec: 3.3055255413481155
collect_time: 2.117666287081582
reward_mean: 1316.5714111328125
reward_std: 463.5961608886719
reward_max: 2280.0
reward_min: 611.0
total_envstep_count: 2152050
total_train_sample_count: 2152003
total_episode_count: 13964
total_duration: 2719.751187643836
[2024-11-20 00:19:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 652
train_sample_count: 652
avg_envstep_per_episode: 93.14285714285714
avg_sample_per_episode: 93.14285714285714
avg_envstep_per_sec: 687.1503734711213
avg_train_sample_per_sec: 687.1503734711213
avg_episode_per_sec: 7.377381310272774
collect_time: 0.9488461698804584
reward_mean: 570.2857055664062
reward_std: 130.95333862304688
reward_max: 635.0
reward_min: 250.0
total_envstep_count: 2153036
total_train_sample_count: 2152991
total_episode_count: 13971
total_duration: 2720.700033813717
[2024-11-20 00:19:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1531
train_sample_count: 1531
avg_envstep_per_episode: 191.375
avg_sample_per_episode: 191.375
avg_envstep_per_sec: 710.296318075852
avg_train_sample_per_sec: 710.296318075852
avg_episode_per_sec: 3.711541831879044
collect_time: 2.1554384572165355
reward_mean: 1368.375
reward_std: 528.47705078125
reward_max: 2297.0
reward_min: 610.0
total_envstep_count: 2154053
total_train_sample_count: 2154006
total_episode_count: 13979
total_duration: 2722.855472270933
[2024-11-20 00:19:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 632
train_sample_count: 632
avg_envstep_per_episode: 126.4
avg_sample_per_episode: 126.4
avg_envstep_per_sec: 699.8728867943798
avg_train_sample_per_sec: 699.8728867943798
avg_episode_per_sec: 5.5369690410947765
collect_time: 0.9030211227280753
reward_mean: 1129.800048828125
reward_std: 426.2278137207031
reward_max: 1691.0
reward_min: 614.0
total_envstep_count: 2155024
total_train_sample_count: 2154986
total_episode_count: 13984
total_duration: 2723.7584933936614
[2024-11-20 00:19:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1077
train_sample_count: 1077
avg_envstep_per_episode: 119.66666666666667
avg_sample_per_episode: 119.66666666666667
avg_envstep_per_sec: 702.1890035827238
avg_train_sample_per_sec: 702.1890035827238
avg_episode_per_sec: 5.8678746817497816
collect_time: 1.5337750869137903
reward_mean: 947.3333129882812
reward_std: 501.82135009765625
reward_max: 1878.0
reward_min: 588.0
total_envstep_count: 2156032
total_train_sample_count: 2155991
total_episode_count: 13993
total_duration: 2725.2922684805753
[2024-11-20 00:20:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 715
train_sample_count: 715
avg_envstep_per_episode: 119.16666666666667
avg_sample_per_episode: 119.16666666666667
avg_envstep_per_sec: 700.7329186111572
avg_train_sample_per_sec: 700.7329186111572
avg_episode_per_sec: 5.880276240093626
collect_time: 1.0203602271420615
reward_mean: 866.6666870117188
reward_std: 397.287353515625
reward_max: 1330.0
reward_min: 250.0
total_envstep_count: 2157042
total_train_sample_count: 2156994
total_episode_count: 13999
total_duration: 2726.3126287077175
[2024-11-20 00:20:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 685
train_sample_count: 685
avg_envstep_per_episode: 114.16666666666667
avg_sample_per_episode: 114.16666666666667
avg_envstep_per_sec: 701.7844794490711
avg_train_sample_per_sec: 701.7844794490711
avg_episode_per_sec: 6.147017338240039
collect_time: 0.9760831424168178
reward_mean: 1030.6666259765625
reward_std: 438.0931091308594
reward_max: 1692.0
reward_min: 608.0
total_envstep_count: 2158014
total_train_sample_count: 2157991
total_episode_count: 14005
total_duration: 2727.2887118501344
[2024-11-20 00:20:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1636
train_sample_count: 1636
avg_envstep_per_episode: 181.77777777777777
avg_sample_per_episode: 181.77777777777777
avg_envstep_per_sec: 703.0905710916383
avg_train_sample_per_sec: 703.0905710916383
avg_episode_per_sec: 3.8678576649295504
collect_time: 2.326869492019926
reward_mean: 1045.77783203125
reward_std: 730.5687255859375
reward_max: 2321.0
reward_min: 237.0
total_envstep_count: 2158985
total_train_sample_count: 2158967
total_episode_count: 14014
total_duration: 2729.615581342154
[2024-11-20 00:20:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 949
train_sample_count: 949
avg_envstep_per_episode: 118.625
avg_sample_per_episode: 118.625
avg_envstep_per_sec: 709.447736899985
avg_train_sample_per_sec: 709.447736899985
avg_episode_per_sec: 5.980592091886069
collect_time: 1.3376601977007732
reward_mean: 808.0
reward_std: 331.7585754394531
reward_max: 1430.0
reward_min: 587.0
total_envstep_count: 2159989
total_train_sample_count: 2159964
total_episode_count: 14022
total_duration: 2730.953241539855
[2024-11-20 00:20:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 586
train_sample_count: 586
avg_envstep_per_episode: 117.2
avg_sample_per_episode: 117.2
avg_envstep_per_sec: 715.5244565725236
avg_train_sample_per_sec: 715.5244565725236
avg_episode_per_sec: 6.105157479287744
collect_time: 0.8189796933106013
reward_mean: 677.7999877929688
reward_std: 373.50897216796875
reward_max: 1322.0
reward_min: 156.0
total_envstep_count: 2160992
total_train_sample_count: 2160958
total_episode_count: 14027
total_duration: 2731.7722212331655
[2024-11-20 00:20:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1436
train_sample_count: 1436
avg_envstep_per_episode: 287.2
avg_sample_per_episode: 287.2
avg_envstep_per_sec: 695.4340524334184
avg_train_sample_per_sec: 695.4340524334184
avg_episode_per_sec: 2.4214277591692843
collect_time: 2.064897447824478
reward_mean: 1306.5999755859375
reward_std: 549.8402099609375
reward_max: 2279.0
reward_min: 605.0
total_envstep_count: 2161987
total_train_sample_count: 2161938
total_episode_count: 14032
total_duration: 2733.83711868099
[2024-11-20 00:20:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1364
train_sample_count: 1364
avg_envstep_per_episode: 151.55555555555554
avg_sample_per_episode: 151.55555555555554
avg_envstep_per_sec: 700.9807512985298
avg_train_sample_per_sec: 700.9807512985298
avg_episode_per_sec: 4.625239561353935
collect_time: 1.9458451569080353
reward_mean: 1095.0
reward_std: 443.8265380859375
reward_max: 1701.0
reward_min: 601.0
total_envstep_count: 2162980
total_train_sample_count: 2162954
total_episode_count: 14041
total_duration: 2735.782963837898
[2024-11-20 00:20:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 380
train_sample_count: 380
avg_envstep_per_episode: 95.0
avg_sample_per_episode: 95.0
avg_envstep_per_sec: 703.0353817894825
avg_train_sample_per_sec: 703.0353817894825
avg_episode_per_sec: 7.400372439889289
collect_time: 0.5405133366584778
reward_mean: 904.25
reward_std: 312.4486999511719
reward_max: 1350.0
reward_min: 610.0
total_envstep_count: 2163977
total_train_sample_count: 2163934
total_episode_count: 14045
total_duration: 2736.3234771745565
[2024-11-20 00:20:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1149
train_sample_count: 1149
avg_envstep_per_episode: 164.14285714285714
avg_sample_per_episode: 164.14285714285714
avg_envstep_per_sec: 704.1317271274463
avg_train_sample_per_sec: 704.1317271274463
avg_episode_per_sec: 4.28974942549358
collect_time: 1.631796943289893
reward_mean: 1292.7142333984375
reward_std: 287.40997314453125
reward_max: 1550.0
reward_min: 610.0
total_envstep_count: 2164955
total_train_sample_count: 2164915
total_episode_count: 14052
total_duration: 2737.9552741178463
[2024-11-20 00:20:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1035
train_sample_count: 1035
avg_envstep_per_episode: 147.85714285714286
avg_sample_per_episode: 147.85714285714286
avg_envstep_per_sec: 696.085780797742
avg_train_sample_per_sec: 696.085780797742
avg_episode_per_sec: 4.707826536796323
collect_time: 1.486885709421975
reward_mean: 851.2857055664062
reward_std: 377.8861083984375
reward_max: 1563.0
reward_min: 589.0
total_envstep_count: 2165933
total_train_sample_count: 2165914
total_episode_count: 14059
total_duration: 2739.4421598272684
[2024-11-20 00:20:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1323
train_sample_count: 1323
avg_envstep_per_episode: 165.375
avg_sample_per_episode: 165.375
avg_envstep_per_sec: 699.6192946314109
avg_train_sample_per_sec: 699.6192946314109
avg_episode_per_sec: 4.230502159524782
collect_time: 1.8910284638404842
reward_mean: 1124.25
reward_std: 566.568115234375
reward_max: 2322.0
reward_min: 610.0
total_envstep_count: 2166967
total_train_sample_count: 2166949
total_episode_count: 14067
total_duration: 2741.333188291109
[2024-11-20 00:20:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 903
train_sample_count: 903
avg_envstep_per_episode: 150.5
avg_sample_per_episode: 150.5
avg_envstep_per_sec: 693.4443579988505
avg_train_sample_per_sec: 693.4443579988505
avg_episode_per_sec: 4.607603707633558
collect_time: 1.3021953233650752
reward_mean: 1141.0
reward_std: 422.8269958496094
reward_max: 1705.0
reward_min: 607.0
total_envstep_count: 2167963
total_train_sample_count: 2167924
total_episode_count: 14073
total_duration: 2742.635383614474
[2024-11-20 00:20:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 857
train_sample_count: 857
avg_envstep_per_episode: 142.83333333333334
avg_sample_per_episode: 142.83333333333334
avg_envstep_per_sec: 689.3564314515323
avg_train_sample_per_sec: 689.3564314515323
avg_episode_per_sec: 4.826299403394626
collect_time: 1.2431885174342563
reward_mean: 958.6666870117188
reward_std: 470.58001708984375
reward_max: 1689.0
reward_min: 606.0
total_envstep_count: 2168934
total_train_sample_count: 2168901
total_episode_count: 14079
total_duration: 2743.878572131908
[2024-11-20 00:20:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1130
train_sample_count: 1130
avg_envstep_per_episode: 161.42857142857142
avg_sample_per_episode: 161.42857142857142
avg_envstep_per_sec: 694.4602002401787
avg_train_sample_per_sec: 694.4602002401787
avg_episode_per_sec: 4.301965842195797
collect_time: 1.6271630823612213
reward_mean: 1248.142822265625
reward_std: 132.89999389648438
reward_max: 1348.0
reward_min: 1035.0
total_envstep_count: 2169936
total_train_sample_count: 2169899
total_episode_count: 14086
total_duration: 2745.5057352142694
[2024-11-20 00:21:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 967
train_sample_count: 967
avg_envstep_per_episode: 161.16666666666666
avg_sample_per_episode: 161.16666666666666
avg_envstep_per_sec: 705.9921317030678
avg_train_sample_per_sec: 705.9921317030678
avg_episode_per_sec: 4.380509607257918
collect_time: 1.3697036504745483
reward_mean: 1398.1666259765625
reward_std: 544.7936401367188
reward_max: 2374.0
reward_min: 608.0
total_envstep_count: 2170954
total_train_sample_count: 2170914
total_episode_count: 14092
total_duration: 2746.875438864744
[2024-11-20 00:21:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1072
train_sample_count: 1072
avg_envstep_per_episode: 134.0
avg_sample_per_episode: 134.0
avg_envstep_per_sec: 709.4924229279147
avg_train_sample_per_sec: 709.4924229279147
avg_episode_per_sec: 5.294719574088917
collect_time: 1.5109393213476452
reward_mean: 967.75
reward_std: 465.5654602050781
reward_max: 1927.0
reward_min: 602.0
total_envstep_count: 2171939
total_train_sample_count: 2171902
total_episode_count: 14100
total_duration: 2748.3863781860914
[2024-11-20 00:21:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 792
train_sample_count: 792
avg_envstep_per_episode: 132.0
avg_sample_per_episode: 132.0
avg_envstep_per_sec: 719.1170681010648
avg_train_sample_per_sec: 719.1170681010648
avg_episode_per_sec: 5.447856576523217
collect_time: 1.1013505799429757
reward_mean: 979.5
reward_std: 501.4159240722656
reward_max: 1688.0
reward_min: 243.0
total_envstep_count: 2172934
total_train_sample_count: 2172886
total_episode_count: 14106
total_duration: 2749.4877287660343
[2024-11-20 00:21:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 945
train_sample_count: 945
avg_envstep_per_episode: 135.0
avg_sample_per_episode: 135.0
avg_envstep_per_sec: 718.639186126254
avg_train_sample_per_sec: 718.639186126254
avg_episode_per_sec: 5.323253230564844
collect_time: 1.3149853476456235
reward_mean: 926.8571166992188
reward_std: 550.2891235351562
reward_max: 1702.0
reward_min: 240.0
total_envstep_count: 2173896
total_train_sample_count: 2173867
total_episode_count: 14113
total_duration: 2750.80271411368
[2024-11-20 00:21:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1063
train_sample_count: 1063
avg_envstep_per_episode: 151.85714285714286
avg_sample_per_episode: 151.85714285714286
avg_envstep_per_sec: 723.5438038356399
avg_train_sample_per_sec: 723.5438038356399
avg_episode_per_sec: 4.764634644261034
collect_time: 1.4691577681473325
reward_mean: 920.2857055664062
reward_std: 234.19998168945312
reward_max: 1304.0
reward_min: 610.0
total_envstep_count: 2174905
total_train_sample_count: 2174870
total_episode_count: 14120
total_duration: 2752.2718718818273
[2024-11-20 00:21:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 972
train_sample_count: 972
avg_envstep_per_episode: 194.4
avg_sample_per_episode: 194.4
avg_envstep_per_sec: 721.1513162592513
avg_train_sample_per_sec: 721.1513162592513
avg_episode_per_sec: 3.7096261124447087
collect_time: 1.347844728401729
reward_mean: 1235.4000244140625
reward_std: 456.64013671875
reward_max: 1697.0
reward_min: 635.0
total_envstep_count: 2175894
total_train_sample_count: 2175854
total_episode_count: 14125
total_duration: 2753.6197166102293
[2024-11-20 00:21:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1307
train_sample_count: 1307
avg_envstep_per_episode: 118.81818181818181
avg_sample_per_episode: 118.81818181818181
avg_envstep_per_sec: 719.7493998380021
avg_train_sample_per_sec: 719.7493998380021
avg_episode_per_sec: 6.057569547221135
collect_time: 1.8159098156860896
reward_mean: 1080.3636474609375
reward_std: 429.2215576171875
reward_max: 1691.0
reward_min: 604.0
total_envstep_count: 2176900
total_train_sample_count: 2176861
total_episode_count: 14136
total_duration: 2755.4356264259154
[2024-11-20 00:21:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1011
train_sample_count: 1011
avg_envstep_per_episode: 112.33333333333333
avg_sample_per_episode: 112.33333333333333
avg_envstep_per_sec: 721.0651686007795
avg_train_sample_per_sec: 721.0651686007795
avg_episode_per_sec: 6.418977762024744
collect_time: 1.402092409985406
reward_mean: 788.5555419921875
reward_std: 448.8521423339844
reward_max: 1927.0
reward_min: 243.0
total_envstep_count: 2177900
total_train_sample_count: 2177848
total_episode_count: 14145
total_duration: 2756.837718835901
[2024-11-20 00:21:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 958
train_sample_count: 958
avg_envstep_per_episode: 136.85714285714286
avg_sample_per_episode: 136.85714285714286
avg_envstep_per_sec: 720.86900944481
avg_train_sample_per_sec: 720.86900944481
avg_episode_per_sec: 5.267310089889008
collect_time: 1.3289515674114227
reward_mean: 951.8571166992188
reward_std: 390.2872314453125
reward_max: 1685.0
reward_min: 601.0
total_envstep_count: 2178886
total_train_sample_count: 2178866
total_episode_count: 14152
total_duration: 2758.1666704033123
[2024-11-20 00:21:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 745
train_sample_count: 745
avg_envstep_per_episode: 106.42857142857143
avg_sample_per_episode: 106.42857142857143
avg_envstep_per_sec: 720.5853387900802
avg_train_sample_per_sec: 720.5853387900802
avg_episode_per_sec: 6.77060049869874
collect_time: 1.0338817068508692
reward_mean: 868.5714111328125
reward_std: 343.0334777832031
reward_max: 1400.0
reward_min: 604.0
total_envstep_count: 2179896
total_train_sample_count: 2179851
total_episode_count: 14159
total_duration: 2759.2005521101632
[2024-11-20 00:21:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 213
train_sample_count: 213
avg_envstep_per_episode: 106.5
avg_sample_per_episode: 106.5
avg_envstep_per_sec: 717.1858340394261
avg_train_sample_per_sec: 717.1858340394261
avg_episode_per_sec: 6.734139286755175
collect_time: 0.29699415394238066
reward_mean: 719.0
reward_std: 611.0
reward_max: 1330.0
reward_min: 108.0
total_envstep_count: 2180862
total_train_sample_count: 2180820
total_episode_count: 14161
total_duration: 2759.4975462641055
[2024-11-20 00:21:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1429
train_sample_count: 1429
avg_envstep_per_episode: 238.16666666666666
avg_sample_per_episode: 238.16666666666666
avg_envstep_per_sec: 725.6985365688137
avg_train_sample_per_sec: 725.6985365688137
avg_episode_per_sec: 3.047019747664718
collect_time: 1.9691372215747833
reward_mean: 874.3333129882812
reward_std: 255.40403747558594
reward_max: 1296.0
reward_min: 606.0
total_envstep_count: 2181872
total_train_sample_count: 2181829
total_episode_count: 14167
total_duration: 2761.4666834856803
[2024-11-20 00:21:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1135
train_sample_count: 1135
avg_envstep_per_episode: 283.75
avg_sample_per_episode: 283.75
avg_envstep_per_sec: 728.1295043852635
avg_train_sample_per_sec: 728.1295043852635
avg_episode_per_sec: 2.5660951696396954
collect_time: 1.5587886401585171
reward_mean: 1447.25
reward_std: 150.55958557128906
reward_max: 1692.0
reward_min: 1281.0
total_envstep_count: 2182837
total_train_sample_count: 2182796
total_episode_count: 14171
total_duration: 2763.025472125839
[2024-11-20 00:22:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1037
train_sample_count: 1037
avg_envstep_per_episode: 172.83333333333334
avg_sample_per_episode: 172.83333333333334
avg_envstep_per_sec: 720.9433729345973
avg_train_sample_per_sec: 720.9433729345973
avg_episode_per_sec: 4.171321347741161
collect_time: 1.4383931372846877
reward_mean: 1453.3333740234375
reward_std: 420.1089782714844
reward_max: 1932.0
reward_min: 615.0
total_envstep_count: 2183839
total_train_sample_count: 2183809
total_episode_count: 14177
total_duration: 2764.4638652631234
[2024-11-20 00:22:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1042
train_sample_count: 1042
avg_envstep_per_episode: 173.66666666666666
avg_sample_per_episode: 173.66666666666666
avg_envstep_per_sec: 709.9753383720519
avg_train_sample_per_sec: 709.9753383720519
avg_episode_per_sec: 4.088149741105865
collect_time: 1.4676566123962402
reward_mean: 1310.0
reward_std: 591.2301025390625
reward_max: 2344.0
reward_min: 608.0
total_envstep_count: 2184841
total_train_sample_count: 2184803
total_episode_count: 14183
total_duration: 2765.9315218755196
[2024-11-20 00:22:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 907
train_sample_count: 907
avg_envstep_per_episode: 226.75
avg_sample_per_episode: 226.75
avg_envstep_per_sec: 707.5999433659878
avg_train_sample_per_sec: 707.5999433659878
avg_episode_per_sec: 3.1206171703020407
collect_time: 1.281797728368214
reward_mean: 1675.5
reward_std: 396.9927673339844
reward_max: 2317.0
reward_min: 1340.0
total_envstep_count: 2185813
total_train_sample_count: 2185782
total_episode_count: 14187
total_duration: 2767.2133196038876
[2024-11-20 00:22:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1233
train_sample_count: 1233
avg_envstep_per_episode: 154.125
avg_sample_per_episode: 154.125
avg_envstep_per_sec: 701.1002469855007
avg_train_sample_per_sec: 701.1002469855007
avg_episode_per_sec: 4.548906711990272
collect_time: 1.7586643355233327
reward_mean: 1212.75
reward_std: 478.363037109375
reward_max: 1859.0
reward_min: 608.0
total_envstep_count: 2186847
total_train_sample_count: 2186835
total_episode_count: 14195
total_duration: 2768.971983939411
[2024-11-20 00:22:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 571
train_sample_count: 571
avg_envstep_per_episode: 285.5
avg_sample_per_episode: 285.5
avg_envstep_per_sec: 703.772515258835
avg_train_sample_per_sec: 703.772515258835
avg_episode_per_sec: 2.4650525928505607
collect_time: 0.8113417157105038
reward_mean: 1886.5
reward_std: 454.5
reward_max: 2341.0
reward_min: 1432.0
total_envstep_count: 2187845
total_train_sample_count: 2187802
total_episode_count: 14197
total_duration: 2769.7833256551216
[2024-11-20 00:22:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1315
train_sample_count: 1315
avg_envstep_per_episode: 131.5
avg_sample_per_episode: 131.5
avg_envstep_per_sec: 697.3137456219634
avg_train_sample_per_sec: 697.3137456219634
avg_episode_per_sec: 5.302766126402764
collect_time: 1.8858082294464111
reward_mean: 1151.4000244140625
reward_std: 594.3958740234375
reward_max: 2356.0
reward_min: 611.0
total_envstep_count: 2188854
total_train_sample_count: 2188829
total_episode_count: 14207
total_duration: 2771.669133884568
[2024-11-20 00:22:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1088
train_sample_count: 1088
avg_envstep_per_episode: 181.33333333333334
avg_sample_per_episode: 181.33333333333334
avg_envstep_per_sec: 693.8095358137841
avg_train_sample_per_sec: 693.8095358137841
avg_episode_per_sec: 3.826155528384839
collect_time: 1.568153713430677
reward_mean: 1193.5
reward_std: 568.5797119140625
reward_max: 2335.0
reward_min: 612.0
total_envstep_count: 2189850
total_train_sample_count: 2189809
total_episode_count: 14213
total_duration: 2773.2372875979986
[2024-11-20 00:22:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1187
train_sample_count: 1187
avg_envstep_per_episode: 131.88888888888889
avg_sample_per_episode: 131.88888888888889
avg_envstep_per_sec: 687.0501402377752
avg_train_sample_per_sec: 687.0501402377752
avg_episode_per_sec: 5.20931024611624
collect_time: 1.7276759445667265
reward_mean: 903.7777709960938
reward_std: 544.3832397460938
reward_max: 2357.0
reward_min: 587.0
total_envstep_count: 2190858
total_train_sample_count: 2190816
total_episode_count: 14222
total_duration: 2774.9649635425653
[2024-11-20 00:22:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 316
train_sample_count: 316
avg_envstep_per_episode: 105.33333333333333
avg_sample_per_episode: 105.33333333333333
avg_envstep_per_sec: 684.1798775829639
avg_train_sample_per_sec: 684.1798775829639
avg_episode_per_sec: 6.495378584648392
collect_time: 0.461866842848914
reward_mean: 757.0
reward_std: 218.81651306152344
reward_max: 1066.0
reward_min: 588.0
total_envstep_count: 2191815
total_train_sample_count: 2191780
total_episode_count: 14225
total_duration: 2775.426830385414
[2024-11-20 00:22:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1129
train_sample_count: 1129
avg_envstep_per_episode: 141.125
avg_sample_per_episode: 141.125
avg_envstep_per_sec: 706.0017420238405
avg_train_sample_per_sec: 706.0017420238405
avg_episode_per_sec: 5.002669562613573
collect_time: 1.5991461958204
reward_mean: 1136.875
reward_std: 433.9007263183594
reward_max: 1697.0
reward_min: 609.0
total_envstep_count: 2192839
total_train_sample_count: 2192789
total_episode_count: 14233
total_duration: 2777.0259765812348
[2024-11-20 00:22:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1686
train_sample_count: 1686
avg_envstep_per_episode: 168.6
avg_sample_per_episode: 168.6
avg_envstep_per_sec: 704.9628705035951
avg_train_sample_per_sec: 704.9628705035951
avg_episode_per_sec: 4.181274439523103
collect_time: 2.3916153184005196
reward_mean: 1147.0
reward_std: 741.5783081054688
reward_max: 3012.0
reward_min: 594.0
total_envstep_count: 2193806
total_train_sample_count: 2193779
total_episode_count: 14243
total_duration: 2779.417591899635
[2024-11-20 00:22:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 431
train_sample_count: 431
avg_envstep_per_episode: 143.66666666666666
avg_sample_per_episode: 143.66666666666666
avg_envstep_per_sec: 714.6075682213901
avg_train_sample_per_sec: 714.6075682213901
avg_episode_per_sec: 4.974066600148888
collect_time: 0.6031282331262315
reward_mean: 1091.3333740234375
reward_std: 343.9305419921875
reward_max: 1341.0
reward_min: 605.0
total_envstep_count: 2194773
total_train_sample_count: 2194750
total_episode_count: 14246
total_duration: 2780.0207201327617
[2024-11-20 00:22:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1182
train_sample_count: 1182
avg_envstep_per_episode: 197.0
avg_sample_per_episode: 197.0
avg_envstep_per_sec: 713.6040681492478
avg_train_sample_per_sec: 713.6040681492478
avg_episode_per_sec: 3.6223556758845072
collect_time: 1.6563806916986195
reward_mean: 1277.8333740234375
reward_std: 321.17047119140625
reward_max: 1854.0
reward_min: 811.0
total_envstep_count: 2195775
total_train_sample_count: 2195740
total_episode_count: 14252
total_duration: 2781.6771008244605
[2024-11-20 00:22:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 575
train_sample_count: 575
avg_envstep_per_episode: 287.5
avg_sample_per_episode: 287.5
avg_envstep_per_sec: 701.2081957265323
avg_train_sample_per_sec: 701.2081957265323
avg_episode_per_sec: 2.4389850286140256
collect_time: 0.820013233593532
reward_mean: 2014.5
reward_std: 326.5
reward_max: 2341.0
reward_min: 1688.0
total_envstep_count: 2196774
total_train_sample_count: 2196711
total_episode_count: 14254
total_duration: 2782.497114058054
[2024-11-20 00:22:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1391
train_sample_count: 1391
avg_envstep_per_episode: 231.83333333333334
avg_sample_per_episode: 231.83333333333334
avg_envstep_per_sec: 701.985462029196
avg_train_sample_per_sec: 701.985462029196
avg_episode_per_sec: 3.027974674460946
collect_time: 1.9815225175448825
reward_mean: 1585.8333740234375
reward_std: 402.57025146484375
reward_max: 2347.0
reward_min: 1064.0
total_envstep_count: 2197729
total_train_sample_count: 2197694
total_episode_count: 14260
total_duration: 2784.478636575599
[2024-11-20 00:23:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1260
train_sample_count: 1260
avg_envstep_per_episode: 157.5
avg_sample_per_episode: 157.5
avg_envstep_per_sec: 709.2338821275359
avg_train_sample_per_sec: 709.2338821275359
avg_episode_per_sec: 4.503072267476418
collect_time: 1.7765648705618722
reward_mean: 1167.625
reward_std: 797.1384887695312
reward_max: 2618.0
reward_min: 593.0
total_envstep_count: 2198754
total_train_sample_count: 2198714
total_episode_count: 14268
total_duration: 2786.2552014461608
[2024-11-20 00:23:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 712
train_sample_count: 712
avg_envstep_per_episode: 142.4
avg_sample_per_episode: 142.4
avg_envstep_per_sec: 705.3911283937648
avg_train_sample_per_sec: 705.3911283937648
avg_episode_per_sec: 4.953589384787675
collect_time: 1.0093690880707333
reward_mean: 1114.800048828125
reward_std: 434.9820251464844
reward_max: 1705.0
reward_min: 606.0
total_envstep_count: 2199749
total_train_sample_count: 2199714
total_episode_count: 14273
total_duration: 2787.2645705342316
[2024-11-20 00:23:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 576
train_sample_count: 576
avg_envstep_per_episode: 144.0
avg_sample_per_episode: 144.0
avg_envstep_per_sec: 713.426609490927
avg_train_sample_per_sec: 713.426609490927
avg_episode_per_sec: 4.954351454798105
collect_time: 0.8073710628918239
reward_mean: 795.5
reward_std: 409.71728515625
reward_max: 1300.0
reward_min: 220.0
total_envstep_count: 2200737
total_train_sample_count: 2200710
total_episode_count: 14277
total_duration: 2788.0719415971234
[2024-11-20 00:23:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1479
train_sample_count: 1479
avg_envstep_per_episode: 246.5
avg_sample_per_episode: 246.5
avg_envstep_per_sec: 707.0538704129378
avg_train_sample_per_sec: 707.0538704129378
avg_episode_per_sec: 2.8683726994439667
collect_time: 2.0917783805302212
reward_mean: 1172.6666259765625
reward_std: 378.3502197265625
reward_max: 1674.0
reward_min: 643.0
total_envstep_count: 2201716
total_train_sample_count: 2201685
total_episode_count: 14283
total_duration: 2790.1637199776537
[2024-11-20 00:23:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 498
train_sample_count: 498
avg_envstep_per_episode: 124.5
avg_sample_per_episode: 124.5
avg_envstep_per_sec: 699.8289319140157
avg_train_sample_per_sec: 699.8289319140157
avg_episode_per_sec: 5.621115918988078
collect_time: 0.711602474961962
reward_mean: 653.5
reward_std: 55.5
reward_max: 749.0
reward_min: 616.0
total_envstep_count: 2202696
total_train_sample_count: 2202663
total_episode_count: 14287
total_duration: 2790.875322452616
[2024-11-20 00:23:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 648
train_sample_count: 648
avg_envstep_per_episode: 81.0
avg_sample_per_episode: 81.0
avg_envstep_per_sec: 708.6590295974132
avg_train_sample_per_sec: 708.6590295974132
avg_episode_per_sec: 8.74887690861004
collect_time: 0.9144030809402465
reward_mean: 666.125
reward_std: 33.986900329589844
reward_max: 756.0
reward_min: 651.0
total_envstep_count: 2203688
total_train_sample_count: 2203659
total_episode_count: 14295
total_duration: 2791.789725533556
[2024-11-20 00:23:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1460
train_sample_count: 1460
avg_envstep_per_episode: 243.33333333333334
avg_sample_per_episode: 243.33333333333334
avg_envstep_per_sec: 696.6109167217769
avg_train_sample_per_sec: 696.6109167217769
avg_episode_per_sec: 2.862784589267576
collect_time: 2.095861498798643
reward_mean: 1257.8333740234375
reward_std: 654.4033813476562
reward_max: 2303.0
reward_min: 613.0
total_envstep_count: 2204699
total_train_sample_count: 2204663
total_episode_count: 14301
total_duration: 2793.8855870323546
[2024-11-20 00:23:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1331
train_sample_count: 1331
avg_envstep_per_episode: 221.83333333333334
avg_sample_per_episode: 221.83333333333334
avg_envstep_per_sec: 689.357050204766
avg_train_sample_per_sec: 689.357050204766
avg_episode_per_sec: 3.107544929548156
collect_time: 1.9307846341814319
reward_mean: 1477.3333740234375
reward_std: 142.63433837890625
reward_max: 1704.0
reward_min: 1332.0
total_envstep_count: 2205693
total_train_sample_count: 2205658
total_episode_count: 14307
total_duration: 2795.816371666536
[2024-11-20 00:23:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 739
train_sample_count: 739
avg_envstep_per_episode: 184.75
avg_sample_per_episode: 184.75
avg_envstep_per_sec: 696.5532870432878
avg_train_sample_per_sec: 696.5532870432878
avg_episode_per_sec: 3.770247832439988
collect_time: 1.0609382135527476
reward_mean: 1703.5
reward_std: 7.29725980758667
reward_max: 1709.0
reward_min: 1691.0
total_envstep_count: 2206665
total_train_sample_count: 2206637
total_episode_count: 14311
total_duration: 2796.8773098800884
[2024-11-20 00:23:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1206
train_sample_count: 1206
avg_envstep_per_episode: 150.75
avg_sample_per_episode: 150.75
avg_envstep_per_sec: 703.082370802669
avg_train_sample_per_sec: 703.082370802669
avg_episode_per_sec: 4.663896323732464
collect_time: 1.7153039957795824
reward_mean: 1289.125
reward_std: 617.9462890625
reward_max: 2356.0
reward_min: 233.0
total_envstep_count: 2207668
total_train_sample_count: 2207627
total_episode_count: 14319
total_duration: 2798.592613875868
[2024-11-20 00:23:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 579
train_sample_count: 579
avg_envstep_per_episode: 96.5
avg_sample_per_episode: 96.5
avg_envstep_per_sec: 705.2059103565471
avg_train_sample_per_sec: 705.2059103565471
avg_episode_per_sec: 7.307833267943493
collect_time: 0.8210367943559375
reward_mean: 796.8333129882812
reward_std: 402.6182556152344
reward_max: 1697.0
reward_min: 607.0
total_envstep_count: 2208655
total_train_sample_count: 2208614
total_episode_count: 14325
total_duration: 2799.4136506702243
[2024-11-20 00:23:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 928
train_sample_count: 928
avg_envstep_per_episode: 132.57142857142858
avg_sample_per_episode: 132.57142857142858
avg_envstep_per_sec: 694.3423491187926
avg_train_sample_per_sec: 694.3423491187926
avg_episode_per_sec: 5.237496167921927
collect_time: 1.336516491004399
reward_mean: 1054.5714111328125
reward_std: 591.658447265625
reward_max: 1701.0
reward_min: 238.0
total_envstep_count: 2209666
total_train_sample_count: 2209638
total_episode_count: 14332
total_duration: 2800.7501671612285
[2024-11-20 00:23:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 725
train_sample_count: 725
avg_envstep_per_episode: 103.57142857142857
avg_sample_per_episode: 103.57142857142857
avg_envstep_per_sec: 712.0685453809938
avg_train_sample_per_sec: 712.0685453809938
avg_episode_per_sec: 6.875144576092354
collect_time: 1.0181604070322854
reward_mean: 993.8571166992188
reward_std: 445.64605712890625
reward_max: 1707.0
reward_min: 609.0
total_envstep_count: 2210685
total_train_sample_count: 2210651
total_episode_count: 14339
total_duration: 2801.7683275682607
[2024-11-20 00:23:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 838
train_sample_count: 838
avg_envstep_per_episode: 167.6
avg_sample_per_episode: 167.6
avg_envstep_per_sec: 708.9027297680357
avg_train_sample_per_sec: 708.9027297680357
avg_episode_per_sec: 4.229729891217397
collect_time: 1.1821085810661316
reward_mean: 1051.5999755859375
reward_std: 741.7532348632812
reward_max: 2357.0
reward_min: 239.0
total_envstep_count: 2211696
total_train_sample_count: 2211657
total_episode_count: 14344
total_duration: 2802.950436149327
[2024-11-20 00:24:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 575
train_sample_count: 575
avg_envstep_per_episode: 191.66666666666666
avg_sample_per_episode: 191.66666666666666
avg_envstep_per_sec: 708.7326330864765
avg_train_sample_per_sec: 708.7326330864765
avg_episode_per_sec: 3.697735476972921
collect_time: 0.8113073578902652
reward_mean: 1082.6666259765625
reward_std: 415.849609375
reward_max: 1670.0
reward_min: 763.0
total_envstep_count: 2212686
total_train_sample_count: 2212664
total_episode_count: 14347
total_duration: 2803.761743507217
[2024-11-20 00:24:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 993
train_sample_count: 993
avg_envstep_per_episode: 198.6
avg_sample_per_episode: 198.6
avg_envstep_per_sec: 706.2128744075524
avg_train_sample_per_sec: 706.2128744075524
avg_episode_per_sec: 3.555956064489186
collect_time: 1.4060916134289334
reward_mean: 1508.0
reward_std: 518.8514404296875
reward_max: 2338.0
reward_min: 748.0
total_envstep_count: 2213690
total_train_sample_count: 2213657
total_episode_count: 14352
total_duration: 2805.167835120646
[2024-11-20 00:24:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1089
train_sample_count: 1089
avg_envstep_per_episode: 272.25
avg_sample_per_episode: 272.25
avg_envstep_per_sec: 705.5833560941518
avg_train_sample_per_sec: 705.5833560941518
avg_episode_per_sec: 2.591674402549685
collect_time: 1.5434037532125202
reward_mean: 1459.25
reward_std: 863.2503662109375
reward_max: 2323.0
reward_min: 595.0
total_envstep_count: 2214654
total_train_sample_count: 2214626
total_episode_count: 14356
total_duration: 2806.7112388738587
[2024-11-20 00:24:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1299
train_sample_count: 1299
avg_envstep_per_episode: 129.9
avg_sample_per_episode: 129.9
avg_envstep_per_sec: 697.0679651983501
avg_train_sample_per_sec: 697.0679651983501
avg_episode_per_sec: 5.366189108532333
collect_time: 1.8635198644229343
reward_mean: 1093.800048828125
reward_std: 510.34808349609375
reward_max: 1708.0
reward_min: 235.0
total_envstep_count: 2215685
total_train_sample_count: 2215649
total_episode_count: 14366
total_duration: 2808.5747587382816
[2024-11-20 00:24:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 511
train_sample_count: 511
avg_envstep_per_episode: 127.75
avg_sample_per_episode: 127.75
avg_envstep_per_sec: 699.6889102934975
avg_train_sample_per_sec: 699.6889102934975
avg_episode_per_sec: 5.47701691032092
collect_time: 0.7303245663642883
reward_mean: 926.0
reward_std: 337.1735534667969
reward_max: 1432.0
reward_min: 610.0
total_envstep_count: 2216657
total_train_sample_count: 2216628
total_episode_count: 14370
total_duration: 2809.305083304646
[2024-11-20 00:24:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 679
train_sample_count: 679
avg_envstep_per_episode: 169.75
avg_sample_per_episode: 169.75
avg_envstep_per_sec: 704.3172054859278
avg_train_sample_per_sec: 704.3172054859278
avg_episode_per_sec: 4.149144067663787
collect_time: 0.9640542566776276
reward_mean: 1048.75
reward_std: 394.5829162597656
reward_max: 1694.0
reward_min: 724.0
total_envstep_count: 2217646
total_train_sample_count: 2217607
total_episode_count: 14374
total_duration: 2810.2691375613235
[2024-11-20 00:24:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1096
train_sample_count: 1096
avg_envstep_per_episode: 137.0
avg_sample_per_episode: 137.0
avg_envstep_per_sec: 704.8179568847983
avg_train_sample_per_sec: 704.8179568847983
avg_episode_per_sec: 5.144656619597068
collect_time: 1.5550114597593034
reward_mean: 1038.125
reward_std: 641.426025390625
reward_max: 1865.0
reward_min: 248.0
total_envstep_count: 2218670
total_train_sample_count: 2218619
total_episode_count: 14382
total_duration: 2811.824149021083
[2024-11-20 00:24:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1047
train_sample_count: 1047
avg_envstep_per_episode: 130.875
avg_sample_per_episode: 130.875
avg_envstep_per_sec: 705.5534239296728
avg_train_sample_per_sec: 705.5534239296728
avg_episode_per_sec: 5.391048129357576
collect_time: 1.483941491161074
reward_mean: 1223.0
reward_std: 394.2803649902344
reward_max: 1699.0
reward_min: 613.0
total_envstep_count: 2219670
total_train_sample_count: 2219630
total_episode_count: 14390
total_duration: 2813.3080905122442
[2024-11-20 00:24:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2703
train_sample_count: 2703
avg_envstep_per_episode: 450.5
avg_sample_per_episode: 450.5
avg_envstep_per_sec: 700.319496080293
avg_train_sample_per_sec: 700.319496080293
avg_episode_per_sec: 1.554538282087221
collect_time: 3.859666930777686
reward_mean: 1130.1666259765625
reward_std: 441.8768310546875
reward_max: 1706.0
reward_min: 510.0
total_envstep_count: 2220666
total_train_sample_count: 2220629
total_episode_count: 14396
total_duration: 2817.167757443022
[2024-11-20 00:24:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 932
train_sample_count: 932
avg_envstep_per_episode: 155.33333333333334
avg_sample_per_episode: 155.33333333333334
avg_envstep_per_sec: 680.7856383510433
avg_train_sample_per_sec: 680.7856383510433
avg_episode_per_sec: 4.382740161058218
collect_time: 1.3690065528665272
reward_mean: 1509.0
reward_std: 137.90576171875
reward_max: 1706.0
reward_min: 1343.0
total_envstep_count: 2221628
total_train_sample_count: 2221597
total_episode_count: 14402
total_duration: 2818.5367639958886
[2024-11-20 00:24:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 575
train_sample_count: 575
avg_envstep_per_episode: 115.0
avg_sample_per_episode: 115.0
avg_envstep_per_sec: 684.6459983585115
avg_train_sample_per_sec: 684.6459983585115
avg_episode_per_sec: 5.953443463987057
collect_time: 0.8398500851222446
reward_mean: 891.5999755859375
reward_std: 489.1595458984375
reward_max: 1865.0
reward_min: 585.0
total_envstep_count: 2222640
total_train_sample_count: 2222592
total_episode_count: 14407
total_duration: 2819.3766140810108
[2024-11-20 00:24:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1066
train_sample_count: 1066
avg_envstep_per_episode: 152.28571428571428
avg_sample_per_episode: 152.28571428571428
avg_envstep_per_sec: 684.6625756166848
avg_train_sample_per_sec: 684.6625756166848
avg_episode_per_sec: 4.495908095043896
collect_time: 1.5569713285991125
reward_mean: 1158.5714111328125
reward_std: 603.2142333984375
reward_max: 2355.0
reward_min: 604.0
total_envstep_count: 2223666
total_train_sample_count: 2223622
total_episode_count: 14414
total_duration: 2820.93358540961
[2024-11-20 00:24:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 686
train_sample_count: 686
avg_envstep_per_episode: 171.5
avg_sample_per_episode: 171.5
avg_envstep_per_sec: 697.7330664735576
avg_train_sample_per_sec: 697.7330664735576
avg_episode_per_sec: 4.068414381770015
collect_time: 0.9831840183053697
reward_mean: 1277.0
reward_std: 324.3123474121094
reward_max: 1688.0
reward_min: 779.0
total_envstep_count: 2224654
total_train_sample_count: 2224620
total_episode_count: 14418
total_duration: 2821.9167694279154
[2024-11-20 00:24:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 912
train_sample_count: 912
avg_envstep_per_episode: 182.4
avg_sample_per_episode: 182.4
avg_envstep_per_sec: 674.2756380238759
avg_train_sample_per_sec: 674.2756380238759
avg_episode_per_sec: 3.696686611973004
collect_time: 1.352562585047313
reward_mean: 1575.199951171875
reward_std: 398.10272216796875
reward_max: 2365.0
reward_min: 1317.0
total_envstep_count: 2225642
total_train_sample_count: 2225592
total_episode_count: 14423
total_duration: 2823.269332012963
[2024-11-20 00:24:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 887
train_sample_count: 887
avg_envstep_per_episode: 221.75
avg_sample_per_episode: 221.75
avg_envstep_per_sec: 662.952294503826
avg_train_sample_per_sec: 662.952294503826
avg_episode_per_sec: 2.9896383066688883
collect_time: 1.3379544913768768
reward_mean: 1594.25
reward_std: 479.5640563964844
reward_max: 2323.0
reward_min: 1045.0
total_envstep_count: 2226607
total_train_sample_count: 2226563
total_episode_count: 14427
total_duration: 2824.6072865043398
[2024-11-20 00:25:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 460
train_sample_count: 460
avg_envstep_per_episode: 115.0
avg_sample_per_episode: 115.0
avg_envstep_per_sec: 664.7332819845158
avg_train_sample_per_sec: 664.7332819845158
avg_episode_per_sec: 5.780289408561006
collect_time: 0.6920068732329777
reward_mean: 844.5
reward_std: 420.3513488769531
reward_max: 1572.0
reward_min: 586.0
total_envstep_count: 2227579
total_train_sample_count: 2227551
total_episode_count: 14431
total_duration: 2825.2992933775727
[2024-11-20 00:25:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 552
train_sample_count: 552
avg_envstep_per_episode: 138.0
avg_sample_per_episode: 138.0
avg_envstep_per_sec: 666.8339700523823
avg_train_sample_per_sec: 666.8339700523823
avg_episode_per_sec: 4.832130217770886
collect_time: 0.827792261328016
reward_mean: 1074.5
reward_std: 448.9724426269531
reward_max: 1696.0
reward_min: 645.0
total_envstep_count: 2228591
total_train_sample_count: 2228547
total_episode_count: 14435
total_duration: 2826.1270856389006
[2024-11-20 00:25:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1057
train_sample_count: 1057
avg_envstep_per_episode: 264.25
avg_sample_per_episode: 264.25
avg_envstep_per_sec: 669.1007749667029
avg_train_sample_per_sec: 669.1007749667029
avg_episode_per_sec: 2.5320748343110804
collect_time: 1.579732141324452
reward_mean: 1636.5
reward_std: 906.7062377929688
reward_max: 3025.0
reward_min: 652.0
total_envstep_count: 2229587
total_train_sample_count: 2229544
total_episode_count: 14439
total_duration: 2827.706817780225
[2024-11-20 00:25:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1230
train_sample_count: 1230
avg_envstep_per_episode: 246.0
avg_sample_per_episode: 246.0
avg_envstep_per_sec: 654.6260894177593
avg_train_sample_per_sec: 654.6260894177593
avg_episode_per_sec: 2.6610816642998345
collect_time: 1.8789351965699879
reward_mean: 1417.4000244140625
reward_std: 700.128173828125
reward_max: 2300.0
reward_min: 237.0
total_envstep_count: 2230575
total_train_sample_count: 2230546
total_episode_count: 14444
total_duration: 2829.585752976795
[2024-11-20 00:25:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 758
train_sample_count: 758
avg_envstep_per_episode: 151.6
avg_sample_per_episode: 151.6
avg_envstep_per_sec: 661.453916709937
avg_train_sample_per_sec: 661.453916709937
avg_episode_per_sec: 4.3631524848940435
collect_time: 1.1459604075976781
reward_mean: 1110.0
reward_std: 519.8153686523438
reward_max: 1923.0
reward_min: 561.0
total_envstep_count: 2231562
total_train_sample_count: 2231520
total_episode_count: 14449
total_duration: 2830.7317133843926
[2024-11-20 00:25:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 681
train_sample_count: 681
avg_envstep_per_episode: 85.125
avg_sample_per_episode: 85.125
avg_envstep_per_sec: 677.1990265629888
avg_train_sample_per_sec: 677.1990265629888
avg_episode_per_sec: 7.955348329668004
collect_time: 1.0056127863270896
reward_mean: 373.5
reward_std: 400.11810302734375
reward_max: 1431.0
reward_min: 178.0
total_envstep_count: 2232581
total_train_sample_count: 2232549
total_episode_count: 14457
total_duration: 2831.73732617072
[2024-11-20 00:25:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 678
train_sample_count: 678
avg_envstep_per_episode: 135.6
avg_sample_per_episode: 135.6
avg_envstep_per_sec: 677.1387851597227
avg_train_sample_per_sec: 677.1387851597227
avg_episode_per_sec: 4.993648858110049
collect_time: 1.0012718439102173
reward_mean: 834.5999755859375
reward_std: 409.1697082519531
reward_max: 1324.0
reward_min: 232.0
total_envstep_count: 2233576
total_train_sample_count: 2233539
total_episode_count: 14462
total_duration: 2832.73859801463
[2024-11-20 00:25:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 989
train_sample_count: 989
avg_envstep_per_episode: 197.8
avg_sample_per_episode: 197.8
avg_envstep_per_sec: 681.7940974502459
avg_train_sample_per_sec: 681.7940974502459
avg_episode_per_sec: 3.44688623584553
collect_time: 1.4505845734051293
reward_mean: 1387.800048828125
reward_std: 495.5152282714844
reward_max: 1921.0
reward_min: 592.0
total_envstep_count: 2234565
total_train_sample_count: 2234528
total_episode_count: 14467
total_duration: 2834.1891825880352
[2024-11-20 00:25:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 2486
train_sample_count: 2486
avg_envstep_per_episode: 621.5
avg_sample_per_episode: 621.5
avg_envstep_per_sec: 677.3163753003765
avg_train_sample_per_sec: 677.3163753003765
avg_episode_per_sec: 1.0898091316176615
collect_time: 3.670367483581816
reward_mean: 1658.5
reward_std: 582.7754516601562
reward_max: 2583.0
reward_min: 1038.0
total_envstep_count: 2235569
total_train_sample_count: 2235526
total_episode_count: 14471
total_duration: 2837.859550071617
[2024-11-20 00:25:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 771
train_sample_count: 771
avg_envstep_per_episode: 128.5
avg_sample_per_episode: 128.5
avg_envstep_per_sec: 678.4103227574462
avg_train_sample_per_sec: 678.4103227574462
avg_episode_per_sec: 5.279457764649387
collect_time: 1.1364803484507968
reward_mean: 1035.8333740234375
reward_std: 387.698974609375
reward_max: 1581.0
reward_min: 609.0
total_envstep_count: 2236548
total_train_sample_count: 2236501
total_episode_count: 14477
total_duration: 2838.9960304200677
[2024-11-20 00:25:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 957
train_sample_count: 957
avg_envstep_per_episode: 119.625
avg_sample_per_episode: 119.625
avg_envstep_per_sec: 664.863382915638
avg_train_sample_per_sec: 664.863382915638
avg_episode_per_sec: 5.557896617894571
collect_time: 1.4393934522356304
reward_mean: 929.875
reward_std: 412.7984924316406
reward_max: 1336.0
reward_min: 238.0
total_envstep_count: 2237534
total_train_sample_count: 2237482
total_episode_count: 14485
total_duration: 2840.435423872303
[2024-11-20 00:25:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 276
train_sample_count: 276
avg_envstep_per_episode: 138.0
avg_sample_per_episode: 138.0
avg_envstep_per_sec: 680.4491406925179
avg_train_sample_per_sec: 680.4491406925179
avg_episode_per_sec: 4.9307908745834625
collect_time: 0.40561444418770926
reward_mean: 976.0
reward_std: 344.0
reward_max: 1320.0
reward_min: 632.0
total_envstep_count: 2238509
total_train_sample_count: 2238502
total_episode_count: 14487
total_duration: 2840.841038316491
[2024-11-20 00:25:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 651
train_sample_count: 651
avg_envstep_per_episode: 325.5
avg_sample_per_episode: 325.5
avg_envstep_per_sec: 678.7790924233001
avg_train_sample_per_sec: 678.7790924233001
avg_episode_per_sec: 2.0853428338657456
collect_time: 0.9590749144554138
reward_mean: 1446.0
reward_std: 837.0
reward_max: 2283.0
reward_min: 609.0
total_envstep_count: 2239469
total_train_sample_count: 2239465
total_episode_count: 14489
total_duration: 2841.8001132309464
[2024-11-20 00:25:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 373
train_sample_count: 373
avg_envstep_per_episode: 186.5
avg_sample_per_episode: 186.5
avg_envstep_per_sec: 646.7305052441935
avg_train_sample_per_sec: 646.7305052441935
avg_episode_per_sec: 3.4677238887088127
collect_time: 0.5767471875463213
reward_mean: 1694.0
reward_std: 2.0
reward_max: 1696.0
reward_min: 1692.0
total_envstep_count: 2240507
total_train_sample_count: 2240438
total_episode_count: 14491
total_duration: 2842.376860418493
[2024-11-20 00:26:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1584
train_sample_count: 1584
avg_envstep_per_episode: 198.0
avg_sample_per_episode: 198.0
avg_envstep_per_sec: 658.584882138267
avg_train_sample_per_sec: 658.584882138267
avg_episode_per_sec: 3.3261862734255905
collect_time: 2.4051569402217865
reward_mean: 1081.875
reward_std: 826.51611328125
reward_max: 2609.0
reward_min: 233.0
total_envstep_count: 2241525
total_train_sample_count: 2241482
total_episode_count: 14499
total_duration: 2844.7820173587147
[2024-11-20 00:26:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 812
train_sample_count: 812
avg_envstep_per_episode: 270.6666666666667
avg_sample_per_episode: 270.6666666666667
avg_envstep_per_sec: 665.6573468349316
avg_train_sample_per_sec: 665.6573468349316
avg_episode_per_sec: 2.4593251730354613
collect_time: 1.2198468233857835
reward_mean: 1186.3333740234375
reward_std: 413.3685302734375
reward_max: 1620.0
reward_min: 630.0
total_envstep_count: 2242490
total_train_sample_count: 2242462
total_episode_count: 14502
total_duration: 2846.0018641821007
[2024-11-20 00:26:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1438
train_sample_count: 1438
avg_envstep_per_episode: 239.66666666666666
avg_sample_per_episode: 239.66666666666666
avg_envstep_per_sec: 673.5036463661846
avg_train_sample_per_sec: 673.5036463661846
avg_episode_per_sec: 2.8101682045876966
collect_time: 2.1351035109588077
reward_mean: 1458.1666259765625
reward_std: 808.0580444335938
reward_max: 2984.0
reward_min: 600.0
total_envstep_count: 2243486
total_train_sample_count: 2243456
total_episode_count: 14508
total_duration: 2848.1369676930594
[2024-11-20 00:26:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 322
train_sample_count: 322
avg_envstep_per_episode: 107.33333333333333
avg_sample_per_episode: 107.33333333333333
avg_envstep_per_sec: 697.5682824863565
avg_train_sample_per_sec: 697.5682824863565
avg_episode_per_sec: 6.499083377202078
collect_time: 0.4616035563605172
reward_mean: 902.6666870117188
reward_std: 380.2686462402344
reward_max: 1440.0
reward_min: 615.0
total_envstep_count: 2244445
total_train_sample_count: 2244426
total_episode_count: 14511
total_duration: 2848.59857124942
[2024-11-20 00:26:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 459.14285714285717
avg_sample_per_episode: 459.14285714285717
avg_envstep_per_sec: 677.0183627160168
avg_train_sample_per_sec: 677.0183627160168
avg_episode_per_sec: 1.4745266145028368
collect_time: 4.747286302702767
reward_mean: 1274.5714111328125
reward_std: 665.1981201171875
reward_max: 2331.0
reward_min: 506.0
total_envstep_count: 2245470
total_train_sample_count: 2245432
total_episode_count: 14518
total_duration: 2853.3458575521227
[2024-11-20 00:26:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 945
train_sample_count: 945
avg_envstep_per_episode: 157.5
avg_sample_per_episode: 157.5
avg_envstep_per_sec: 693.1684343553275
avg_train_sample_per_sec: 693.1684343553275
avg_episode_per_sec: 4.401069424478269
collect_time: 1.3633050109658922
reward_mean: 992.0
reward_std: 299.6269836425781
reward_max: 1343.0
reward_min: 601.0
total_envstep_count: 2246441
total_train_sample_count: 2246401
total_episode_count: 14524
total_duration: 2854.7091625630887
[2024-11-20 00:26:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1152
train_sample_count: 1152
avg_envstep_per_episode: 288.0
avg_sample_per_episode: 288.0
avg_envstep_per_sec: 575.7058197264364
avg_train_sample_per_sec: 575.7058197264364
avg_episode_per_sec: 1.9989785407167933
collect_time: 2.001021981239319
reward_mean: 1150.75
reward_std: 662.0899658203125
reward_max: 2265.0
reward_min: 651.0
total_envstep_count: 2247405
total_train_sample_count: 2247373
total_episode_count: 14528
total_duration: 2856.710184544328
[2024-11-20 00:26:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 585
train_sample_count: 585
avg_envstep_per_episode: 146.25
avg_sample_per_episode: 146.25
avg_envstep_per_sec: 695.5502998744247
avg_train_sample_per_sec: 695.5502998744247
avg_episode_per_sec: 4.755899486320852
collect_time: 0.8410606682300568
reward_mean: 1059.25
reward_std: 465.64544677734375
reward_max: 1686.0
reward_min: 586.0
total_envstep_count: 2248409
total_train_sample_count: 2248354
total_episode_count: 14532
total_duration: 2857.551245212558
[2024-11-20 00:26:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1155
train_sample_count: 1155
avg_envstep_per_episode: 192.5
avg_sample_per_episode: 192.5
avg_envstep_per_sec: 693.9319724565513
avg_train_sample_per_sec: 693.9319724565513
avg_episode_per_sec: 3.604841415358708
collect_time: 1.6644282809325626
reward_mean: 1216.3333740234375
reward_std: 326.9483337402344
reward_max: 1677.0
reward_min: 620.0
total_envstep_count: 2249396
total_train_sample_count: 2249353
total_episode_count: 14538
total_duration: 2859.2156734934906
[2024-11-20 00:27:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 872
train_sample_count: 872
avg_envstep_per_episode: 145.33333333333334
avg_sample_per_episode: 145.33333333333334
avg_envstep_per_sec: 699.785786629408
avg_train_sample_per_sec: 699.785786629408
avg_episode_per_sec: 4.815039816257395
collect_time: 1.2460956147738866
reward_mean: 853.0
reward_std: 285.7265625
reward_max: 1420.0
reward_min: 646.0
total_envstep_count: 2250366
total_train_sample_count: 2250333
total_episode_count: 14544
total_duration: 2860.4617691082644
[2024-11-20 00:27:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1370
train_sample_count: 1370
avg_envstep_per_episode: 342.5
avg_sample_per_episode: 342.5
avg_envstep_per_sec: 697.2249602672433
avg_train_sample_per_sec: 697.2249602672433
avg_episode_per_sec: 2.035693314648886
collect_time: 1.9649325226034433
reward_mean: 1398.25
reward_std: 623.7805786132812
reward_max: 2248.0
reward_min: 614.0
total_envstep_count: 2251355
total_train_sample_count: 2251319
total_episode_count: 14548
total_duration: 2862.4267016308677
[2024-11-20 00:27:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1463
train_sample_count: 1463
avg_envstep_per_episode: 162.55555555555554
avg_sample_per_episode: 162.55555555555554
avg_envstep_per_sec: 697.2683350533234
avg_train_sample_per_sec: 697.2683350533234
avg_episode_per_sec: 4.289415594996521
collect_time: 2.0981879234313965
reward_mean: 988.0
reward_std: 541.76416015625
reward_max: 1864.0
reward_min: 229.0
total_envstep_count: 2252388
total_train_sample_count: 2252350
total_episode_count: 14557
total_duration: 2864.524889554299
[2024-11-20 00:27:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 449
train_sample_count: 449
avg_envstep_per_episode: 149.66666666666666
avg_sample_per_episode: 149.66666666666666
avg_envstep_per_sec: 707.0695725722528
avg_train_sample_per_sec: 707.0695725722528
avg_episode_per_sec: 4.724295585115275
collect_time: 0.6350153045994895
reward_mean: 1251.3333740234375
reward_std: 392.9175720214844
reward_max: 1689.0
reward_min: 736.0
total_envstep_count: 2253377
total_train_sample_count: 2253327
total_episode_count: 14560
total_duration: 2865.1599048588987
[2024-11-20 00:27:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1175
train_sample_count: 1175
avg_envstep_per_episode: 146.875
avg_sample_per_episode: 146.875
avg_envstep_per_sec: 695.9071949932743
avg_train_sample_per_sec: 695.9071949932743
avg_episode_per_sec: 4.73809154037974
collect_time: 1.6884435287543706
reward_mean: 1212.625
reward_std: 489.8736877441406
reward_max: 1919.0
reward_min: 608.0
total_envstep_count: 2254378
total_train_sample_count: 2254334
total_episode_count: 14568
total_duration: 2866.848348387653
[2024-11-20 00:27:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 867
train_sample_count: 867
avg_envstep_per_episode: 216.75
avg_sample_per_episode: 216.75
avg_envstep_per_sec: 702.8652436798124
avg_train_sample_per_sec: 702.8652436798124
avg_episode_per_sec: 3.242746222282871
collect_time: 1.233522368328912
reward_mean: 1552.5
reward_std: 642.4634399414062
reward_max: 2340.0
reward_min: 629.0
total_envstep_count: 2255343
total_train_sample_count: 2255321
total_episode_count: 14572
total_duration: 2868.081870755982
[2024-11-20 00:27:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 601
train_sample_count: 601
avg_envstep_per_episode: 150.25
avg_sample_per_episode: 150.25
avg_envstep_per_sec: 697.9461279324439
avg_train_sample_per_sec: 697.9461279324439
avg_episode_per_sec: 4.645232132661857
collect_time: 0.8610979786940983
reward_mean: 1155.0
reward_std: 539.5377807617188
reward_max: 1696.0
reward_min: 582.0
total_envstep_count: 2256339
total_train_sample_count: 2256294
total_episode_count: 14576
total_duration: 2868.942968734676
[2024-11-20 00:27:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 775
train_sample_count: 775
avg_envstep_per_episode: 155.0
avg_sample_per_episode: 155.0
avg_envstep_per_sec: 690.9744778943848
avg_train_sample_per_sec: 690.9744778943848
avg_episode_per_sec: 4.457899857383128
collect_time: 1.1216043787343162
reward_mean: 1187.199951171875
reward_std: 489.7094421386719
reward_max: 1690.0
reward_min: 604.0
total_envstep_count: 2257326
total_train_sample_count: 2257285
total_episode_count: 14581
total_duration: 2870.0645731134105
[2024-11-20 00:27:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 629
train_sample_count: 629
avg_envstep_per_episode: 157.25
avg_sample_per_episode: 157.25
avg_envstep_per_sec: 714.5990454023728
avg_train_sample_per_sec: 714.5990454023728
avg_episode_per_sec: 4.544350050253564
collect_time: 0.8802138822419303
reward_mean: 1174.25
reward_std: 320.7486267089844
reward_max: 1436.0
reward_min: 625.0
total_envstep_count: 2258300
total_train_sample_count: 2258274
total_episode_count: 14585
total_duration: 2870.9447869956525
[2024-11-20 00:27:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 595
train_sample_count: 595
avg_envstep_per_episode: 297.5
avg_sample_per_episode: 297.5
avg_envstep_per_sec: 724.3824424231526
avg_train_sample_per_sec: 724.3824424231526
avg_episode_per_sec: 2.434898966128244
collect_time: 0.8213893175125122
reward_mean: 2014.0
reward_std: 324.0
reward_max: 2338.0
reward_min: 1690.0
total_envstep_count: 2259266
total_train_sample_count: 2259241
total_episode_count: 14587
total_duration: 2871.766176313165
[2024-11-20 00:27:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1354
train_sample_count: 1354
avg_envstep_per_episode: 451.3333333333333
avg_sample_per_episode: 451.3333333333333
avg_envstep_per_sec: 727.7757321724104
avg_train_sample_per_sec: 727.7757321724104
avg_episode_per_sec: 1.6125016222431545
collect_time: 1.8604632445744107
reward_mean: 1741.3333740234375
reward_std: 368.474609375
reward_max: 2214.0
reward_min: 1315.0
total_envstep_count: 2260263
total_train_sample_count: 2260223
total_episode_count: 14590
total_duration: 2873.6266395577395
[2024-11-20 00:27:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2186
train_sample_count: 2186
avg_envstep_per_episode: 273.25
avg_sample_per_episode: 273.25
avg_envstep_per_sec: 761.0371574387159
avg_train_sample_per_sec: 761.0371574387159
avg_episode_per_sec: 2.7851314087418695
collect_time: 2.8723958858421867
reward_mean: 1585.625
reward_std: 740.812744140625
reward_max: 2968.0
reward_min: 604.0
total_envstep_count: 2261256
total_train_sample_count: 2261221
total_episode_count: 14598
total_duration: 2876.4990354435818
[2024-11-20 00:27:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 801
train_sample_count: 801
avg_envstep_per_episode: 160.2
avg_sample_per_episode: 160.2
avg_envstep_per_sec: 786.236686413035
avg_train_sample_per_sec: 786.236686413035
avg_episode_per_sec: 4.907844484475874
collect_time: 1.0187771873814717
reward_mean: 1056.0
reward_std: 505.0627746582031
reward_max: 1920.0
reward_min: 610.0
total_envstep_count: 2262252
total_train_sample_count: 2262202
total_episode_count: 14603
total_duration: 2877.5178126309634
[2024-11-20 00:27:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 652
train_sample_count: 652
avg_envstep_per_episode: 163.0
avg_sample_per_episode: 163.0
avg_envstep_per_sec: 787.5157440769086
avg_train_sample_per_sec: 787.5157440769086
avg_episode_per_sec: 4.83138493298717
collect_time: 0.8279199557644981
reward_mean: 1323.0
reward_std: 462.9811096191406
reward_max: 1853.0
reward_min: 579.0
total_envstep_count: 2263209
total_train_sample_count: 2263178
total_episode_count: 14607
total_duration: 2878.345732586728
[2024-11-20 00:27:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1081
train_sample_count: 1081
avg_envstep_per_episode: 216.2
avg_sample_per_episode: 216.2
avg_envstep_per_sec: 788.029096145294
avg_train_sample_per_sec: 788.029096145294
avg_episode_per_sec: 3.6449079377673175
collect_time: 1.371776759624481
reward_mean: 1175.4000244140625
reward_std: 691.6264038085938
reward_max: 2280.0
reward_min: 612.0
total_envstep_count: 2264181
total_train_sample_count: 2264151
total_episode_count: 14612
total_duration: 2879.7175093463525
[2024-11-20 00:27:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 900
train_sample_count: 900
avg_envstep_per_episode: 180.0
avg_sample_per_episode: 180.0
avg_envstep_per_sec: 789.4345974574985
avg_train_sample_per_sec: 789.4345974574985
avg_episode_per_sec: 4.385747763652769
collect_time: 1.1400564440659116
reward_mean: 1188.800048828125
reward_std: 496.9122009277344
reward_max: 1701.0
reward_min: 587.0
total_envstep_count: 2265192
total_train_sample_count: 2265159
total_episode_count: 14617
total_duration: 2880.8575657904184
[2024-11-20 00:28:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 732
train_sample_count: 732
avg_envstep_per_episode: 146.4
avg_sample_per_episode: 146.4
avg_envstep_per_sec: 784.4514524064709
avg_train_sample_per_sec: 784.4514524064709
avg_episode_per_sec: 5.358274948131632
collect_time: 0.9331361395972115
reward_mean: 1013.0
reward_std: 494.6053161621094
reward_max: 1848.0
reward_min: 608.0
total_envstep_count: 2266196
total_train_sample_count: 2266167
total_episode_count: 14622
total_duration: 2881.7907019300155
[2024-11-20 00:28:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 979
train_sample_count: 979
avg_envstep_per_episode: 244.75
avg_sample_per_episode: 244.75
avg_envstep_per_sec: 791.3187984485854
avg_train_sample_per_sec: 791.3187984485854
avg_episode_per_sec: 3.233171801628541
collect_time: 1.2371752091816492
reward_mean: 1325.0
reward_std: 617.55810546875
reward_max: 2305.0
reward_min: 625.0
total_envstep_count: 2267184
total_train_sample_count: 2267158
total_episode_count: 14626
total_duration: 2883.0278771391972
[2024-11-20 00:28:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 955
train_sample_count: 955
avg_envstep_per_episode: 191.0
avg_sample_per_episode: 191.0
avg_envstep_per_sec: 789.2131869757592
avg_train_sample_per_sec: 789.2131869757592
avg_episode_per_sec: 4.132006214532771
collect_time: 1.2100659438541959
reward_mean: 1305.199951171875
reward_std: 409.1417541503906
reward_max: 1925.0
reward_min: 633.0
total_envstep_count: 2268195
total_train_sample_count: 2268137
total_episode_count: 14631
total_duration: 2884.2379430830515
[2024-11-20 00:28:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2044
train_sample_count: 2044
avg_envstep_per_episode: 292.0
avg_sample_per_episode: 292.0
avg_envstep_per_sec: 789.9253782865206
avg_train_sample_per_sec: 789.9253782865206
avg_episode_per_sec: 2.705223898241509
collect_time: 2.5875861900193353
reward_mean: 1318.0
reward_std: 511.9112548828125
reward_max: 2240.0
reward_min: 616.0
total_envstep_count: 2269181
total_train_sample_count: 2269149
total_episode_count: 14638
total_duration: 2886.825529273071
[2024-11-20 00:28:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 728
train_sample_count: 728
avg_envstep_per_episode: 145.6
avg_sample_per_episode: 145.6
avg_envstep_per_sec: 781.0034769792833
avg_train_sample_per_sec: 781.0034769792833
avg_episode_per_sec: 5.364034869363209
collect_time: 0.9321341344288417
reward_mean: 1129.4000244140625
reward_std: 328.7543640136719
reward_max: 1430.0
reward_min: 653.0
total_envstep_count: 2270192
total_train_sample_count: 2270141
total_episode_count: 14643
total_duration: 2887.7576634075
[2024-11-20 00:28:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 815
train_sample_count: 815
avg_envstep_per_episode: 135.83333333333334
avg_sample_per_episode: 135.83333333333334
avg_envstep_per_sec: 789.1522420573885
avg_train_sample_per_sec: 789.1522420573885
avg_episode_per_sec: 5.809709757477707
collect_time: 1.0327538294451577
reward_mean: 1036.1666259765625
reward_std: 436.32611083984375
reward_max: 1708.0
reward_min: 584.0
total_envstep_count: 2271227
total_train_sample_count: 2271172
total_episode_count: 14649
total_duration: 2888.790417236945
[2024-11-20 00:28:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 280
train_sample_count: 280
avg_envstep_per_episode: 140.0
avg_sample_per_episode: 140.0
avg_envstep_per_sec: 788.5466364123836
avg_train_sample_per_sec: 788.5466364123836
avg_episode_per_sec: 5.632475974374168
collect_time: 0.3550836273602077
reward_mean: 964.0
reward_std: 355.0
reward_max: 1319.0
reward_min: 609.0
total_envstep_count: 2272193
total_train_sample_count: 2272136
total_episode_count: 14651
total_duration: 2889.145500864305
[2024-11-20 00:28:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1172
train_sample_count: 1172
avg_envstep_per_episode: 234.4
avg_sample_per_episode: 234.4
avg_envstep_per_sec: 790.2833542397132
avg_train_sample_per_sec: 790.2833542397132
avg_episode_per_sec: 3.371516016381029
collect_time: 1.4830123824732646
reward_mean: 1495.0
reward_std: 236.81723022460938
reward_max: 1856.0
reward_min: 1270.0
total_envstep_count: 2273156
total_train_sample_count: 2273116
total_episode_count: 14656
total_duration: 2890.6285132467783
[2024-11-20 00:28:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1273
train_sample_count: 1273
avg_envstep_per_episode: 212.16666666666666
avg_sample_per_episode: 212.16666666666666
avg_envstep_per_sec: 791.7084576153043
avg_train_sample_per_sec: 791.7084576153043
avg_episode_per_sec: 3.731540255845896
collect_time: 1.6079151204654152
reward_mean: 1387.1666259765625
reward_std: 680.6588745117188
reward_max: 2618.0
reward_min: 623.0
total_envstep_count: 2274159
total_train_sample_count: 2274113
total_episode_count: 14662
total_duration: 2892.2364283672437
[2024-11-20 00:28:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 716
train_sample_count: 716
avg_envstep_per_episode: 143.2
avg_sample_per_episode: 143.2
avg_envstep_per_sec: 798.5066486275264
avg_train_sample_per_sec: 798.5066486275264
avg_episode_per_sec: 5.576163747398927
collect_time: 0.8966738113335201
reward_mean: 1067.800048828125
reward_std: 516.3632202148438
reward_max: 1698.0
reward_min: 571.0
total_envstep_count: 2275146
total_train_sample_count: 2275117
total_episode_count: 14667
total_duration: 2893.1331021785772
[2024-11-20 00:28:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1138
train_sample_count: 1138
avg_envstep_per_episode: 284.5
avg_sample_per_episode: 284.5
avg_envstep_per_sec: 788.0802282217902
avg_train_sample_per_sec: 788.0802282217902
avg_episode_per_sec: 2.7700535262628834
collect_time: 1.4440154177801952
reward_mean: 826.0
reward_std: 222.23074340820312
reward_max: 1196.0
reward_min: 603.0
total_envstep_count: 2276118
total_train_sample_count: 2276099
total_episode_count: 14671
total_duration: 2894.5771175963573
[2024-11-20 00:28:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1397
train_sample_count: 1397
avg_envstep_per_episode: 199.57142857142858
avg_sample_per_episode: 199.57142857142858
avg_envstep_per_sec: 793.4094561601951
avg_train_sample_per_sec: 793.4094561601951
avg_episode_per_sec: 3.9755663515543063
collect_time: 1.7607554197311401
reward_mean: 1233.7142333984375
reward_std: 415.5473937988281
reward_max: 1682.0
reward_min: 606.0
total_envstep_count: 2277113
total_train_sample_count: 2277076
total_episode_count: 14678
total_duration: 2896.3378730160885
[2024-11-20 00:29:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 978
train_sample_count: 978
avg_envstep_per_episode: 139.71428571428572
avg_sample_per_episode: 139.71428571428572
avg_envstep_per_sec: 788.6543969652377
avg_train_sample_per_sec: 788.6543969652377
avg_episode_per_sec: 5.644765622450576
collect_time: 1.2400869173663003
reward_mean: 1092.5714111328125
reward_std: 534.5411376953125
reward_max: 1696.0
reward_min: 247.0
total_envstep_count: 2278122
total_train_sample_count: 2278078
total_episode_count: 14685
total_duration: 2897.5779599334546
[2024-11-20 00:29:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 624
train_sample_count: 624
avg_envstep_per_episode: 104.0
avg_sample_per_episode: 104.0
avg_envstep_per_sec: 798.6004280593822
avg_train_sample_per_sec: 798.6004280593822
avg_episode_per_sec: 7.678850269801752
collect_time: 0.7813669741153716
reward_mean: 786.6666870117188
reward_std: 398.93218994140625
reward_max: 1678.0
reward_min: 578.0
total_envstep_count: 2279117
total_train_sample_count: 2279062
total_episode_count: 14691
total_duration: 2898.35932690757
[2024-11-20 00:29:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 996
train_sample_count: 996
avg_envstep_per_episode: 124.5
avg_sample_per_episode: 124.5
avg_envstep_per_sec: 792.2203012570242
avg_train_sample_per_sec: 792.2203012570242
avg_episode_per_sec: 6.363215271140756
collect_time: 1.257226049900055
reward_mean: 990.125
reward_std: 559.9701538085938
reward_max: 1854.0
reward_min: 235.0
total_envstep_count: 2280102
total_train_sample_count: 2280070
total_episode_count: 14699
total_duration: 2899.61655295747
[2024-11-20 00:29:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 721
train_sample_count: 721
avg_envstep_per_episode: 120.16666666666667
avg_sample_per_episode: 120.16666666666667
avg_envstep_per_sec: 789.8035573149608
avg_train_sample_per_sec: 789.8035573149608
avg_episode_per_sec: 6.5725677446459985
collect_time: 0.9128852273736682
reward_mean: 1015.8333129882812
reward_std: 282.7008972167969
reward_max: 1347.0
reward_min: 654.0
total_envstep_count: 2281121
total_train_sample_count: 2281067
total_episode_count: 14705
total_duration: 2900.529438184844
[2024-11-20 00:29:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 543
train_sample_count: 543
avg_envstep_per_episode: 181.0
avg_sample_per_episode: 181.0
avg_envstep_per_sec: 785.627271700205
avg_train_sample_per_sec: 785.627271700205
avg_episode_per_sec: 4.34048216408953
collect_time: 0.6911674525056566
reward_mean: 1374.3333740234375
reward_std: 449.32269287109375
reward_max: 1702.0
reward_min: 739.0
total_envstep_count: 2282070
total_train_sample_count: 2282030
total_episode_count: 14708
total_duration: 2901.2206056373498
[2024-11-20 00:29:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 886
train_sample_count: 886
avg_envstep_per_episode: 177.2
avg_sample_per_episode: 177.2
avg_envstep_per_sec: 794.8513106377591
avg_train_sample_per_sec: 794.8513106377591
avg_episode_per_sec: 4.4856168771882565
collect_time: 1.1146738869803292
reward_mean: 1326.0
reward_std: 751.0739135742188
reward_max: 2347.0
reward_min: 248.0
total_envstep_count: 2283041
total_train_sample_count: 2283012
total_episode_count: 14713
total_duration: 2902.33527952433
[2024-11-20 00:29:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1316
train_sample_count: 1316
avg_envstep_per_episode: 188.0
avg_sample_per_episode: 188.0
avg_envstep_per_sec: 796.6821758613437
avg_train_sample_per_sec: 796.6821758613437
avg_episode_per_sec: 4.237671148198637
collect_time: 1.651850687605994
reward_mean: 1160.5714111328125
reward_std: 574.2318725585938
reward_max: 2328.0
reward_min: 607.0
total_envstep_count: 2284042
total_train_sample_count: 2284004
total_episode_count: 14720
total_duration: 2903.987130211936
[2024-11-20 00:29:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 838
train_sample_count: 838
avg_envstep_per_episode: 139.66666666666666
avg_sample_per_episode: 139.66666666666666
avg_envstep_per_sec: 792.7123498682187
avg_train_sample_per_sec: 792.7123498682187
avg_episode_per_sec: 5.6757447484598
collect_time: 1.05712999190603
reward_mean: 1166.6666259765625
reward_std: 482.226318359375
reward_max: 1851.0
reward_min: 653.0
total_envstep_count: 2285012
total_train_sample_count: 2284986
total_episode_count: 14726
total_duration: 2905.044260203842
[2024-11-20 00:29:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 582
train_sample_count: 582
avg_envstep_per_episode: 145.5
avg_sample_per_episode: 145.5
avg_envstep_per_sec: 778.6591607148746
avg_train_sample_per_sec: 778.6591607148746
avg_episode_per_sec: 5.351609351992265
collect_time: 0.7474387117794582
reward_mean: 1008.5
reward_std: 323.8784484863281
reward_max: 1331.0
reward_min: 614.0
total_envstep_count: 2285969
total_train_sample_count: 2285952
total_episode_count: 14730
total_duration: 2905.7916989156215
[2024-11-20 00:29:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1050
train_sample_count: 1050
avg_envstep_per_episode: 131.25
avg_sample_per_episode: 131.25
avg_envstep_per_sec: 792.1935059883402
avg_train_sample_per_sec: 792.1935059883402
avg_episode_per_sec: 6.03576004562545
collect_time: 1.3254337381748926
reward_mean: 964.375
reward_std: 517.0507202148438
reward_max: 1689.0
reward_min: 247.0
total_envstep_count: 2286995
total_train_sample_count: 2286966
total_episode_count: 14738
total_duration: 2907.1171326537965
[2024-11-20 00:29:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 951
train_sample_count: 951
avg_envstep_per_episode: 158.5
avg_sample_per_episode: 158.5
avg_envstep_per_sec: 797.5409913511849
avg_train_sample_per_sec: 797.5409913511849
avg_episode_per_sec: 5.031804361837128
collect_time: 1.192415199109486
reward_mean: 1092.1666259765625
reward_std: 368.912109375
reward_max: 1435.0
reward_min: 599.0
total_envstep_count: 2288005
total_train_sample_count: 2287977
total_episode_count: 14744
total_duration: 2908.309547852906
[2024-11-20 00:29:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 659
train_sample_count: 659
avg_envstep_per_episode: 131.8
avg_sample_per_episode: 131.8
avg_envstep_per_sec: 785.6662752968698
avg_train_sample_per_sec: 785.6662752968698
avg_episode_per_sec: 5.961049129718283
collect_time: 0.8387785255908967
reward_mean: 958.5999755859375
reward_std: 389.2601318359375
reward_max: 1440.0
reward_min: 588.0
total_envstep_count: 2289001
total_train_sample_count: 2288960
total_episode_count: 14749
total_duration: 2909.1483263784967
[2024-11-20 00:29:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 3235
train_sample_count: 3235
avg_envstep_per_episode: 359.44444444444446
avg_sample_per_episode: 359.44444444444446
avg_envstep_per_sec: 788.2305416991151
avg_train_sample_per_sec: 788.2305416991151
avg_episode_per_sec: 2.1929134081273682
collect_time: 4.104129222177324
reward_mean: 924.7777709960938
reward_std: 482.9176940917969
reward_max: 1430.0
reward_min: 219.0
total_envstep_count: 2289992
total_train_sample_count: 2289951
total_episode_count: 14758
total_duration: 2913.252455600674
[2024-11-20 00:29:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 537
train_sample_count: 537
avg_envstep_per_episode: 134.25
avg_sample_per_episode: 134.25
avg_envstep_per_sec: 769.9298280706416
avg_train_sample_per_sec: 769.9298280706416
avg_episode_per_sec: 5.735045274269211
collect_time: 0.697466159150714
reward_mean: 1064.5
reward_std: 468.6355285644531
reward_max: 1701.0
reward_min: 602.0
total_envstep_count: 2290972
total_train_sample_count: 2290932
total_episode_count: 14762
total_duration: 2913.9499217598245
[2024-11-20 00:29:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1046
train_sample_count: 1046
avg_envstep_per_episode: 174.33333333333334
avg_sample_per_episode: 174.33333333333334
avg_envstep_per_sec: 723.6243154484218
avg_train_sample_per_sec: 723.6243154484218
avg_episode_per_sec: 4.1508086928207755
collect_time: 1.445501453819729
reward_mean: 1345.3333740234375
reward_std: 554.9527587890625
reward_max: 1922.0
reward_min: 608.0
total_envstep_count: 2291950
total_train_sample_count: 2291906
total_episode_count: 14768
total_duration: 2915.3954232136443
[2024-11-20 00:29:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 660
train_sample_count: 660
avg_envstep_per_episode: 165.0
avg_sample_per_episode: 165.0
avg_envstep_per_sec: 687.4049483287426
avg_train_sample_per_sec: 687.4049483287426
avg_episode_per_sec: 4.166090595931774
collect_time: 0.9601327450502486
reward_mean: 1400.75
reward_std: 476.76953125
reward_max: 1859.0
reward_min: 617.0
total_envstep_count: 2292939
total_train_sample_count: 2292890
total_episode_count: 14772
total_duration: 2916.3555559586944
[2024-11-20 00:30:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1587
train_sample_count: 1587
avg_envstep_per_episode: 226.71428571428572
avg_sample_per_episode: 226.71428571428572
avg_envstep_per_sec: 703.4886466875037
avg_train_sample_per_sec: 703.4886466875037
avg_episode_per_sec: 3.10297449704633
collect_time: 2.2558999458948774
reward_mean: 1376.5714111328125
reward_std: 482.993896484375
reward_max: 2301.0
reward_min: 630.0
total_envstep_count: 2293911
total_train_sample_count: 2293901
total_episode_count: 14779
total_duration: 2918.611455904589
[2024-11-20 00:30:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 665
train_sample_count: 665
avg_envstep_per_episode: 133.0
avg_sample_per_episode: 133.0
avg_envstep_per_sec: 695.4170936782693
avg_train_sample_per_sec: 695.4170936782693
avg_episode_per_sec: 5.22869995246819
collect_time: 0.9562606470925468
reward_mean: 964.4000244140625
reward_std: 599.3131713867188
reward_max: 1682.0
reward_min: 245.0
total_envstep_count: 2294956
total_train_sample_count: 2294902
total_episode_count: 14784
total_duration: 2919.5677165516818
[2024-11-20 00:30:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 976
train_sample_count: 976
avg_envstep_per_episode: 139.42857142857142
avg_sample_per_episode: 139.42857142857142
avg_envstep_per_sec: 695.2435037760479
avg_train_sample_per_sec: 695.2435037760479
avg_episode_per_sec: 4.986377588557721
collect_time: 1.4038246955190385
reward_mean: 972.4285888671875
reward_std: 441.459228515625
reward_max: 1435.0
reward_min: 249.0
total_envstep_count: 2295981
total_train_sample_count: 2295950
total_episode_count: 14791
total_duration: 2920.971541247201
[2024-11-20 00:30:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 982
train_sample_count: 982
avg_envstep_per_episode: 196.4
avg_sample_per_episode: 196.4
avg_envstep_per_sec: 691.5378508624964
avg_train_sample_per_sec: 691.5378508624964
avg_episode_per_sec: 3.5210684870799205
collect_time: 1.420023500919342
reward_mean: 1386.0
reward_std: 478.3400573730469
reward_max: 1916.0
reward_min: 622.0
total_envstep_count: 2296978
total_train_sample_count: 2296932
total_episode_count: 14796
total_duration: 2922.3915647481203
[2024-11-20 00:30:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1153
train_sample_count: 1153
avg_envstep_per_episode: 230.6
avg_sample_per_episode: 230.6
avg_envstep_per_sec: 691.3398030482088
avg_train_sample_per_sec: 691.3398030482088
avg_episode_per_sec: 2.9980043497320414
collect_time: 1.6677760992731365
reward_mean: 1535.199951171875
reward_std: 384.7921142578125
reward_max: 1835.0
reward_min: 774.0
total_envstep_count: 2297974
total_train_sample_count: 2297929
total_episode_count: 14801
total_duration: 2924.0593408473933
[2024-11-20 00:30:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 878
train_sample_count: 878
avg_envstep_per_episode: 146.33333333333334
avg_sample_per_episode: 146.33333333333334
avg_envstep_per_sec: 691.535327822752
avg_train_sample_per_sec: 691.535327822752
avg_episode_per_sec: 4.725753948674843
collect_time: 1.2696386788572585
reward_mean: 1048.0
reward_std: 423.1331481933594
reward_max: 1696.0
reward_min: 639.0
total_envstep_count: 2298960
total_train_sample_count: 2298915
total_episode_count: 14807
total_duration: 2925.3289795262504
[2024-11-20 00:30:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1277
train_sample_count: 1277
avg_envstep_per_episode: 255.4
avg_sample_per_episode: 255.4
avg_envstep_per_sec: 696.5183237481032
avg_train_sample_per_sec: 696.5183237481032
avg_episode_per_sec: 2.7271664986221738
collect_time: 1.8334047453744071
reward_mean: 1500.199951171875
reward_std: 424.15771484375
reward_max: 2303.0
reward_min: 1043.0
total_envstep_count: 2299956
total_train_sample_count: 2299916
total_episode_count: 14812
total_duration: 2927.162384271625
[2024-11-20 00:30:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 186
train_sample_count: 186
avg_envstep_per_episode: 186.0
avg_sample_per_episode: 186.0
avg_envstep_per_sec: 670.6659247277507
avg_train_sample_per_sec: 670.6659247277507
avg_episode_per_sec: 3.6057307781061865
collect_time: 0.27733629090445383
reward_mean: 1310.0
reward_std: 0.0
reward_max: 1310.0
reward_min: 1310.0
total_envstep_count: 2300915
total_train_sample_count: 2300882
total_episode_count: 14813
total_duration: 2927.439720562529
[2024-11-20 00:30:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1531
train_sample_count: 1531
avg_envstep_per_episode: 170.11111111111111
avg_sample_per_episode: 170.11111111111111
avg_envstep_per_sec: 683.0587548678687
avg_train_sample_per_sec: 683.0587548678687
avg_episode_per_sec: 4.015368251999228
collect_time: 2.2413884443896155
reward_mean: 1364.22216796875
reward_std: 588.6951293945312
reward_max: 2344.0
reward_min: 603.0
total_envstep_count: 2301939
total_train_sample_count: 2301897
total_episode_count: 14822
total_duration: 2929.6811090069186
[2024-11-20 00:30:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 638
train_sample_count: 638
avg_envstep_per_episode: 127.6
avg_sample_per_episode: 127.6
avg_envstep_per_sec: 664.9920742609493
avg_train_sample_per_sec: 664.9920742609493
avg_episode_per_sec: 5.211536632139101
collect_time: 0.9594099308763231
reward_mean: 791.2000122070312
reward_std: 267.9211730957031
reward_max: 1318.0
reward_min: 601.0
total_envstep_count: 2302919
total_train_sample_count: 2302895
total_episode_count: 14827
total_duration: 2930.640518937795
[2024-11-20 00:30:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1644
train_sample_count: 1644
avg_envstep_per_episode: 205.5
avg_sample_per_episode: 205.5
avg_envstep_per_sec: 683.4591024676844
avg_train_sample_per_sec: 683.4591024676844
avg_episode_per_sec: 3.3258350485045467
collect_time: 2.4054109369005476
reward_mean: 1217.375
reward_std: 652.78076171875
reward_max: 2280.0
reward_min: 566.0
total_envstep_count: 2303954
total_train_sample_count: 2303903
total_episode_count: 14835
total_duration: 2933.0459298746955
[2024-11-20 00:30:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1030
train_sample_count: 1030
avg_envstep_per_episode: 147.14285714285714
avg_sample_per_episode: 147.14285714285714
avg_envstep_per_sec: 677.7165442484101
avg_train_sample_per_sec: 677.7165442484101
avg_episode_per_sec: 4.605840591979486
collect_time: 1.5198094376495908
reward_mean: 1052.4285888671875
reward_std: 634.0711669921875
reward_max: 2345.0
reward_min: 249.0
total_envstep_count: 2304939
total_train_sample_count: 2304909
total_episode_count: 14842
total_duration: 2934.565739312345
[2024-11-20 00:30:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 952
train_sample_count: 952
avg_envstep_per_episode: 158.66666666666666
avg_sample_per_episode: 158.66666666666666
avg_envstep_per_sec: 668.2968459714966
avg_train_sample_per_sec: 668.2968459714966
avg_episode_per_sec: 4.211954911585062
collect_time: 1.4245166735989707
reward_mean: 1226.8333740234375
reward_std: 444.8233337402344
reward_max: 1704.0
reward_min: 621.0
total_envstep_count: 2305966
total_train_sample_count: 2305933
total_episode_count: 14848
total_duration: 2935.9902559859443
[2024-11-20 00:30:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 777
train_sample_count: 777
avg_envstep_per_episode: 155.4
avg_sample_per_episode: 155.4
avg_envstep_per_sec: 677.8408949338558
avg_train_sample_per_sec: 677.8408949338558
avg_episode_per_sec: 4.361910520809883
collect_time: 1.1462866961956024
reward_mean: 1353.0
reward_std: 378.8387451171875
reward_max: 1636.0
reward_min: 625.0
total_envstep_count: 2306969
total_train_sample_count: 2306938
total_episode_count: 14853
total_duration: 2937.13654268214
[2024-11-20 00:31:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 883
train_sample_count: 883
avg_envstep_per_episode: 147.16666666666666
avg_sample_per_episode: 147.16666666666666
avg_envstep_per_sec: 687.4112712377286
avg_train_sample_per_sec: 687.4112712377286
avg_episode_per_sec: 4.67097126548853
collect_time: 1.2845294177532196
reward_mean: 966.0
reward_std: 689.6409912109375
reward_max: 2330.0
reward_min: 247.0
total_envstep_count: 2307940
total_train_sample_count: 2307905
total_episode_count: 14859
total_duration: 2938.421072099893
[2024-11-20 00:31:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 678
train_sample_count: 678
avg_envstep_per_episode: 226.0
avg_sample_per_episode: 226.0
avg_envstep_per_sec: 692.3098357219493
avg_train_sample_per_sec: 692.3098357219493
avg_episode_per_sec: 3.0633178571767665
collect_time: 0.9793303012847899
reward_mean: 1770.3333740234375
reward_std: 604.3411865234375
reward_max: 2625.0
reward_min: 1342.0
total_envstep_count: 2308929
total_train_sample_count: 2308883
total_episode_count: 14862
total_duration: 2939.400402401178
[2024-11-20 00:31:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 812
train_sample_count: 812
avg_envstep_per_episode: 203.0
avg_sample_per_episode: 203.0
avg_envstep_per_sec: 697.6510558886436
avg_train_sample_per_sec: 697.6510558886436
avg_episode_per_sec: 3.436704708811052
collect_time: 1.1639056418623244
reward_mean: 1595.5
reward_std: 614.3958129882812
reward_max: 2354.0
reward_min: 639.0
total_envstep_count: 2309909
total_train_sample_count: 2309863
total_episode_count: 14866
total_duration: 2940.56430804304
[2024-11-20 00:31:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1371
train_sample_count: 1371
avg_envstep_per_episode: 228.5
avg_sample_per_episode: 228.5
avg_envstep_per_sec: 696.5024549437444
avg_train_sample_per_sec: 696.5024549437444
avg_episode_per_sec: 3.0481507874999756
collect_time: 1.9684065580368038
reward_mean: 1482.3333740234375
reward_std: 972.9100341796875
reward_max: 3000.0
reward_min: 233.0
total_envstep_count: 2310897
total_train_sample_count: 2310862
total_episode_count: 14872
total_duration: 2942.532714601077
[2024-11-20 00:31:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 556
train_sample_count: 556
avg_envstep_per_episode: 139.0
avg_sample_per_episode: 139.0
avg_envstep_per_sec: 699.06140988624
avg_train_sample_per_sec: 699.06140988624
avg_episode_per_sec: 5.02921877616
collect_time: 0.7953521566731588
reward_mean: 1281.25
reward_std: 454.1890563964844
reward_max: 1860.0
reward_min: 586.0
total_envstep_count: 2311894
total_train_sample_count: 2311850
total_episode_count: 14876
total_duration: 2943.32806675775
[2024-11-20 00:31:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 545
train_sample_count: 545
avg_envstep_per_episode: 181.66666666666666
avg_sample_per_episode: 181.66666666666666
avg_envstep_per_sec: 705.196874103717
avg_train_sample_per_sec: 705.196874103717
avg_episode_per_sec: 3.881817655616791
collect_time: 0.7728338284151894
reward_mean: 1406.3333740234375
reward_std: 572.8352661132812
reward_max: 1910.0
reward_min: 605.0
total_envstep_count: 2312907
total_train_sample_count: 2312875
total_episode_count: 14879
total_duration: 2944.100900586165
[2024-11-20 00:31:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1690
train_sample_count: 1690
avg_envstep_per_episode: 241.42857142857142
avg_sample_per_episode: 241.42857142857142
avg_envstep_per_sec: 698.8368037833084
avg_train_sample_per_sec: 698.8368037833084
avg_episode_per_sec: 2.894590311528496
collect_time: 2.4183042319048016
reward_mean: 1282.857177734375
reward_std: 665.4172973632812
reward_max: 2296.0
reward_min: 569.0
total_envstep_count: 2313886
total_train_sample_count: 2313857
total_episode_count: 14886
total_duration: 2946.5192048180697
[2024-11-20 00:31:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 580
train_sample_count: 580
avg_envstep_per_episode: 145.0
avg_sample_per_episode: 145.0
avg_envstep_per_sec: 740.1242267420715
avg_train_sample_per_sec: 740.1242267420715
avg_episode_per_sec: 5.1043050120142865
collect_time: 0.783652228968484
reward_mean: 1166.25
reward_std: 472.84423828125
reward_max: 1701.0
reward_min: 633.0
total_envstep_count: 2314874
total_train_sample_count: 2314833
total_episode_count: 14890
total_duration: 2947.3028570470383
[2024-11-20 00:31:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2001
train_sample_count: 2001
avg_envstep_per_episode: 250.125
avg_sample_per_episode: 250.125
avg_envstep_per_sec: 736.6953598785442
avg_train_sample_per_sec: 736.6953598785442
avg_episode_per_sec: 2.945308785121616
collect_time: 2.7161837972345806
reward_mean: 1142.125
reward_std: 579.5973510742188
reward_max: 2215.0
reward_min: 247.0
total_envstep_count: 2315851
total_train_sample_count: 2315814
total_episode_count: 14898
total_duration: 2950.0190408442727
[2024-11-20 00:31:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 894
train_sample_count: 894
avg_envstep_per_episode: 127.71428571428571
avg_sample_per_episode: 127.71428571428571
avg_envstep_per_sec: 785.0007483733648
avg_train_sample_per_sec: 785.0007483733648
avg_episode_per_sec: 6.146538298225451
collect_time: 1.1388524174690247
reward_mean: 674.4285888671875
reward_std: 300.0870666503906
reward_max: 1336.0
reward_min: 249.0
total_envstep_count: 2316862
total_train_sample_count: 2316816
total_episode_count: 14905
total_duration: 2951.1578932617417
[2024-11-20 00:31:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1323
train_sample_count: 1323
avg_envstep_per_episode: 120.27272727272727
avg_sample_per_episode: 120.27272727272727
avg_envstep_per_sec: 784.2713793502803
avg_train_sample_per_sec: 784.2713793502803
avg_episode_per_sec: 6.520774884998552
collect_time: 1.6869160788399833
reward_mean: 932.4545288085938
reward_std: 367.4967956542969
reward_max: 1694.0
reward_min: 603.0
total_envstep_count: 2317859
total_train_sample_count: 2317827
total_episode_count: 14916
total_duration: 2952.844809340582
[2024-11-20 00:31:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 310
train_sample_count: 310
avg_envstep_per_episode: 155.0
avg_sample_per_episode: 155.0
avg_envstep_per_sec: 787.6095295555102
avg_train_sample_per_sec: 787.6095295555102
avg_episode_per_sec: 5.081351803583937
collect_time: 0.3935960502851577
reward_mean: 1202.0
reward_std: 488.0
reward_max: 1690.0
reward_min: 714.0
total_envstep_count: 2318825
total_train_sample_count: 2318797
total_episode_count: 14918
total_duration: 2953.238405390867
[2024-11-20 00:31:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 880
train_sample_count: 880
avg_envstep_per_episode: 176.0
avg_sample_per_episode: 176.0
avg_envstep_per_sec: 716.1051726429488
avg_train_sample_per_sec: 716.1051726429488
avg_episode_per_sec: 4.068779390016754
collect_time: 1.228869771673566
reward_mean: 1211.5999755859375
reward_std: 661.80859375
reward_max: 1844.0
reward_min: 240.0
total_envstep_count: 2319804
total_train_sample_count: 2319773
total_episode_count: 14923
total_duration: 2954.4672751625403
[2024-11-20 00:31:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1002
train_sample_count: 1002
avg_envstep_per_episode: 167.0
avg_sample_per_episode: 167.0
avg_envstep_per_sec: 746.9236584779386
avg_train_sample_per_sec: 746.9236584779386
avg_episode_per_sec: 4.4725967573529255
collect_time: 1.3415025600365227
reward_mean: 916.0
reward_std: 710.7584838867188
reward_max: 1907.0
reward_min: 141.0
total_envstep_count: 2320808
total_train_sample_count: 2320775
total_episode_count: 14929
total_duration: 2955.808777722577
[2024-11-20 00:31:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 862
train_sample_count: 862
avg_envstep_per_episode: 287.3333333333333
avg_sample_per_episode: 287.3333333333333
avg_envstep_per_sec: 742.1675207533356
avg_train_sample_per_sec: 742.1675207533356
avg_episode_per_sec: 2.582949608190263
collect_time: 1.1614628448372797
reward_mean: 1525.3333740234375
reward_std: 710.8718872070312
reward_max: 2307.0
reward_min: 587.0
total_envstep_count: 2321806
total_train_sample_count: 2321769
total_episode_count: 14932
total_duration: 2956.9702405674143
[2024-11-20 00:31:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1005
train_sample_count: 1005
avg_envstep_per_episode: 201.0
avg_sample_per_episode: 201.0
avg_envstep_per_sec: 791.7939427959022
avg_train_sample_per_sec: 791.7939427959022
avg_episode_per_sec: 3.9392733472432946
collect_time: 1.2692696239267078
reward_mean: 1090.199951171875
reward_std: 318.1209716796875
reward_max: 1575.0
reward_min: 739.0
total_envstep_count: 2322833
total_train_sample_count: 2322786
total_episode_count: 14937
total_duration: 2958.239510191341
[2024-11-20 00:32:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 890
train_sample_count: 890
avg_envstep_per_episode: 222.5
avg_sample_per_episode: 222.5
avg_envstep_per_sec: 791.4615853308161
avg_train_sample_per_sec: 791.4615853308161
avg_episode_per_sec: 3.5571307205879377
collect_time: 1.1245018286364419
reward_mean: 1227.75
reward_std: 624.9469604492188
reward_max: 1881.0
reward_min: 203.0
total_envstep_count: 2323821
total_train_sample_count: 2323784
total_episode_count: 14941
total_duration: 2959.3640120199775
[2024-11-20 00:32:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 647
train_sample_count: 647
avg_envstep_per_episode: 215.66666666666666
avg_sample_per_episode: 215.66666666666666
avg_envstep_per_sec: 801.5966657111418
avg_train_sample_per_sec: 801.5966657111418
avg_episode_per_sec: 3.71683152570854
collect_time: 0.8071390858718327
reward_mean: 1215.0
reward_std: 126.24578857421875
reward_max: 1316.0
reward_min: 1037.0
total_envstep_count: 2324818
total_train_sample_count: 2324779
total_episode_count: 14944
total_duration: 2960.1711511058493
[2024-11-20 00:32:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1997
train_sample_count: 1997
avg_envstep_per_episode: 399.4
avg_sample_per_episode: 399.4
avg_envstep_per_sec: 784.1667785550201
avg_train_sample_per_sec: 784.1667785550201
avg_episode_per_sec: 1.9633619893716077
collect_time: 2.54665213397571
reward_mean: 1277.5999755859375
reward_std: 846.2500610351562
reward_max: 2951.0
reward_min: 697.0
total_envstep_count: 2325791
total_train_sample_count: 2325768
total_episode_count: 14949
total_duration: 2962.717803239825
[2024-11-20 00:32:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1318
train_sample_count: 1318
avg_envstep_per_episode: 188.28571428571428
avg_sample_per_episode: 188.28571428571428
avg_envstep_per_sec: 787.7420528798817
avg_train_sample_per_sec: 787.7420528798817
avg_episode_per_sec: 4.183759006190571
collect_time: 1.6731365237917217
reward_mean: 791.8571166992188
reward_std: 525.9754028320312
reward_max: 1400.0
reward_min: 131.0
total_envstep_count: 2326840
total_train_sample_count: 2326822
total_episode_count: 14956
total_duration: 2964.3909397636166
[2024-11-20 00:32:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 763
train_sample_count: 763
avg_envstep_per_episode: 127.16666666666667
avg_sample_per_episode: 127.16666666666667
avg_envstep_per_sec: 786.2844704502995
avg_train_sample_per_sec: 786.2844704502995
avg_episode_per_sec: 6.1831019956773225
collect_time: 0.9703867094857352
reward_mean: 999.5
reward_std: 299.31353759765625
reward_max: 1347.0
reward_min: 607.0
total_envstep_count: 2327837
total_train_sample_count: 2327813
total_episode_count: 14962
total_duration: 2965.3613264731025
[2024-11-20 00:32:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 888
train_sample_count: 888
avg_envstep_per_episode: 177.6
avg_sample_per_episode: 177.6
avg_envstep_per_sec: 789.9296433121077
avg_train_sample_per_sec: 789.9296433121077
avg_episode_per_sec: 4.447802045676282
collect_time: 1.1241507487637654
reward_mean: 1200.800048828125
reward_std: 479.228271484375
reward_max: 1694.0
reward_min: 617.0
total_envstep_count: 2328834
total_train_sample_count: 2328809
total_episode_count: 14967
total_duration: 2966.4854772218664
[2024-11-20 00:32:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 821
train_sample_count: 821
avg_envstep_per_episode: 164.2
avg_sample_per_episode: 164.2
avg_envstep_per_sec: 786.1738870712952
avg_train_sample_per_sec: 786.1738870712952
avg_episode_per_sec: 4.787904306158923
collect_time: 1.044298231601715
reward_mean: 1028.199951171875
reward_std: 346.23541259765625
reward_max: 1334.0
reward_min: 585.0
total_envstep_count: 2329814
total_train_sample_count: 2329786
total_episode_count: 14972
total_duration: 2967.529775453468
[2024-11-20 00:32:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1313
train_sample_count: 1313
avg_envstep_per_episode: 164.125
avg_sample_per_episode: 164.125
avg_envstep_per_sec: 786.3548088289982
avg_train_sample_per_sec: 786.3548088289982
avg_episode_per_sec: 4.7911945701690675
collect_time: 1.6697297266551425
reward_mean: 980.875
reward_std: 336.58782958984375
reward_max: 1329.0
reward_min: 626.0
total_envstep_count: 2330830
total_train_sample_count: 2330787
total_episode_count: 14980
total_duration: 2969.199505180123
[2024-11-20 00:32:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 386
train_sample_count: 386
avg_envstep_per_episode: 128.66666666666666
avg_sample_per_episode: 128.66666666666666
avg_envstep_per_sec: 785.1600536985154
avg_train_sample_per_sec: 785.1600536985154
avg_episode_per_sec: 6.102280210092089
collect_time: 0.4916195088908786
reward_mean: 960.0
reward_std: 493.6746520996094
reward_max: 1658.0
reward_min: 598.0
total_envstep_count: 2331804
total_train_sample_count: 2331773
total_episode_count: 14983
total_duration: 2969.691124689014
[2024-11-20 00:32:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1780
train_sample_count: 1780
avg_envstep_per_episode: 254.28571428571428
avg_sample_per_episode: 254.28571428571428
avg_envstep_per_sec: 784.1136302540948
avg_train_sample_per_sec: 784.1136302540948
avg_episode_per_sec: 3.0835929279655416
collect_time: 2.2700791458288827
reward_mean: 1573.7142333984375
reward_std: 550.0103149414062
reward_max: 2335.0
reward_min: 625.0
total_envstep_count: 2332814
total_train_sample_count: 2332785
total_episode_count: 14990
total_duration: 2971.9612038348428
[2024-11-20 00:32:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 823
train_sample_count: 823
avg_envstep_per_episode: 137.16666666666666
avg_sample_per_episode: 137.16666666666666
avg_envstep_per_sec: 774.2981105691396
avg_train_sample_per_sec: 774.2981105691396
avg_episode_per_sec: 5.644943697952415
collect_time: 1.0628981121948788
reward_mean: 1240.8333740234375
reward_std: 463.9703369140625
reward_max: 1854.0
reward_min: 622.0
total_envstep_count: 2333817
total_train_sample_count: 2333776
total_episode_count: 14996
total_duration: 2973.0241019470377
[2024-11-20 00:32:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 408
train_sample_count: 408
avg_envstep_per_episode: 102.0
avg_sample_per_episode: 102.0
avg_envstep_per_sec: 779.602772860806
avg_train_sample_per_sec: 779.602772860806
avg_episode_per_sec: 7.643164439811823
collect_time: 0.5233434438705444
reward_mean: 708.75
reward_std: 393.67523193359375
reward_max: 1329.0
reward_min: 235.0
total_envstep_count: 2334775
total_train_sample_count: 2334748
total_episode_count: 15000
total_duration: 2973.5474453909083
[2024-11-20 00:32:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 551
train_sample_count: 551
avg_envstep_per_episode: 137.75
avg_sample_per_episode: 137.75
avg_envstep_per_sec: 790.983218450707
avg_train_sample_per_sec: 790.983218450707
avg_episode_per_sec: 5.742164925231992
collect_time: 0.6966013780661993
reward_mean: 1167.25
reward_std: 532.42529296875
reward_max: 1703.0
reward_min: 616.0
total_envstep_count: 2335763
total_train_sample_count: 2335719
total_episode_count: 15004
total_duration: 2974.2440467689744
[2024-11-20 00:32:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 628
train_sample_count: 628
avg_envstep_per_episode: 209.33333333333334
avg_sample_per_episode: 209.33333333333334
avg_envstep_per_sec: 799.854614262156
avg_train_sample_per_sec: 799.854614262156
avg_episode_per_sec: 3.8209615330994717
collect_time: 0.785142685685839
reward_mean: 1464.6666259765625
reward_std: 706.2626342773438
reward_max: 2346.0
reward_min: 617.0
total_envstep_count: 2336720
total_train_sample_count: 2336683
total_episode_count: 15007
total_duration: 2975.0291894546604
[2024-11-20 00:32:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1072
train_sample_count: 1072
avg_envstep_per_episode: 214.4
avg_sample_per_episode: 214.4
avg_envstep_per_sec: 790.5690120041611
avg_train_sample_per_sec: 790.5690120041611
avg_episode_per_sec: 3.6873554664373183
collect_time: 1.3559853519712175
reward_mean: 939.7999877929688
reward_std: 414.21319580078125
reward_max: 1576.0
reward_min: 573.0
total_envstep_count: 2337741
total_train_sample_count: 2337719
total_episode_count: 15012
total_duration: 2976.3851748066318
[2024-11-20 00:32:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1522
train_sample_count: 1522
avg_envstep_per_episode: 217.42857142857142
avg_sample_per_episode: 217.42857142857142
avg_envstep_per_sec: 794.4707304010057
avg_train_sample_per_sec: 794.4707304010057
avg_episode_per_sec: 3.6539389703068594
collect_time: 1.9157408092703139
reward_mean: 1086.4285888671875
reward_std: 807.3595581054688
reward_max: 2982.0
reward_min: 623.0
total_envstep_count: 2338745
total_train_sample_count: 2338713
total_episode_count: 15019
total_duration: 2978.300915615902
[2024-11-20 00:32:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 363
train_sample_count: 363
avg_envstep_per_episode: 72.6
avg_sample_per_episode: 72.6
avg_envstep_per_sec: 795.8792487716686
avg_train_sample_per_sec: 795.8792487716686
avg_episode_per_sec: 10.96252408776403
collect_time: 0.45609933989388607
reward_mean: 546.7999877929688
reward_std: 150.1258087158203
reward_max: 634.0
reward_min: 247.0
total_envstep_count: 2339749
total_train_sample_count: 2339688
total_episode_count: 15024
total_duration: 2978.757014955796
[2024-11-20 00:33:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2733
train_sample_count: 2733
avg_envstep_per_episode: 341.625
avg_sample_per_episode: 341.625
avg_envstep_per_sec: 792.8526351708883
avg_train_sample_per_sec: 792.8526351708883
avg_episode_per_sec: 2.320827325783793
collect_time: 3.447046624762671
reward_mean: 1552.75
reward_std: 584.6032104492188
reward_max: 2580.0
reward_min: 623.0
total_envstep_count: 2340726
total_train_sample_count: 2340693
total_episode_count: 15032
total_duration: 2982.2040615805586
[2024-11-20 00:33:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 489
train_sample_count: 489
avg_envstep_per_episode: 122.25
avg_sample_per_episode: 122.25
avg_envstep_per_sec: 784.6889458499835
avg_train_sample_per_sec: 784.6889458499835
avg_episode_per_sec: 6.418723483435448
collect_time: 0.6231768684727805
reward_mean: 940.25
reward_std: 436.4598388671875
reward_max: 1432.0
reward_min: 235.0
total_envstep_count: 2341707
total_train_sample_count: 2341674
total_episode_count: 15036
total_duration: 2982.8272384490315
[2024-11-20 00:33:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1026
train_sample_count: 1026
avg_envstep_per_episode: 205.2
avg_sample_per_episode: 205.2
avg_envstep_per_sec: 787.867254758494
avg_train_sample_per_sec: 787.867254758494
avg_episode_per_sec: 3.839509038784084
collect_time: 1.3022498318127222
reward_mean: 1471.199951171875
reward_std: 526.3429565429688
reward_max: 1913.0
reward_min: 653.0
total_envstep_count: 2342687
total_train_sample_count: 2342652
total_episode_count: 15041
total_duration: 2984.1294882808443
[2024-11-20 00:33:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1036
train_sample_count: 1036
avg_envstep_per_episode: 207.2
avg_sample_per_episode: 207.2
avg_envstep_per_sec: 792.5934471493313
avg_train_sample_per_sec: 792.5934471493313
avg_episode_per_sec: 3.8252579495624093
collect_time: 1.3071013944489613
reward_mean: 1307.4000244140625
reward_std: 814.9663696289062
reward_max: 2633.0
reward_min: 587.0
total_envstep_count: 2343643
total_train_sample_count: 2343616
total_episode_count: 15046
total_duration: 2985.4365896752934
[2024-11-20 00:33:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 754
train_sample_count: 754
avg_envstep_per_episode: 150.8
avg_sample_per_episode: 150.8
avg_envstep_per_sec: 786.5107425798952
avg_train_sample_per_sec: 786.5107425798952
avg_episode_per_sec: 5.21558847864652
collect_time: 0.9586645918233053
reward_mean: 1078.800048828125
reward_std: 433.9319763183594
reward_max: 1692.0
reward_min: 607.0
total_envstep_count: 2344646
total_train_sample_count: 2344598
total_episode_count: 15051
total_duration: 2986.395254267117
[2024-11-20 00:33:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 719
train_sample_count: 719
avg_envstep_per_episode: 143.8
avg_sample_per_episode: 143.8
avg_envstep_per_sec: 790.3835484523125
avg_train_sample_per_sec: 790.3835484523125
avg_episode_per_sec: 5.496408542783815
collect_time: 0.9096849262714386
reward_mean: 1036.199951171875
reward_std: 529.0967407226562
reward_max: 1695.0
reward_min: 237.0
total_envstep_count: 2345617
total_train_sample_count: 2345581
total_episode_count: 15056
total_duration: 2987.3049391933882
[2024-11-20 00:33:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1301
train_sample_count: 1301
avg_envstep_per_episode: 260.2
avg_sample_per_episode: 260.2
avg_envstep_per_sec: 791.2719113172433
avg_train_sample_per_sec: 791.2719113172433
avg_episode_per_sec: 3.041014263325301
collect_time: 1.644188276359013
reward_mean: 1522.4000244140625
reward_std: 765.1019897460938
reward_max: 2345.0
reward_min: 617.0
total_envstep_count: 2346612
total_train_sample_count: 2346570
total_episode_count: 15061
total_duration: 2988.949127469747
[2024-11-20 00:33:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1050
train_sample_count: 1050
avg_envstep_per_episode: 210.0
avg_sample_per_episode: 210.0
avg_envstep_per_sec: 787.0706465907933
avg_train_sample_per_sec: 787.0706465907933
avg_episode_per_sec: 3.747955459956159
collect_time: 1.3340606774602617
reward_mean: 1039.4000244140625
reward_std: 411.4154052734375
reward_max: 1667.0
reward_min: 630.0
total_envstep_count: 2347615
total_train_sample_count: 2347560
total_episode_count: 15066
total_duration: 2990.2831881472075
[2024-11-20 00:33:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 595
train_sample_count: 595
avg_envstep_per_episode: 297.5
avg_sample_per_episode: 297.5
avg_envstep_per_sec: 794.3907682374686
avg_train_sample_per_sec: 794.3907682374686
avg_episode_per_sec: 2.670221069705777
collect_time: 0.749001654840651
reward_mean: 1423.0
reward_std: 410.0
reward_max: 1833.0
reward_min: 1013.0
total_envstep_count: 2348581
total_train_sample_count: 2348539
total_episode_count: 15068
total_duration: 2991.0321898020484
[2024-11-20 00:33:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1341
train_sample_count: 1341
avg_envstep_per_episode: 134.1
avg_sample_per_episode: 134.1
avg_envstep_per_sec: 788.0569930437325
avg_train_sample_per_sec: 788.0569930437325
avg_episode_per_sec: 5.87663678630673
collect_time: 1.701653575613385
reward_mean: 1018.5999755859375
reward_std: 396.72515869140625
reward_max: 1575.0
reward_min: 610.0
total_envstep_count: 2349580
total_train_sample_count: 2349556
total_episode_count: 15078
total_duration: 2992.7338433776617
[2024-11-20 00:33:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1092
train_sample_count: 1092
avg_envstep_per_episode: 218.4
avg_sample_per_episode: 218.4
avg_envstep_per_sec: 778.9466613482848
avg_train_sample_per_sec: 778.9466613482848
avg_episode_per_sec: 3.5666055922540516
collect_time: 1.4018931644303458
reward_mean: 828.7999877929688
reward_std: 264.328125
reward_max: 1278.0
reward_min: 609.0
total_envstep_count: 2350584
total_train_sample_count: 2350540
total_episode_count: 15083
total_duration: 2994.135736542092
[2024-11-20 00:33:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 824
train_sample_count: 824
avg_envstep_per_episode: 137.33333333333334
avg_sample_per_episode: 137.33333333333334
avg_envstep_per_sec: 686.3220286171183
avg_train_sample_per_sec: 686.3220286171183
avg_episode_per_sec: 4.997490499639211
collect_time: 1.200602582522801
reward_mean: 1044.1666259765625
reward_std: 467.0544128417969
reward_max: 1698.0
reward_min: 619.0
total_envstep_count: 2351580
total_train_sample_count: 2351556
total_episode_count: 15089
total_duration: 2995.336339124615
[2024-11-20 00:33:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1529
train_sample_count: 1529
avg_envstep_per_episode: 169.88888888888889
avg_sample_per_episode: 169.88888888888889
avg_envstep_per_sec: 702.1460207841375
avg_train_sample_per_sec: 702.1460207841375
avg_episode_per_sec: 4.132971999383412
collect_time: 2.1776097204004015
reward_mean: 1257.4444580078125
reward_std: 462.4171142578125
reward_max: 1841.0
reward_min: 610.0
total_envstep_count: 2352579
total_train_sample_count: 2352533
total_episode_count: 15098
total_duration: 2997.5139488450154
[2024-11-20 00:33:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 918
train_sample_count: 918
avg_envstep_per_episode: 183.6
avg_sample_per_episode: 183.6
avg_envstep_per_sec: 747.1451179023268
avg_train_sample_per_sec: 747.1451179023268
avg_episode_per_sec: 4.0694178534985115
collect_time: 1.2286769705159324
reward_mean: 1429.5999755859375
reward_std: 236.92579650878906
reward_max: 1704.0
reward_min: 1036.0
total_envstep_count: 2353560
total_train_sample_count: 2353511
total_episode_count: 15103
total_duration: 2998.7426258155315
[2024-11-20 00:33:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 446
train_sample_count: 446
avg_envstep_per_episode: 111.5
avg_sample_per_episode: 111.5
avg_envstep_per_sec: 747.8653228789136
avg_train_sample_per_sec: 747.8653228789136
avg_episode_per_sec: 6.707312312815368
collect_time: 0.5963640596185412
reward_mean: 884.25
reward_std: 465.4993896484375
reward_max: 1334.0
reward_min: 247.0
total_envstep_count: 2354524
total_train_sample_count: 2354485
total_episode_count: 15107
total_duration: 2999.33898987515
[2024-11-20 00:33:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1583
train_sample_count: 1583
avg_envstep_per_episode: 158.3
avg_sample_per_episode: 158.3
avg_envstep_per_sec: 782.4725076556336
avg_train_sample_per_sec: 782.4725076556336
avg_episode_per_sec: 4.942972253036221
collect_time: 2.0230742735522136
reward_mean: 1225.9000244140625
reward_std: 637.1622314453125
reward_max: 2343.0
reward_min: 247.0
total_envstep_count: 2355518
total_train_sample_count: 2355492
total_episode_count: 15117
total_duration: 3001.3620641487023
[2024-11-20 00:34:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 665
train_sample_count: 665
avg_envstep_per_episode: 95.0
avg_sample_per_episode: 95.0
avg_envstep_per_sec: 572.2136493296196
avg_train_sample_per_sec: 572.2136493296196
avg_episode_per_sec: 6.023301571890732
collect_time: 1.1621533334255219
reward_mean: 723.8571166992188
reward_std: 331.967041015625
reward_max: 1323.0
reward_min: 202.0
total_envstep_count: 2356568
total_train_sample_count: 2356529
total_episode_count: 15124
total_duration: 3002.524217482128
[2024-11-20 00:34:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 224
train_sample_count: 224
avg_envstep_per_episode: 112.0
avg_sample_per_episode: 112.0
avg_envstep_per_sec: 765.0378549814673
avg_train_sample_per_sec: 765.0378549814673
avg_episode_per_sec: 6.830695133763101
collect_time: 0.29279596890722004
reward_mean: 845.0
reward_std: 192.0
reward_max: 1037.0
reward_min: 653.0
total_envstep_count: 2357550
total_train_sample_count: 2357509
total_episode_count: 15126
total_duration: 3002.817013451035
[2024-11-20 00:34:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1056
train_sample_count: 1056
avg_envstep_per_episode: 211.2
avg_sample_per_episode: 211.2
avg_envstep_per_sec: 777.5346528621642
avg_train_sample_per_sec: 777.5346528621642
avg_episode_per_sec: 3.6815087730216107
collect_time: 1.358138825212206
reward_mean: 1641.5999755859375
reward_std: 368.9588623046875
reward_max: 2346.0
reward_min: 1332.0
total_envstep_count: 2358537
total_train_sample_count: 2358493
total_episode_count: 15131
total_duration: 3004.1751522762474
[2024-11-20 00:34:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1348
train_sample_count: 1348
avg_envstep_per_episode: 192.57142857142858
avg_sample_per_episode: 192.57142857142858
avg_envstep_per_sec: 786.266983977006
avg_train_sample_per_sec: 786.266983977006
avg_episode_per_sec: 4.082988789198103
collect_time: 1.714430374758584
reward_mean: 1163.857177734375
reward_std: 833.3723754882812
reward_max: 2628.0
reward_min: 614.0
total_envstep_count: 2359540
total_train_sample_count: 2359505
total_episode_count: 15138
total_duration: 3005.889582651006
[2024-11-20 00:34:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1449
train_sample_count: 1449
avg_envstep_per_episode: 241.5
avg_sample_per_episode: 241.5
avg_envstep_per_sec: 789.2563966520333
avg_train_sample_per_sec: 789.2563966520333
avg_episode_per_sec: 3.2681424292009664
collect_time: 1.835905297881081
reward_mean: 1295.0
reward_std: 491.4689025878906
reward_max: 1760.0
reward_min: 601.0
total_envstep_count: 2360518
total_train_sample_count: 2360498
total_episode_count: 15144
total_duration: 3007.7254879488873
[2024-11-20 00:34:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1006
train_sample_count: 1006
avg_envstep_per_episode: 125.75
avg_sample_per_episode: 125.75
avg_envstep_per_sec: 781.9907770703315
avg_train_sample_per_sec: 781.9907770703315
avg_episode_per_sec: 6.218614529386334
collect_time: 1.2864601853347961
reward_mean: 706.375
reward_std: 390.5575866699219
reward_max: 1438.0
reward_min: 121.0
total_envstep_count: 2361558
total_train_sample_count: 2361516
total_episode_count: 15152
total_duration: 3009.011948134222
[2024-11-20 00:34:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 761
train_sample_count: 761
avg_envstep_per_episode: 126.83333333333333
avg_sample_per_episode: 126.83333333333333
avg_envstep_per_sec: 793.6971065861952
avg_train_sample_per_sec: 793.6971065861952
avg_episode_per_sec: 6.257795846934522
collect_time: 0.9588040496621814
reward_mean: 864.1666870117188
reward_std: 435.42559814453125
reward_max: 1574.0
reward_min: 164.0
total_envstep_count: 2362529
total_train_sample_count: 2362493
total_episode_count: 15158
total_duration: 3009.9707521838845
[2024-11-20 00:34:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1517
train_sample_count: 1517
avg_envstep_per_episode: 168.55555555555554
avg_sample_per_episode: 168.55555555555554
avg_envstep_per_sec: 784.8690646405554
avg_train_sample_per_sec: 784.8690646405554
avg_episode_per_sec: 4.65644138547462
collect_time: 1.9328064620494845
reward_mean: 1171.888916015625
reward_std: 450.92608642578125
reward_max: 1894.0
reward_min: 606.0
total_envstep_count: 2363521
total_train_sample_count: 2363482
total_episode_count: 15167
total_duration: 3011.903558645934
[2024-11-20 00:34:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 516
train_sample_count: 516
avg_envstep_per_episode: 103.2
avg_sample_per_episode: 103.2
avg_envstep_per_sec: 782.0326552840936
avg_train_sample_per_sec: 782.0326552840936
avg_episode_per_sec: 7.5778358070164105
collect_time: 0.659818994147437
reward_mean: 757.4000244140625
reward_std: 288.41748046875
reward_max: 1333.0
reward_min: 595.0
total_envstep_count: 2364478
total_train_sample_count: 2364454
total_episode_count: 15172
total_duration: 3012.5633776400814
[2024-11-20 00:34:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 580
train_sample_count: 580
avg_envstep_per_episode: 116.0
avg_sample_per_episode: 116.0
avg_envstep_per_sec: 793.658808049218
avg_train_sample_per_sec: 793.658808049218
avg_episode_per_sec: 6.841886276286362
collect_time: 0.7307926203523364
reward_mean: 985.7999877929688
reward_std: 312.89703369140625
reward_max: 1326.0
reward_min: 610.0
total_envstep_count: 2365498
total_train_sample_count: 2365454
total_episode_count: 15177
total_duration: 3013.294170260434
[2024-11-20 00:34:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1443
train_sample_count: 1443
avg_envstep_per_episode: 180.375
avg_sample_per_episode: 180.375
avg_envstep_per_sec: 794.0389519699295
avg_train_sample_per_sec: 794.0389519699295
avg_episode_per_sec: 4.402156351877641
collect_time: 1.81729120016098
reward_mean: 1093.25
reward_std: 827.8195190429688
reward_max: 2615.0
reward_min: 232.0
total_envstep_count: 2366498
total_train_sample_count: 2366453
total_episode_count: 15185
total_duration: 3015.111461460595
[2024-11-20 00:34:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 645
train_sample_count: 645
avg_envstep_per_episode: 129.0
avg_sample_per_episode: 129.0
avg_envstep_per_sec: 790.9498287245044
avg_train_sample_per_sec: 790.9498287245044
avg_episode_per_sec: 6.131394021120189
collect_time: 0.8154752382210324
reward_mean: 1151.0
reward_std: 287.18426513671875
reward_max: 1432.0
reward_min: 640.0
total_envstep_count: 2367469
total_train_sample_count: 2367422
total_episode_count: 15190
total_duration: 3015.926936698816
[2024-11-20 00:34:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1075
train_sample_count: 1075
avg_envstep_per_episode: 179.16666666666666
avg_sample_per_episode: 179.16666666666666
avg_envstep_per_sec: 790.409352664086
avg_train_sample_per_sec: 790.409352664086
avg_episode_per_sec: 4.41158708463676
collect_time: 1.3600547569138663
reward_mean: 1277.0
reward_std: 600.41650390625
reward_max: 2326.0
reward_min: 629.0
total_envstep_count: 2368447
total_train_sample_count: 2368413
total_episode_count: 15196
total_duration: 3017.28699145573
[2024-11-20 00:34:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1111
train_sample_count: 1111
avg_envstep_per_episode: 370.3333333333333
avg_sample_per_episode: 370.3333333333333
avg_envstep_per_sec: 794.0435988672468
avg_train_sample_per_sec: 794.0435988672468
avg_episode_per_sec: 2.144132130154582
collect_time: 1.399167503629412
reward_mean: 2192.333251953125
reward_std: 191.86859130859375
reward_max: 2330.0
reward_min: 1921.0
total_envstep_count: 2369436
total_train_sample_count: 2369392
total_episode_count: 15199
total_duration: 3018.6861589593595
[2024-11-20 00:34:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 563
train_sample_count: 563
avg_envstep_per_episode: 187.66666666666666
avg_sample_per_episode: 187.66666666666666
avg_envstep_per_sec: 794.3495413625824
avg_train_sample_per_sec: 794.3495413625824
avg_episode_per_sec: 4.2327684264436005
collect_time: 0.7087559955460685
reward_mean: 1353.0
reward_std: 55.16037368774414
reward_max: 1431.0
reward_min: 1313.0
total_envstep_count: 2370393
total_train_sample_count: 2370363
total_episode_count: 15202
total_duration: 3019.3949149549057
[2024-11-20 00:34:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 448
train_sample_count: 448
avg_envstep_per_episode: 149.33333333333334
avg_sample_per_episode: 149.33333333333334
avg_envstep_per_sec: 795.597551043214
avg_train_sample_per_sec: 795.597551043214
avg_episode_per_sec: 5.32766217216438
collect_time: 0.5630987669740404
reward_mean: 1258.0
reward_std: 388.8092956542969
reward_max: 1691.0
reward_min: 748.0
total_envstep_count: 2371390
total_train_sample_count: 2371339
total_episode_count: 15205
total_duration: 3019.95801372188
[2024-11-20 00:35:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1367
train_sample_count: 1367
avg_envstep_per_episode: 195.28571428571428
avg_sample_per_episode: 195.28571428571428
avg_envstep_per_sec: 789.5198689627626
avg_train_sample_per_sec: 789.5198689627626
avg_episode_per_sec: 4.042896183423071
collect_time: 1.7314320433707464
reward_mean: 1438.4285888671875
reward_std: 548.9938354492188
reward_max: 1914.0
reward_min: 622.0
total_envstep_count: 2372361
total_train_sample_count: 2372334
total_episode_count: 15212
total_duration: 3021.6894457652506
[2024-11-20 00:35:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 370
train_sample_count: 370
avg_envstep_per_episode: 92.5
avg_sample_per_episode: 92.5
avg_envstep_per_sec: 788.8963802698493
avg_train_sample_per_sec: 788.8963802698493
avg_episode_per_sec: 8.528609516430802
collect_time: 0.46900963073685054
reward_mean: 576.75
reward_std: 440.48291015625
reward_max: 1277.0
reward_min: 167.0
total_envstep_count: 2373373
total_train_sample_count: 2373328
total_episode_count: 15216
total_duration: 3022.1584553959874
[2024-11-20 00:35:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 656
train_sample_count: 656
avg_envstep_per_episode: 131.2
avg_sample_per_episode: 131.2
avg_envstep_per_sec: 799.0438202965537
avg_train_sample_per_sec: 799.0438202965537
avg_episode_per_sec: 6.090273020553
collect_time: 0.8209812570185888
reward_mean: 1060.5999755859375
reward_std: 340.2008972167969
reward_max: 1451.0
reward_min: 623.0
total_envstep_count: 2374353
total_train_sample_count: 2374320
total_episode_count: 15221
total_duration: 3022.979436653006
[2024-11-20 00:35:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 923
train_sample_count: 923
avg_envstep_per_episode: 153.83333333333334
avg_sample_per_episode: 153.83333333333334
avg_envstep_per_sec: 799.6213225231506
avg_train_sample_per_sec: 799.6213225231506
avg_episode_per_sec: 5.197971760713871
collect_time: 1.1542963825521015
reward_mean: 1092.5
reward_std: 619.820068359375
reward_max: 2340.0
reward_min: 605.0
total_envstep_count: 2375356
total_train_sample_count: 2375327
total_episode_count: 15227
total_duration: 3024.133733035558
[2024-11-20 00:35:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 420
train_sample_count: 420
avg_envstep_per_episode: 140.0
avg_sample_per_episode: 140.0
avg_envstep_per_sec: 812.3023936489814
avg_train_sample_per_sec: 812.3023936489814
avg_episode_per_sec: 5.802159954635581
collect_time: 0.5170488272394452
reward_mean: 1061.3333740234375
reward_std: 208.29519653320312
reward_max: 1326.0
reward_min: 817.0
total_envstep_count: 2376338
total_train_sample_count: 2376311
total_episode_count: 15230
total_duration: 3024.6507818627974
[2024-11-20 00:35:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 155.0
avg_sample_per_episode: 155.0
avg_envstep_per_sec: 787.1370879083786
avg_train_sample_per_sec: 787.1370879083786
avg_episode_per_sec: 5.078303792957281
collect_time: 0.7876645752361842
reward_mean: 1132.25
reward_std: 503.2516174316406
reward_max: 1637.0
reward_min: 628.0
total_envstep_count: 2377342
total_train_sample_count: 2377291
total_episode_count: 15234
total_duration: 3025.4384464380337
[2024-11-20 00:35:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 659
train_sample_count: 659
avg_envstep_per_episode: 164.75
avg_sample_per_episode: 164.75
avg_envstep_per_sec: 792.7428920347595
avg_train_sample_per_sec: 792.7428920347595
avg_episode_per_sec: 4.811792971379421
collect_time: 0.8312909603118898
reward_mean: 1335.75
reward_std: 444.0108947753906
reward_max: 1707.0
reward_min: 611.0
total_envstep_count: 2378314
total_train_sample_count: 2378262
total_episode_count: 15238
total_duration: 3026.2697373983456
[2024-11-20 00:35:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 504
train_sample_count: 504
avg_envstep_per_episode: 126.0
avg_sample_per_episode: 126.0
avg_envstep_per_sec: 798.4124081694492
avg_train_sample_per_sec: 798.4124081694492
avg_episode_per_sec: 6.336606414043248
collect_time: 0.6312527145658221
reward_mean: 1081.75
reward_std: 459.7049865722656
reward_max: 1697.0
reward_min: 627.0
total_envstep_count: 2379278
total_train_sample_count: 2379246
total_episode_count: 15242
total_duration: 3026.9009901129116
[2024-11-20 00:35:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 595
train_sample_count: 595
avg_envstep_per_episode: 198.33333333333334
avg_sample_per_episode: 198.33333333333334
avg_envstep_per_sec: 798.9993735004491
avg_train_sample_per_sec: 798.9993735004491
avg_episode_per_sec: 4.0285682697501635
collect_time: 0.7446814349719456
reward_mean: 1550.6666259765625
reward_std: 723.9310913085938
reward_max: 2360.0
reward_min: 603.0
total_envstep_count: 2380259
total_train_sample_count: 2380225
total_episode_count: 15245
total_duration: 3027.6456715478835
[2024-11-20 00:35:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 283
train_sample_count: 283
avg_envstep_per_episode: 94.33333333333333
avg_sample_per_episode: 94.33333333333333
avg_envstep_per_sec: 810.1574550649191
avg_train_sample_per_sec: 810.1574550649191
avg_episode_per_sec: 8.58824157312635
collect_time: 0.34931481310299467
reward_mean: 673.0
reward_std: 45.36518478393555
reward_max: 736.0
reward_min: 631.0
total_envstep_count: 2381256
total_train_sample_count: 2381204
total_episode_count: 15248
total_duration: 3027.9949863609863
[2024-11-20 00:35:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 304
train_sample_count: 304
avg_envstep_per_episode: 304.0
avg_sample_per_episode: 304.0
avg_envstep_per_sec: 811.4297924236457
avg_train_sample_per_sec: 811.4297924236457
avg_episode_per_sec: 2.6691769487619923
collect_time: 0.3746473235743386
reward_mean: 1296.0
reward_std: 0.0
reward_max: 1296.0
reward_min: 1296.0
total_envstep_count: 2382215
total_train_sample_count: 2382168
total_episode_count: 15249
total_duration: 3028.3696336845605
[2024-11-20 00:35:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 185
train_sample_count: 185
avg_envstep_per_episode: 185.0
avg_sample_per_episode: 185.0
avg_envstep_per_sec: 805.7829733842141
avg_train_sample_per_sec: 805.7829733842141
avg_episode_per_sec: 4.355583639914671
collect_time: 0.22959035634994507
reward_mean: 1705.0
reward_std: 0.0
reward_max: 1705.0
reward_min: 1705.0
total_envstep_count: 2383174
total_train_sample_count: 2383133
total_episode_count: 15250
total_duration: 3028.5992240409105
[2024-11-20 00:35:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 4831
train_sample_count: 4831
avg_envstep_per_episode: 690.1428571428571
avg_sample_per_episode: 690.1428571428571
avg_envstep_per_sec: 797.4543182529344
avg_train_sample_per_sec: 797.4543182529344
avg_episode_per_sec: 1.1554916637902175
collect_time: 6.058027261779422
reward_mean: 1094.7142333984375
reward_std: 492.1679992675781
reward_max: 1878.0
reward_min: 595.0
total_envstep_count: 2384175
total_train_sample_count: 2384112
total_episode_count: 15257
total_duration: 3034.65725130269
[2024-11-20 00:35:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 370
train_sample_count: 370
avg_envstep_per_episode: 185.0
avg_sample_per_episode: 185.0
avg_envstep_per_sec: 807.0226577892605
avg_train_sample_per_sec: 807.0226577892605
avg_episode_per_sec: 4.362284636698706
collect_time: 0.45847535559109276
reward_mean: 1674.0
reward_std: 28.0
reward_max: 1702.0
reward_min: 1646.0
total_envstep_count: 2385141
total_train_sample_count: 2385094
total_episode_count: 15259
total_duration: 3035.115726658281
[2024-11-20 00:35:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 460
train_sample_count: 460
avg_envstep_per_episode: 153.33333333333334
avg_sample_per_episode: 153.33333333333334
avg_envstep_per_sec: 797.7724762740166
avg_train_sample_per_sec: 797.7724762740166
avg_episode_per_sec: 5.202863975700109
collect_time: 0.5766055030482156
reward_mean: 1093.0
reward_std: 440.63818359375
reward_max: 1652.0
reward_min: 575.0
total_envstep_count: 2386122
total_train_sample_count: 2386082
total_episode_count: 15262
total_duration: 3035.692332161329
[2024-11-20 00:35:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 323
train_sample_count: 323
avg_envstep_per_episode: 161.5
avg_sample_per_episode: 161.5
avg_envstep_per_sec: 802.4810186678723
avg_train_sample_per_sec: 802.4810186678723
avg_episode_per_sec: 4.968922716209735
collect_time: 0.4025017321109772
reward_mean: 1079.5
reward_std: 343.5
reward_max: 1423.0
reward_min: 736.0
total_envstep_count: 2387088
total_train_sample_count: 2387053
total_episode_count: 15264
total_duration: 3036.09483389344
[2024-11-20 00:35:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 810
train_sample_count: 810
avg_envstep_per_episode: 270.0
avg_sample_per_episode: 270.0
avg_envstep_per_sec: 804.8116736846316
avg_train_sample_per_sec: 804.8116736846316
avg_episode_per_sec: 2.9807839766097466
collect_time: 1.0064466340201241
reward_mean: 1656.6666259765625
reward_std: 479.1251220703125
reward_max: 2334.0
reward_min: 1302.0
total_envstep_count: 2388053
total_train_sample_count: 2388019
total_episode_count: 15267
total_duration: 3037.10128052746
[2024-11-20 00:36:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2735
train_sample_count: 2735
avg_envstep_per_episode: 547.0
avg_sample_per_episode: 547.0
avg_envstep_per_sec: 800.9893149866665
avg_train_sample_per_sec: 800.9893149866665
avg_episode_per_sec: 1.4643314716392442
collect_time: 3.414527446031571
reward_mean: 988.4000244140625
reward_std: 390.8302001953125
reward_max: 1721.0
reward_min: 620.0
total_envstep_count: 2389024
total_train_sample_count: 2388990
total_episode_count: 15272
total_duration: 3040.5158079734915
[2024-11-20 00:36:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 567
train_sample_count: 567
avg_envstep_per_episode: 189.0
avg_sample_per_episode: 189.0
avg_envstep_per_sec: 801.1602311852561
avg_train_sample_per_sec: 801.1602311852561
avg_episode_per_sec: 4.238943022144213
collect_time: 0.7077235962663377
reward_mean: 1462.0
reward_std: 302.2724914550781
reward_max: 1693.0
reward_min: 1035.0
total_envstep_count: 2390030
total_train_sample_count: 2389977
total_episode_count: 15275
total_duration: 3041.223531569758
[2024-11-20 00:36:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1264
train_sample_count: 1264
avg_envstep_per_episode: 180.57142857142858
avg_sample_per_episode: 180.57142857142858
avg_envstep_per_sec: 793.5600929393214
avg_train_sample_per_sec: 793.5600929393214
avg_episode_per_sec: 4.394715704569027
collect_time: 1.5928220323153903
reward_mean: 1185.0
reward_std: 399.79852294921875
reward_max: 1688.0
reward_min: 637.0
total_envstep_count: 2391007
total_train_sample_count: 2390965
total_episode_count: 15282
total_duration: 3042.8163536020734
[2024-11-20 00:36:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 404
train_sample_count: 404
avg_envstep_per_episode: 101.0
avg_sample_per_episode: 101.0
avg_envstep_per_sec: 799.3200509809063
avg_train_sample_per_sec: 799.3200509809063
avg_episode_per_sec: 7.9140599107020435
collect_time: 0.5054295829364231
reward_mean: 902.5
reward_std: 305.66033935546875
reward_max: 1322.0
reward_min: 602.0
total_envstep_count: 2391971
total_train_sample_count: 2391933
total_episode_count: 15286
total_duration: 3043.3217831850097
[2024-11-20 00:36:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 509
train_sample_count: 509
avg_envstep_per_episode: 254.5
avg_sample_per_episode: 254.5
avg_envstep_per_sec: 712.5661283798585
avg_train_sample_per_sec: 712.5661283798585
avg_episode_per_sec: 2.7998669091546504
collect_time: 0.7143196676458632
reward_mean: 1303.0
reward_std: 13.0
reward_max: 1316.0
reward_min: 1290.0
total_envstep_count: 2392937
total_train_sample_count: 2392910
total_episode_count: 15288
total_duration: 3044.0361028526554
[2024-11-20 00:36:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 985
train_sample_count: 985
avg_envstep_per_episode: 164.16666666666666
avg_sample_per_episode: 164.16666666666666
avg_envstep_per_sec: 713.906216063792
avg_train_sample_per_sec: 713.906216063792
avg_episode_per_sec: 4.348667305972337
collect_time: 1.3797330487342108
reward_mean: 1102.3333740234375
reward_std: 302.5192565917969
reward_max: 1324.0
reward_min: 612.0
total_envstep_count: 2393907
total_train_sample_count: 2393883
total_episode_count: 15294
total_duration: 3045.4158359013895
[2024-11-20 00:36:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2694
train_sample_count: 2694
avg_envstep_per_episode: 538.8
avg_sample_per_episode: 538.8
avg_envstep_per_sec: 794.6347514571656
avg_train_sample_per_sec: 794.6347514571656
avg_episode_per_sec: 1.4748232209672711
collect_time: 3.3902368290083755
reward_mean: 1274.0
reward_std: 254.32814025878906
reward_max: 1571.0
reward_min: 800.0
total_envstep_count: 2394926
total_train_sample_count: 2394873
total_episode_count: 15299
total_duration: 3048.806072730398
[2024-11-20 00:36:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2822
train_sample_count: 2822
avg_envstep_per_episode: 470.3333333333333
avg_sample_per_episode: 470.3333333333333
avg_envstep_per_sec: 782.1196693460313
avg_train_sample_per_sec: 782.1196693460313
avg_episode_per_sec: 1.6629050375890104
collect_time: 3.608143498500189
reward_mean: 1106.3333740234375
reward_std: 333.25799560546875
reward_max: 1574.0
reward_min: 593.0
total_envstep_count: 2395889
total_train_sample_count: 2395859
total_episode_count: 15305
total_duration: 3052.414216228898
[2024-11-20 00:36:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 777
train_sample_count: 777
avg_envstep_per_episode: 194.25
avg_sample_per_episode: 194.25
avg_envstep_per_sec: 793.4819964499633
avg_train_sample_per_sec: 793.4819964499633
avg_episode_per_sec: 4.084849402573814
collect_time: 0.979228266647884
reward_mean: 1348.75
reward_std: 567.3532104492188
reward_max: 1924.0
reward_min: 746.0
total_envstep_count: 2396886
total_train_sample_count: 2396840
total_episode_count: 15309
total_duration: 3053.393444495546
[2024-11-20 00:36:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 599
train_sample_count: 599
avg_envstep_per_episode: 149.75
avg_sample_per_episode: 149.75
avg_envstep_per_sec: 794.2998087808816
avg_train_sample_per_sec: 794.2998087808816
avg_episode_per_sec: 5.304172345782181
collect_time: 0.7541233088288988
reward_mean: 1175.75
reward_std: 310.8813171386719
reward_max: 1438.0
reward_min: 645.0
total_envstep_count: 2397866
total_train_sample_count: 2397823
total_episode_count: 15313
total_duration: 3054.1475678043753
[2024-11-20 00:36:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1188
train_sample_count: 1188
avg_envstep_per_episode: 237.6
avg_sample_per_episode: 237.6
avg_envstep_per_sec: 781.2551760070497
avg_train_sample_per_sec: 781.2551760070497
avg_episode_per_sec: 3.2881110101306805
collect_time: 1.5206299253872464
reward_mean: 1346.0
reward_std: 618.7293701171875
reward_max: 2313.0
reward_min: 598.0
total_envstep_count: 2398845
total_train_sample_count: 2398807
total_episode_count: 15318
total_duration: 3055.6681977297626
[2024-11-20 00:36:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1058
train_sample_count: 1058
avg_envstep_per_episode: 176.33333333333334
avg_sample_per_episode: 176.33333333333334
avg_envstep_per_sec: 786.5083469843808
avg_train_sample_per_sec: 786.5083469843808
avg_episode_per_sec: 4.460349793862273
collect_time: 1.3451859780720303
reward_mean: 1275.6666259765625
reward_std: 639.4048461914062
reward_max: 2342.0
reward_min: 627.0
total_envstep_count: 2399817
total_train_sample_count: 2399781
total_episode_count: 15324
total_duration: 3057.0133837078347
[2024-11-20 00:36:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 897
train_sample_count: 897
avg_envstep_per_episode: 128.14285714285714
avg_sample_per_episode: 128.14285714285714
avg_envstep_per_sec: 793.8429690646336
avg_train_sample_per_sec: 793.8429690646336
avg_episode_per_sec: 6.19498415100606
collect_time: 1.1299463936260767
reward_mean: 1045.2857666015625
reward_std: 333.2964172363281
reward_max: 1349.0
reward_min: 612.0
total_envstep_count: 2400852
total_train_sample_count: 2400834
total_episode_count: 15331
total_duration: 3058.143330101461
[2024-11-20 00:36:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 809
train_sample_count: 809
avg_envstep_per_episode: 115.57142857142857
avg_sample_per_episode: 115.57142857142857
avg_envstep_per_sec: 802.108819758283
avg_train_sample_per_sec: 802.108819758283
avg_episode_per_sec: 6.940372976894908
collect_time: 1.0085913283484325
reward_mean: 836.2857055664062
reward_std: 342.0830078125
reward_max: 1424.0
reward_min: 603.0
total_envstep_count: 2401886
total_train_sample_count: 2401847
total_episode_count: 15338
total_duration: 3059.151921429809
[2024-11-20 00:36:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 690
train_sample_count: 690
avg_envstep_per_episode: 172.5
avg_sample_per_episode: 172.5
avg_envstep_per_sec: 799.1946830257377
avg_train_sample_per_sec: 799.1946830257377
avg_episode_per_sec: 4.633012655221668
collect_time: 0.863369107246399
reward_mean: 1227.75
reward_std: 594.443603515625
reward_max: 1692.0
reward_min: 232.0
total_envstep_count: 2402931
total_train_sample_count: 2402873
total_episode_count: 15342
total_duration: 3060.0152905370555
[2024-11-20 00:36:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2406
train_sample_count: 2406
avg_envstep_per_episode: 300.75
avg_sample_per_episode: 300.75
avg_envstep_per_sec: 791.5253516108743
avg_train_sample_per_sec: 791.5253516108743
avg_episode_per_sec: 2.6318382430951766
collect_time: 3.039700491087777
reward_mean: 1297.625
reward_std: 537.2766723632812
reward_max: 1852.0
reward_min: 603.0
total_envstep_count: 2403878
total_train_sample_count: 2403851
total_episode_count: 15350
total_duration: 3063.0549910281434
[2024-11-20 00:37:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 395
train_sample_count: 395
avg_envstep_per_episode: 98.75
avg_sample_per_episode: 98.75
avg_envstep_per_sec: 792.4813857895089
avg_train_sample_per_sec: 792.4813857895089
avg_episode_per_sec: 8.025127957362114
collect_time: 0.498434420142855
reward_mean: 639.25
reward_std: 73.47576141357422
reward_max: 764.0
reward_min: 574.0
total_envstep_count: 2404835
total_train_sample_count: 2404822
total_episode_count: 15354
total_duration: 3063.5534254482864
[2024-11-20 00:37:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1401
train_sample_count: 1401
avg_envstep_per_episode: 175.125
avg_sample_per_episode: 175.125
avg_envstep_per_sec: 785.4317098299329
avg_train_sample_per_sec: 785.4317098299329
avg_episode_per_sec: 4.484977643568496
collect_time: 1.7837324142456055
reward_mean: 1339.375
reward_std: 515.3986206054688
reward_max: 1856.0
reward_min: 608.0
total_envstep_count: 2405860
total_train_sample_count: 2405827
total_episode_count: 15362
total_duration: 3065.337157862532
[2024-11-20 00:37:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 757
train_sample_count: 757
avg_envstep_per_episode: 189.25
avg_sample_per_episode: 189.25
avg_envstep_per_sec: 783.0008313714342
avg_train_sample_per_sec: 783.0008313714342
avg_episode_per_sec: 4.137388805133074
collect_time: 0.9667933540684837
reward_mean: 1535.0
reward_std: 606.3163452148438
reward_max: 2343.0
reward_min: 652.0
total_envstep_count: 2406850
total_train_sample_count: 2406824
total_episode_count: 15366
total_duration: 3066.3039512166006
[2024-11-20 00:37:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 920
train_sample_count: 920
avg_envstep_per_episode: 131.42857142857142
avg_sample_per_episode: 131.42857142857142
avg_envstep_per_sec: 795.174552170179
avg_train_sample_per_sec: 795.174552170179
avg_episode_per_sec: 6.050241157816579
collect_time: 1.1569786752973283
reward_mean: 955.4285888671875
reward_std: 472.4797668457031
reward_max: 1703.0
reward_min: 612.0
total_envstep_count: 2407845
total_train_sample_count: 2407804
total_episode_count: 15373
total_duration: 3067.460929891898
[2024-11-20 00:37:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 963
train_sample_count: 963
avg_envstep_per_episode: 160.5
avg_sample_per_episode: 160.5
avg_envstep_per_sec: 784.526943949462
avg_train_sample_per_sec: 784.526943949462
avg_episode_per_sec: 4.888018342364249
collect_time: 1.2274913021496365
reward_mean: 1207.1666259765625
reward_std: 621.8677368164062
reward_max: 2339.0
reward_min: 610.0
total_envstep_count: 2408816
total_train_sample_count: 2408791
total_episode_count: 15379
total_duration: 3068.688421194048
[2024-11-20 00:37:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1056
train_sample_count: 1056
avg_envstep_per_episode: 211.2
avg_sample_per_episode: 211.2
avg_envstep_per_sec: 789.3463059447711
avg_train_sample_per_sec: 789.3463059447711
avg_episode_per_sec: 3.737435160723348
collect_time: 1.3378158509731293
reward_mean: 1541.800048828125
reward_std: 532.9853515625
reward_max: 2335.0
reward_min: 654.0
total_envstep_count: 2409819
total_train_sample_count: 2409775
total_episode_count: 15384
total_duration: 3070.026237045021
[2024-11-20 00:37:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 823
train_sample_count: 823
avg_envstep_per_episode: 164.6
avg_sample_per_episode: 164.6
avg_envstep_per_sec: 783.7666663648754
avg_train_sample_per_sec: 783.7666663648754
avg_episode_per_sec: 4.7616443886079916
collect_time: 1.0500574154513225
reward_mean: 1084.5999755859375
reward_std: 393.3490295410156
reward_max: 1564.0
reward_min: 581.0
total_envstep_count: 2410790
total_train_sample_count: 2410754
total_episode_count: 15389
total_duration: 3071.076294460472
[2024-11-20 00:37:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 884
train_sample_count: 884
avg_envstep_per_episode: 176.8
avg_sample_per_episode: 176.8
avg_envstep_per_sec: 789.8933270713466
avg_train_sample_per_sec: 789.8933270713466
avg_episode_per_sec: 4.467722438186349
collect_time: 1.1191384579454149
reward_mean: 1132.800048828125
reward_std: 613.396240234375
reward_max: 1920.0
reward_min: 624.0
total_envstep_count: 2411793
total_train_sample_count: 2411746
total_episode_count: 15394
total_duration: 3072.1954329184177
[2024-11-20 00:37:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 643
train_sample_count: 643
avg_envstep_per_episode: 128.6
avg_sample_per_episode: 128.6
avg_envstep_per_sec: 787.4276272597862
avg_train_sample_per_sec: 787.4276272597862
avg_episode_per_sec: 6.123076417261167
collect_time: 0.8165829820292336
reward_mean: 912.0
reward_std: 327.519775390625
reward_max: 1316.0
reward_min: 630.0
total_envstep_count: 2412764
total_train_sample_count: 2412737
total_episode_count: 15399
total_duration: 3073.012015900447
[2024-11-20 00:37:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1158
train_sample_count: 1158
avg_envstep_per_episode: 144.75
avg_sample_per_episode: 144.75
avg_envstep_per_sec: 786.9193673303384
avg_train_sample_per_sec: 786.9193673303384
avg_episode_per_sec: 5.43640322853429
collect_time: 1.471561189208712
reward_mean: 713.5
reward_std: 175.710693359375
reward_max: 1025.0
reward_min: 582.0
total_envstep_count: 2413780
total_train_sample_count: 2413727
total_episode_count: 15407
total_duration: 3074.4835770896557
[2024-11-20 00:37:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1531
train_sample_count: 1531
avg_envstep_per_episode: 218.71428571428572
avg_sample_per_episode: 218.71428571428572
avg_envstep_per_sec: 789.8075305113729
avg_train_sample_per_sec: 789.8075305113729
avg_episode_per_sec: 3.6111382845066036
collect_time: 1.9384469517639706
reward_mean: 1205.857177734375
reward_std: 600.3214111328125
reward_max: 2279.0
reward_min: 206.0
total_envstep_count: 2414765
total_train_sample_count: 2414730
total_episode_count: 15414
total_duration: 3076.4220240414197
[2024-11-20 00:37:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1182
train_sample_count: 1182
avg_envstep_per_episode: 168.85714285714286
avg_sample_per_episode: 168.85714285714286
avg_envstep_per_sec: 795.9602957142985
avg_train_sample_per_sec: 795.9602957142985
avg_episode_per_sec: 4.713808857868096
collect_time: 1.4849986944879803
reward_mean: 1242.0
reward_std: 440.6867980957031
reward_max: 1911.0
reward_min: 598.0
total_envstep_count: 2415727
total_train_sample_count: 2415708
total_episode_count: 15421
total_duration: 3077.9070227359075
[2024-11-20 00:37:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 954
train_sample_count: 954
avg_envstep_per_episode: 106.0
avg_sample_per_episode: 106.0
avg_envstep_per_sec: 785.5791692896287
avg_train_sample_per_sec: 785.5791692896287
avg_episode_per_sec: 7.411124238581403
collect_time: 1.214390652520316
reward_mean: 899.6666870117188
reward_std: 536.1334838867188
reward_max: 1706.0
reward_min: 242.0
total_envstep_count: 2416727
total_train_sample_count: 2416698
total_episode_count: 15430
total_duration: 3079.1214133884278
[2024-11-20 00:37:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1005
train_sample_count: 1005
avg_envstep_per_episode: 125.625
avg_sample_per_episode: 125.625
avg_envstep_per_sec: 783.8363134436983
avg_train_sample_per_sec: 783.8363134436983
avg_episode_per_sec: 6.239493042337896
collect_time: 1.28215544848215
reward_mean: 892.125
reward_std: 352.1943359375
reward_max: 1570.0
reward_min: 624.0
total_envstep_count: 2417727
total_train_sample_count: 2417679
total_episode_count: 15438
total_duration: 3080.40356883691
[2024-11-20 00:37:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 918
train_sample_count: 918
avg_envstep_per_episode: 131.14285714285714
avg_sample_per_episode: 131.14285714285714
avg_envstep_per_sec: 796.6183064347695
avg_train_sample_per_sec: 796.6183064347695
avg_episode_per_sec: 6.074431530548352
collect_time: 1.1523712078730264
reward_mean: 874.7142944335938
reward_std: 514.4454956054688
reward_max: 1903.0
reward_min: 244.0
total_envstep_count: 2418722
total_train_sample_count: 2418693
total_episode_count: 15445
total_duration: 3081.555940044783
[2024-11-20 00:37:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 831
train_sample_count: 831
avg_envstep_per_episode: 166.2
avg_sample_per_episode: 166.2
avg_envstep_per_sec: 794.095211401111
avg_train_sample_per_sec: 794.095211401111
avg_episode_per_sec: 4.777949527082497
collect_time: 1.0464740097522736
reward_mean: 1107.4000244140625
reward_std: 587.5888061523438
reward_max: 1698.0
reward_min: 240.0
total_envstep_count: 2419710
total_train_sample_count: 2419668
total_episode_count: 15450
total_duration: 3082.602414054535
[2024-11-20 00:37:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1098
train_sample_count: 1098
avg_envstep_per_episode: 99.81818181818181
avg_sample_per_episode: 99.81818181818181
avg_envstep_per_sec: 804.4368828813058
avg_train_sample_per_sec: 804.4368828813058
avg_episode_per_sec: 8.059021595350059
collect_time: 1.3649299570492335
reward_mean: 702.9091186523438
reward_std: 259.2529296875
reward_max: 1307.0
reward_min: 232.0
total_envstep_count: 2420723
total_train_sample_count: 2420694
total_episode_count: 15461
total_duration: 3083.9673440115844
[2024-11-20 00:38:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 272
train_sample_count: 272
avg_envstep_per_episode: 54.4
avg_sample_per_episode: 54.4
avg_envstep_per_sec: 761.0328593234091
avg_train_sample_per_sec: 761.0328593234091
avg_episode_per_sec: 13.989574619915608
collect_time: 0.3574090089116779
reward_mean: 398.6000061035156
reward_std: 196.9929962158203
reward_max: 654.0
reward_min: 228.0
total_envstep_count: 2421695
total_train_sample_count: 2421662
total_episode_count: 15466
total_duration: 3084.3247530204962
[2024-11-20 00:38:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 996
train_sample_count: 996
avg_envstep_per_episode: 199.2
avg_sample_per_episode: 199.2
avg_envstep_per_sec: 758.447455576018
avg_train_sample_per_sec: 758.447455576018
avg_episode_per_sec: 3.8074671464659535
collect_time: 1.3132089674472809
reward_mean: 1484.4000244140625
reward_std: 388.438232421875
reward_max: 1862.0
reward_min: 814.0
total_envstep_count: 2422716
total_train_sample_count: 2422694
total_episode_count: 15471
total_duration: 3085.6379619879435
[2024-11-20 00:38:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1548
train_sample_count: 1548
avg_envstep_per_episode: 258.0
avg_sample_per_episode: 258.0
avg_envstep_per_sec: 774.7670632179276
avg_train_sample_per_sec: 774.7670632179276
avg_episode_per_sec: 3.0029731132477813
collect_time: 1.9980198868683405
reward_mean: 1502.3333740234375
reward_std: 691.1045532226562
reward_max: 2333.0
reward_min: 621.0
total_envstep_count: 2423736
total_train_sample_count: 2423702
total_episode_count: 15477
total_duration: 3087.635981874812
[2024-11-20 00:38:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 685
train_sample_count: 685
avg_envstep_per_episode: 228.33333333333334
avg_sample_per_episode: 228.33333333333334
avg_envstep_per_sec: 793.1522582817079
avg_train_sample_per_sec: 793.1522582817079
avg_episode_per_sec: 3.4736595253213483
collect_time: 0.8636425009795599
reward_mean: 1798.3333740234375
reward_std: 165.04208374023438
reward_max: 1920.0
reward_min: 1565.0
total_envstep_count: 2424726
total_train_sample_count: 2424687
total_episode_count: 15480
total_duration: 3088.4996243757914
[2024-11-20 00:38:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1332
train_sample_count: 1332
avg_envstep_per_episode: 190.28571428571428
avg_sample_per_episode: 190.28571428571428
avg_envstep_per_sec: 797.886152065215
avg_train_sample_per_sec: 797.886152065215
avg_episode_per_sec: 4.193095393736114
collect_time: 1.6694111015115467
reward_mean: 1264.857177734375
reward_std: 556.5440063476562
reward_max: 2354.0
reward_min: 615.0
total_envstep_count: 2425761
total_train_sample_count: 2425719
total_episode_count: 15487
total_duration: 3090.169035477303
[2024-11-20 00:38:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1033
train_sample_count: 1033
avg_envstep_per_episode: 206.6
avg_sample_per_episode: 206.6
avg_envstep_per_sec: 798.4500304391016
avg_train_sample_per_sec: 798.4500304391016
avg_episode_per_sec: 3.864714571341247
collect_time: 1.2937566041946411
reward_mean: 1346.4000244140625
reward_std: 680.0189819335938
reward_max: 2336.0
reward_min: 607.0
total_envstep_count: 2426772
total_train_sample_count: 2426728
total_episode_count: 15492
total_duration: 3091.462792081498
[2024-11-20 00:38:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1147
train_sample_count: 1147
avg_envstep_per_episode: 191.16666666666666
avg_sample_per_episode: 191.16666666666666
avg_envstep_per_sec: 794.8307759548672
avg_train_sample_per_sec: 794.8307759548672
avg_episode_per_sec: 4.157789586511948
collect_time: 1.4430744690554482
reward_mean: 1332.8333740234375
reward_std: 311.6030578613281
reward_max: 1502.0
reward_min: 639.0
total_envstep_count: 2427758
total_train_sample_count: 2427731
total_episode_count: 15498
total_duration: 3092.905866550553
[2024-11-20 00:38:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 793
train_sample_count: 793
avg_envstep_per_episode: 132.16666666666666
avg_sample_per_episode: 132.16666666666666
avg_envstep_per_sec: 785.6830905156731
avg_train_sample_per_sec: 785.6830905156731
avg_episode_per_sec: 5.944638768088321
collect_time: 1.0093127999986922
reward_mean: 1072.6666259765625
reward_std: 462.15283203125
reward_max: 1692.0
reward_min: 604.0
total_envstep_count: 2428752
total_train_sample_count: 2428716
total_episode_count: 15504
total_duration: 3093.9151793505516
[2024-11-20 00:38:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 745
train_sample_count: 745
avg_envstep_per_episode: 186.25
avg_sample_per_episode: 186.25
avg_envstep_per_sec: 790.8608646788687
avg_train_sample_per_sec: 790.8608646788687
avg_episode_per_sec: 4.24623283049057
collect_time: 0.9420114627906255
reward_mean: 1063.25
reward_std: 737.0211181640625
reward_max: 2337.0
reward_min: 583.0
total_envstep_count: 2429732
total_train_sample_count: 2429689
total_episode_count: 15508
total_duration: 3094.857190813342
[2024-11-20 00:38:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 819
train_sample_count: 819
avg_envstep_per_episode: 163.8
avg_sample_per_episode: 163.8
avg_envstep_per_sec: 806.0532381183135
avg_train_sample_per_sec: 806.0532381183135
avg_episode_per_sec: 4.920959939672244
collect_time: 1.0160619190761022
reward_mean: 1234.5999755859375
reward_std: 441.80291748046875
reward_max: 1695.0
reward_min: 628.0
total_envstep_count: 2430711
total_train_sample_count: 2430676
total_episode_count: 15513
total_duration: 3095.873252732418
[2024-11-20 00:38:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 951
train_sample_count: 951
avg_envstep_per_episode: 158.5
avg_sample_per_episode: 158.5
avg_envstep_per_sec: 796.8821081444847
avg_train_sample_per_sec: 796.8821081444847
avg_episode_per_sec: 5.027647369996749
collect_time: 1.1934011195387157
reward_mean: 863.0
reward_std: 280.769775390625
reward_max: 1410.0
reward_min: 615.0
total_envstep_count: 2431699
total_train_sample_count: 2431663
total_episode_count: 15519
total_duration: 3097.0666538519567
[2024-11-20 00:38:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 648
train_sample_count: 648
avg_envstep_per_episode: 324.0
avg_sample_per_episode: 324.0
avg_envstep_per_sec: 799.487860326231
avg_train_sample_per_sec: 799.487860326231
avg_episode_per_sec: 2.467555124463676
collect_time: 0.8105188735893796
reward_mean: 1822.0
reward_std: 1189.0
reward_max: 3011.0
reward_min: 633.0
total_envstep_count: 2432659
total_train_sample_count: 2432623
total_episode_count: 15521
total_duration: 3097.877172725546
[2024-11-20 00:39:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 937
train_sample_count: 937
avg_envstep_per_episode: 187.4
avg_sample_per_episode: 187.4
avg_envstep_per_sec: 804.1959542362671
avg_train_sample_per_sec: 804.1959542362671
avg_episode_per_sec: 4.291333800620422
collect_time: 1.1651389130524226
reward_mean: 1183.4000244140625
reward_std: 483.8556213378906
reward_max: 1696.0
reward_min: 597.0
total_envstep_count: 2433686
total_train_sample_count: 2433644
total_episode_count: 15526
total_duration: 3099.0423116385987
[2024-11-20 00:39:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1410
train_sample_count: 1410
avg_envstep_per_episode: 201.42857142857142
avg_sample_per_episode: 201.42857142857142
avg_envstep_per_sec: 801.3913108118203
avg_train_sample_per_sec: 801.3913108118203
avg_episode_per_sec: 3.97853842247003
collect_time: 1.7594400899750844
reward_mean: 1386.142822265625
reward_std: 583.8141479492188
reward_max: 2331.0
reward_min: 588.0
total_envstep_count: 2434695
total_train_sample_count: 2434646
total_episode_count: 15533
total_duration: 3100.801751728574
[2024-11-20 00:39:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 771
train_sample_count: 771
avg_envstep_per_episode: 192.75
avg_sample_per_episode: 192.75
avg_envstep_per_sec: 801.3508857736642
avg_train_sample_per_sec: 801.3508857736642
avg_episode_per_sec: 4.157462442405522
collect_time: 0.9621253481933049
reward_mean: 1303.75
reward_std: 453.55340576171875
reward_max: 1921.0
reward_min: 640.0
total_envstep_count: 2435667
total_train_sample_count: 2435621
total_episode_count: 15537
total_duration: 3101.763877076767
[2024-11-20 00:39:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 416
train_sample_count: 416
avg_envstep_per_episode: 208.0
avg_sample_per_episode: 208.0
avg_envstep_per_sec: 810.8147202197928
avg_train_sample_per_sec: 810.8147202197928
avg_episode_per_sec: 3.8981476933643884
collect_time: 0.5130641928740911
reward_mean: 1489.5
reward_std: 70.5
reward_max: 1560.0
reward_min: 1419.0
total_envstep_count: 2436625
total_train_sample_count: 2436589
total_episode_count: 15539
total_duration: 3102.276941269641
[2024-11-20 00:39:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1448
train_sample_count: 1448
avg_envstep_per_episode: 206.85714285714286
avg_sample_per_episode: 206.85714285714286
avg_envstep_per_sec: 802.9340085317534
avg_train_sample_per_sec: 802.9340085317534
avg_episode_per_sec: 3.88158705781925
collect_time: 1.8033860623836515
reward_mean: 1320.2857666015625
reward_std: 644.8948364257812
reward_max: 2337.0
reward_min: 217.0
total_envstep_count: 2437595
total_train_sample_count: 2437569
total_episode_count: 15546
total_duration: 3104.080327332025
[2024-11-20 00:39:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 743
train_sample_count: 743
avg_envstep_per_episode: 148.6
avg_sample_per_episode: 148.6
avg_envstep_per_sec: 793.6098773776097
avg_train_sample_per_sec: 793.6098773776097
avg_episode_per_sec: 5.340577909674359
collect_time: 0.9362282667841232
reward_mean: 849.4000244140625
reward_std: 277.5093688964844
reward_max: 1307.0
reward_min: 626.0
total_envstep_count: 2438623
total_train_sample_count: 2438588
total_episode_count: 15551
total_duration: 3105.0165555988087
[2024-11-20 00:39:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1042
train_sample_count: 1042
avg_envstep_per_episode: 94.72727272727273
avg_sample_per_episode: 94.72727272727273
avg_envstep_per_sec: 801.9662198153035
avg_train_sample_per_sec: 801.9662198153035
avg_episode_per_sec: 8.46605414392355
collect_time: 1.29930659702846
reward_mean: 782.5454711914062
reward_std: 416.5187683105469
reward_max: 1689.0
reward_min: 245.0
total_envstep_count: 2439598
total_train_sample_count: 2439570
total_episode_count: 15562
total_duration: 3106.3158621958373
[2024-11-20 00:39:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 555
train_sample_count: 555
avg_envstep_per_episode: 138.75
avg_sample_per_episode: 138.75
avg_envstep_per_sec: 802.8519547200971
avg_train_sample_per_sec: 802.8519547200971
avg_episode_per_sec: 5.786320394379078
collect_time: 0.6912856059415
reward_mean: 1085.5
reward_std: 295.24609375
reward_max: 1343.0
reward_min: 610.0
total_envstep_count: 2440594
total_train_sample_count: 2440557
total_episode_count: 15566
total_duration: 3107.007147801779
[2024-11-20 00:39:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 742
train_sample_count: 742
avg_envstep_per_episode: 185.5
avg_sample_per_episode: 185.5
avg_envstep_per_sec: 800.8319113461172
avg_train_sample_per_sec: 800.8319113461172
avg_episode_per_sec: 4.3171531608955105
collect_time: 0.9265365047114236
reward_mean: 1357.75
reward_std: 438.79058837890625
reward_max: 1687.0
reward_min: 618.0
total_envstep_count: 2441591
total_train_sample_count: 2441539
total_episode_count: 15570
total_duration: 3107.9336843064902
[2024-11-20 00:39:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 868
train_sample_count: 868
avg_envstep_per_episode: 173.6
avg_sample_per_episode: 173.6
avg_envstep_per_sec: 808.875236303631
avg_train_sample_per_sec: 808.875236303631
avg_episode_per_sec: 4.659419563961008
collect_time: 1.0730950349853152
reward_mean: 1350.800048828125
reward_std: 299.361572265625
reward_max: 1854.0
reward_min: 1043.0
total_envstep_count: 2442554
total_train_sample_count: 2442527
total_episode_count: 15575
total_duration: 3109.0067793414755
[2024-11-20 00:39:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1212
train_sample_count: 1212
avg_envstep_per_episode: 173.14285714285714
avg_sample_per_episode: 173.14285714285714
avg_envstep_per_sec: 799.0907373364853
avg_train_sample_per_sec: 799.0907373364853
avg_episode_per_sec: 4.61521052917112
collect_time: 1.516723875488554
reward_mean: 1273.0
reward_std: 637.75341796875
reward_max: 2337.0
reward_min: 601.0
total_envstep_count: 2443533
total_train_sample_count: 2443499
total_episode_count: 15582
total_duration: 3110.523503216964
[2024-11-20 00:39:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2358
train_sample_count: 2358
avg_envstep_per_episode: 786.0
avg_sample_per_episode: 786.0
avg_envstep_per_sec: 800.7342466667197
avg_train_sample_per_sec: 800.7342466667197
avg_episode_per_sec: 1.0187458608991347
collect_time: 2.9447972405524485
reward_mean: 1683.6666259765625
reward_std: 742.60546875
reward_max: 2592.0
reward_min: 773.0
total_envstep_count: 2444507
total_train_sample_count: 2444477
total_episode_count: 15585
total_duration: 3113.4683004575163
[2024-11-20 00:39:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 388
train_sample_count: 388
avg_envstep_per_episode: 129.33333333333334
avg_sample_per_episode: 129.33333333333334
avg_envstep_per_sec: 817.456824722714
avg_train_sample_per_sec: 817.456824722714
avg_episode_per_sec: 6.3205424591962425
collect_time: 0.4746428046907698
reward_mean: 631.6666870117188
reward_std: 51.42200469970703
reward_max: 704.0
reward_min: 589.0
total_envstep_count: 2445504
total_train_sample_count: 2445465
total_episode_count: 15588
total_duration: 3113.942943262207
[2024-11-20 00:39:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1379
train_sample_count: 1379
avg_envstep_per_episode: 275.8
avg_sample_per_episode: 275.8
avg_envstep_per_sec: 800.5217975773735
avg_train_sample_per_sec: 800.5217975773735
avg_episode_per_sec: 2.9025445887504477
collect_time: 1.7226264221327645
reward_mean: 1101.800048828125
reward_std: 425.12701416015625
reward_max: 1660.0
reward_min: 530.0
total_envstep_count: 2446500
total_train_sample_count: 2446460
total_episode_count: 15593
total_duration: 3115.6655696843395
[2024-11-20 00:39:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 491
train_sample_count: 491
avg_envstep_per_episode: 163.66666666666666
avg_sample_per_episode: 163.66666666666666
avg_envstep_per_sec: 805.7719912105997
avg_train_sample_per_sec: 805.7719912105997
avg_episode_per_sec: 4.923250455461913
collect_time: 0.6093535210405078
reward_mean: 986.6666870117188
reward_std: 488.2010192871094
reward_max: 1677.0
reward_min: 632.0
total_envstep_count: 2447457
total_train_sample_count: 2447431
total_episode_count: 15596
total_duration: 3116.27492320538
[2024-11-20 00:39:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1323
train_sample_count: 1323
avg_envstep_per_episode: 264.6
avg_sample_per_episode: 264.6
avg_envstep_per_sec: 808.692189035291
avg_train_sample_per_sec: 808.692189035291
avg_episode_per_sec: 3.056281893557411
collect_time: 1.635974747794015
reward_mean: 1472.800048828125
reward_std: 437.9038391113281
reward_max: 1851.0
reward_min: 616.0
total_envstep_count: 2448453
total_train_sample_count: 2448406
total_episode_count: 15601
total_duration: 3117.9108979531743
[2024-11-20 00:40:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 923
train_sample_count: 923
avg_envstep_per_episode: 184.6
avg_sample_per_episode: 184.6
avg_envstep_per_sec: 796.0144709979546
avg_train_sample_per_sec: 796.0144709979546
avg_episode_per_sec: 4.312104393271693
collect_time: 1.1595266589096616
reward_mean: 1391.199951171875
reward_std: 410.28448486328125
reward_max: 1830.0
reward_min: 648.0
total_envstep_count: 2449432
total_train_sample_count: 2449389
total_episode_count: 15606
total_duration: 3119.070424612084
[2024-11-20 00:40:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 336
train_sample_count: 336
avg_envstep_per_episode: 112.0
avg_sample_per_episode: 112.0
avg_envstep_per_sec: 795.6056538027092
avg_train_sample_per_sec: 795.6056538027092
avg_episode_per_sec: 7.10362190895276
collect_time: 0.42231977411678856
reward_mean: 846.3333129882812
reward_std: 336.6861572265625
reward_max: 1322.0
reward_min: 590.0
total_envstep_count: 2450421
total_train_sample_count: 2450385
total_episode_count: 15609
total_duration: 3119.4927443862007
[2024-11-20 00:40:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 254
train_sample_count: 254
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 806.7833787298283
avg_train_sample_per_sec: 806.7833787298283
avg_episode_per_sec: 3.1763125146843634
collect_time: 0.314830482006073
reward_mean: 1300.0
reward_std: 0.0
reward_max: 1300.0
reward_min: 1300.0
total_envstep_count: 2451381
total_train_sample_count: 2451347
total_episode_count: 15610
total_duration: 3119.8075748682068
[2024-11-20 00:40:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1027
train_sample_count: 1027
avg_envstep_per_episode: 342.3333333333333
avg_sample_per_episode: 342.3333333333333
avg_envstep_per_sec: 807.4952806933289
avg_train_sample_per_sec: 807.4952806933289
avg_episode_per_sec: 2.358798288295995
collect_time: 1.2718340584209986
reward_mean: 1725.6666259765625
reward_std: 428.0851135253906
reward_max: 2315.0
reward_min: 1311.0
total_envstep_count: 2452339
total_train_sample_count: 2452314
total_episode_count: 15613
total_duration: 3121.079408926628
[2024-11-20 00:40:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 863
train_sample_count: 863
avg_envstep_per_episode: 287.6666666666667
avg_sample_per_episode: 287.6666666666667
avg_envstep_per_sec: 806.015495122326
avg_train_sample_per_sec: 806.015495122326
avg_episode_per_sec: 2.801907862534158
collect_time: 1.07069901909147
reward_mean: 1506.0
reward_std: 142.57862854003906
reward_max: 1645.0
reward_min: 1310.0
total_envstep_count: 2453313
total_train_sample_count: 2453285
total_episode_count: 15616
total_duration: 3122.1501079457194
[2024-11-20 00:40:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 824
train_sample_count: 824
avg_envstep_per_episode: 412.0
avg_sample_per_episode: 412.0
avg_envstep_per_sec: 807.2734347194079
avg_train_sample_per_sec: 807.2734347194079
avg_episode_per_sec: 1.959401540581087
collect_time: 1.020719826221466
reward_mean: 1586.0
reward_std: 253.0
reward_max: 1839.0
reward_min: 1333.0
total_envstep_count: 2454287
total_train_sample_count: 2454253
total_episode_count: 15618
total_duration: 3123.170827771941
[2024-11-20 00:40:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1868
train_sample_count: 1868
avg_envstep_per_episode: 311.3333333333333
avg_sample_per_episode: 311.3333333333333
avg_envstep_per_sec: 809.9449881091932
avg_train_sample_per_sec: 809.9449881091932
avg_episode_per_sec: 2.6015363643764235
collect_time: 2.3063294759818485
reward_mean: 1155.1666259765625
reward_std: 569.456298828125
reward_max: 2268.0
reward_min: 637.0
total_envstep_count: 2455281
total_train_sample_count: 2455233
total_episode_count: 15624
total_duration: 3125.4771572479226
[2024-11-20 00:40:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 602
train_sample_count: 602
avg_envstep_per_episode: 301.0
avg_sample_per_episode: 301.0
avg_envstep_per_sec: 810.6569733453327
avg_train_sample_per_sec: 810.6569733453327
avg_episode_per_sec: 2.693212536031006
collect_time: 0.7426075637340546
reward_mean: 1290.5
reward_std: 13.5
reward_max: 1304.0
reward_min: 1277.0
total_envstep_count: 2456239
total_train_sample_count: 2456195
total_episode_count: 15626
total_duration: 3126.2197648116567
[2024-11-20 00:40:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1291
train_sample_count: 1291
avg_envstep_per_episode: 184.42857142857142
avg_sample_per_episode: 184.42857142857142
avg_envstep_per_sec: 806.6951583882474
avg_train_sample_per_sec: 806.6951583882474
avg_episode_per_sec: 4.374024871198863
collect_time: 1.6003566980361938
reward_mean: 1372.5714111328125
reward_std: 386.0191955566406
reward_max: 1689.0
reward_min: 598.0
total_envstep_count: 2457218
total_train_sample_count: 2457186
total_episode_count: 15633
total_duration: 3127.820121509693
[2024-11-20 00:40:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 219
train_sample_count: 219
avg_envstep_per_episode: 73.0
avg_sample_per_episode: 73.0
avg_envstep_per_sec: 812.7766217892787
avg_train_sample_per_sec: 812.7766217892787
avg_episode_per_sec: 11.13392632588053
collect_time: 0.2694467263562339
reward_mean: 597.6666870117188
reward_std: 513.5953979492188
reward_max: 1324.0
reward_min: 234.0
total_envstep_count: 2458199
total_train_sample_count: 2458161
total_episode_count: 15636
total_duration: 3128.089568236049
[2024-11-20 00:40:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 937
train_sample_count: 937
avg_envstep_per_episode: 187.4
avg_sample_per_episode: 187.4
avg_envstep_per_sec: 799.762707018871
avg_train_sample_per_sec: 799.762707018871
avg_episode_per_sec: 4.2676771986065685
collect_time: 1.1715975148337228
reward_mean: 958.2000122070312
reward_std: 461.3555603027344
reward_max: 1829.0
reward_min: 582.0
total_envstep_count: 2459163
total_train_sample_count: 2459134
total_episode_count: 15641
total_duration: 3129.261165750883
[2024-11-20 00:40:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 3149
train_sample_count: 3149
avg_envstep_per_episode: 524.8333333333334
avg_sample_per_episode: 524.8333333333334
avg_envstep_per_sec: 806.5064912227637
avg_train_sample_per_sec: 806.5064912227637
avg_episode_per_sec: 1.5366906787350212
collect_time: 3.904494302613394
reward_mean: 1171.6666259765625
reward_std: 671.3495483398438
reward_max: 1683.0
reward_min: 181.0
total_envstep_count: 2460133
total_train_sample_count: 2460099
total_episode_count: 15647
total_duration: 3133.165660053496
[2024-11-20 00:40:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1324
train_sample_count: 1324
avg_envstep_per_episode: 189.14285714285714
avg_sample_per_episode: 189.14285714285714
avg_envstep_per_sec: 801.8747097062869
avg_train_sample_per_sec: 801.8747097062869
avg_episode_per_sec: 4.239518857963753
collect_time: 1.6511307614190236
reward_mean: 1462.0
reward_std: 229.73524475097656
reward_max: 1706.0
reward_min: 1049.0
total_envstep_count: 2461120
total_train_sample_count: 2461087
total_episode_count: 15654
total_duration: 3134.8167908149153
[2024-11-20 00:40:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 327
train_sample_count: 327
avg_envstep_per_episode: 109.0
avg_sample_per_episode: 109.0
avg_envstep_per_sec: 786.7027029308107
avg_train_sample_per_sec: 786.7027029308107
avg_episode_per_sec: 7.217455990190924
collect_time: 0.41565892526081627
reward_mean: 746.3333129882812
reward_std: 204.1589813232422
reward_max: 1035.0
reward_min: 597.0
total_envstep_count: 2462109
total_train_sample_count: 2462074
total_episode_count: 15657
total_duration: 3135.232449740176
[2024-11-20 00:40:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 852
train_sample_count: 852
avg_envstep_per_episode: 213.0
avg_sample_per_episode: 213.0
avg_envstep_per_sec: 801.0545830282258
avg_train_sample_per_sec: 801.0545830282258
avg_episode_per_sec: 3.7608196386301684
collect_time: 1.063597934586661
reward_mean: 1380.5
reward_std: 436.86639404296875
reward_max: 1919.0
reward_min: 715.0
total_envstep_count: 2463105
total_train_sample_count: 2463070
total_episode_count: 15661
total_duration: 3136.2960476747626
[2024-11-20 00:40:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 691
train_sample_count: 691
avg_envstep_per_episode: 230.33333333333334
avg_sample_per_episode: 230.33333333333334
avg_envstep_per_sec: 800.0461326577137
avg_train_sample_per_sec: 800.0461326577137
avg_episode_per_sec: 3.473427493448829
collect_time: 0.8637001940182277
reward_mean: 1385.3333740234375
reward_std: 251.27053833007812
reward_max: 1566.0
reward_min: 1030.0
total_envstep_count: 2464086
total_train_sample_count: 2464049
total_episode_count: 15664
total_duration: 3137.159747868781
[2024-11-20 00:40:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1779
train_sample_count: 1779
avg_envstep_per_episode: 222.375
avg_sample_per_episode: 222.375
avg_envstep_per_sec: 806.3632256014047
avg_train_sample_per_sec: 806.3632256014047
avg_episode_per_sec: 3.6261415428955805
collect_time: 2.2062018002782553
reward_mean: 1249.375
reward_std: 739.7933959960938
reward_max: 2325.0
reward_min: 184.0
total_envstep_count: 2465118
total_train_sample_count: 2465060
total_episode_count: 15672
total_duration: 3139.3659496690593
[2024-11-20 00:40:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 459
train_sample_count: 459
avg_envstep_per_episode: 153.0
avg_sample_per_episode: 153.0
avg_envstep_per_sec: 745.3915476333585
avg_train_sample_per_sec: 745.3915476333585
avg_episode_per_sec: 4.871840180610187
collect_time: 0.6157837467534202
reward_mean: 1234.6666259765625
reward_std: 458.00750732421875
reward_max: 1687.0
reward_min: 607.0
total_envstep_count: 2466085
total_train_sample_count: 2466047
total_episode_count: 15675
total_duration: 3139.981733415813
[2024-11-20 00:41:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 612
train_sample_count: 612
avg_envstep_per_episode: 306.0
avg_sample_per_episode: 306.0
avg_envstep_per_sec: 745.2216087121061
avg_train_sample_per_sec: 745.2216087121061
avg_episode_per_sec: 2.435364734353288
collect_time: 0.8212322252137321
reward_mean: 1565.5
reward_std: 759.5
reward_max: 2325.0
reward_min: 806.0
total_envstep_count: 2467043
total_train_sample_count: 2467007
total_episode_count: 15677
total_duration: 3140.8029656410267
[2024-11-20 00:41:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1245
train_sample_count: 1245
avg_envstep_per_episode: 249.0
avg_sample_per_episode: 249.0
avg_envstep_per_sec: 769.4829319675484
avg_train_sample_per_sec: 769.4829319675484
avg_episode_per_sec: 3.090292899468066
collect_time: 1.6179696108613695
reward_mean: 1241.800048828125
reward_std: 660.6304321289062
reward_max: 2303.0
reward_min: 593.0
total_envstep_count: 2468031
total_train_sample_count: 2468012
total_episode_count: 15682
total_duration: 3142.4209352518883
[2024-11-20 00:41:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 831
train_sample_count: 831
avg_envstep_per_episode: 166.2
avg_sample_per_episode: 166.2
avg_envstep_per_sec: 773.5937787384797
avg_train_sample_per_sec: 773.5937787384797
avg_episode_per_sec: 4.654595539942718
collect_time: 1.0742071909563882
reward_mean: 864.7999877929688
reward_std: 397.6251525878906
reward_max: 1645.0
reward_min: 604.0
total_envstep_count: 2469043
total_train_sample_count: 2468987
total_episode_count: 15687
total_duration: 3143.4951424428446
[2024-11-20 00:41:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 831
train_sample_count: 831
avg_envstep_per_episode: 207.75
avg_sample_per_episode: 207.75
avg_envstep_per_sec: 816.0007023455885
avg_train_sample_per_sec: 816.0007023455885
avg_episode_per_sec: 3.927801214659872
collect_time: 1.0183814764022827
reward_mean: 1776.0
reward_std: 80.38345336914062
reward_max: 1864.0
reward_min: 1682.0
total_envstep_count: 2469999
total_train_sample_count: 2469962
total_episode_count: 15691
total_duration: 3144.513523919247
[2024-11-20 00:41:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1145
train_sample_count: 1145
avg_envstep_per_episode: 229.0
avg_sample_per_episode: 229.0
avg_envstep_per_sec: 782.9950644125996
avg_train_sample_per_sec: 782.9950644125996
avg_episode_per_sec: 3.419192421015719
collect_time: 1.4623336110796246
reward_mean: 1275.800048828125
reward_std: 632.215576171875
reward_max: 2291.0
reward_min: 613.0
total_envstep_count: 2470956
total_train_sample_count: 2470927
total_episode_count: 15696
total_duration: 3145.9758575303263
[2024-11-20 00:41:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1680
train_sample_count: 1680
avg_envstep_per_episode: 280.0
avg_sample_per_episode: 280.0
avg_envstep_per_sec: 792.7346974380789
avg_train_sample_per_sec: 792.7346974380789
avg_episode_per_sec: 2.831195347993139
collect_time: 2.1192462061132704
reward_mean: 1551.5
reward_std: 866.299560546875
reward_max: 2971.0
reward_min: 764.0
total_envstep_count: 2471958
total_train_sample_count: 2471935
total_episode_count: 15702
total_duration: 3148.0951037364393
[2024-11-20 00:41:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 754
train_sample_count: 754
avg_envstep_per_episode: 107.71428571428571
avg_sample_per_episode: 107.71428571428571
avg_envstep_per_sec: 805.8186769187138
avg_train_sample_per_sec: 805.8186769187138
avg_episode_per_sec: 7.481075249908484
collect_time: 0.9356943709509714
reward_mean: 716.7142944335938
reward_std: 248.7406768798828
reward_max: 1324.0
reward_min: 581.0
total_envstep_count: 2472962
total_train_sample_count: 2472917
total_episode_count: 15709
total_duration: 3149.03079810739
[2024-11-20 00:41:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1256
train_sample_count: 1256
avg_envstep_per_episode: 251.2
avg_sample_per_episode: 251.2
avg_envstep_per_sec: 804.082132832418
avg_train_sample_per_sec: 804.082132832418
avg_episode_per_sec: 3.2009639045876512
collect_time: 1.5620294851916179
reward_mean: 1402.5999755859375
reward_std: 623.0847778320312
reward_max: 2355.0
reward_min: 706.0
total_envstep_count: 2473949
total_train_sample_count: 2473897
total_episode_count: 15714
total_duration: 3150.5928275925817
[2024-11-20 00:41:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1247
train_sample_count: 1247
avg_envstep_per_episode: 138.55555555555554
avg_sample_per_episode: 138.55555555555554
avg_envstep_per_sec: 803.339640891812
avg_train_sample_per_sec: 803.339640891812
avg_episode_per_sec: 5.79796051966825
collect_time: 1.5522699696677074
reward_mean: 983.5555419921875
reward_std: 544.2752685546875
reward_max: 1926.0
reward_min: 568.0
total_envstep_count: 2474911
total_train_sample_count: 2474880
total_episode_count: 15723
total_duration: 3152.1450975622492
[2024-11-20 00:41:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 776
train_sample_count: 776
avg_envstep_per_episode: 129.33333333333334
avg_sample_per_episode: 129.33333333333334
avg_envstep_per_sec: 803.3636654654405
avg_train_sample_per_sec: 803.3636654654405
avg_episode_per_sec: 6.21157473298021
collect_time: 0.9659386319773537
reward_mean: 845.3333129882812
reward_std: 389.5812683105469
reward_max: 1701.0
reward_min: 599.0
total_envstep_count: 2475963
total_train_sample_count: 2475920
total_episode_count: 15729
total_duration: 3153.1110361942265
[2024-11-20 00:41:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 531
train_sample_count: 531
avg_envstep_per_episode: 106.2
avg_sample_per_episode: 106.2
avg_envstep_per_sec: 803.4250952909942
avg_train_sample_per_sec: 803.4250952909942
avg_episode_per_sec: 7.565208053587516
collect_time: 0.6609203560011727
reward_mean: 757.4000244140625
reward_std: 451.84136962890625
reward_max: 1569.0
reward_min: 175.0
total_envstep_count: 2476959
total_train_sample_count: 2476931
total_episode_count: 15734
total_duration: 3153.7719565502275
[2024-11-20 00:41:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1359
train_sample_count: 1359
avg_envstep_per_episode: 226.5
avg_sample_per_episode: 226.5
avg_envstep_per_sec: 800.7524275811044
avg_train_sample_per_sec: 800.7524275811044
avg_episode_per_sec: 3.535330806097591
collect_time: 1.6971537683691298
reward_mean: 1127.3333740234375
reward_std: 493.50469970703125
reward_max: 1804.0
reward_min: 631.0
total_envstep_count: 2477954
total_train_sample_count: 2477918
total_episode_count: 15740
total_duration: 3155.4691103185964
[2024-11-20 00:41:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 847
train_sample_count: 847
avg_envstep_per_episode: 282.3333333333333
avg_sample_per_episode: 282.3333333333333
avg_envstep_per_sec: 812.5990089557995
avg_train_sample_per_sec: 812.5990089557995
avg_episode_per_sec: 2.878154695238959
collect_time: 1.0423345225197926
reward_mean: 1903.6666259765625
reward_std: 510.4261779785156
reward_max: 2604.0
reward_min: 1402.0
total_envstep_count: 2478928
total_train_sample_count: 2478885
total_episode_count: 15743
total_duration: 3156.5114448411164
[2024-11-20 00:41:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1113
train_sample_count: 1113
avg_envstep_per_episode: 185.5
avg_sample_per_episode: 185.5
avg_envstep_per_sec: 801.2215183606828
avg_train_sample_per_sec: 801.2215183606828
avg_episode_per_sec: 4.3192534682516595
collect_time: 1.3891289418651946
reward_mean: 1138.3333740234375
reward_std: 659.6988525390625
reward_max: 2341.0
reward_min: 607.0
total_envstep_count: 2479923
total_train_sample_count: 2479878
total_episode_count: 15749
total_duration: 3157.9005737829816
[2024-11-20 00:41:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 874
train_sample_count: 874
avg_envstep_per_episode: 174.8
avg_sample_per_episode: 174.8
avg_envstep_per_sec: 809.3451649407866
avg_train_sample_per_sec: 809.3451649407866
avg_episode_per_sec: 4.630121080896949
collect_time: 1.0798853664171129
reward_mean: 1367.0
reward_std: 695.300537109375
reward_max: 2361.0
reward_min: 605.0
total_envstep_count: 2480895
total_train_sample_count: 2480872
total_episode_count: 15754
total_duration: 3158.980459149399
[2024-11-20 00:41:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 855
train_sample_count: 855
avg_envstep_per_episode: 142.5
avg_sample_per_episode: 142.5
avg_envstep_per_sec: 802.5697331384066
avg_train_sample_per_sec: 802.5697331384066
avg_episode_per_sec: 5.63206830272566
collect_time: 1.0653279892035894
reward_mean: 887.1666870117188
reward_std: 548.240966796875
reward_max: 1654.0
reward_min: 232.0
total_envstep_count: 2481889
total_train_sample_count: 2481847
total_episode_count: 15760
total_duration: 3160.0457871386025
[2024-11-20 00:41:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 760
train_sample_count: 760
avg_envstep_per_episode: 152.0
avg_sample_per_episode: 152.0
avg_envstep_per_sec: 812.3075613653489
avg_train_sample_per_sec: 812.3075613653489
avg_episode_per_sec: 5.344128693193085
collect_time: 0.9356062114238739
reward_mean: 1190.199951171875
reward_std: 339.6164855957031
reward_max: 1586.0
reward_min: 610.0
total_envstep_count: 2482869
total_train_sample_count: 2482835
total_episode_count: 15765
total_duration: 3160.9813933500263
[2024-11-20 00:42:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 527
train_sample_count: 527
avg_envstep_per_episode: 175.66666666666666
avg_sample_per_episode: 175.66666666666666
avg_envstep_per_sec: 809.8735348720727
avg_train_sample_per_sec: 809.8735348720727
avg_episode_per_sec: 4.610285777260376
collect_time: 0.650718880551202
reward_mean: 951.0
reward_std: 507.768310546875
reward_max: 1669.0
reward_min: 582.0
total_envstep_count: 2483834
total_train_sample_count: 2483806
total_episode_count: 15768
total_duration: 3161.6321122305776
[2024-11-20 00:42:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1028
train_sample_count: 1028
avg_envstep_per_episode: 257.0
avg_sample_per_episode: 257.0
avg_envstep_per_sec: 808.3205084579416
avg_train_sample_per_sec: 808.3205084579416
avg_episode_per_sec: 3.145215986217672
collect_time: 1.2717727550438473
reward_mean: 1726.0
reward_std: 286.5850524902344
reward_max: 2023.0
reward_min: 1271.0
total_envstep_count: 2484791
total_train_sample_count: 2484774
total_episode_count: 15772
total_duration: 3162.9038849856215
[2024-11-20 00:42:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1090
train_sample_count: 1090
avg_envstep_per_episode: 272.5
avg_sample_per_episode: 272.5
avg_envstep_per_sec: 809.3277770730792
avg_train_sample_per_sec: 809.3277770730792
avg_episode_per_sec: 2.970010191093869
collect_time: 1.346796725477491
reward_mean: 1707.75
reward_std: 709.4266357421875
reward_max: 2344.0
reward_min: 607.0
total_envstep_count: 2485828
total_train_sample_count: 2485768
total_episode_count: 15776
total_duration: 3164.250681711099
[2024-11-20 00:42:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1761
train_sample_count: 1761
avg_envstep_per_episode: 293.5
avg_sample_per_episode: 293.5
avg_envstep_per_sec: 807.766217237558
avg_train_sample_per_sec: 807.766217237558
avg_episode_per_sec: 2.752184726533417
collect_time: 2.1800862210137506
reward_mean: 1240.3333740234375
reward_std: 655.7971801757812
reward_max: 2219.0
reward_min: 599.0
total_envstep_count: 2486815
total_train_sample_count: 2486785
total_episode_count: 15782
total_duration: 3166.4307679321128
[2024-11-20 00:42:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1201
train_sample_count: 1201
avg_envstep_per_episode: 200.16666666666666
avg_sample_per_episode: 200.16666666666666
avg_envstep_per_sec: 804.8055034647432
avg_train_sample_per_sec: 804.8055034647432
avg_episode_per_sec: 4.020676953196053
collect_time: 1.4922860179628645
reward_mean: 1202.6666259765625
reward_std: 622.6491088867188
reward_max: 2352.0
reward_min: 634.0
total_envstep_count: 2487825
total_train_sample_count: 2487782
total_episode_count: 15788
total_duration: 3167.9230539500754
[2024-11-20 00:42:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 801
train_sample_count: 801
avg_envstep_per_episode: 133.5
avg_sample_per_episode: 133.5
avg_envstep_per_sec: 789.7293192946374
avg_train_sample_per_sec: 789.7293192946374
avg_episode_per_sec: 5.9155754254279955
collect_time: 1.0142715743609838
reward_mean: 1120.1666259765625
reward_std: 369.9429931640625
reward_max: 1695.0
reward_min: 609.0
total_envstep_count: 2488812
total_train_sample_count: 2488775
total_episode_count: 15794
total_duration: 3168.9373255244363
[2024-11-20 00:42:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 964
train_sample_count: 964
avg_envstep_per_episode: 192.8
avg_sample_per_episode: 192.8
avg_envstep_per_sec: 803.8687609386626
avg_train_sample_per_sec: 803.8687609386626
avg_episode_per_sec: 4.169443780802192
collect_time: 1.1992007238524298
reward_mean: 1141.800048828125
reward_std: 535.8900756835938
reward_max: 1847.0
reward_min: 579.0
total_envstep_count: 2489799
total_train_sample_count: 2489763
total_episode_count: 15799
total_duration: 3170.1365262482886
[2024-11-20 00:42:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 672
train_sample_count: 672
avg_envstep_per_episode: 224.0
avg_sample_per_episode: 224.0
avg_envstep_per_sec: 801.8808883118346
avg_train_sample_per_sec: 801.8808883118346
avg_episode_per_sec: 3.5798253942492617
collect_time: 0.8380296996661596
reward_mean: 1275.3333740234375
reward_std: 361.3321228027344
reward_max: 1688.0
reward_min: 808.0
total_envstep_count: 2490796
total_train_sample_count: 2490735
total_episode_count: 15802
total_duration: 3170.9745559479547
[2024-11-20 00:42:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 505
train_sample_count: 505
avg_envstep_per_episode: 126.25
avg_sample_per_episode: 126.25
avg_envstep_per_sec: 800.5811050510754
avg_train_sample_per_sec: 800.5811050510754
avg_episode_per_sec: 6.3412364756520825
collect_time: 0.6307918046201978
reward_mean: 970.75
reward_std: 574.0807495117188
reward_max: 1704.0
reward_min: 230.0
total_envstep_count: 2491768
total_train_sample_count: 2491720
total_episode_count: 15806
total_duration: 3171.6053477525747
[2024-11-20 00:42:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1357
train_sample_count: 1357
avg_envstep_per_episode: 271.4
avg_sample_per_episode: 271.4
avg_envstep_per_sec: 806.1092776203718
avg_train_sample_per_sec: 806.1092776203718
avg_episode_per_sec: 2.9701889374368897
collect_time: 1.683394593851907
reward_mean: 1642.4000244140625
reward_std: 554.217529296875
reward_max: 2302.0
reward_min: 629.0
total_envstep_count: 2492763
total_train_sample_count: 2492729
total_episode_count: 15811
total_duration: 3173.2887423464267
[2024-11-20 00:42:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 823
train_sample_count: 823
avg_envstep_per_episode: 137.16666666666666
avg_sample_per_episode: 137.16666666666666
avg_envstep_per_sec: 809.6716011976082
avg_train_sample_per_sec: 809.6716011976082
avg_episode_per_sec: 5.902830628415127
collect_time: 1.0164614873273032
reward_mean: 900.8333129882812
reward_std: 384.90838623046875
reward_max: 1681.0
reward_min: 580.0
total_envstep_count: 2493766
total_train_sample_count: 2493720
total_episode_count: 15817
total_duration: 3174.305203833754
[2024-11-20 00:42:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1433
train_sample_count: 1433
avg_envstep_per_episode: 204.71428571428572
avg_sample_per_episode: 204.71428571428572
avg_envstep_per_sec: 805.7268881966218
avg_train_sample_per_sec: 805.7268881966218
avg_episode_per_sec: 3.9358605843519556
collect_time: 1.7785182808126723
reward_mean: 1078.2857666015625
reward_std: 622.149658203125
reward_max: 2286.0
reward_min: 603.0
total_envstep_count: 2494745
total_train_sample_count: 2494721
total_episode_count: 15824
total_duration: 3176.0837221145666
[2024-11-20 00:42:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 843
train_sample_count: 843
avg_envstep_per_episode: 140.5
avg_sample_per_episode: 140.5
avg_envstep_per_sec: 796.7357787500237
avg_train_sample_per_sec: 796.7357787500237
avg_episode_per_sec: 5.6707172864770365
collect_time: 1.0580672068255288
reward_mean: 962.8333129882812
reward_std: 441.5168762207031
reward_max: 1849.0
reward_min: 590.0
total_envstep_count: 2495779
total_train_sample_count: 2495732
total_episode_count: 15830
total_duration: 3177.141789321392
[2024-11-20 00:42:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 540
train_sample_count: 540
avg_envstep_per_episode: 135.0
avg_sample_per_episode: 135.0
avg_envstep_per_sec: 807.5718917292528
avg_train_sample_per_sec: 807.5718917292528
avg_episode_per_sec: 5.982014012809279
collect_time: 0.6686711183616094
reward_mean: 1088.0
reward_std: 485.5970458984375
reward_max: 1576.0
reward_min: 589.0
total_envstep_count: 2496736
total_train_sample_count: 2496692
total_episode_count: 15834
total_duration: 3177.8104604397536
[2024-11-20 00:42:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 745
train_sample_count: 745
avg_envstep_per_episode: 186.25
avg_sample_per_episode: 186.25
avg_envstep_per_sec: 804.3183276346999
avg_train_sample_per_sec: 804.3183276346999
avg_episode_per_sec: 4.318487665152751
collect_time: 0.9262501852852958
reward_mean: 1487.25
reward_std: 151.8360595703125
reward_max: 1689.0
reward_min: 1337.0
total_envstep_count: 2497748
total_train_sample_count: 2497701
total_episode_count: 15838
total_duration: 3178.736710625039
[2024-11-20 00:42:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 964
train_sample_count: 964
avg_envstep_per_episode: 241.0
avg_sample_per_episode: 241.0
avg_envstep_per_sec: 810.1967781867935
avg_train_sample_per_sec: 810.1967781867935
avg_episode_per_sec: 3.3618123576215497
collect_time: 1.1898344031402044
reward_mean: 1645.75
reward_std: 852.238037109375
reward_max: 2356.0
reward_min: 189.0
total_envstep_count: 2498720
total_train_sample_count: 2498677
total_episode_count: 15842
total_duration: 3179.926545028179
[2024-11-20 00:42:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 808
train_sample_count: 808
avg_envstep_per_episode: 202.0
avg_sample_per_episode: 202.0
avg_envstep_per_sec: 797.8681848560943
avg_train_sample_per_sec: 797.8681848560943
avg_episode_per_sec: 3.949842499287596
collect_time: 1.0126986077853612
reward_mean: 1191.25
reward_std: 621.4420166015625
reward_max: 1824.0
reward_min: 249.0
total_envstep_count: 2499685
total_train_sample_count: 2499653
total_episode_count: 15846
total_duration: 3180.9392436359644
[2024-11-20 00:43:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 999
train_sample_count: 999
avg_envstep_per_episode: 199.8
avg_sample_per_episode: 199.8
avg_envstep_per_sec: 806.2328128576611
avg_train_sample_per_sec: 806.2328128576611
avg_episode_per_sec: 4.035199263551857
collect_time: 1.2390961817332677
reward_mean: 1294.800048828125
reward_std: 389.7472839355469
reward_max: 1690.0
reward_min: 652.0
total_envstep_count: 2500672
total_train_sample_count: 2500628
total_episode_count: 15851
total_duration: 3182.1783398176976
[2024-11-20 00:43:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 132
train_sample_count: 132
avg_envstep_per_episode: 132.0
avg_sample_per_episode: 132.0
avg_envstep_per_sec: 792.6706825981629
avg_train_sample_per_sec: 792.6706825981629
avg_episode_per_sec: 6.005080928773961
collect_time: 0.16652564917291912
reward_mean: 637.0
reward_std: 0.0
reward_max: 637.0
reward_min: 637.0
total_envstep_count: 2501631
total_train_sample_count: 2501588
total_episode_count: 15852
total_duration: 3182.3448654668705
[2024-11-20 00:43:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 771
train_sample_count: 771
avg_envstep_per_episode: 257.0
avg_sample_per_episode: 257.0
avg_envstep_per_sec: 812.1553321528644
avg_train_sample_per_sec: 812.1553321528644
avg_episode_per_sec: 3.1601374791940247
collect_time: 0.9493257871695927
reward_mean: 1256.3333740234375
reward_std: 490.0029602050781
reward_max: 1818.0
reward_min: 624.0
total_envstep_count: 2502637
total_train_sample_count: 2502611
total_episode_count: 15855
total_duration: 3183.29419125404
[2024-11-20 00:43:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1750
train_sample_count: 1750
avg_envstep_per_episode: 250.0
avg_sample_per_episode: 250.0
avg_envstep_per_sec: 804.6667870451075
avg_train_sample_per_sec: 804.6667870451075
avg_episode_per_sec: 3.21866714818043
collect_time: 2.1748132620538985
reward_mean: 1434.4285888671875
reward_std: 565.7023315429688
reward_max: 2339.0
reward_min: 611.0
total_envstep_count: 2503623
total_train_sample_count: 2503581
total_episode_count: 15862
total_duration: 3185.4690045160937
[2024-11-20 00:43:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 577
train_sample_count: 577
avg_envstep_per_episode: 82.42857142857143
avg_sample_per_episode: 82.42857142857143
avg_envstep_per_sec: 806.9225833894898
avg_train_sample_per_sec: 806.9225833894898
avg_episode_per_sec: 9.789355431068334
collect_time: 0.7150624011244093
reward_mean: 693.0
reward_std: 378.60797119140625
reward_max: 1566.0
reward_min: 239.0
total_envstep_count: 2504594
total_train_sample_count: 2504554
total_episode_count: 15869
total_duration: 3186.184066917218
[2024-11-20 00:43:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 563
train_sample_count: 563
avg_envstep_per_episode: 140.75
avg_sample_per_episode: 140.75
avg_envstep_per_sec: 809.503511219052
avg_train_sample_per_sec: 809.503511219052
avg_episode_per_sec: 5.751357095694863
collect_time: 0.6954880271639142
reward_mean: 1164.75
reward_std: 525.8195190429688
reward_max: 1692.0
reward_min: 627.0
total_envstep_count: 2505551
total_train_sample_count: 2505525
total_episode_count: 15873
total_duration: 3186.8795549443817
[2024-11-20 00:43:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2612
train_sample_count: 2612
avg_envstep_per_episode: 435.3333333333333
avg_sample_per_episode: 435.3333333333333
avg_envstep_per_sec: 803.4682688427066
avg_train_sample_per_sec: 803.4682688427066
avg_episode_per_sec: 1.8456392086739049
collect_time: 3.250906229019165
reward_mean: 892.1666870117188
reward_std: 452.85845947265625
reward_max: 1701.0
reward_min: 513.0
total_envstep_count: 2506554
total_train_sample_count: 2506517
total_episode_count: 15879
total_duration: 3190.130461173401
[2024-11-20 00:43:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1035
train_sample_count: 1035
avg_envstep_per_episode: 172.5
avg_sample_per_episode: 172.5
avg_envstep_per_sec: 811.5118942782276
avg_train_sample_per_sec: 811.5118942782276
avg_episode_per_sec: 4.704416778424508
collect_time: 1.2753972027982985
reward_mean: 1482.6666259765625
reward_std: 270.3249206542969
reward_max: 1881.0
reward_min: 1045.0
total_envstep_count: 2507541
total_train_sample_count: 2507492
total_episode_count: 15885
total_duration: 3191.405858376199
[2024-11-20 00:43:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 586
train_sample_count: 586
avg_envstep_per_episode: 117.2
avg_sample_per_episode: 117.2
avg_envstep_per_sec: 809.1816370981066
avg_train_sample_per_sec: 809.1816370981066
avg_episode_per_sec: 6.904280180017975
collect_time: 0.7241884555135454
reward_mean: 977.2000122070312
reward_std: 440.23468017578125
reward_max: 1589.0
reward_min: 601.0
total_envstep_count: 2508520
total_train_sample_count: 2508486
total_episode_count: 15890
total_duration: 3192.1300468317127
[2024-11-20 00:43:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 747
train_sample_count: 747
avg_envstep_per_episode: 186.75
avg_sample_per_episode: 186.75
avg_envstep_per_sec: 800.7513927054208
avg_train_sample_per_sec: 800.7513927054208
avg_episode_per_sec: 4.287825396012963
collect_time: 0.9328738067831313
reward_mean: 1055.25
reward_std: 430.70892333984375
reward_max: 1628.0
reward_min: 639.0
total_envstep_count: 2509524
total_train_sample_count: 2509473
total_episode_count: 15894
total_duration: 3193.0629206384956
[2024-11-20 00:43:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 616
train_sample_count: 616
avg_envstep_per_episode: 154.0
avg_sample_per_episode: 154.0
avg_envstep_per_sec: 780.0971087646692
avg_train_sample_per_sec: 780.0971087646692
avg_episode_per_sec: 5.065565641329021
collect_time: 0.7896452801568168
reward_mean: 833.75
reward_std: 508.0213317871094
reward_max: 1583.0
reward_min: 149.0
total_envstep_count: 2510490
total_train_sample_count: 2510449
total_episode_count: 15898
total_duration: 3193.8525659186525
[2024-11-20 00:43:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1747
train_sample_count: 1747
avg_envstep_per_episode: 873.5
avg_sample_per_episode: 873.5
avg_envstep_per_sec: 792.484543287322
avg_train_sample_per_sec: 792.484543287322
avg_episode_per_sec: 0.9072519098881763
collect_time: 2.204459398984909
reward_mean: 1464.5
reward_std: 354.5
reward_max: 1819.0
reward_min: 1110.0
total_envstep_count: 2511464
total_train_sample_count: 2511416
total_episode_count: 15900
total_duration: 3196.0570253176375
[2024-11-20 00:43:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1119
train_sample_count: 1119
avg_envstep_per_episode: 373.0
avg_sample_per_episode: 373.0
avg_envstep_per_sec: 777.3790031939423
avg_train_sample_per_sec: 777.3790031939423
avg_episode_per_sec: 2.084126013924778
collect_time: 1.4394523075648717
reward_mean: 1591.3333740234375
reward_std: 714.1345825195312
reward_max: 2258.0
reward_min: 601.0
total_envstep_count: 2512453
total_train_sample_count: 2512391
total_episode_count: 15903
total_duration: 3197.4964776252023
[2024-11-20 00:43:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 2028
train_sample_count: 2028
avg_envstep_per_episode: 225.33333333333334
avg_sample_per_episode: 225.33333333333334
avg_envstep_per_sec: 743.1202187727856
avg_train_sample_per_sec: 743.1202187727856
avg_episode_per_sec: 3.2978707933703504
collect_time: 2.7290335382734026
reward_mean: 1498.0
reward_std: 803.2500610351562
reward_max: 2357.0
reward_min: 607.0
total_envstep_count: 2513453
total_train_sample_count: 2513399
total_episode_count: 15912
total_duration: 3200.225511163476
[2024-11-20 00:43:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 623
train_sample_count: 623
avg_envstep_per_episode: 124.6
avg_sample_per_episode: 124.6
avg_envstep_per_sec: 714.4025679086024
avg_train_sample_per_sec: 714.4025679086024
avg_episode_per_sec: 5.733567960743197
collect_time: 0.8720573357173375
reward_mean: 833.5999755859375
reward_std: 427.2547607421875
reward_max: 1688.0
reward_min: 609.0
total_envstep_count: 2514424
total_train_sample_count: 2514382
total_episode_count: 15917
total_duration: 3201.097568499193
[2024-11-20 00:43:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1243
train_sample_count: 1243
avg_envstep_per_episode: 177.57142857142858
avg_sample_per_episode: 177.57142857142858
avg_envstep_per_sec: 718.7529257190432
avg_train_sample_per_sec: 718.7529257190432
avg_episode_per_sec: 4.047683411128964
collect_time: 1.729384264775685
reward_mean: 1123.0
reward_std: 561.2681884765625
reward_max: 2326.0
reward_min: 588.0
total_envstep_count: 2515435
total_train_sample_count: 2515385
total_episode_count: 15924
total_duration: 3202.8269527639686
[2024-11-20 00:44:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 386
train_sample_count: 386
avg_envstep_per_episode: 77.2
avg_sample_per_episode: 77.2
avg_envstep_per_sec: 711.3931368368004
avg_train_sample_per_sec: 711.3931368368004
avg_episode_per_sec: 9.214937005658037
collect_time: 0.5425973066261837
reward_mean: 566.4000244140625
reward_std: 165.78131103515625
reward_max: 733.0
reward_min: 248.0
total_envstep_count: 2516391
total_train_sample_count: 2516359
total_episode_count: 15929
total_duration: 3203.369550070595
[2024-11-20 00:44:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 930
train_sample_count: 930
avg_envstep_per_episode: 232.5
avg_sample_per_episode: 232.5
avg_envstep_per_sec: 719.5242990851873
avg_train_sample_per_sec: 719.5242990851873
avg_episode_per_sec: 3.0947281681083325
collect_time: 1.2925206295081546
reward_mean: 1345.5
reward_std: 558.5917358398438
reward_max: 1904.0
reward_min: 594.0
total_envstep_count: 2517363
total_train_sample_count: 2517325
total_episode_count: 15933
total_duration: 3204.662070700103
[2024-11-20 00:44:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 263
train_sample_count: 263
avg_envstep_per_episode: 131.5
avg_sample_per_episode: 131.5
avg_envstep_per_sec: 765.4053268243714
avg_train_sample_per_sec: 765.4053268243714
avg_episode_per_sec: 5.82057282756176
collect_time: 0.34360879233905245
reward_mean: 379.5
reward_std: 271.5
reward_max: 651.0
reward_min: 108.0
total_envstep_count: 2518329
total_train_sample_count: 2518296
total_episode_count: 15935
total_duration: 3205.005679492442
[2024-11-20 00:44:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1307
train_sample_count: 1307
avg_envstep_per_episode: 217.83333333333334
avg_sample_per_episode: 217.83333333333334
avg_envstep_per_sec: 766.8233723449792
avg_train_sample_per_sec: 766.8233723449792
avg_episode_per_sec: 3.5202297123717488
collect_time: 1.7044342245374409
reward_mean: 1358.8333740234375
reward_std: 541.88818359375
reward_max: 2314.0
reward_min: 636.0
total_envstep_count: 2519318
total_train_sample_count: 2519279
total_episode_count: 15941
total_duration: 3206.71011371698
[2024-11-20 00:44:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1180
train_sample_count: 1180
avg_envstep_per_episode: 196.66666666666666
avg_sample_per_episode: 196.66666666666666
avg_envstep_per_sec: 794.7287636875241
avg_train_sample_per_sec: 794.7287636875241
avg_episode_per_sec: 4.040993713665376
collect_time: 1.4847833045891354
reward_mean: 1347.5
reward_std: 593.4817504882812
reward_max: 2312.0
reward_min: 609.0
total_envstep_count: 2520320
total_train_sample_count: 2520267
total_episode_count: 15947
total_duration: 3208.194897021569
[2024-11-20 00:44:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1771
train_sample_count: 1771
avg_envstep_per_episode: 295.1666666666667
avg_sample_per_episode: 295.1666666666667
avg_envstep_per_sec: 778.6616625777694
avg_train_sample_per_sec: 778.6616625777694
avg_episode_per_sec: 2.6380406411443347
collect_time: 2.2744153014251167
reward_mean: 1376.0
reward_std: 803.0529174804688
reward_max: 2363.0
reward_min: 126.0
total_envstep_count: 2521306
total_train_sample_count: 2521282
total_episode_count: 15953
total_duration: 3210.469312322994
[2024-11-20 00:44:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 484
train_sample_count: 484
avg_envstep_per_episode: 242.0
avg_sample_per_episode: 242.0
avg_envstep_per_sec: 811.4037867712702
avg_train_sample_per_sec: 811.4037867712702
avg_episode_per_sec: 3.3529082097986374
collect_time: 0.5964970929282052
reward_mean: 985.5
reward_std: 386.5
reward_max: 1372.0
reward_min: 599.0
total_envstep_count: 2522265
total_train_sample_count: 2522246
total_episode_count: 15955
total_duration: 3211.065809415922
[2024-11-20 00:44:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1321
train_sample_count: 1321
avg_envstep_per_episode: 220.16666666666666
avg_sample_per_episode: 220.16666666666666
avg_envstep_per_sec: 808.1929854761304
avg_train_sample_per_sec: 808.1929854761304
avg_episode_per_sec: 3.6708235525032418
collect_time: 1.6345105980123793
reward_mean: 1325.6666259765625
reward_std: 516.4622192382812
reward_max: 1898.0
reward_min: 603.0
total_envstep_count: 2523253
total_train_sample_count: 2523231
total_episode_count: 15961
total_duration: 3212.7003200139343
[2024-11-20 00:44:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 797
train_sample_count: 797
avg_envstep_per_episode: 159.4
avg_sample_per_episode: 159.4
avg_envstep_per_sec: 808.4968557124744
avg_train_sample_per_sec: 808.4968557124744
avg_episode_per_sec: 5.07212582002807
collect_time: 0.9857799623693738
reward_mean: 1007.0
reward_std: 378.86041259765625
reward_max: 1658.0
reward_min: 610.0
total_envstep_count: 2524273
total_train_sample_count: 2524220
total_episode_count: 15966
total_duration: 3213.6860999763035
[2024-11-20 00:44:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1286
train_sample_count: 1286
avg_envstep_per_episode: 214.33333333333334
avg_sample_per_episode: 214.33333333333334
avg_envstep_per_sec: 806.3260951664156
avg_train_sample_per_sec: 806.3260951664156
avg_episode_per_sec: 3.7620191065307105
collect_time: 1.594888231584004
reward_mean: 1516.5
reward_std: 629.9747924804688
reward_max: 2351.0
reward_min: 607.0
total_envstep_count: 2525236
total_train_sample_count: 2525206
total_episode_count: 15972
total_duration: 3215.2809882078873
[2024-11-20 00:44:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 979
train_sample_count: 979
avg_envstep_per_episode: 163.16666666666666
avg_sample_per_episode: 163.16666666666666
avg_envstep_per_sec: 812.2529897742857
avg_train_sample_per_sec: 812.2529897742857
avg_episode_per_sec: 4.978057138555377
collect_time: 1.205289500100272
reward_mean: 762.8333129882812
reward_std: 502.0071105957031
reward_max: 1562.0
reward_min: 223.0
total_envstep_count: 2526239
total_train_sample_count: 2526185
total_episode_count: 15978
total_duration: 3216.4862777079875
[2024-11-20 00:44:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 668
train_sample_count: 668
avg_envstep_per_episode: 133.6
avg_sample_per_episode: 133.6
avg_envstep_per_sec: 810.7248925514081
avg_train_sample_per_sec: 810.7248925514081
avg_episode_per_sec: 6.0683000939476655
collect_time: 0.8239539776529584
reward_mean: 906.4000244140625
reward_std: 531.5255737304688
reward_max: 1694.0
reward_min: 243.0
total_envstep_count: 2527226
total_train_sample_count: 2527177
total_episode_count: 15983
total_duration: 3217.3102316856402
[2024-11-20 00:44:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1152
train_sample_count: 1152
avg_envstep_per_episode: 192.0
avg_sample_per_episode: 192.0
avg_envstep_per_sec: 805.064014979205
avg_train_sample_per_sec: 805.064014979205
avg_episode_per_sec: 4.193041744683359
collect_time: 1.430942109652928
reward_mean: 1074.0
reward_std: 507.45770263671875
reward_max: 1641.0
reward_min: 117.0
total_envstep_count: 2528244
total_train_sample_count: 2528209
total_episode_count: 15989
total_duration: 3218.741173795293
[2024-11-20 00:44:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 735
train_sample_count: 735
avg_envstep_per_episode: 183.75
avg_sample_per_episode: 183.75
avg_envstep_per_sec: 814.2055405567122
avg_train_sample_per_sec: 814.2055405567122
avg_episode_per_sec: 4.431050560852856
collect_time: 0.9027204598699298
reward_mean: 900.75
reward_std: 316.7912292480469
reward_max: 1350.0
reward_min: 600.0
total_envstep_count: 2529216
total_train_sample_count: 2529184
total_episode_count: 15993
total_duration: 3219.643894255163
[2024-11-20 00:44:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1281
train_sample_count: 1281
avg_envstep_per_episode: 256.2
avg_sample_per_episode: 256.2
avg_envstep_per_sec: 804.7343792802046
avg_train_sample_per_sec: 804.7343792802046
avg_episode_per_sec: 3.141039731772852
collect_time: 1.591829593692507
reward_mean: 1369.199951171875
reward_std: 390.92987060546875
reward_max: 1683.0
reward_min: 626.0
total_envstep_count: 2530196
total_train_sample_count: 2530153
total_episode_count: 15998
total_duration: 3221.2357238488557
[2024-11-20 00:44:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1227
train_sample_count: 1227
avg_envstep_per_episode: 136.33333333333334
avg_sample_per_episode: 136.33333333333334
avg_envstep_per_sec: 804.3215278410277
avg_train_sample_per_sec: 804.3215278410277
avg_episode_per_sec: 5.899668908369396
collect_time: 1.5255093361650192
reward_mean: 914.111083984375
reward_std: 500.8070068359375
reward_max: 1694.0
reward_min: 152.0
total_envstep_count: 2531187
total_train_sample_count: 2531140
total_episode_count: 16007
total_duration: 3222.761233185021
[2024-11-20 00:44:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 619
train_sample_count: 619
avg_envstep_per_episode: 123.8
avg_sample_per_episode: 123.8
avg_envstep_per_sec: 807.0689783370137
avg_train_sample_per_sec: 807.0689783370137
avg_episode_per_sec: 6.519135527762631
collect_time: 0.7669728568622044
reward_mean: 653.5999755859375
reward_std: 75.06157684326172
reward_max: 803.0
reward_min: 606.0
total_envstep_count: 2532161
total_train_sample_count: 2532119
total_episode_count: 16012
total_duration: 3223.528206041883
[2024-11-20 00:45:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1341
train_sample_count: 1341
avg_envstep_per_episode: 167.625
avg_sample_per_episode: 167.625
avg_envstep_per_sec: 811.7013334789939
avg_train_sample_per_sec: 811.7013334789939
avg_episode_per_sec: 4.842364405542097
collect_time: 1.6520854958466122
reward_mean: 1064.375
reward_std: 464.8870544433594
reward_max: 1696.0
reward_min: 585.0
total_envstep_count: 2533210
total_train_sample_count: 2533172
total_episode_count: 16020
total_duration: 3225.1802915377298
[2024-11-20 00:45:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 958
train_sample_count: 958
avg_envstep_per_episode: 159.66666666666666
avg_sample_per_episode: 159.66666666666666
avg_envstep_per_sec: 814.356163044196
avg_train_sample_per_sec: 814.356163044196
avg_episode_per_sec: 5.100351751842564
collect_time: 1.1763894515378135
reward_mean: 1052.8333740234375
reward_std: 472.5799560546875
reward_max: 1828.0
reward_min: 601.0
total_envstep_count: 2534204
total_train_sample_count: 2534166
total_episode_count: 16026
total_duration: 3226.3566809892677
[2024-11-20 00:45:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 893
train_sample_count: 893
avg_envstep_per_episode: 148.83333333333334
avg_sample_per_episode: 148.83333333333334
avg_envstep_per_sec: 807.8168046858599
avg_train_sample_per_sec: 807.8168046858599
avg_episode_per_sec: 5.427660501808689
collect_time: 1.1054486547197613
reward_mean: 1195.0
reward_std: 664.0474243164062
reward_max: 1927.0
reward_min: 250.0
total_envstep_count: 2535182
total_train_sample_count: 2535167
total_episode_count: 16032
total_duration: 3227.4621296439873
[2024-11-20 00:45:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 840
train_sample_count: 840
avg_envstep_per_episode: 210.0
avg_sample_per_episode: 210.0
avg_envstep_per_sec: 797.1433661462439
avg_train_sample_per_sec: 797.1433661462439
avg_episode_per_sec: 3.79592079117259
collect_time: 1.0537627679961068
reward_mean: 1675.0
reward_std: 416.9586181640625
reward_max: 2350.0
reward_min: 1323.0
total_envstep_count: 2536194
total_train_sample_count: 2536151
total_episode_count: 16036
total_duration: 3228.5158924119833
[2024-11-20 00:45:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 688
train_sample_count: 688
avg_envstep_per_episode: 137.6
avg_sample_per_episode: 137.6
avg_envstep_per_sec: 801.5939666345281
avg_train_sample_per_sec: 801.5939666345281
avg_episode_per_sec: 5.825537548216047
collect_time: 0.8582898931843892
reward_mean: 1015.7999877929688
reward_std: 530.9253540039062
reward_max: 1919.0
reward_min: 594.0
total_envstep_count: 2537190
total_train_sample_count: 2537163
total_episode_count: 16041
total_duration: 3229.374182305168
[2024-11-20 00:45:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1245
train_sample_count: 1245
avg_envstep_per_episode: 177.85714285714286
avg_sample_per_episode: 177.85714285714286
avg_envstep_per_sec: 807.6147706578904
avg_train_sample_per_sec: 807.6147706578904
avg_episode_per_sec: 4.540805939441954
collect_time: 1.5415765600545066
reward_mean: 1331.5714111328125
reward_std: 580.2626953125
reward_max: 2348.0
reward_min: 597.0
total_envstep_count: 2538232
total_train_sample_count: 2538180
total_episode_count: 16048
total_duration: 3230.9157588652224
[2024-11-20 00:45:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 580
train_sample_count: 580
avg_envstep_per_episode: 96.66666666666667
avg_sample_per_episode: 96.66666666666667
avg_envstep_per_sec: 802.4937546819526
avg_train_sample_per_sec: 802.4937546819526
avg_episode_per_sec: 8.301659531192612
collect_time: 0.7227470576763153
reward_mean: 783.3333129882812
reward_std: 416.5999755859375
reward_max: 1339.0
reward_min: 184.0
total_envstep_count: 2539218
total_train_sample_count: 2539180
total_episode_count: 16054
total_duration: 3231.6385059228987
[2024-11-20 00:45:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2043
train_sample_count: 2043
avg_envstep_per_episode: 255.375
avg_sample_per_episode: 255.375
avg_envstep_per_sec: 714.0347809098909
avg_train_sample_per_sec: 714.0347809098909
avg_episode_per_sec: 2.796024594850282
collect_time: 2.8612051606178284
reward_mean: 1296.25
reward_std: 726.9388427734375
reward_max: 2343.0
reward_min: 236.0
total_envstep_count: 2540220
total_train_sample_count: 2540191
total_episode_count: 16062
total_duration: 3234.4997110835166
[2024-11-20 00:45:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 337
train_sample_count: 337
avg_envstep_per_episode: 112.33333333333333
avg_sample_per_episode: 112.33333333333333
avg_envstep_per_sec: 790.2544639197513
avg_train_sample_per_sec: 790.2544639197513
avg_episode_per_sec: 7.034906207000754
collect_time: 0.4264449179172516
reward_mean: 970.3333129882812
reward_std: 518.8001098632812
reward_max: 1704.0
reward_min: 598.0
total_envstep_count: 2541193
total_train_sample_count: 2541164
total_episode_count: 16065
total_duration: 3234.926156001434
[2024-11-20 00:45:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1627
train_sample_count: 1627
avg_envstep_per_episode: 180.77777777777777
avg_sample_per_episode: 180.77777777777777
avg_envstep_per_sec: 800.1127947511941
avg_train_sample_per_sec: 800.1127947511941
avg_episode_per_sec: 4.425946621242008
collect_time: 2.03346329501697
reward_mean: 1290.4444580078125
reward_std: 632.3330688476562
reward_max: 1922.0
reward_min: 243.0
total_envstep_count: 2542184
total_train_sample_count: 2542155
total_episode_count: 16074
total_duration: 3236.959619296451
[2024-11-20 00:45:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 518
train_sample_count: 518
avg_envstep_per_episode: 129.5
avg_sample_per_episode: 129.5
avg_envstep_per_sec: 810.4430157340889
avg_train_sample_per_sec: 810.4430157340889
avg_episode_per_sec: 6.258247225745861
collect_time: 0.639156597001212
reward_mean: 757.0
reward_std: 190.45602416992188
reward_max: 1069.0
reward_min: 602.0
total_envstep_count: 2543165
total_train_sample_count: 2543129
total_episode_count: 16078
total_duration: 3237.598775893452
[2024-11-20 00:45:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1275
train_sample_count: 1275
avg_envstep_per_episode: 159.375
avg_sample_per_episode: 159.375
avg_envstep_per_sec: 799.324328970002
avg_train_sample_per_sec: 799.324328970002
avg_episode_per_sec: 5.015368338635306
collect_time: 1.5950972012111118
reward_mean: 1340.25
reward_std: 424.69482421875
reward_max: 1898.0
reward_min: 605.0
total_envstep_count: 2544160
total_train_sample_count: 2544128
total_episode_count: 16086
total_duration: 3239.193873094663
[2024-11-20 00:45:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 906
train_sample_count: 906
avg_envstep_per_episode: 129.42857142857142
avg_sample_per_episode: 129.42857142857142
avg_envstep_per_sec: 807.7220330589912
avg_train_sample_per_sec: 807.7220330589912
avg_episode_per_sec: 6.24067795961693
collect_time: 1.1216730049678256
reward_mean: 1060.142822265625
reward_std: 458.10211181640625
reward_max: 1915.0
reward_min: 626.0
total_envstep_count: 2545145
total_train_sample_count: 2545118
total_episode_count: 16093
total_duration: 3240.315546099631
[2024-11-20 00:45:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 690
train_sample_count: 690
avg_envstep_per_episode: 172.5
avg_sample_per_episode: 172.5
avg_envstep_per_sec: 805.2621015919011
avg_train_sample_per_sec: 805.2621015919011
avg_episode_per_sec: 4.668186096184934
collect_time: 0.8568638690880366
reward_mean: 1178.75
reward_std: 318.29339599609375
reward_max: 1427.0
reward_min: 632.0
total_envstep_count: 2546126
total_train_sample_count: 2546096
total_episode_count: 16097
total_duration: 3241.172409968719
[2024-11-20 00:45:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 944
train_sample_count: 944
avg_envstep_per_episode: 134.85714285714286
avg_sample_per_episode: 134.85714285714286
avg_envstep_per_sec: 801.4190258305111
avg_train_sample_per_sec: 801.4190258305111
avg_episode_per_sec: 5.942725827133028
collect_time: 1.1779106429644992
reward_mean: 998.0
reward_std: 429.2468566894531
reward_max: 1696.0
reward_min: 605.0
total_envstep_count: 2547153
total_train_sample_count: 2547100
total_episode_count: 16104
total_duration: 3242.3503206116834
[2024-11-20 00:45:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 775
train_sample_count: 775
avg_envstep_per_episode: 193.75
avg_sample_per_episode: 193.75
avg_envstep_per_sec: 806.3340177418136
avg_train_sample_per_sec: 806.3340177418136
avg_episode_per_sec: 4.161723962538393
collect_time: 0.9611401515347617
reward_mean: 1483.75
reward_std: 186.0421600341797
reward_max: 1693.0
reward_min: 1295.0
total_envstep_count: 2548118
total_train_sample_count: 2548079
total_episode_count: 16108
total_duration: 3243.3114607632183
[2024-11-20 00:45:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 754
train_sample_count: 754
avg_envstep_per_episode: 150.8
avg_sample_per_episode: 150.8
avg_envstep_per_sec: 806.0919811517526
avg_train_sample_per_sec: 806.0919811517526
avg_episode_per_sec: 5.345437540794116
collect_time: 0.9353771252291543
reward_mean: 1017.7999877929688
reward_std: 423.26605224609375
reward_max: 1693.0
reward_min: 613.0
total_envstep_count: 2549082
total_train_sample_count: 2549061
total_episode_count: 16113
total_duration: 3244.2468378884473
[2024-11-20 00:46:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 744
train_sample_count: 744
avg_envstep_per_episode: 124.0
avg_sample_per_episode: 124.0
avg_envstep_per_sec: 812.1393567453534
avg_train_sample_per_sec: 812.1393567453534
avg_episode_per_sec: 6.549510941494786
collect_time: 0.9160989352634974
reward_mean: 971.6666870117188
reward_std: 513.3026123046875
reward_max: 1699.0
reward_min: 600.0
total_envstep_count: 2550078
total_train_sample_count: 2550057
total_episode_count: 16119
total_duration: 3245.162936823711
[2024-11-20 00:46:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2177
train_sample_count: 2177
avg_envstep_per_episode: 272.125
avg_sample_per_episode: 272.125
avg_envstep_per_sec: 805.3713426899787
avg_train_sample_per_sec: 805.3713426899787
avg_episode_per_sec: 2.9595639602755304
collect_time: 2.7031008984361375
reward_mean: 1126.5
reward_std: 746.8960571289062
reward_max: 2312.0
reward_min: 250.0
total_envstep_count: 2551088
total_train_sample_count: 2551046
total_episode_count: 16127
total_duration: 3247.866037722147
[2024-11-20 00:46:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 750
train_sample_count: 750
avg_envstep_per_episode: 125.0
avg_sample_per_episode: 125.0
avg_envstep_per_sec: 802.6510076650331
avg_train_sample_per_sec: 802.6510076650331
avg_episode_per_sec: 6.421208061320265
collect_time: 0.934403611080987
reward_mean: 966.0
reward_std: 664.1270141601562
reward_max: 1911.0
reward_min: 182.0
total_envstep_count: 2552066
total_train_sample_count: 2552024
total_episode_count: 16133
total_duration: 3248.8004413332283
[2024-11-20 00:46:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 678
train_sample_count: 678
avg_envstep_per_episode: 135.6
avg_sample_per_episode: 135.6
avg_envstep_per_sec: 800.1457817544897
avg_train_sample_per_sec: 800.1457817544897
avg_episode_per_sec: 5.90078010143429
collect_time: 0.8473455905914306
reward_mean: 940.2000122070312
reward_std: 568.7999267578125
reward_max: 1829.0
reward_min: 245.0
total_envstep_count: 2553064
total_train_sample_count: 2553014
total_episode_count: 16138
total_duration: 3249.6477869238197
[2024-11-20 00:46:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 706
train_sample_count: 706
avg_envstep_per_episode: 176.5
avg_sample_per_episode: 176.5
avg_envstep_per_sec: 795.855873559119
avg_train_sample_per_sec: 795.855873559119
avg_episode_per_sec: 4.509098433762714
collect_time: 0.8870952938284193
reward_mean: 1398.0
reward_std: 836.89697265625
reward_max: 2644.0
reward_min: 628.0
total_envstep_count: 2554028
total_train_sample_count: 2554008
total_episode_count: 16142
total_duration: 3250.534882217648
[2024-11-20 00:46:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 726
train_sample_count: 726
avg_envstep_per_episode: 145.2
avg_sample_per_episode: 145.2
avg_envstep_per_sec: 804.8957438317678
avg_train_sample_per_sec: 804.8957438317678
avg_episode_per_sec: 5.543359117298676
collect_time: 0.9019801701818193
reward_mean: 1113.199951171875
reward_std: 427.6177673339844
reward_max: 1697.0
reward_min: 607.0
total_envstep_count: 2555007
total_train_sample_count: 2554986
total_episode_count: 16147
total_duration: 3251.43686238783
[2024-11-20 00:46:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1034
train_sample_count: 1034
avg_envstep_per_episode: 206.8
avg_sample_per_episode: 206.8
avg_envstep_per_sec: 806.2850782227431
avg_train_sample_per_sec: 806.2850782227431
avg_episode_per_sec: 3.898864014616746
collect_time: 1.2824248245784213
reward_mean: 1194.5999755859375
reward_std: 695.5399169921875
reward_max: 2324.0
reward_min: 600.0
total_envstep_count: 2555986
total_train_sample_count: 2555960
total_episode_count: 16152
total_duration: 3252.7192872124083
[2024-11-20 00:46:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1731
train_sample_count: 1731
avg_envstep_per_episode: 288.5
avg_sample_per_episode: 288.5
avg_envstep_per_sec: 802.901609231284
avg_train_sample_per_sec: 802.901609231284
avg_episode_per_sec: 2.7830211758450054
collect_time: 2.155930415505454
reward_mean: 1502.8333740234375
reward_std: 699.00341796875
reward_max: 2318.0
reward_min: 622.0
total_envstep_count: 2556997
total_train_sample_count: 2556959
total_episode_count: 16158
total_duration: 3254.8752176279136
[2024-11-20 00:46:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 961
train_sample_count: 961
avg_envstep_per_episode: 137.28571428571428
avg_sample_per_episode: 137.28571428571428
avg_envstep_per_sec: 804.6156343636836
avg_train_sample_per_sec: 804.6156343636836
avg_episode_per_sec: 5.860883913158986
collect_time: 1.1943590939044955
reward_mean: 1118.142822265625
reward_std: 553.6799926757812
reward_max: 1865.0
reward_min: 622.0
total_envstep_count: 2558014
total_train_sample_count: 2557968
total_episode_count: 16165
total_duration: 3256.069576721818
[2024-11-20 00:46:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 707
train_sample_count: 707
avg_envstep_per_episode: 141.4
avg_sample_per_episode: 141.4
avg_envstep_per_sec: 808.3327593175833
avg_train_sample_per_sec: 808.3327593175833
avg_episode_per_sec: 5.716639033363389
collect_time: 0.8746397963591984
reward_mean: 1128.800048828125
reward_std: 465.7438659667969
reward_max: 1690.0
reward_min: 624.0
total_envstep_count: 2558985
total_train_sample_count: 2558951
total_episode_count: 16170
total_duration: 3256.944216518177
[2024-11-20 00:46:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 685
train_sample_count: 685
avg_envstep_per_episode: 137.0
avg_sample_per_episode: 137.0
avg_envstep_per_sec: 798.0697293402119
avg_train_sample_per_sec: 798.0697293402119
avg_episode_per_sec: 5.825326491534393
collect_time: 0.8583209897790636
reward_mean: 1043.0
reward_std: 475.57879638671875
reward_max: 1850.0
reward_min: 618.0
total_envstep_count: 2559942
total_train_sample_count: 2559924
total_episode_count: 16175
total_duration: 3257.8025375079565
[2024-11-20 00:46:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1231
train_sample_count: 1231
avg_envstep_per_episode: 246.2
avg_sample_per_episode: 246.2
avg_envstep_per_sec: 794.9572071281146
avg_train_sample_per_sec: 794.9572071281146
avg_episode_per_sec: 3.228908233664154
collect_time: 1.5485110254514782
reward_mean: 1317.0
reward_std: 868.9600830078125
reward_max: 2971.0
reward_min: 619.0
total_envstep_count: 2560977
total_train_sample_count: 2560927
total_episode_count: 16180
total_duration: 3259.3510485334077
[2024-11-20 00:46:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 786
train_sample_count: 786
avg_envstep_per_episode: 157.2
avg_sample_per_episode: 157.2
avg_envstep_per_sec: 802.8365486073667
avg_train_sample_per_sec: 802.8365486073667
avg_episode_per_sec: 5.107102726509966
collect_time: 0.9790286719799042
reward_mean: 1128.4000244140625
reward_std: 266.96636962890625
reward_max: 1332.0
reward_min: 640.0
total_envstep_count: 2561956
total_train_sample_count: 2561917
total_episode_count: 16185
total_duration: 3260.3300772053876
[2024-11-20 00:46:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 416
train_sample_count: 416
avg_envstep_per_episode: 138.66666666666666
avg_sample_per_episode: 138.66666666666666
avg_envstep_per_sec: 804.9969793532485
avg_train_sample_per_sec: 804.9969793532485
avg_episode_per_sec: 5.805266678028234
collect_time: 0.5167721254484994
reward_mean: 1014.3333129882812
reward_std: 477.33587646484375
reward_max: 1686.0
reward_min: 620.0
total_envstep_count: 2562937
total_train_sample_count: 2562897
total_episode_count: 16188
total_duration: 3260.846849330836
[2024-11-20 00:46:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1576
train_sample_count: 1576
avg_envstep_per_episode: 225.14285714285714
avg_sample_per_episode: 225.14285714285714
avg_envstep_per_sec: 802.1001543995018
avg_train_sample_per_sec: 802.1001543995018
avg_episode_per_sec: 3.5626275893378887
collect_time: 1.9648419107709612
reward_mean: 1542.0
reward_std: 756.9061279296875
reward_max: 3000.0
reward_min: 605.0
total_envstep_count: 2563972
total_train_sample_count: 2563933
total_episode_count: 16195
total_duration: 3262.811691241607
[2024-11-20 00:46:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 244
train_sample_count: 244
avg_envstep_per_episode: 122.0
avg_sample_per_episode: 122.0
avg_envstep_per_sec: 810.2636291960458
avg_train_sample_per_sec: 810.2636291960458
avg_episode_per_sec: 6.641505157344638
collect_time: 0.30113655754498075
reward_mean: 972.0
reward_std: 352.0
reward_max: 1324.0
reward_min: 620.0
total_envstep_count: 2564930
total_train_sample_count: 2564897
total_episode_count: 16197
total_duration: 3263.112827799152
[2024-11-20 00:46:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 775
train_sample_count: 775
avg_envstep_per_episode: 155.0
avg_sample_per_episode: 155.0
avg_envstep_per_sec: 798.8163183395181
avg_train_sample_per_sec: 798.8163183395181
avg_episode_per_sec: 5.153653666706569
collect_time: 0.9701854884624482
reward_mean: 1433.199951171875
reward_std: 413.3789367675781
reward_max: 1700.0
reward_min: 632.0
total_envstep_count: 2565950
total_train_sample_count: 2565912
total_episode_count: 16202
total_duration: 3264.0830132876144
[2024-11-20 00:47:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1368
train_sample_count: 1368
avg_envstep_per_episode: 684.0
avg_sample_per_episode: 684.0
avg_envstep_per_sec: 799.5611842339383
avg_train_sample_per_sec: 799.5611842339383
avg_episode_per_sec: 1.1689490997572198
collect_time: 1.710938483476639
reward_mean: 1808.5
reward_std: 369.5
reward_max: 2178.0
reward_min: 1439.0
total_envstep_count: 2566909
total_train_sample_count: 2566872
total_episode_count: 16204
total_duration: 3265.793951771091
[2024-11-20 00:47:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 920
train_sample_count: 920
avg_envstep_per_episode: 153.33333333333334
avg_sample_per_episode: 153.33333333333334
avg_envstep_per_sec: 805.9220043105025
avg_train_sample_per_sec: 805.9220043105025
avg_episode_per_sec: 5.256013071590234
collect_time: 1.1415496723992486
reward_mean: 1113.8333740234375
reward_std: 666.3666381835938
reward_max: 2348.0
reward_min: 596.0
total_envstep_count: 2567928
total_train_sample_count: 2567876
total_episode_count: 16210
total_duration: 3266.9355014434905
[2024-11-20 00:47:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1423
train_sample_count: 1423
avg_envstep_per_episode: 284.6
avg_sample_per_episode: 284.6
avg_envstep_per_sec: 812.7943501466596
avg_train_sample_per_sec: 812.7943501466596
avg_episode_per_sec: 2.8559183069102585
collect_time: 1.7507503586156028
reward_mean: 1521.800048828125
reward_std: 547.2612915039062
reward_max: 2294.0
reward_min: 638.0
total_envstep_count: 2568924
total_train_sample_count: 2568879
total_episode_count: 16215
total_duration: 3268.686251802106
[2024-11-20 00:47:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1087
train_sample_count: 1087
avg_envstep_per_episode: 135.875
avg_sample_per_episode: 135.875
avg_envstep_per_sec: 795.9309950299577
avg_train_sample_per_sec: 795.9309950299577
avg_episode_per_sec: 5.8578178107080605
collect_time: 1.365696281194687
reward_mean: 1038.75
reward_std: 550.8215942382812
reward_max: 1852.0
reward_min: 234.0
total_envstep_count: 2569932
total_train_sample_count: 2569906
total_episode_count: 16223
total_duration: 3270.051948083301
[2024-11-20 00:47:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1837
train_sample_count: 1837
avg_envstep_per_episode: 459.25
avg_sample_per_episode: 459.25
avg_envstep_per_sec: 808.7934339377592
avg_train_sample_per_sec: 808.7934339377592
avg_episode_per_sec: 1.7611179835334987
collect_time: 2.271284512111119
reward_mean: 1795.0
reward_std: 467.8797912597656
reward_max: 2327.0
reward_min: 1325.0
total_envstep_count: 2570921
total_train_sample_count: 2570891
total_episode_count: 16227
total_duration: 3272.323232595412
[2024-11-20 00:47:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 823
train_sample_count: 823
avg_envstep_per_episode: 137.16666666666666
avg_sample_per_episode: 137.16666666666666
avg_envstep_per_sec: 813.3212731926967
avg_train_sample_per_sec: 813.3212731926967
avg_episode_per_sec: 5.929438200675796
collect_time: 1.0119002504008157
reward_mean: 1266.8333740234375
reward_std: 384.2696228027344
reward_max: 1863.0
reward_min: 598.0
total_envstep_count: 2571923
total_train_sample_count: 2571882
total_episode_count: 16233
total_duration: 3273.3351328458125
[2024-11-20 00:47:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 908
train_sample_count: 908
avg_envstep_per_episode: 181.6
avg_sample_per_episode: 181.6
avg_envstep_per_sec: 803.5937221548841
avg_train_sample_per_sec: 803.5937221548841
avg_episode_per_sec: 4.425075562526895
collect_time: 1.1299242079257965
reward_mean: 1205.199951171875
reward_std: 451.2867736816406
reward_max: 1683.0
reward_min: 616.0
total_envstep_count: 2572918
total_train_sample_count: 2572874
total_episode_count: 16238
total_duration: 3274.4650570537383
[2024-11-20 00:47:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 907
train_sample_count: 907
avg_envstep_per_episode: 302.3333333333333
avg_sample_per_episode: 302.3333333333333
avg_envstep_per_sec: 815.2820757548996
avg_train_sample_per_sec: 815.2820757548996
avg_episode_per_sec: 2.6966331061352795
collect_time: 1.1124983940805708
reward_mean: 1737.0
reward_std: 425.00433349609375
reward_max: 2319.0
reward_min: 1316.0
total_envstep_count: 2573884
total_train_sample_count: 2573841
total_episode_count: 16241
total_duration: 3275.5775554478187
[2024-11-20 00:47:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 760
train_sample_count: 760
avg_envstep_per_episode: 190.0
avg_sample_per_episode: 190.0
avg_envstep_per_sec: 809.9417057928056
avg_train_sample_per_sec: 809.9417057928056
avg_episode_per_sec: 4.2628510831200295
collect_time: 0.9383391354765211
reward_mean: 1240.25
reward_std: 636.0048828125
reward_max: 1900.0
reward_min: 596.0
total_envstep_count: 2574857
total_train_sample_count: 2574817
total_episode_count: 16245
total_duration: 3276.515894583295
[2024-11-20 00:47:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 12
envstep_count: 1960
train_sample_count: 1960
avg_envstep_per_episode: 163.33333333333334
avg_sample_per_episode: 163.33333333333334
avg_envstep_per_sec: 807.3168165937888
avg_train_sample_per_sec: 807.3168165937888
avg_episode_per_sec: 4.942756019961972
collect_time: 2.427795333521707
reward_mean: 1189.6666259765625
reward_std: 614.85302734375
reward_max: 2316.0
reward_min: 234.0
total_envstep_count: 2575864
total_train_sample_count: 2575817
total_episode_count: 16257
total_duration: 3278.9436899168168
[2024-11-20 00:47:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 567
train_sample_count: 567
avg_envstep_per_episode: 113.4
avg_sample_per_episode: 113.4
avg_envstep_per_sec: 812.1125017942512
avg_train_sample_per_sec: 812.1125017942512
avg_episode_per_sec: 7.161485906474878
collect_time: 0.6981791300433022
reward_mean: 985.0
reward_std: 326.8192138671875
reward_max: 1342.0
reward_min: 605.0
total_envstep_count: 2576820
total_train_sample_count: 2576792
total_episode_count: 16262
total_duration: 3279.64186904686
[2024-11-20 00:47:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 807
train_sample_count: 807
avg_envstep_per_episode: 134.5
avg_sample_per_episode: 134.5
avg_envstep_per_sec: 816.8208895007713
avg_train_sample_per_sec: 816.8208895007713
avg_episode_per_sec: 6.073017765804991
collect_time: 0.9879766915525707
reward_mean: 1133.0
reward_std: 539.912353515625
reward_max: 1915.0
reward_min: 604.0
total_envstep_count: 2577814
total_train_sample_count: 2577779
total_episode_count: 16268
total_duration: 3280.6298457384123
[2024-11-20 00:47:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1302
train_sample_count: 1302
avg_envstep_per_episode: 217.0
avg_sample_per_episode: 217.0
avg_envstep_per_sec: 814.932978676087
avg_train_sample_per_sec: 814.932978676087
avg_episode_per_sec: 3.755451514636346
collect_time: 1.5976773968764717
reward_mean: 1151.6666259765625
reward_std: 623.6560668945312
reward_max: 2315.0
reward_min: 602.0
total_envstep_count: 2578800
total_train_sample_count: 2578769
total_episode_count: 16274
total_duration: 3282.2275231352887
[2024-11-20 00:47:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 863
train_sample_count: 863
avg_envstep_per_episode: 123.28571428571429
avg_sample_per_episode: 123.28571428571429
avg_envstep_per_sec: 805.9893880367289
avg_train_sample_per_sec: 805.9893880367289
avg_episode_per_sec: 6.537573251746353
collect_time: 1.07073370047978
reward_mean: 996.7142944335938
reward_std: 469.6967468261719
reward_max: 1866.0
reward_min: 603.0
total_envstep_count: 2579819
total_train_sample_count: 2579776
total_episode_count: 16281
total_duration: 3283.2982568357684
[2024-11-20 00:47:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 676
train_sample_count: 676
avg_envstep_per_episode: 135.2
avg_sample_per_episode: 135.2
avg_envstep_per_sec: 801.0368820460934
avg_train_sample_per_sec: 801.0368820460934
avg_episode_per_sec: 5.924829009216667
collect_time: 0.8439062110015323
reward_mean: 1006.5999755859375
reward_std: 659.4581298828125
reward_max: 1888.0
reward_min: 248.0
total_envstep_count: 2580798
total_train_sample_count: 2580752
total_episode_count: 16286
total_duration: 3284.14216304677
[2024-11-20 00:47:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 874
train_sample_count: 874
avg_envstep_per_episode: 174.8
avg_sample_per_episode: 174.8
avg_envstep_per_sec: 809.4507803397238
avg_train_sample_per_sec: 809.4507803397238
avg_episode_per_sec: 4.630725287984689
collect_time: 1.0797444652943384
reward_mean: 1324.4000244140625
reward_std: 422.5799865722656
reward_max: 1885.0
reward_min: 586.0
total_envstep_count: 2581793
total_train_sample_count: 2581758
total_episode_count: 16291
total_duration: 3285.2219075120643
[2024-11-20 00:47:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 349
train_sample_count: 349
avg_envstep_per_episode: 349.0
avg_sample_per_episode: 349.0
avg_envstep_per_sec: 804.7782489922716
avg_train_sample_per_sec: 804.7782489922716
avg_episode_per_sec: 2.3059548681726985
collect_time: 0.43365983168284095
reward_mean: 2349.0
reward_std: 0.0
reward_max: 2349.0
reward_min: 2349.0
total_envstep_count: 2582944
total_train_sample_count: 2582911
total_episode_count: 16292
total_duration: 3285.655567343747
[2024-11-20 00:48:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1203
train_sample_count: 1203
avg_envstep_per_episode: 171.85714285714286
avg_sample_per_episode: 171.85714285714286
avg_envstep_per_sec: 810.4593619788326
avg_train_sample_per_sec: 810.4593619788326
avg_episode_per_sec: 4.715889886826125
collect_time: 1.4843433939275288
reward_mean: 1145.0
reward_std: 485.9329833984375
reward_max: 1834.0
reward_min: 614.0
total_envstep_count: 2583953
total_train_sample_count: 2583910
total_episode_count: 16299
total_duration: 3287.1399107376747
[2024-11-20 00:48:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 863
train_sample_count: 863
avg_envstep_per_episode: 143.83333333333334
avg_sample_per_episode: 143.83333333333334
avg_envstep_per_sec: 803.3823241197376
avg_train_sample_per_sec: 803.3823241197376
avg_episode_per_sec: 5.585508626556693
collect_time: 1.0742083489894867
reward_mean: 1116.1666259765625
reward_std: 813.6310424804688
reward_max: 2344.0
reward_min: 242.0
total_envstep_count: 2584931
total_train_sample_count: 2584893
total_episode_count: 16305
total_duration: 3288.214119086664
[2024-11-20 00:48:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1294
train_sample_count: 1294
avg_envstep_per_episode: 215.66666666666666
avg_sample_per_episode: 215.66666666666666
avg_envstep_per_sec: 811.9852505753618
avg_train_sample_per_sec: 811.9852505753618
avg_episode_per_sec: 3.7650011618641193
collect_time: 1.5936250062215898
reward_mean: 1312.1666259765625
reward_std: 599.5602416992188
reward_max: 2290.0
reward_min: 619.0
total_envstep_count: 2585918
total_train_sample_count: 2585887
total_episode_count: 16311
total_duration: 3289.8077440928855
[2024-11-20 00:48:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 511
train_sample_count: 511
avg_envstep_per_episode: 127.75
avg_sample_per_episode: 127.75
avg_envstep_per_sec: 802.1383158818334
avg_train_sample_per_sec: 802.1383158818334
avg_episode_per_sec: 6.2789692045544685
collect_time: 0.6370472397123064
reward_mean: 499.5
reward_std: 151.4504852294922
reward_max: 622.0
reward_min: 240.0
total_envstep_count: 2586922
total_train_sample_count: 2586878
total_episode_count: 16315
total_duration: 3290.444791332598
[2024-11-20 00:48:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 891
train_sample_count: 891
avg_envstep_per_episode: 222.75
avg_sample_per_episode: 222.75
avg_envstep_per_sec: 811.8477884049136
avg_train_sample_per_sec: 811.8477884049136
avg_episode_per_sec: 3.6446589827381084
collect_time: 1.0974963690553392
reward_mean: 1230.5
reward_std: 346.72576904296875
reward_max: 1485.0
reward_min: 641.0
total_envstep_count: 2587911
total_train_sample_count: 2587865
total_episode_count: 16319
total_duration: 3291.5422877016535
[2024-11-20 00:48:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 769
train_sample_count: 769
avg_envstep_per_episode: 192.25
avg_sample_per_episode: 192.25
avg_envstep_per_sec: 813.2234803414312
avg_train_sample_per_sec: 813.2234803414312
avg_episode_per_sec: 4.230031107107575
collect_time: 0.945619523525238
reward_mean: 1313.25
reward_std: 183.26397705078125
reward_max: 1554.0
reward_min: 1038.0
total_envstep_count: 2588884
total_train_sample_count: 2588850
total_episode_count: 16323
total_duration: 3292.487907225179
[2024-11-20 00:48:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 444
train_sample_count: 444
avg_envstep_per_episode: 148.0
avg_sample_per_episode: 148.0
avg_envstep_per_sec: 812.7452020353518
avg_train_sample_per_sec: 812.7452020353518
avg_episode_per_sec: 5.491521635373998
collect_time: 0.5462966731616429
reward_mean: 1413.6666259765625
reward_std: 112.66864013671875
reward_max: 1573.0
reward_min: 1333.0
total_envstep_count: 2589881
total_train_sample_count: 2589834
total_episode_count: 16326
total_duration: 3293.0342038983404
[2024-11-20 00:48:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1216
train_sample_count: 1216
avg_envstep_per_episode: 304.0
avg_sample_per_episode: 304.0
avg_envstep_per_sec: 812.041602082236
avg_train_sample_per_sec: 812.041602082236
avg_episode_per_sec: 2.6711894805336707
collect_time: 1.4974602247987474
reward_mean: 1538.0
reward_std: 462.3478088378906
reward_max: 2273.0
reward_min: 1044.0
total_envstep_count: 2590837
total_train_sample_count: 2590810
total_episode_count: 16330
total_duration: 3294.5316641231393
[2024-11-20 00:48:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 776
train_sample_count: 776
avg_envstep_per_episode: 129.33333333333334
avg_sample_per_episode: 129.33333333333334
avg_envstep_per_sec: 807.52567451805
avg_train_sample_per_sec: 807.52567451805
avg_episode_per_sec: 6.243755215345747
collect_time: 0.9609601582799641
reward_mean: 1051.8333740234375
reward_std: 482.3199157714844
reward_max: 1632.0
reward_min: 252.0
total_envstep_count: 2591856
total_train_sample_count: 2591814
total_episode_count: 16336
total_duration: 3295.4926242814195
[2024-11-20 00:48:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 399
train_sample_count: 399
avg_envstep_per_episode: 99.75
avg_sample_per_episode: 99.75
avg_envstep_per_sec: 821.4722213140287
avg_train_sample_per_sec: 821.4722213140287
avg_episode_per_sec: 8.235310489363696
collect_time: 0.48571332011904034
reward_mean: 730.5
reward_std: 178.14671325683594
reward_max: 1039.0
reward_min: 622.0
total_envstep_count: 2592830
total_train_sample_count: 2592801
total_episode_count: 16340
total_duration: 3295.9783376015384
[2024-11-20 00:48:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 3798
train_sample_count: 3798
avg_envstep_per_episode: 542.5714285714286
avg_sample_per_episode: 542.5714285714286
avg_envstep_per_sec: 806.4397958674884
avg_train_sample_per_sec: 806.4397958674884
avg_episode_per_sec: 1.486329270951137
collect_time: 4.709589010193236
reward_mean: 1631.5714111328125
reward_std: 827.6387939453125
reward_max: 2996.0
reward_min: 619.0
total_envstep_count: 2593856
total_train_sample_count: 2593803
total_episode_count: 16347
total_duration: 3300.6879266117317
[2024-11-20 00:48:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 838
train_sample_count: 838
avg_envstep_per_episode: 209.5
avg_sample_per_episode: 209.5
avg_envstep_per_sec: 818.1738747247714
avg_train_sample_per_sec: 818.1738747247714
avg_episode_per_sec: 3.905364557158814
collect_time: 1.0242321661540439
reward_mean: 1649.5
reward_std: 602.5050048828125
reward_max: 2639.0
reward_min: 1043.0
total_envstep_count: 2594821
total_train_sample_count: 2594797
total_episode_count: 16351
total_duration: 3301.7121587778856
[2024-11-20 00:48:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 592
train_sample_count: 592
avg_envstep_per_episode: 148.0
avg_sample_per_episode: 148.0
avg_envstep_per_sec: 827.2032672852248
avg_train_sample_per_sec: 827.2032672852248
avg_episode_per_sec: 5.589211265440708
collect_time: 0.7156644846711839
reward_mean: 889.75
reward_std: 517.7723388671875
reward_max: 1693.0
reward_min: 246.0
total_envstep_count: 2595779
total_train_sample_count: 2595761
total_episode_count: 16355
total_duration: 3302.427823262557
[2024-11-20 00:48:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 701
train_sample_count: 701
avg_envstep_per_episode: 175.25
avg_sample_per_episode: 175.25
avg_envstep_per_sec: 813.925756504023
avg_train_sample_per_sec: 813.925756504023
avg_episode_per_sec: 4.644369509295424
collect_time: 0.8612579149859293
reward_mean: 1379.0
reward_std: 447.7320556640625
reward_max: 1695.0
reward_min: 607.0
total_envstep_count: 2596808
total_train_sample_count: 2596738
total_episode_count: 16359
total_duration: 3303.289081177543
[2024-11-20 00:48:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 791
train_sample_count: 791
avg_envstep_per_episode: 197.75
avg_sample_per_episode: 197.75
avg_envstep_per_sec: 795.9559495864935
avg_train_sample_per_sec: 795.9559495864935
avg_episode_per_sec: 4.025061691967098
collect_time: 0.9937735881124223
reward_mean: 1266.75
reward_std: 715.4202270507812
reward_max: 2327.0
reward_min: 607.0
total_envstep_count: 2597780
total_train_sample_count: 2597733
total_episode_count: 16363
total_duration: 3304.2828547656554
[2024-11-20 00:48:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1306
train_sample_count: 1306
avg_envstep_per_episode: 261.2
avg_sample_per_episode: 261.2
avg_envstep_per_sec: 818.2223953357069
avg_train_sample_per_sec: 818.2223953357069
avg_episode_per_sec: 3.132551283827362
collect_time: 1.5961430626256126
reward_mean: 1595.4000244140625
reward_std: 808.2382202148438
reward_max: 2608.0
reward_min: 618.0
total_envstep_count: 2598767
total_train_sample_count: 2598739
total_episode_count: 16368
total_duration: 3305.878997828281
[2024-11-20 00:48:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 334
train_sample_count: 334
avg_envstep_per_episode: 167.0
avg_sample_per_episode: 167.0
avg_envstep_per_sec: 806.5814898484012
avg_train_sample_per_sec: 806.5814898484012
avg_episode_per_sec: 4.829829280529349
collect_time: 0.4140933113438743
reward_mean: 1270.0
reward_std: 647.0
reward_max: 1917.0
reward_min: 623.0
total_envstep_count: 2599733
total_train_sample_count: 2599709
total_episode_count: 16370
total_duration: 3306.293091139625
[2024-11-20 00:49:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 996
train_sample_count: 996
avg_envstep_per_episode: 166.0
avg_sample_per_episode: 166.0
avg_envstep_per_sec: 817.5269579620647
avg_train_sample_per_sec: 817.5269579620647
avg_episode_per_sec: 4.924861192542558
collect_time: 1.218308448791504
reward_mean: 1236.5
reward_std: 785.0088500976562
reward_max: 2350.0
reward_min: 249.0
total_envstep_count: 2600736
total_train_sample_count: 2600705
total_episode_count: 16376
total_duration: 3307.5113995884167
[2024-11-20 00:49:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1422
train_sample_count: 1422
avg_envstep_per_episode: 203.14285714285714
avg_sample_per_episode: 203.14285714285714
avg_envstep_per_sec: 808.7900485591998
avg_train_sample_per_sec: 808.7900485591998
avg_episode_per_sec: 3.981385611754148
collect_time: 1.7581818699836735
reward_mean: 1119.5714111328125
reward_std: 810.5999755859375
reward_max: 2314.0
reward_min: 243.0
total_envstep_count: 2601738
total_train_sample_count: 2601695
total_episode_count: 16383
total_duration: 3309.2695814584004
[2024-11-20 00:49:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 582
train_sample_count: 582
avg_envstep_per_episode: 145.5
avg_sample_per_episode: 145.5
avg_envstep_per_sec: 808.7993376804293
avg_train_sample_per_sec: 808.7993376804293
avg_episode_per_sec: 5.5587583345733975
collect_time: 0.7195851589952196
reward_mean: 1012.75
reward_std: 397.4665832519531
reward_max: 1491.0
reward_min: 608.0
total_envstep_count: 2602734
total_train_sample_count: 2602673
total_episode_count: 16387
total_duration: 3309.9891666173958
[2024-11-20 00:49:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1457
train_sample_count: 1457
avg_envstep_per_episode: 208.14285714285714
avg_sample_per_episode: 208.14285714285714
avg_envstep_per_sec: 813.9085516011189
avg_train_sample_per_sec: 813.9085516011189
avg_episode_per_sec: 3.91033621222226
collect_time: 1.790127400841032
reward_mean: 1436.0
reward_std: 644.4722900390625
reward_max: 2621.0
reward_min: 618.0
total_envstep_count: 2603743
total_train_sample_count: 2603698
total_episode_count: 16394
total_duration: 3311.7792940182367
[2024-11-20 00:49:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 479
train_sample_count: 479
avg_envstep_per_episode: 79.83333333333333
avg_sample_per_episode: 79.83333333333333
avg_envstep_per_sec: 803.66709995724
avg_train_sample_per_sec: 803.66709995724
avg_episode_per_sec: 10.066811272950813
collect_time: 0.5960179283505393
reward_mean: 656.8333129882812
reward_std: 445.4804382324219
reward_max: 1581.0
reward_min: 246.0
total_envstep_count: 2604737
total_train_sample_count: 2604693
total_episode_count: 16400
total_duration: 3312.3753119465873
[2024-11-20 00:49:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 920
train_sample_count: 920
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 805.559612926315
avg_train_sample_per_sec: 805.559612926315
avg_episode_per_sec: 4.378041374599538
collect_time: 1.1420632132462094
reward_mean: 1343.0
reward_std: 597.9926147460938
reward_max: 1940.0
reward_min: 598.0
total_envstep_count: 2605700
total_train_sample_count: 2605661
total_episode_count: 16405
total_duration: 3313.5173751598336
[2024-11-20 00:49:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 497
train_sample_count: 497
avg_envstep_per_episode: 124.25
avg_sample_per_episode: 124.25
avg_envstep_per_sec: 808.986183151071
avg_train_sample_per_sec: 808.986183151071
avg_episode_per_sec: 6.51095519638689
collect_time: 0.6143491821629661
reward_mean: 895.0
reward_std: 305.05572509765625
reward_max: 1328.0
reward_min: 600.0
total_envstep_count: 2606705
total_train_sample_count: 2606662
total_episode_count: 16409
total_duration: 3314.1317243419967
[2024-11-20 00:49:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 718
train_sample_count: 718
avg_envstep_per_episode: 143.6
avg_sample_per_episode: 143.6
avg_envstep_per_sec: 822.8143927312723
avg_train_sample_per_sec: 822.8143927312723
avg_episode_per_sec: 5.7299052418612275
collect_time: 0.87261477964265
reward_mean: 722.2000122070312
reward_std: 343.19989013671875
reward_max: 1301.0
reward_min: 247.0
total_envstep_count: 2607709
total_train_sample_count: 2607668
total_episode_count: 16414
total_duration: 3315.0043391216395
[2024-11-20 00:49:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 347
train_sample_count: 347
avg_envstep_per_episode: 173.5
avg_sample_per_episode: 173.5
avg_envstep_per_sec: 813.3717502202716
avg_train_sample_per_sec: 813.3717502202716
avg_episode_per_sec: 4.688021615102429
collect_time: 0.42661919338362553
reward_mean: 1206.5
reward_std: 489.5
reward_max: 1696.0
reward_min: 717.0
total_envstep_count: 2608715
total_train_sample_count: 2608675
total_episode_count: 16416
total_duration: 3315.430958315023
[2024-11-20 00:49:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 3296
train_sample_count: 3296
avg_envstep_per_episode: 549.3333333333334
avg_sample_per_episode: 549.3333333333334
avg_envstep_per_sec: 815.4567638054526
avg_train_sample_per_sec: 815.4567638054526
avg_episode_per_sec: 1.4844479923642948
collect_time: 4.041906507242293
reward_mean: 952.3333129882812
reward_std: 212.1459197998047
reward_max: 1273.0
reward_min: 613.0
total_envstep_count: 2609664
total_train_sample_count: 2609643
total_episode_count: 16422
total_duration: 3319.4728648222654
[2024-11-20 00:49:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 597
train_sample_count: 597
avg_envstep_per_episode: 119.4
avg_sample_per_episode: 119.4
avg_envstep_per_sec: 808.1303991142838
avg_train_sample_per_sec: 808.1303991142838
avg_episode_per_sec: 6.768261299114605
collect_time: 0.7387421642030988
reward_mean: 412.20001220703125
reward_std: 544.5950927734375
reward_max: 1500.0
reward_min: 103.0
total_envstep_count: 2610709
total_train_sample_count: 2610672
total_episode_count: 16427
total_duration: 3320.2116069864683
[2024-11-20 00:49:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 558
train_sample_count: 558
avg_envstep_per_episode: 186.0
avg_sample_per_episode: 186.0
avg_envstep_per_sec: 818.729793854441
avg_train_sample_per_sec: 818.729793854441
avg_episode_per_sec: 4.40177308523893
collect_time: 0.6815435375486101
reward_mean: 802.3333129882812
reward_std: 164.54449462890625
reward_max: 1022.0
reward_min: 626.0
total_envstep_count: 2611674
total_train_sample_count: 2611638
total_episode_count: 16430
total_duration: 3320.893150524017
[2024-11-20 00:49:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 536
train_sample_count: 536
avg_envstep_per_episode: 178.66666666666666
avg_sample_per_episode: 178.66666666666666
avg_envstep_per_sec: 827.6072602854812
avg_train_sample_per_sec: 827.6072602854812
avg_episode_per_sec: 4.632130188165006
collect_time: 0.647650190762111
reward_mean: 1199.0
reward_std: 813.1744384765625
reward_max: 2349.0
reward_min: 622.0
total_envstep_count: 2612631
total_train_sample_count: 2612606
total_episode_count: 16433
total_duration: 3321.5408007147794
[2024-11-20 00:49:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 264
train_sample_count: 264
avg_envstep_per_episode: 132.0
avg_sample_per_episode: 132.0
avg_envstep_per_sec: 807.4293198899871
avg_train_sample_per_sec: 807.4293198899871
avg_episode_per_sec: 6.116888787045357
collect_time: 0.3269636034965515
reward_mean: 1273.0
reward_std: 657.0
reward_max: 1930.0
reward_min: 616.0
total_envstep_count: 2613637
total_train_sample_count: 2613578
total_episode_count: 16435
total_duration: 3321.867764318276
[2024-11-20 00:49:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2491
train_sample_count: 2491
avg_envstep_per_episode: 311.375
avg_sample_per_episode: 311.375
avg_envstep_per_sec: 804.4233695779917
avg_train_sample_per_sec: 804.4233695779917
avg_episode_per_sec: 2.5834552214467816
collect_time: 3.0966280869075233
reward_mean: 1546.875
reward_std: 692.4253540039062
reward_max: 2314.0
reward_min: 617.0
total_envstep_count: 2614614
total_train_sample_count: 2614593
total_episode_count: 16443
total_duration: 3324.9643924051834
[2024-11-20 00:49:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 327
train_sample_count: 327
avg_envstep_per_episode: 163.5
avg_sample_per_episode: 163.5
avg_envstep_per_sec: 811.5032235833792
avg_train_sample_per_sec: 811.5032235833792
avg_episode_per_sec: 4.9633224683998725
collect_time: 0.4029558854443686
reward_mean: 1513.0
reward_std: 184.0
reward_max: 1697.0
reward_min: 1329.0
total_envstep_count: 2615574
total_train_sample_count: 2615556
total_episode_count: 16445
total_duration: 3325.367348290628
[2024-11-20 00:49:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 966
train_sample_count: 966
avg_envstep_per_episode: 138.0
avg_sample_per_episode: 138.0
avg_envstep_per_sec: 812.6498993662191
avg_train_sample_per_sec: 812.6498993662191
avg_episode_per_sec: 5.8887673867117325
collect_time: 1.1887037711484094
reward_mean: 1110.0
reward_std: 560.7938232421875
reward_max: 1697.0
reward_min: 245.0
total_envstep_count: 2616593
total_train_sample_count: 2616534
total_episode_count: 16452
total_duration: 3326.5560520617764
[2024-11-20 00:50:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2881
train_sample_count: 2881
avg_envstep_per_episode: 411.57142857142856
avg_sample_per_episode: 411.57142857142856
avg_envstep_per_sec: 816.8069551698786
avg_train_sample_per_sec: 816.8069551698786
avg_episode_per_sec: 1.9846055835436136
collect_time: 3.5271492018586112
reward_mean: 1273.2857666015625
reward_std: 580.6377563476562
reward_max: 2333.0
reward_min: 603.0
total_envstep_count: 2617547
total_train_sample_count: 2617519
total_episode_count: 16459
total_duration: 3330.083201263635
[2024-11-20 00:50:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 334
train_sample_count: 334
avg_envstep_per_episode: 111.33333333333333
avg_sample_per_episode: 111.33333333333333
avg_envstep_per_sec: 806.7037528000599
avg_train_sample_per_sec: 806.7037528000599
avg_episode_per_sec: 7.245842091018502
collect_time: 0.4140305519104004
reward_mean: 756.0
reward_std: 203.6483917236328
reward_max: 1044.0
reward_min: 611.0
total_envstep_count: 2618536
total_train_sample_count: 2618501
total_episode_count: 16462
total_duration: 3330.4972318155455
[2024-11-20 00:50:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1615
train_sample_count: 1615
avg_envstep_per_episode: 161.5
avg_sample_per_episode: 161.5
avg_envstep_per_sec: 817.2899781307792
avg_train_sample_per_sec: 817.2899781307792
avg_episode_per_sec: 5.060619059633308
collect_time: 1.9760428283895763
reward_mean: 1118.199951171875
reward_std: 454.884765625
reward_max: 1896.0
reward_min: 621.0
total_envstep_count: 2619536
total_train_sample_count: 2619492
total_episode_count: 16472
total_duration: 3332.473274643935
[2024-11-20 00:50:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 671
train_sample_count: 671
avg_envstep_per_episode: 167.75
avg_sample_per_episode: 167.75
avg_envstep_per_sec: 804.018462229813
avg_train_sample_per_sec: 804.018462229813
avg_episode_per_sec: 4.792956555766397
collect_time: 0.8345579504966737
reward_mean: 1247.25
reward_std: 299.19757080078125
reward_max: 1569.0
reward_min: 757.0
total_envstep_count: 2620532
total_train_sample_count: 2620487
total_episode_count: 16476
total_duration: 3333.3078325944316
[2024-11-20 00:50:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 671
train_sample_count: 671
avg_envstep_per_episode: 134.2
avg_sample_per_episode: 134.2
avg_envstep_per_sec: 800.0216643637017
avg_train_sample_per_sec: 800.0216643637017
avg_episode_per_sec: 5.961413296301801
collect_time: 0.838727286883763
reward_mean: 1095.5999755859375
reward_std: 581.1727905273438
reward_max: 1910.0
reward_min: 623.0
total_envstep_count: 2621488
total_train_sample_count: 2621458
total_episode_count: 16481
total_duration: 3334.146559881315
[2024-11-20 00:50:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 784
train_sample_count: 784
avg_envstep_per_episode: 196.0
avg_sample_per_episode: 196.0
avg_envstep_per_sec: 811.9404577042061
avg_train_sample_per_sec: 811.9404577042061
avg_episode_per_sec: 4.142553355633705
collect_time: 0.9655880459717343
reward_mean: 1273.25
reward_std: 730.1915283203125
reward_max: 2330.0
reward_min: 583.0
total_envstep_count: 2622484
total_train_sample_count: 2622434
total_episode_count: 16485
total_duration: 3335.112147927287
[2024-11-20 00:50:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1054
train_sample_count: 1054
avg_envstep_per_episode: 175.66666666666666
avg_sample_per_episode: 175.66666666666666
avg_envstep_per_sec: 819.2510820682432
avg_train_sample_per_sec: 819.2510820682432
avg_episode_per_sec: 4.663668398870455
collect_time: 1.2865408701556067
reward_mean: 1222.0
reward_std: 690.1729125976562
reward_max: 2368.0
reward_min: 249.0
total_envstep_count: 2623448
total_train_sample_count: 2623416
total_episode_count: 16491
total_duration: 3336.3986887974424
[2024-11-20 00:50:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 987
train_sample_count: 987
avg_envstep_per_episode: 329.0
avg_sample_per_episode: 329.0
avg_envstep_per_sec: 810.7324102760947
avg_train_sample_per_sec: 810.7324102760947
avg_episode_per_sec: 2.464232250079315
collect_time: 1.2174177169799805
reward_mean: 1619.0
reward_std: 804.607177734375
reward_max: 2562.0
reward_min: 596.0
total_envstep_count: 2624407
total_train_sample_count: 2624379
total_episode_count: 16494
total_duration: 3337.6161065144224
[2024-11-20 00:50:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1332
train_sample_count: 1332
avg_envstep_per_episode: 222.0
avg_sample_per_episode: 222.0
avg_envstep_per_sec: 811.6368913211173
avg_train_sample_per_sec: 811.6368913211173
avg_episode_per_sec: 3.656022032978006
collect_time: 1.641127965279988
reward_mean: 1218.1666259765625
reward_std: 442.5081787109375
reward_max: 1688.0
reward_min: 620.0
total_envstep_count: 2625395
total_train_sample_count: 2625363
total_episode_count: 16500
total_duration: 3339.257234479702
[2024-11-20 00:50:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 670
train_sample_count: 670
avg_envstep_per_episode: 335.0
avg_sample_per_episode: 335.0
avg_envstep_per_sec: 813.5736305389207
avg_train_sample_per_sec: 813.5736305389207
avg_episode_per_sec: 2.428578001608719
collect_time: 0.823527182851519
reward_mean: 2350.5
reward_std: 0.5
reward_max: 2351.0
reward_min: 2350.0
total_envstep_count: 2626369
total_train_sample_count: 2626333
total_episode_count: 16502
total_duration: 3340.080761662554
[2024-11-20 00:50:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1467
train_sample_count: 1467
avg_envstep_per_episode: 163.0
avg_sample_per_episode: 163.0
avg_envstep_per_sec: 811.1197807647654
avg_train_sample_per_sec: 811.1197807647654
avg_episode_per_sec: 4.976194974016966
collect_time: 1.808610805443355
reward_mean: 1088.111083984375
reward_std: 617.1600341796875
reward_max: 2349.0
reward_min: 243.0
total_envstep_count: 2627373
total_train_sample_count: 2627344
total_episode_count: 16511
total_duration: 3341.8893724679974
[2024-11-20 00:50:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1300
train_sample_count: 1300
avg_envstep_per_episode: 130.0
avg_sample_per_episode: 130.0
avg_envstep_per_sec: 812.2065600479318
avg_train_sample_per_sec: 812.2065600479318
avg_episode_per_sec: 6.247742769599475
collect_time: 1.600578059752782
reward_mean: 968.5999755859375
reward_std: 645.268798828125
reward_max: 2335.0
reward_min: 245.0
total_envstep_count: 2628379
total_train_sample_count: 2628356
total_episode_count: 16521
total_duration: 3343.4899505277504
[2024-11-20 00:50:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 613
train_sample_count: 613
avg_envstep_per_episode: 87.57142857142857
avg_sample_per_episode: 87.57142857142857
avg_envstep_per_sec: 807.2469301724464
avg_train_sample_per_sec: 807.2469301724464
avg_episode_per_sec: 9.218154178151917
collect_time: 0.7593711132094974
reward_mean: 769.1428833007812
reward_std: 607.5575561523438
reward_max: 1703.0
reward_min: 243.0
total_envstep_count: 2629366
total_train_sample_count: 2629329
total_episode_count: 16528
total_duration: 3344.24932164096
[2024-11-20 00:50:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1010
train_sample_count: 1010
avg_envstep_per_episode: 144.28571428571428
avg_sample_per_episode: 144.28571428571428
avg_envstep_per_sec: 805.1464766146621
avg_train_sample_per_sec: 805.1464766146621
avg_episode_per_sec: 5.580223105250134
collect_time: 1.2544301308336712
reward_mean: 1220.2857666015625
reward_std: 645.5639038085938
reward_max: 1865.0
reward_min: 246.0
total_envstep_count: 2630337
total_train_sample_count: 2630315
total_episode_count: 16535
total_duration: 3345.5037517717933
[2024-11-20 00:50:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 242
train_sample_count: 242
avg_envstep_per_episode: 242.0
avg_sample_per_episode: 242.0
avg_envstep_per_sec: 813.0711456036292
avg_train_sample_per_sec: 813.0711456036292
avg_episode_per_sec: 3.3597981223290465
collect_time: 0.29763693043163847
reward_mean: 1387.0
reward_std: 0.0
reward_max: 1387.0
reward_min: 1387.0
total_envstep_count: 2631297
total_train_sample_count: 2631277
total_episode_count: 16536
total_duration: 3345.801388702225
[2024-11-20 00:50:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 11
envstep_count: 1991
train_sample_count: 1991
avg_envstep_per_episode: 181.0
avg_sample_per_episode: 181.0
avg_envstep_per_sec: 806.7246998856034
avg_train_sample_per_sec: 806.7246998856034
avg_episode_per_sec: 4.457042540804438
collect_time: 2.468004265001842
reward_mean: 1090.54541015625
reward_std: 689.6656494140625
reward_max: 2341.0
reward_min: 245.0
total_envstep_count: 2632350
total_train_sample_count: 2632308
total_episode_count: 16547
total_duration: 3348.269392967227
[2024-11-20 00:50:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 580
train_sample_count: 580
avg_envstep_per_episode: 193.33333333333334
avg_sample_per_episode: 193.33333333333334
avg_envstep_per_sec: 810.6253030971527
avg_train_sample_per_sec: 810.6253030971527
avg_episode_per_sec: 4.192889498778376
collect_time: 0.7154970339366369
reward_mean: 1196.0
reward_std: 448.4915466308594
reward_max: 1680.0
reward_min: 599.0
total_envstep_count: 2633331
total_train_sample_count: 2633296
total_episode_count: 16550
total_duration: 3348.9848900011634
[2024-11-20 00:51:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1071
train_sample_count: 1071
avg_envstep_per_episode: 178.5
avg_sample_per_episode: 178.5
avg_envstep_per_sec: 806.4956156557529
avg_train_sample_per_sec: 806.4956156557529
avg_episode_per_sec: 4.51818272076052
collect_time: 1.327967541558402
reward_mean: 1334.5
reward_std: 325.172119140625
reward_max: 1703.0
reward_min: 808.0
total_envstep_count: 2634333
total_train_sample_count: 2634295
total_episode_count: 16556
total_duration: 3350.3128575427218
[2024-11-20 00:51:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1022
train_sample_count: 1022
avg_envstep_per_episode: 127.75
avg_sample_per_episode: 127.75
avg_envstep_per_sec: 809.3836177227173
avg_train_sample_per_sec: 809.3836177227173
avg_episode_per_sec: 6.335683896068237
collect_time: 1.2626892583710805
reward_mean: 848.625
reward_std: 519.5076904296875
reward_max: 1698.0
reward_min: 155.0
total_envstep_count: 2635326
total_train_sample_count: 2635281
total_episode_count: 16564
total_duration: 3351.575546801093
[2024-11-20 00:51:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1170
train_sample_count: 1170
avg_envstep_per_episode: 167.14285714285714
avg_sample_per_episode: 167.14285714285714
avg_envstep_per_sec: 806.6369064175224
avg_train_sample_per_sec: 806.6369064175224
avg_episode_per_sec: 4.826032773438168
collect_time: 1.4504667350224087
reward_mean: 1005.4285888671875
reward_std: 757.4797973632812
reward_max: 2316.0
reward_min: 234.0
total_envstep_count: 2636303
total_train_sample_count: 2636271
total_episode_count: 16571
total_duration: 3353.0260135361154
[2024-11-20 00:51:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 971
train_sample_count: 971
avg_envstep_per_episode: 161.83333333333334
avg_sample_per_episode: 161.83333333333334
avg_envstep_per_sec: 800.442978680824
avg_train_sample_per_sec: 800.442978680824
avg_episode_per_sec: 4.94609461594742
collect_time: 1.2130782902240753
reward_mean: 1237.0
reward_std: 475.2308044433594
reward_max: 1857.0
reward_min: 609.0
total_envstep_count: 2637314
total_train_sample_count: 2637266
total_episode_count: 16577
total_duration: 3354.2390918263395
[2024-11-20 00:51:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 616
train_sample_count: 616
avg_envstep_per_episode: 123.2
avg_sample_per_episode: 123.2
avg_envstep_per_sec: 805.6050157933687
avg_train_sample_per_sec: 805.6050157933687
avg_episode_per_sec: 6.53900175156955
collect_time: 0.7646427069391524
reward_mean: 769.4000244140625
reward_std: 418.1423645019531
reward_max: 1322.0
reward_min: 128.0
total_envstep_count: 2638286
total_train_sample_count: 2638254
total_episode_count: 16582
total_duration: 3355.0037345332785
[2024-11-20 00:51:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 252
train_sample_count: 252
avg_envstep_per_episode: 252.0
avg_sample_per_episode: 252.0
avg_envstep_per_sec: 814.2295595943841
avg_train_sample_per_sec: 814.2295595943841
avg_episode_per_sec: 3.2310696809300956
collect_time: 0.3094950275761741
reward_mean: 1306.0
reward_std: 0.0
reward_max: 1306.0
reward_min: 1306.0
total_envstep_count: 2639245
total_train_sample_count: 2639214
total_episode_count: 16583
total_duration: 3355.313229560855
[2024-11-20 00:51:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1045
train_sample_count: 1045
avg_envstep_per_episode: 348.3333333333333
avg_sample_per_episode: 348.3333333333333
avg_envstep_per_sec: 815.7149415033454
avg_train_sample_per_sec: 815.7149415033454
avg_episode_per_sec: 2.3417653823062543
collect_time: 1.2810847844396318
reward_mean: 1678.3333740234375
reward_std: 807.7727661132812
reward_max: 2591.0
reward_min: 627.0
total_envstep_count: 2640235
total_train_sample_count: 2640199
total_episode_count: 16586
total_duration: 3356.5943143452946
[2024-11-20 00:51:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1490
train_sample_count: 1490
avg_envstep_per_episode: 248.33333333333334
avg_sample_per_episode: 248.33333333333334
avg_envstep_per_sec: 815.85559263802
avg_train_sample_per_sec: 815.85559263802
avg_episode_per_sec: 3.2853245341128323
collect_time: 1.8263035927500044
reward_mean: 1106.0
reward_std: 712.87353515625
reward_max: 2343.0
reward_min: 235.0
total_envstep_count: 2641237
total_train_sample_count: 2641185
total_episode_count: 16592
total_duration: 3358.4206179380444
[2024-11-20 00:51:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1495
train_sample_count: 1495
avg_envstep_per_episode: 249.16666666666666
avg_sample_per_episode: 249.16666666666666
avg_envstep_per_sec: 808.3008891478341
avg_train_sample_per_sec: 808.3008891478341
avg_episode_per_sec: 3.244016946412712
collect_time: 1.8495587720757438
reward_mean: 1016.8333129882812
reward_std: 412.3337707519531
reward_max: 1683.0
reward_min: 626.0
total_envstep_count: 2642231
total_train_sample_count: 2642212
total_episode_count: 16598
total_duration: 3360.2701767101203
[2024-11-20 00:51:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1163
train_sample_count: 1163
avg_envstep_per_episode: 166.14285714285714
avg_sample_per_episode: 166.14285714285714
avg_envstep_per_sec: 805.7891930044659
avg_train_sample_per_sec: 805.7891930044659
avg_episode_per_sec: 4.84997794585663
collect_time: 1.443305532137553
reward_mean: 1331.4285888671875
reward_std: 504.3462219238281
reward_max: 1858.0
reward_min: 198.0
total_envstep_count: 2643257
total_train_sample_count: 2643207
total_episode_count: 16605
total_duration: 3361.7134822422577
[2024-11-20 00:51:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 717
train_sample_count: 717
avg_envstep_per_episode: 102.42857142857143
avg_sample_per_episode: 102.42857142857143
avg_envstep_per_sec: 812.4019575946345
avg_train_sample_per_sec: 812.4019575946345
avg_episode_per_sec: 7.931399864940643
collect_time: 0.8825680358069283
reward_mean: 820.8571166992188
reward_std: 324.751953125
reward_max: 1341.0
reward_min: 590.0
total_envstep_count: 2644259
total_train_sample_count: 2644236
total_episode_count: 16612
total_duration: 3362.5960502780645
[2024-11-20 00:51:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1466
train_sample_count: 1466
avg_envstep_per_episode: 183.25
avg_sample_per_episode: 183.25
avg_envstep_per_sec: 808.6351528241067
avg_train_sample_per_sec: 808.6351528241067
avg_episode_per_sec: 4.412742989490351
collect_time: 1.8129313261736006
reward_mean: 1097.625
reward_std: 515.598876953125
reward_max: 2329.0
reward_min: 624.0
total_envstep_count: 2645292
total_train_sample_count: 2645246
total_episode_count: 16620
total_duration: 3364.408981604238
[2024-11-20 00:51:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1121
train_sample_count: 1121
avg_envstep_per_episode: 140.125
avg_sample_per_episode: 140.125
avg_envstep_per_sec: 809.6317549226806
avg_train_sample_per_sec: 809.6317549226806
avg_episode_per_sec: 5.777925102035187
collect_time: 1.3845800799982888
reward_mean: 1102.75
reward_std: 435.667236328125
reward_max: 1697.0
reward_min: 610.0
total_envstep_count: 2646276
total_train_sample_count: 2646247
total_episode_count: 16628
total_duration: 3365.793561684236
[2024-11-20 00:51:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 890
train_sample_count: 890
avg_envstep_per_episode: 127.14285714285714
avg_sample_per_episode: 127.14285714285714
avg_envstep_per_sec: 807.8670955842329
avg_train_sample_per_sec: 807.8670955842329
avg_episode_per_sec: 6.354010864145652
collect_time: 1.1016663568360465
reward_mean: 961.0
reward_std: 456.9995422363281
reward_max: 1701.0
reward_min: 620.0
total_envstep_count: 2647262
total_train_sample_count: 2647221
total_episode_count: 16635
total_duration: 3366.895228041072
[2024-11-20 00:51:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 688
train_sample_count: 688
avg_envstep_per_episode: 86.0
avg_sample_per_episode: 86.0
avg_envstep_per_sec: 806.4862184869813
avg_train_sample_per_sec: 806.4862184869813
avg_episode_per_sec: 9.377746726592807
collect_time: 0.8530833934034621
reward_mean: 720.125
reward_std: 224.1653594970703
reward_max: 1313.0
reward_min: 621.0
total_envstep_count: 2648266
total_train_sample_count: 2648233
total_episode_count: 16643
total_duration: 3367.7483114344755
[2024-11-20 00:51:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1014
train_sample_count: 1014
avg_envstep_per_episode: 144.85714285714286
avg_sample_per_episode: 144.85714285714286
avg_envstep_per_sec: 811.7005815284424
avg_train_sample_per_sec: 811.7005815284424
avg_episode_per_sec: 5.603455691024751
collect_time: 1.2492291160992213
reward_mean: 1252.4285888671875
reward_std: 716.1345825195312
reward_max: 2361.0
reward_min: 248.0
total_envstep_count: 2649307
total_train_sample_count: 2649283
total_episode_count: 16650
total_duration: 3368.9975405505747
[2024-11-20 00:51:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 381
train_sample_count: 381
avg_envstep_per_episode: 95.25
avg_sample_per_episode: 95.25
avg_envstep_per_sec: 795.4005409241353
avg_train_sample_per_sec: 795.4005409241353
avg_episode_per_sec: 8.35066184697255
collect_time: 0.4790039488247463
reward_mean: 739.25
reward_std: 663.26171875
reward_max: 1859.0
reward_min: 241.0
total_envstep_count: 2650327
total_train_sample_count: 2650276
total_episode_count: 16654
total_duration: 3369.4765444993996
[2024-11-20 00:52:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1075
train_sample_count: 1075
avg_envstep_per_episode: 215.0
avg_sample_per_episode: 215.0
avg_envstep_per_sec: 666.8656156377073
avg_train_sample_per_sec: 666.8656156377073
avg_episode_per_sec: 3.1017005378498013
collect_time: 1.6120189357371557
reward_mean: 1333.5999755859375
reward_std: 638.3593139648438
reward_max: 2354.0
reward_min: 578.0
total_envstep_count: 2651292
total_train_sample_count: 2651255
total_episode_count: 16659
total_duration: 3371.0885634351366
[2024-11-20 00:52:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1229
train_sample_count: 1229
avg_envstep_per_episode: 204.83333333333334
avg_sample_per_episode: 204.83333333333334
avg_envstep_per_sec: 821.3818318538713
avg_train_sample_per_sec: 821.3818318538713
avg_episode_per_sec: 4.01000080644689
collect_time: 1.4962590507098608
reward_mean: 1307.0
reward_std: 553.8922729492188
reward_max: 2312.0
reward_min: 608.0
total_envstep_count: 2652318
total_train_sample_count: 2652268
total_episode_count: 16665
total_duration: 3372.5848224858464
[2024-11-20 00:52:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 808
train_sample_count: 808
avg_envstep_per_episode: 269.3333333333333
avg_sample_per_episode: 269.3333333333333
avg_envstep_per_sec: 819.6592153147354
avg_train_sample_per_sec: 819.6592153147354
avg_episode_per_sec: 3.0432891657725323
collect_time: 0.9857755331766038
reward_mean: 1394.3333740234375
reward_std: 895.9127197265625
reward_max: 2317.0
reward_min: 181.0
total_envstep_count: 2653275
total_train_sample_count: 2653232
total_episode_count: 16668
total_duration: 3373.5705980190232
[2024-11-20 00:52:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1524
train_sample_count: 1524
avg_envstep_per_episode: 190.5
avg_sample_per_episode: 190.5
avg_envstep_per_sec: 817.3375783796008
avg_train_sample_per_sec: 817.3375783796008
avg_episode_per_sec: 4.290485975745936
collect_time: 1.8645906419981095
reward_mean: 1338.375
reward_std: 612.524658203125
reward_max: 2340.0
reward_min: 233.0
total_envstep_count: 2654245
total_train_sample_count: 2654228
total_episode_count: 16676
total_duration: 3375.435188661021
[2024-11-20 00:52:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 599
train_sample_count: 599
avg_envstep_per_episode: 119.8
avg_sample_per_episode: 119.8
avg_envstep_per_sec: 822.9826760864923
avg_train_sample_per_sec: 822.9826760864923
avg_episode_per_sec: 6.869638364661872
collect_time: 0.7278403512069158
reward_mean: 918.2000122070312
reward_std: 427.0945739746094
reward_max: 1706.0
reward_min: 603.0
total_envstep_count: 2655226
total_train_sample_count: 2655199
total_episode_count: 16681
total_duration: 3376.163029012228
[2024-11-20 00:52:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 461
train_sample_count: 461
avg_envstep_per_episode: 230.5
avg_sample_per_episode: 230.5
avg_envstep_per_sec: 822.742141790215
avg_train_sample_per_sec: 822.742141790215
avg_episode_per_sec: 3.569380224686399
collect_time: 0.560321365083967
reward_mean: 1772.5
reward_std: 78.5
reward_max: 1851.0
reward_min: 1694.0
total_envstep_count: 2656184
total_train_sample_count: 2656164
total_episode_count: 16683
total_duration: 3376.723350377312
[2024-11-20 00:52:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2020
train_sample_count: 2020
avg_envstep_per_episode: 252.5
avg_sample_per_episode: 252.5
avg_envstep_per_sec: 817.9383327278372
avg_train_sample_per_sec: 817.9383327278372
avg_episode_per_sec: 3.2393597335755926
collect_time: 2.469623832475571
reward_mean: 1633.5
reward_std: 819.0764770507812
reward_max: 2994.0
reward_min: 243.0
total_envstep_count: 2657224
total_train_sample_count: 2657188
total_episode_count: 16691
total_duration: 3379.1929742097873
[2024-11-20 00:52:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 599
train_sample_count: 599
avg_envstep_per_episode: 149.75
avg_sample_per_episode: 149.75
avg_envstep_per_sec: 806.3340248495248
avg_train_sample_per_sec: 806.3340248495248
avg_episode_per_sec: 5.384534389646242
collect_time: 0.7428683170250484
reward_mean: 1327.75
reward_std: 421.2281799316406
reward_max: 1692.0
reward_min: 617.0
total_envstep_count: 2658244
total_train_sample_count: 2658195
total_episode_count: 16695
total_duration: 3379.9358425268124
[2024-11-20 00:52:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 921
train_sample_count: 921
avg_envstep_per_episode: 153.5
avg_sample_per_episode: 153.5
avg_envstep_per_sec: 809.144031586318
avg_train_sample_per_sec: 809.144031586318
avg_episode_per_sec: 5.271296622712169
collect_time: 1.1382398733070918
reward_mean: 1159.5
reward_std: 714.12109375
reward_max: 2356.0
reward_min: 247.0
total_envstep_count: 2659270
total_train_sample_count: 2659236
total_episode_count: 16701
total_duration: 3381.0740824001196
[2024-11-20 00:52:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1551
train_sample_count: 1551
avg_envstep_per_episode: 172.33333333333334
avg_sample_per_episode: 172.33333333333334
avg_envstep_per_sec: 810.8650006106297
avg_train_sample_per_sec: 810.8650006106297
avg_episode_per_sec: 4.705212769500753
collect_time: 1.9127721616200037
reward_mean: 1073.5555419921875
reward_std: 542.6539916992188
reward_max: 1847.0
reward_min: 247.0
total_envstep_count: 2660317
total_train_sample_count: 2660259
total_episode_count: 16710
total_duration: 3382.9868545617396
[2024-11-20 00:52:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 485
train_sample_count: 485
avg_envstep_per_episode: 161.66666666666666
avg_sample_per_episode: 161.66666666666666
avg_envstep_per_sec: 807.9164115745283
avg_train_sample_per_sec: 807.9164115745283
avg_episode_per_sec: 4.997421102522855
collect_time: 0.6003096273967198
reward_mean: 1016.3333129882812
reward_std: 472.6219787597656
reward_max: 1681.0
reward_min: 623.0
total_envstep_count: 2661282
total_train_sample_count: 2661248
total_episode_count: 16713
total_duration: 3383.5871641891363
[2024-11-20 00:52:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1769
train_sample_count: 1769
avg_envstep_per_episode: 221.125
avg_sample_per_episode: 221.125
avg_envstep_per_sec: 805.7279184963924
avg_train_sample_per_sec: 805.7279184963924
avg_episode_per_sec: 3.643766731470401
collect_time: 2.1955302272524153
reward_mean: 1575.625
reward_std: 237.22401428222656
reward_max: 1922.0
reward_min: 1300.0
total_envstep_count: 2662283
total_train_sample_count: 2662237
total_episode_count: 16721
total_duration: 3385.7826944163885
[2024-11-20 00:52:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 242
train_sample_count: 242
avg_envstep_per_episode: 80.66666666666667
avg_sample_per_episode: 80.66666666666667
avg_envstep_per_sec: 797.8291060822214
avg_train_sample_per_sec: 797.8291060822214
avg_episode_per_sec: 9.890443463829191
collect_time: 0.30332310284887043
reward_mean: 474.0
reward_std: 191.3652801513672
reward_max: 625.0
reward_min: 204.0
total_envstep_count: 2663240
total_train_sample_count: 2663199
total_episode_count: 16724
total_duration: 3386.0860175192374
[2024-11-20 00:52:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1091
train_sample_count: 1091
avg_envstep_per_episode: 218.2
avg_sample_per_episode: 218.2
avg_envstep_per_sec: 813.3755820365878
avg_train_sample_per_sec: 813.3755820365878
avg_episode_per_sec: 3.7276607792694216
collect_time: 1.3413237673895697
reward_mean: 1551.199951171875
reward_std: 480.14556884765625
reward_max: 1914.0
reward_min: 607.0
total_envstep_count: 2664243
total_train_sample_count: 2664194
total_episode_count: 16729
total_duration: 3387.427341286627
[2024-11-20 00:52:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1213
train_sample_count: 1213
avg_envstep_per_episode: 242.6
avg_sample_per_episode: 242.6
avg_envstep_per_sec: 807.4250452328114
avg_train_sample_per_sec: 807.4250452328114
avg_episode_per_sec: 3.3282153554526435
collect_time: 1.5023066316332137
reward_mean: 1657.4000244140625
reward_std: 654.2196655273438
reward_max: 2353.0
reward_min: 613.0
total_envstep_count: 2665231
total_train_sample_count: 2665179
total_episode_count: 16734
total_duration: 3388.92964791826
[2024-11-20 00:53:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 592
train_sample_count: 592
avg_envstep_per_episode: 197.33333333333334
avg_sample_per_episode: 197.33333333333334
avg_envstep_per_sec: 800.3525165699965
avg_train_sample_per_sec: 800.3525165699965
avg_episode_per_sec: 4.055840455591198
collect_time: 0.7396740657942635
reward_mean: 1697.0
reward_std: 5.3541259765625
reward_max: 1704.0
reward_min: 1691.0
total_envstep_count: 2666181
total_train_sample_count: 2666143
total_episode_count: 16737
total_duration: 3389.669321984054
[2024-11-20 00:53:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1499
train_sample_count: 1499
avg_envstep_per_episode: 249.83333333333334
avg_sample_per_episode: 249.83333333333334
avg_envstep_per_sec: 806.7019788757779
avg_train_sample_per_sec: 806.7019788757779
avg_episode_per_sec: 3.228960555873694
collect_time: 1.8581831199782237
reward_mean: 1765.8333740234375
reward_std: 579.3828125
reward_max: 2341.0
reward_min: 619.0
total_envstep_count: 2667176
total_train_sample_count: 2667126
total_episode_count: 16743
total_duration: 3391.527505104032
[2024-11-20 00:53:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 430
train_sample_count: 430
avg_envstep_per_episode: 143.33333333333334
avg_sample_per_episode: 143.33333333333334
avg_envstep_per_sec: 811.2841923966328
avg_train_sample_per_sec: 811.2841923966328
avg_episode_per_sec: 5.660122272534647
collect_time: 0.5300238856247493
reward_mean: 1237.0
reward_std: 124.47489929199219
reward_max: 1328.0
reward_min: 1061.0
total_envstep_count: 2668149
total_train_sample_count: 2668108
total_episode_count: 16746
total_duration: 3392.057528989657
[2024-11-20 00:53:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1131
train_sample_count: 1131
avg_envstep_per_episode: 226.2
avg_sample_per_episode: 226.2
avg_envstep_per_sec: 806.58967142269
avg_train_sample_per_sec: 806.58967142269
avg_episode_per_sec: 3.565825249437179
collect_time: 1.4021999537944791
reward_mean: 1641.4000244140625
reward_std: 661.4489135742188
reward_max: 2361.0
reward_min: 609.0
total_envstep_count: 2669137
total_train_sample_count: 2669095
total_episode_count: 16751
total_duration: 3393.4597289434514
[2024-11-20 00:53:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1300
train_sample_count: 1300
avg_envstep_per_episode: 185.71428571428572
avg_sample_per_episode: 185.71428571428572
avg_envstep_per_sec: 805.911817134617
avg_train_sample_per_sec: 805.911817134617
avg_episode_per_sec: 4.339525169186399
collect_time: 1.613079709666116
reward_mean: 1286.857177734375
reward_std: 599.7109985351562
reward_max: 2338.0
reward_min: 625.0
total_envstep_count: 2670130
total_train_sample_count: 2670071
total_episode_count: 16758
total_duration: 3395.0728086531176
[2024-11-20 00:53:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1283
train_sample_count: 1283
avg_envstep_per_episode: 183.28571428571428
avg_sample_per_episode: 183.28571428571428
avg_envstep_per_sec: 805.8167632397602
avg_train_sample_per_sec: 805.8167632397602
avg_episode_per_sec: 4.396506112765644
collect_time: 1.5921733805111475
reward_mean: 1228.0
reward_std: 368.0124206542969
reward_max: 1710.0
reward_min: 755.0
total_envstep_count: 2671101
total_train_sample_count: 2671078
total_episode_count: 16765
total_duration: 3396.664982033629
[2024-11-20 00:53:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 527
train_sample_count: 527
avg_envstep_per_episode: 105.4
avg_sample_per_episode: 105.4
avg_envstep_per_sec: 798.4285842701266
avg_train_sample_per_sec: 798.4285842701266
avg_episode_per_sec: 7.575223759678622
collect_time: 0.6600465093340193
reward_mean: 832.2000122070312
reward_std: 437.4116516113281
reward_max: 1707.0
reward_min: 609.0
total_envstep_count: 2672104
total_train_sample_count: 2672061
total_episode_count: 16770
total_duration: 3397.3250285429626
[2024-11-20 00:53:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 373
train_sample_count: 373
avg_envstep_per_episode: 186.5
avg_sample_per_episode: 186.5
avg_envstep_per_sec: 809.9663217081479
avg_train_sample_per_sec: 809.9663217081479
avg_episode_per_sec: 4.342982958220633
collect_time: 0.4605129744325365
reward_mean: 1301.0
reward_std: 13.0
reward_max: 1314.0
reward_min: 1288.0
total_envstep_count: 2673102
total_train_sample_count: 2673058
total_episode_count: 16772
total_duration: 3397.7855415173954
[2024-11-20 00:53:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1091
train_sample_count: 1091
avg_envstep_per_episode: 218.2
avg_sample_per_episode: 218.2
avg_envstep_per_sec: 813.7877149261863
avg_train_sample_per_sec: 813.7877149261863
avg_episode_per_sec: 3.72954956428133
collect_time: 1.3406444702829632
reward_mean: 1558.5999755859375
reward_std: 573.548828125
reward_max: 2334.0
reward_min: 614.0
total_envstep_count: 2674097
total_train_sample_count: 2674053
total_episode_count: 16777
total_duration: 3399.126185987678
[2024-11-20 00:53:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 455
train_sample_count: 455
avg_envstep_per_episode: 113.75
avg_sample_per_episode: 113.75
avg_envstep_per_sec: 816.2876652944306
avg_train_sample_per_sec: 816.2876652944306
avg_episode_per_sec: 7.176155299291697
collect_time: 0.5574015378952026
reward_mean: 888.75
reward_std: 469.5350646972656
reward_max: 1702.0
reward_min: 615.0
total_envstep_count: 2675086
total_train_sample_count: 2675048
total_episode_count: 16781
total_duration: 3399.6835875255733
[2024-11-20 00:53:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 278
train_sample_count: 278
avg_envstep_per_episode: 92.66666666666667
avg_sample_per_episode: 92.66666666666667
avg_envstep_per_sec: 832.9477696996323
avg_train_sample_per_sec: 832.9477696996323
avg_episode_per_sec: 8.988644996758621
collect_time: 0.33375442028045654
reward_mean: 865.3333129882812
reward_std: 318.8200378417969
reward_max: 1316.0
reward_min: 628.0
total_envstep_count: 2676075
total_train_sample_count: 2676022
total_episode_count: 16784
total_duration: 3400.017341945854
[2024-11-20 00:53:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 240
train_sample_count: 240
avg_envstep_per_episode: 240.0
avg_sample_per_episode: 240.0
avg_envstep_per_sec: 837.392795600023
avg_train_sample_per_sec: 837.392795600023
avg_episode_per_sec: 3.489136648333429
collect_time: 0.2866038509777614
reward_mean: 1634.0
reward_std: 0.0
reward_max: 1634.0
reward_min: 1634.0
total_envstep_count: 2677130
total_train_sample_count: 2677078
total_episode_count: 16785
total_duration: 3400.3039457968316
[2024-11-20 00:53:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2033
train_sample_count: 2033
avg_envstep_per_episode: 406.6
avg_sample_per_episode: 406.6
avg_envstep_per_sec: 816.3386848297233
avg_train_sample_per_sec: 816.3386848297233
avg_episode_per_sec: 2.0077193429161913
collect_time: 2.490387920822416
reward_mean: 1544.0
reward_std: 921.8474731445312
reward_max: 2346.0
reward_min: 233.0
total_envstep_count: 2678109
total_train_sample_count: 2678067
total_episode_count: 16790
total_duration: 3402.794333717654
[2024-11-20 00:53:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 457
train_sample_count: 457
avg_envstep_per_episode: 152.33333333333334
avg_sample_per_episode: 152.33333333333334
avg_envstep_per_sec: 822.825880974295
avg_train_sample_per_sec: 822.825880974295
avg_episode_per_sec: 5.401482807271083
collect_time: 0.5554030452455793
reward_mean: 1291.0
reward_std: 960.2513427734375
reward_max: 2649.0
reward_min: 611.0
total_envstep_count: 2679067
total_train_sample_count: 2679040
total_episode_count: 16793
total_duration: 3403.3497367628993
[2024-11-20 00:54:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 191
train_sample_count: 191
avg_envstep_per_episode: 191.0
avg_sample_per_episode: 191.0
avg_envstep_per_sec: 821.8769163796945
avg_train_sample_per_sec: 821.8769163796945
avg_episode_per_sec: 4.303020504605731
collect_time: 0.2323948953832899
reward_mean: 1318.0
reward_std: 0.0
reward_max: 1318.0
reward_min: 1318.0
total_envstep_count: 2680034
total_train_sample_count: 2680011
total_episode_count: 16794
total_duration: 3403.5821316582824
[2024-11-20 00:54:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 559
train_sample_count: 559
avg_envstep_per_episode: 186.33333333333334
avg_sample_per_episode: 186.33333333333334
avg_envstep_per_sec: 812.5964341386092
avg_train_sample_per_sec: 812.5964341386092
avg_episode_per_sec: 4.360982651906668
collect_time: 0.6879183522292546
reward_mean: 1437.0
reward_std: 699.0894165039062
reward_max: 2350.0
reward_min: 652.0
total_envstep_count: 2681056
total_train_sample_count: 2680990
total_episode_count: 16797
total_duration: 3404.2700500105116
[2024-11-20 00:54:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 225
train_sample_count: 225
avg_envstep_per_episode: 225.0
avg_sample_per_episode: 225.0
avg_envstep_per_sec: 801.733610908821
avg_train_sample_per_sec: 801.733610908821
avg_episode_per_sec: 3.5632604929280935
collect_time: 0.28064184529440744
reward_mean: 1688.0
reward_std: 0.0
reward_max: 1688.0
reward_min: 1688.0
total_envstep_count: 2682111
total_train_sample_count: 2682055
total_episode_count: 16798
total_duration: 3404.550691855806
[2024-11-20 00:54:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 476
train_sample_count: 476
avg_envstep_per_episode: 238.0
avg_sample_per_episode: 238.0
avg_envstep_per_sec: 819.4185396772898
avg_train_sample_per_sec: 819.4185396772898
avg_episode_per_sec: 3.442935040660881
collect_time: 0.5808997196810586
reward_mean: 1602.5
reward_std: 293.5
reward_max: 1896.0
reward_min: 1309.0
total_envstep_count: 2683094
total_train_sample_count: 2683071
total_episode_count: 16800
total_duration: 3405.1315915754867
[2024-11-20 00:54:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 235
train_sample_count: 235
avg_envstep_per_episode: 117.5
avg_sample_per_episode: 117.5
avg_envstep_per_sec: 817.3551669685515
avg_train_sample_per_sec: 817.3551669685515
avg_episode_per_sec: 6.956214186966396
collect_time: 0.28751271111624577
reward_mean: 637.0
reward_std: 2.0
reward_max: 639.0
reward_min: 635.0
total_envstep_count: 2684116
total_train_sample_count: 2684050
total_episode_count: 16802
total_duration: 3405.4191042866028
[2024-11-20 00:54:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 334
train_sample_count: 334
avg_envstep_per_episode: 167.0
avg_sample_per_episode: 167.0
avg_envstep_per_sec: 817.1295063968892
avg_train_sample_per_sec: 817.1295063968892
avg_episode_per_sec: 4.892991056268797
collect_time: 0.40874793699809486
reward_mean: 1374.0
reward_std: 56.0
reward_max: 1430.0
reward_min: 1318.0
total_envstep_count: 2685074
total_train_sample_count: 2685020
total_episode_count: 16804
total_duration: 3405.827852223601
[2024-11-20 00:54:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 383
train_sample_count: 383
avg_envstep_per_episode: 383.0
avg_sample_per_episode: 383.0
avg_envstep_per_sec: 747.3766067452278
avg_train_sample_per_sec: 747.3766067452278
avg_episode_per_sec: 1.9513749523374093
collect_time: 0.5124591759272984
reward_mean: 2335.0
reward_std: 0.0
reward_max: 2335.0
reward_min: 2335.0
total_envstep_count: 2686041
total_train_sample_count: 2685991
total_episode_count: 16805
total_duration: 3406.340311399528
[2024-11-20 00:54:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 2450
train_sample_count: 2450
avg_envstep_per_episode: 816.6666666666666
avg_sample_per_episode: 816.6666666666666
avg_envstep_per_sec: 786.0424978953986
avg_train_sample_per_sec: 786.0424978953986
avg_episode_per_sec: 0.9625010178311003
collect_time: 3.11687982082367
reward_mean: 1250.3333740234375
reward_std: 572.5931396484375
reward_max: 1921.0
reward_min: 522.0
total_envstep_count: 2687008
total_train_sample_count: 2686989
total_episode_count: 16808
total_duration: 3409.457191220352
[2024-11-20 00:54:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 401
train_sample_count: 401
avg_envstep_per_episode: 200.5
avg_sample_per_episode: 200.5
avg_envstep_per_sec: 798.2529379269422
avg_train_sample_per_sec: 798.2529379269422
avg_episode_per_sec: 3.9813114111069434
collect_time: 0.5023470393248968
reward_mean: 1449.5
reward_std: 120.5
reward_max: 1570.0
reward_min: 1329.0
total_envstep_count: 2687966
total_train_sample_count: 2687954
total_episode_count: 16810
total_duration: 3409.9595382596767
[2024-11-20 00:54:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2264
train_sample_count: 2264
avg_envstep_per_episode: 1132.0
avg_sample_per_episode: 1132.0
avg_envstep_per_sec: 803.3908190588954
avg_train_sample_per_sec: 803.3908190588954
avg_episode_per_sec: 0.709709204115632
collect_time: 2.8180556041853766
reward_mean: 1094.5
reward_std: 583.5
reward_max: 1678.0
reward_min: 511.0
total_envstep_count: 2688988
total_train_sample_count: 2688934
total_episode_count: 16812
total_duration: 3412.777593863862
[2024-11-20 00:54:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 873
train_sample_count: 873
avg_envstep_per_episode: 291.0
avg_sample_per_episode: 291.0
avg_envstep_per_sec: 805.2602044920767
avg_train_sample_per_sec: 805.2602044920767
avg_episode_per_sec: 2.767217197567274
collect_time: 1.0841216232095445
reward_mean: 1770.3333740234375
reward_std: 423.3440856933594
reward_max: 2340.0
reward_min: 1326.0
total_envstep_count: 2689945
total_train_sample_count: 2689903
total_episode_count: 16815
total_duration: 3413.8617154870717
[2024-11-20 00:54:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 2005
train_sample_count: 2005
avg_envstep_per_episode: 2005.0
avg_sample_per_episode: 2005.0
avg_envstep_per_sec: 806.1739612162113
avg_train_sample_per_sec: 806.1739612162113
avg_episode_per_sec: 0.4020817761676864
collect_time: 2.487056263855526
reward_mean: 522.0
reward_std: 0.0
reward_max: 522.0
reward_min: 522.0
total_envstep_count: 2691000
total_train_sample_count: 2690960
total_episode_count: 16816
total_duration: 3416.3487717509274
[2024-11-20 00:54:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 550
train_sample_count: 550
avg_envstep_per_episode: 275.0
avg_sample_per_episode: 275.0
avg_envstep_per_sec: 808.6141062861974
avg_train_sample_per_sec: 808.6141062861974
avg_episode_per_sec: 2.940414931949809
collect_time: 0.6801761133330209
reward_mean: 1601.0
reward_std: 302.0
reward_max: 1903.0
reward_min: 1299.0
total_envstep_count: 2692006
total_train_sample_count: 2691978
total_episode_count: 16818
total_duration: 3417.0289478642603
[2024-11-20 00:54:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1601
train_sample_count: 1601
avg_envstep_per_episode: 320.2
avg_sample_per_episode: 320.2
avg_envstep_per_sec: 803.1595962866554
avg_train_sample_per_sec: 803.1595962866554
avg_episode_per_sec: 2.5083060471163505
collect_time: 1.9933771661349704
reward_mean: 1580.199951171875
reward_std: 397.8232727050781
reward_max: 2332.0
reward_min: 1276.0
total_envstep_count: 2693009
total_train_sample_count: 2692979
total_episode_count: 16823
total_duration: 3419.022325030395
[2024-11-20 00:54:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 4560
train_sample_count: 4560
avg_envstep_per_episode: 912.0
avg_sample_per_episode: 912.0
avg_envstep_per_sec: 801.8472021842402
avg_train_sample_per_sec: 801.8472021842402
avg_episode_per_sec: 0.8792184234476319
collect_time: 5.686869003943035
reward_mean: 990.7999877929688
reward_std: 571.8515014648438
reward_max: 1904.0
reward_min: 514.0
total_envstep_count: 2694013
total_train_sample_count: 2693963
total_episode_count: 16828
total_duration: 3424.7091940343385
[2024-11-20 00:54:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 907
train_sample_count: 907
avg_envstep_per_episode: 226.75
avg_sample_per_episode: 226.75
avg_envstep_per_sec: 805.3991300890027
avg_train_sample_per_sec: 805.3991300890027
avg_episode_per_sec: 3.5519256012745433
collect_time: 1.1261497139930727
reward_mean: 1221.0
reward_std: 473.8739318847656
reward_max: 1919.0
reward_min: 612.0
total_envstep_count: 2694970
total_train_sample_count: 2694942
total_episode_count: 16832
total_duration: 3425.8353437483315
[2024-11-20 00:54:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 712
train_sample_count: 712
avg_envstep_per_episode: 178.0
avg_sample_per_episode: 178.0
avg_envstep_per_sec: 808.4504551783076
avg_train_sample_per_sec: 808.4504551783076
avg_episode_per_sec: 4.541856489765773
collect_time: 0.880697135414396
reward_mean: 1045.25
reward_std: 466.55029296875
reward_max: 1689.0
reward_min: 589.0
total_envstep_count: 2695959
total_train_sample_count: 2695918
total_episode_count: 16836
total_duration: 3426.716040883746
[2024-11-20 00:55:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1276
train_sample_count: 1276
avg_envstep_per_episode: 212.66666666666666
avg_sample_per_episode: 212.66666666666666
avg_envstep_per_sec: 806.1720379170899
avg_train_sample_per_sec: 806.1720379170899
avg_episode_per_sec: 3.7907776077606106
collect_time: 1.5827887100832803
reward_mean: 1326.8333740234375
reward_std: 507.1072692871094
reward_max: 1701.0
reward_min: 591.0
total_envstep_count: 2696922
total_train_sample_count: 2696894
total_episode_count: 16842
total_duration: 3428.298829593829
[2024-11-20 00:55:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 361
train_sample_count: 361
avg_envstep_per_episode: 120.33333333333333
avg_sample_per_episode: 120.33333333333333
avg_envstep_per_sec: 801.3818334012524
avg_train_sample_per_sec: 801.3818334012524
avg_episode_per_sec: 6.659682826049188
collect_time: 0.4504719035966056
reward_mean: 873.3333129882812
reward_std: 321.5072021484375
reward_max: 1328.0
reward_min: 643.0
total_envstep_count: 2697903
total_train_sample_count: 2697867
total_episode_count: 16845
total_duration: 3428.7493014974257
[2024-11-20 00:55:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1220
train_sample_count: 1220
avg_envstep_per_episode: 174.28571428571428
avg_sample_per_episode: 174.28571428571428
avg_envstep_per_sec: 815.0007519372213
avg_train_sample_per_sec: 815.0007519372213
avg_episode_per_sec: 4.676233822590614
collect_time: 1.4969311342352913
reward_mean: 1257.2857666015625
reward_std: 621.38916015625
reward_max: 2352.0
reward_min: 606.0
total_envstep_count: 2698889
total_train_sample_count: 2698859
total_episode_count: 16852
total_duration: 3430.246232631661
[2024-11-20 00:55:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1468
train_sample_count: 1468
avg_envstep_per_episode: 293.6
avg_sample_per_episode: 293.6
avg_envstep_per_sec: 801.171053594067
avg_train_sample_per_sec: 801.171053594067
avg_episode_per_sec: 2.7287842424866042
collect_time: 1.8323178220362892
reward_mean: 1833.4000244140625
reward_std: 541.3045654296875
reward_max: 2625.0
reward_min: 1307.0
total_envstep_count: 2699916
total_train_sample_count: 2699883
total_episode_count: 16857
total_duration: 3432.078550453697
[2024-11-20 00:55:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 705
train_sample_count: 705
avg_envstep_per_episode: 176.25
avg_sample_per_episode: 176.25
avg_envstep_per_sec: 797.305246512723
avg_train_sample_per_sec: 797.305246512723
avg_episode_per_sec: 4.523717710710486
collect_time: 0.884228472198759
reward_mean: 1353.0
reward_std: 245.11630249023438
reward_max: 1721.0
reward_min: 1031.0
total_envstep_count: 2700904
total_train_sample_count: 2700864
total_episode_count: 16861
total_duration: 3432.9627789258957
[2024-11-20 00:55:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1012
train_sample_count: 1012
avg_envstep_per_episode: 144.57142857142858
avg_sample_per_episode: 144.57142857142858
avg_envstep_per_sec: 798.728498308235
avg_train_sample_per_sec: 798.728498308235
avg_episode_per_sec: 5.524801865768423
collect_time: 1.267013762678419
reward_mean: 1028.0
reward_std: 389.9007263183594
reward_max: 1642.0
reward_min: 610.0
total_envstep_count: 2701889
total_train_sample_count: 2701840
total_episode_count: 16868
total_duration: 3434.229792688574
[2024-11-20 00:55:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1511
train_sample_count: 1511
avg_envstep_per_episode: 167.88888888888889
avg_sample_per_episode: 167.88888888888889
avg_envstep_per_sec: 802.7951972988187
avg_train_sample_per_sec: 802.7951972988187
avg_episode_per_sec: 4.781705344599185
collect_time: 1.8821736914770943
reward_mean: 1189.888916015625
reward_std: 562.3432006835938
reward_max: 2333.0
reward_min: 605.0
total_envstep_count: 2702912
total_train_sample_count: 2702871
total_episode_count: 16877
total_duration: 3436.111966380051
[2024-11-20 00:55:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 679
train_sample_count: 679
avg_envstep_per_episode: 135.8
avg_sample_per_episode: 135.8
avg_envstep_per_sec: 813.1021332782742
avg_train_sample_per_sec: 813.1021332782742
avg_episode_per_sec: 5.987497299545465
collect_time: 0.8350734455244881
reward_mean: 1114.0
reward_std: 435.38671875
reward_max: 1702.0
reward_min: 602.0
total_envstep_count: 2703908
total_train_sample_count: 2703862
total_episode_count: 16882
total_duration: 3436.9470398255753
[2024-11-20 00:55:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1167
train_sample_count: 1167
avg_envstep_per_episode: 129.66666666666666
avg_sample_per_episode: 129.66666666666666
avg_envstep_per_sec: 806.1159132363135
avg_train_sample_per_sec: 806.1159132363135
avg_episode_per_sec: 6.216832235755631
collect_time: 1.447682623352323
reward_mean: 1166.3333740234375
reward_std: 508.8959655761719
reward_max: 1857.0
reward_min: 248.0
total_envstep_count: 2704876
total_train_sample_count: 2704849
total_episode_count: 16891
total_duration: 3438.3947224489275
[2024-11-20 00:55:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1006
train_sample_count: 1006
avg_envstep_per_episode: 167.66666666666666
avg_sample_per_episode: 167.66666666666666
avg_envstep_per_sec: 797.7972779688251
avg_train_sample_per_sec: 797.7972779688251
avg_episode_per_sec: 4.758234262239514
collect_time: 1.2609719634056091
reward_mean: 1283.6666259765625
reward_std: 606.8551635742188
reward_max: 2347.0
reward_min: 608.0
total_envstep_count: 2705871
total_train_sample_count: 2705831
total_episode_count: 16897
total_duration: 3439.655694412333
[2024-11-20 00:55:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 945
train_sample_count: 945
avg_envstep_per_episode: 135.0
avg_sample_per_episode: 135.0
avg_envstep_per_sec: 800.9969766575233
avg_train_sample_per_sec: 800.9969766575233
avg_episode_per_sec: 5.933310938203876
collect_time: 1.1797797339303155
reward_mean: 1129.0
reward_std: 449.3016662597656
reward_max: 1912.0
reward_min: 615.0
total_envstep_count: 2706857
total_train_sample_count: 2706824
total_episode_count: 16904
total_duration: 3440.8354741462636
[2024-11-20 00:55:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1028
train_sample_count: 1028
avg_envstep_per_episode: 128.5
avg_sample_per_episode: 128.5
avg_envstep_per_sec: 800.9248168544481
avg_train_sample_per_sec: 800.9248168544481
avg_episode_per_sec: 6.232877952174693
collect_time: 1.283516228199005
reward_mean: 978.0
reward_std: 491.1761474609375
reward_max: 1668.0
reward_min: 246.0
total_envstep_count: 2707881
total_train_sample_count: 2707828
total_episode_count: 16912
total_duration: 3442.1189903744626
[2024-11-20 00:55:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 785
train_sample_count: 785
avg_envstep_per_episode: 98.125
avg_sample_per_episode: 98.125
avg_envstep_per_sec: 793.3197082711978
avg_train_sample_per_sec: 793.3197082711978
avg_episode_per_sec: 8.084786835884819
collect_time: 0.9895127926553998
reward_mean: 717.625
reward_std: 540.4758911132812
reward_max: 1843.0
reward_min: 248.0
total_envstep_count: 2708857
total_train_sample_count: 2708817
total_episode_count: 16920
total_duration: 3443.1085031671178
[2024-11-20 00:55:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1220
train_sample_count: 1220
avg_envstep_per_episode: 174.28571428571428
avg_sample_per_episode: 174.28571428571428
avg_envstep_per_sec: 795.8050513295016
avg_train_sample_per_sec: 795.8050513295016
avg_episode_per_sec: 4.566094556808616
collect_time: 1.5330387737069808
reward_mean: 1213.857177734375
reward_std: 612.8470458984375
reward_max: 2342.0
reward_min: 584.0
total_envstep_count: 2709860
total_train_sample_count: 2709833
total_episode_count: 16927
total_duration: 3444.641541940825
[2024-11-20 00:55:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1170
train_sample_count: 1170
avg_envstep_per_episode: 130.0
avg_sample_per_episode: 130.0
avg_envstep_per_sec: 796.4486985164439
avg_train_sample_per_sec: 796.4486985164439
avg_episode_per_sec: 6.126528450126492
collect_time: 1.4690211713314056
reward_mean: 987.6666870117188
reward_std: 414.6894226074219
reward_max: 1705.0
reward_min: 247.0
total_envstep_count: 2710860
total_train_sample_count: 2710835
total_episode_count: 16936
total_duration: 3446.1105631121563
[2024-11-20 00:55:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 889
train_sample_count: 889
avg_envstep_per_episode: 127.0
avg_sample_per_episode: 127.0
avg_envstep_per_sec: 803.6057734074827
avg_train_sample_per_sec: 803.6057734074827
avg_episode_per_sec: 6.327604515019549
collect_time: 1.106263829129083
reward_mean: 949.0
reward_std: 537.6730346679688
reward_max: 1890.0
reward_min: 231.0
total_envstep_count: 2711902
total_train_sample_count: 2711868
total_episode_count: 16943
total_duration: 3447.2168269412855
[2024-11-20 00:55:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 409
train_sample_count: 409
avg_envstep_per_episode: 136.33333333333334
avg_sample_per_episode: 136.33333333333334
avg_envstep_per_sec: 809.6539341801865
avg_train_sample_per_sec: 809.6539341801865
avg_episode_per_sec: 5.938781913302102
collect_time: 0.5051540945257459
reward_mean: 1163.6666259765625
reward_std: 442.7733459472656
reward_max: 1722.0
reward_min: 639.0
total_envstep_count: 2712867
total_train_sample_count: 2712841
total_episode_count: 16946
total_duration: 3447.721981035811
[2024-11-20 00:56:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1000
train_sample_count: 1000
avg_envstep_per_episode: 250.0
avg_sample_per_episode: 250.0
avg_envstep_per_sec: 803.832025232577
avg_train_sample_per_sec: 803.832025232577
avg_episode_per_sec: 3.215328100930308
collect_time: 1.2440410043512071
reward_mean: 1499.75
reward_std: 184.77874755859375
reward_max: 1689.0
reward_min: 1314.0
total_envstep_count: 2713863
total_train_sample_count: 2713817
total_episode_count: 16950
total_duration: 3448.9660220401624
[2024-11-20 00:56:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1190
train_sample_count: 1190
avg_envstep_per_episode: 238.0
avg_sample_per_episode: 238.0
avg_envstep_per_sec: 805.7925582723409
avg_train_sample_per_sec: 805.7925582723409
avg_episode_per_sec: 3.3856830179510125
collect_time: 1.4768068875585285
reward_mean: 1446.800048828125
reward_std: 549.6542358398438
reward_max: 2314.0
reward_min: 620.0
total_envstep_count: 2714859
total_train_sample_count: 2714815
total_episode_count: 16955
total_duration: 3450.442828927721
[2024-11-20 00:56:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1548
train_sample_count: 1548
avg_envstep_per_episode: 172.0
avg_sample_per_episode: 172.0
avg_envstep_per_sec: 805.439161102355
avg_train_sample_per_sec: 805.439161102355
avg_episode_per_sec: 4.682785820362529
collect_time: 1.9219328718526023
reward_mean: 1271.111083984375
reward_std: 566.9033813476562
reward_max: 2329.0
reward_min: 625.0
total_envstep_count: 2715869
total_train_sample_count: 2715823
total_episode_count: 16964
total_duration: 3452.364761799574
[2024-11-20 00:56:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 681
train_sample_count: 681
avg_envstep_per_episode: 136.2
avg_sample_per_episode: 136.2
avg_envstep_per_sec: 797.0281417933566
avg_train_sample_per_sec: 797.0281417933566
avg_episode_per_sec: 5.851895314194982
collect_time: 0.8544240338461739
reward_mean: 1168.800048828125
reward_std: 597.9154663085938
reward_max: 1927.0
reward_min: 619.0
total_envstep_count: 2716880
total_train_sample_count: 2716840
total_episode_count: 16969
total_duration: 3453.21918583342
[2024-11-20 00:56:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 701
train_sample_count: 701
avg_envstep_per_episode: 175.25
avg_sample_per_episode: 175.25
avg_envstep_per_sec: 792.9944617158873
avg_train_sample_per_sec: 792.9944617158873
avg_episode_per_sec: 4.524932734470113
collect_time: 0.8839910413537706
reward_mean: 1159.25
reward_std: 427.7472229003906
reward_max: 1724.0
reward_min: 718.0
total_envstep_count: 2717892
total_train_sample_count: 2717877
total_episode_count: 16973
total_duration: 3454.103176874774
[2024-11-20 00:56:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1288
train_sample_count: 1288
avg_envstep_per_episode: 184.0
avg_sample_per_episode: 184.0
avg_envstep_per_sec: 800.9016632644638
avg_train_sample_per_sec: 800.9016632644638
avg_episode_per_sec: 4.352726430785129
collect_time: 1.6081874455724443
reward_mean: 1392.7142333984375
reward_std: 589.5280151367188
reward_max: 2339.0
reward_min: 610.0
total_envstep_count: 2718902
total_train_sample_count: 2718865
total_episode_count: 16980
total_duration: 3455.7113643203465
[2024-11-20 00:56:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 857
train_sample_count: 857
avg_envstep_per_episode: 142.83333333333334
avg_sample_per_episode: 142.83333333333334
avg_envstep_per_sec: 808.0486191209856
avg_train_sample_per_sec: 808.0486191209856
avg_episode_per_sec: 5.6572832143826295
collect_time: 1.0605797469615936
reward_mean: 974.3333129882812
reward_std: 626.880859375
reward_max: 2330.0
reward_min: 606.0
total_envstep_count: 2719913
total_train_sample_count: 2719878
total_episode_count: 16986
total_duration: 3456.771944067308
[2024-11-20 00:56:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 959
train_sample_count: 959
avg_envstep_per_episode: 137.0
avg_sample_per_episode: 137.0
avg_envstep_per_sec: 797.4206694171204
avg_train_sample_per_sec: 797.4206694171204
avg_episode_per_sec: 5.820588827862193
collect_time: 1.2026274672576358
reward_mean: 987.1428833007812
reward_std: 431.7722473144531
reward_max: 1585.0
reward_min: 605.0
total_envstep_count: 2720877
total_train_sample_count: 2720861
total_episode_count: 16993
total_duration: 3457.9745715345657
[2024-11-20 00:56:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 674
train_sample_count: 674
avg_envstep_per_episode: 134.8
avg_sample_per_episode: 134.8
avg_envstep_per_sec: 805.479746576464
avg_train_sample_per_sec: 805.479746576464
avg_episode_per_sec: 5.975369039884748
collect_time: 0.8367684015205928
reward_mean: 895.7999877929688
reward_std: 379.21307373046875
reward_max: 1582.0
reward_min: 618.0
total_envstep_count: 2721897
total_train_sample_count: 2721859
total_episode_count: 16998
total_duration: 3458.8113399360864
[2024-11-20 00:56:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1380
train_sample_count: 1380
avg_envstep_per_episode: 345.0
avg_sample_per_episode: 345.0
avg_envstep_per_sec: 801.4845095267966
avg_train_sample_per_sec: 801.4845095267966
avg_episode_per_sec: 2.3231435058747727
collect_time: 1.7218049551759447
reward_mean: 1891.25
reward_std: 569.0115966796875
reward_max: 2573.0
reward_min: 1325.0
total_envstep_count: 2722885
total_train_sample_count: 2722855
total_episode_count: 17002
total_duration: 3460.5331448912625
[2024-11-20 00:56:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1245
train_sample_count: 1245
avg_envstep_per_episode: 177.85714285714286
avg_sample_per_episode: 177.85714285714286
avg_envstep_per_sec: 811.6356959378633
avg_train_sample_per_sec: 811.6356959378633
avg_episode_per_sec: 4.563413551457866
collect_time: 1.5339394339493344
reward_mean: 1148.142822265625
reward_std: 467.8935852050781
reward_max: 1682.0
reward_min: 602.0
total_envstep_count: 2723903
total_train_sample_count: 2723872
total_episode_count: 17009
total_duration: 3462.067084325212
[2024-11-20 00:56:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 765
train_sample_count: 765
avg_envstep_per_episode: 191.25
avg_sample_per_episode: 191.25
avg_envstep_per_sec: 806.7962934045986
avg_train_sample_per_sec: 806.7962934045986
avg_episode_per_sec: 4.21854271061228
collect_time: 0.9481947379452842
reward_mean: 1200.25
reward_std: 260.0407409667969
reward_max: 1418.0
reward_min: 756.0
total_envstep_count: 2724900
total_train_sample_count: 2724853
total_episode_count: 17013
total_duration: 3463.0152790631573
[2024-11-20 00:56:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1263
train_sample_count: 1263
avg_envstep_per_episode: 140.33333333333334
avg_sample_per_episode: 140.33333333333334
avg_envstep_per_sec: 799.4703290046706
avg_train_sample_per_sec: 799.4703290046706
avg_episode_per_sec: 5.696938211434707
collect_time: 1.5797959651265825
reward_mean: 1088.5555419921875
reward_std: 439.7552490234375
reward_max: 1692.0
reward_min: 586.0
total_envstep_count: 2725901
total_train_sample_count: 2725876
total_episode_count: 17022
total_duration: 3464.595075028284
[2024-11-20 00:56:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 565
train_sample_count: 565
avg_envstep_per_episode: 113.0
avg_sample_per_episode: 113.0
avg_envstep_per_sec: 807.6746391328608
avg_train_sample_per_sec: 807.6746391328608
avg_episode_per_sec: 7.14756317816691
collect_time: 0.6995391121932438
reward_mean: 938.2000122070312
reward_std: 611.781494140625
reward_max: 1927.0
reward_min: 229.0
total_envstep_count: 2726888
total_train_sample_count: 2726861
total_episode_count: 17027
total_duration: 3465.2946141404773
[2024-11-20 00:56:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 683
train_sample_count: 683
avg_envstep_per_episode: 170.75
avg_sample_per_episode: 170.75
avg_envstep_per_sec: 794.9954502760272
avg_train_sample_per_sec: 794.9954502760272
avg_episode_per_sec: 4.655903076287129
collect_time: 0.8591244135584151
reward_mean: 1469.25
reward_std: 508.0277404785156
reward_max: 1926.0
reward_min: 609.0
total_envstep_count: 2727917
total_train_sample_count: 2727868
total_episode_count: 17031
total_duration: 3466.1537385540355
[2024-11-20 00:56:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 534
train_sample_count: 534
avg_envstep_per_episode: 178.0
avg_sample_per_episode: 178.0
avg_envstep_per_sec: 807.8535002618786
avg_train_sample_per_sec: 807.8535002618786
avg_episode_per_sec: 4.538502810459992
collect_time: 0.6610109380313329
reward_mean: 1185.6666259765625
reward_std: 545.6887817382812
reward_max: 1920.0
reward_min: 613.0
total_envstep_count: 2728899
total_train_sample_count: 2728870
total_episode_count: 17034
total_duration: 3466.8147494920668
[2024-11-20 00:57:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1679
train_sample_count: 1679
avg_envstep_per_episode: 279.8333333333333
avg_sample_per_episode: 279.8333333333333
avg_envstep_per_sec: 803.248468523955
avg_train_sample_per_sec: 803.248468523955
avg_episode_per_sec: 2.87045313349835
collect_time: 2.090262310845511
reward_mean: 1624.3333740234375
reward_std: 721.3248291015625
reward_max: 2972.0
reward_min: 586.0
total_envstep_count: 2729894
total_train_sample_count: 2729853
total_episode_count: 17040
total_duration: 3468.905011802912
[2024-11-20 00:57:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1090
train_sample_count: 1090
avg_envstep_per_episode: 218.0
avg_sample_per_episode: 218.0
avg_envstep_per_sec: 811.7405173973514
avg_train_sample_per_sec: 811.7405173973514
avg_episode_per_sec: 3.723580355033722
collect_time: 1.3427936349596297
reward_mean: 1250.0
reward_std: 576.4196166992188
reward_max: 2322.0
reward_min: 732.0
total_envstep_count: 2730897
total_train_sample_count: 2730859
total_episode_count: 17045
total_duration: 3470.2478054378716
[2024-11-20 00:57:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 654
train_sample_count: 654
avg_envstep_per_episode: 163.5
avg_sample_per_episode: 163.5
avg_envstep_per_sec: 799.9636008782944
avg_train_sample_per_sec: 799.9636008782944
avg_episode_per_sec: 4.892743736258682
collect_time: 0.8175371970449176
reward_mean: 1278.0
reward_std: 432.3037109375
reward_max: 1849.0
reward_min: 631.0
total_envstep_count: 2731885
total_train_sample_count: 2731849
total_episode_count: 17049
total_duration: 3471.0653426349168
[2024-11-20 00:57:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1182
train_sample_count: 1182
avg_envstep_per_episode: 295.5
avg_sample_per_episode: 295.5
avg_envstep_per_sec: 808.0294659732411
avg_train_sample_per_sec: 808.0294659732411
avg_episode_per_sec: 2.7344482774052157
collect_time: 1.462817941393171
reward_mean: 1206.75
reward_std: 384.929443359375
reward_max: 1670.0
reward_min: 603.0
total_envstep_count: 2732881
total_train_sample_count: 2732839
total_episode_count: 17053
total_duration: 3472.52816057631
[2024-11-20 00:57:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1041
train_sample_count: 1041
avg_envstep_per_episode: 260.25
avg_sample_per_episode: 260.25
avg_envstep_per_sec: 810.8615917815292
avg_train_sample_per_sec: 810.8615917815292
avg_episode_per_sec: 3.115702562080804
collect_time: 1.283819594553539
reward_mean: 1488.25
reward_std: 195.20933532714844
reward_max: 1687.0
reward_min: 1275.0
total_envstep_count: 2733838
total_train_sample_count: 2733820
total_episode_count: 17057
total_duration: 3473.8119801708635
[2024-11-20 00:57:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 861
train_sample_count: 861
avg_envstep_per_episode: 287.0
avg_sample_per_episode: 287.0
avg_envstep_per_sec: 805.0445830494918
avg_train_sample_per_sec: 805.0445830494918
avg_episode_per_sec: 2.8050333904163476
collect_time: 1.0695059852940694
reward_mean: 1425.3333740234375
reward_std: 193.39137268066406
reward_max: 1695.0
reward_min: 1251.0
total_envstep_count: 2734843
total_train_sample_count: 2734789
total_episode_count: 17060
total_duration: 3474.8814861561577
[2024-11-20 00:57:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 589
train_sample_count: 589
avg_envstep_per_episode: 117.8
avg_sample_per_episode: 117.8
avg_envstep_per_sec: 808.5438946331218
avg_train_sample_per_sec: 808.5438946331218
avg_episode_per_sec: 6.863700293999337
collect_time: 0.728470035961696
reward_mean: 854.2000122070312
reward_std: 509.1579284667969
reward_max: 1872.0
reward_min: 571.0
total_envstep_count: 2735807
total_train_sample_count: 2735762
total_episode_count: 17065
total_duration: 3475.6099561921196
[2024-11-20 00:57:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1063
train_sample_count: 1063
avg_envstep_per_episode: 265.75
avg_sample_per_episode: 265.75
avg_envstep_per_sec: 807.5540663011037
avg_train_sample_per_sec: 807.5540663011037
avg_episode_per_sec: 3.038773532647615
collect_time: 1.3163205342633382
reward_mean: 1452.25
reward_std: 464.61724853515625
reward_max: 1814.0
reward_min: 654.0
total_envstep_count: 2736811
total_train_sample_count: 2736765
total_episode_count: 17069
total_duration: 3476.926276726383
[2024-11-20 00:57:27][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1716
train_sample_count: 1716
avg_envstep_per_episode: 286.0
avg_sample_per_episode: 286.0
avg_envstep_per_sec: 799.1461788202599
avg_train_sample_per_sec: 799.1461788202599
avg_episode_per_sec: 2.7942174084624476
collect_time: 2.1472917539732794
reward_mean: 1517.8333740234375
reward_std: 854.9539184570312
reward_max: 2973.0
reward_min: 613.0
total_envstep_count: 2737807
total_train_sample_count: 2737761
total_episode_count: 17075
total_duration: 3479.0735684803562
[2024-11-20 00:57:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1010
train_sample_count: 1010
avg_envstep_per_episode: 168.33333333333334
avg_sample_per_episode: 168.33333333333334
avg_envstep_per_sec: 806.0174034918261
avg_train_sample_per_sec: 806.0174034918261
avg_episode_per_sec: 4.788222198961344
collect_time: 1.253074680055891
reward_mean: 1059.0
reward_std: 288.661865234375
reward_max: 1328.0
reward_min: 618.0
total_envstep_count: 2738834
total_train_sample_count: 2738783
total_episode_count: 17081
total_duration: 3480.326643160412
[2024-11-20 00:57:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 10
envstep_count: 1358
train_sample_count: 1358
avg_envstep_per_episode: 135.8
avg_sample_per_episode: 135.8
avg_envstep_per_sec: 805.145432420833
avg_train_sample_per_sec: 805.145432420833
avg_episode_per_sec: 5.9289059824803605
collect_time: 1.6866518088749478
reward_mean: 971.5
reward_std: 506.6192321777344
reward_max: 1852.0
reward_min: 233.0
total_envstep_count: 2739848
total_train_sample_count: 2739805
total_episode_count: 17091
total_duration: 3482.013294969287
[2024-11-20 00:57:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 714
train_sample_count: 714
avg_envstep_per_episode: 142.8
avg_sample_per_episode: 142.8
avg_envstep_per_sec: 814.1822644110533
avg_train_sample_per_sec: 814.1822644110533
avg_episode_per_sec: 5.701556473466759
collect_time: 0.8769535166876656
reward_mean: 1008.5999755859375
reward_std: 398.8747253417969
reward_max: 1703.0
reward_min: 606.0
total_envstep_count: 2740835
total_train_sample_count: 2740807
total_episode_count: 17096
total_duration: 3482.8902484859746
[2024-11-20 00:57:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1207
train_sample_count: 1207
avg_envstep_per_episode: 150.875
avg_sample_per_episode: 150.875
avg_envstep_per_sec: 798.3164823576997
avg_train_sample_per_sec: 798.3164823576997
avg_episode_per_sec: 5.2912442906889785
collect_time: 1.5119317046233582
reward_mean: 1231.125
reward_std: 575.1326904296875
reward_max: 1856.0
reward_min: 244.0
total_envstep_count: 2741861
total_train_sample_count: 2741810
total_episode_count: 17104
total_duration: 3484.402180190598
[2024-11-20 00:57:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 552
train_sample_count: 552
avg_envstep_per_episode: 92.0
avg_sample_per_episode: 92.0
avg_envstep_per_sec: 797.7702192362484
avg_train_sample_per_sec: 797.7702192362484
avg_episode_per_sec: 8.67141542648096
collect_time: 0.6919285612446922
reward_mean: 724.0
reward_std: 149.55267333984375
reward_max: 1047.0
reward_min: 625.0
total_envstep_count: 2742847
total_train_sample_count: 2742818
total_episode_count: 17110
total_duration: 3485.0941087518427
[2024-11-20 00:57:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1084
train_sample_count: 1084
avg_envstep_per_episode: 180.66666666666666
avg_sample_per_episode: 180.66666666666666
avg_envstep_per_sec: 804.2833619612321
avg_train_sample_per_sec: 804.2833619612321
avg_episode_per_sec: 4.45175292598468
collect_time: 1.3477836932454792
reward_mean: 1330.0
reward_std: 728.0849609375
reward_max: 2331.0
reward_min: 605.0
total_envstep_count: 2743849
total_train_sample_count: 2743818
total_episode_count: 17116
total_duration: 3486.4418924450883
[2024-11-20 00:57:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 698
train_sample_count: 698
avg_envstep_per_episode: 174.5
avg_sample_per_episode: 174.5
avg_envstep_per_sec: 802.0047661736743
avg_train_sample_per_sec: 802.0047661736743
avg_episode_per_sec: 4.596015851998133
collect_time: 0.8703190173421588
reward_mean: 1512.75
reward_std: 190.27134704589844
reward_max: 1707.0
reward_min: 1322.0
total_envstep_count: 2744829
total_train_sample_count: 2744792
total_episode_count: 17120
total_duration: 3487.3122114624307
[2024-11-20 00:57:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 362
train_sample_count: 362
avg_envstep_per_episode: 120.66666666666667
avg_sample_per_episode: 120.66666666666667
avg_envstep_per_sec: 799.4993925211979
avg_train_sample_per_sec: 799.4993925211979
avg_episode_per_sec: 6.6256855733800935
collect_time: 0.45278333340372356
reward_mean: 1088.0
reward_std: 615.8057250976562
reward_max: 1693.0
reward_min: 243.0
total_envstep_count: 2745803
total_train_sample_count: 2745766
total_episode_count: 17123
total_duration: 3487.7649947958344
[2024-11-20 00:57:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 602
train_sample_count: 602
avg_envstep_per_episode: 301.0
avg_sample_per_episode: 301.0
avg_envstep_per_sec: 797.1599741922414
avg_train_sample_per_sec: 797.1599741922414
avg_episode_per_sec: 2.648372007283194
collect_time: 0.7551809166158949
reward_mean: 1961.5
reward_std: 671.5
reward_max: 2633.0
reward_min: 1290.0
total_envstep_count: 2746770
total_train_sample_count: 2746740
total_episode_count: 17125
total_duration: 3488.52017571245
[2024-11-20 00:58:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 721
train_sample_count: 721
avg_envstep_per_episode: 180.25
avg_sample_per_episode: 180.25
avg_envstep_per_sec: 802.173740786991
avg_train_sample_per_sec: 802.173740786991
avg_episode_per_sec: 4.450339754712848
collect_time: 0.8988077810832432
reward_mean: 1407.5
reward_std: 574.7584228515625
reward_max: 1999.0
reward_min: 653.0
total_envstep_count: 2747745
total_train_sample_count: 2747713
total_episode_count: 17129
total_duration: 3489.4189834935332
[2024-11-20 00:58:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 231
train_sample_count: 231
avg_envstep_per_episode: 231.0
avg_sample_per_episode: 231.0
avg_envstep_per_sec: 803.8798466720873
avg_train_sample_per_sec: 803.8798466720873
avg_episode_per_sec: 3.4799993362428023
collect_time: 0.2873563766479492
reward_mean: 1336.0
reward_std: 0.0
reward_max: 1336.0
reward_min: 1336.0
total_envstep_count: 2749400
total_train_sample_count: 2749348
total_episode_count: 17130
total_duration: 3489.706339870181
[2024-11-20 00:58:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 2727
train_sample_count: 2727
avg_envstep_per_episode: 681.75
avg_sample_per_episode: 681.75
avg_envstep_per_sec: 817.1909896251153
avg_train_sample_per_sec: 817.1909896251153
avg_episode_per_sec: 1.1986666514486475
collect_time: 3.337041199207306
reward_mean: 2012.0
reward_std: 418.4232177734375
reward_max: 2284.0
reward_min: 1288.0
total_envstep_count: 2750365
total_train_sample_count: 2750323
total_episode_count: 17134
total_duration: 3493.0433810693885
[2024-11-20 00:58:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 972
train_sample_count: 972
avg_envstep_per_episode: 194.4
avg_sample_per_episode: 194.4
avg_envstep_per_sec: 812.8524254305975
avg_train_sample_per_sec: 812.8524254305975
avg_episode_per_sec: 4.18133963698867
collect_time: 1.1957890135901315
reward_mean: 1240.800048828125
reward_std: 924.9716796875
reward_max: 3004.0
reward_min: 613.0
total_envstep_count: 2751344
total_train_sample_count: 2751307
total_episode_count: 17139
total_duration: 3494.2391700829785
[2024-11-20 00:58:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1266
train_sample_count: 1266
avg_envstep_per_episode: 180.85714285714286
avg_sample_per_episode: 180.85714285714286
avg_envstep_per_sec: 800.8016898760816
avg_train_sample_per_sec: 800.8016898760816
avg_episode_per_sec: 4.4278134511315725
collect_time: 1.5809157448155542
reward_mean: 1281.4285888671875
reward_std: 801.3317260742188
reward_max: 3002.0
reward_min: 608.0
total_envstep_count: 2752378
total_train_sample_count: 2752333
total_episode_count: 17146
total_duration: 3495.820085827794
[2024-11-20 00:58:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2196
train_sample_count: 2196
avg_envstep_per_episode: 274.5
avg_sample_per_episode: 274.5
avg_envstep_per_sec: 806.2456221212022
avg_train_sample_per_sec: 806.2456221212022
avg_episode_per_sec: 2.937142521388715
collect_time: 2.7237357199192047
reward_mean: 987.0
reward_std: 362.7647399902344
reward_max: 1573.0
reward_min: 630.0
total_envstep_count: 2753347
total_train_sample_count: 2753317
total_episode_count: 17154
total_duration: 3498.5438215477134
[2024-11-20 00:58:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 782
train_sample_count: 782
avg_envstep_per_episode: 195.5
avg_sample_per_episode: 195.5
avg_envstep_per_sec: 796.745636840314
avg_train_sample_per_sec: 796.745636840314
avg_episode_per_sec: 4.075425252380123
collect_time: 0.9814926669711159
reward_mean: 1414.5
reward_std: 166.12420654296875
reward_max: 1702.0
reward_min: 1309.0
total_envstep_count: 2754343
total_train_sample_count: 2754303
total_episode_count: 17158
total_duration: 3499.5253142146844
[2024-11-20 00:58:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1298
train_sample_count: 1298
avg_envstep_per_episode: 144.22222222222223
avg_sample_per_episode: 144.22222222222223
avg_envstep_per_sec: 799.5468604380875
avg_train_sample_per_sec: 799.5468604380875
avg_episode_per_sec: 5.543853423684736
collect_time: 1.6234195445265087
reward_mean: 946.2222290039062
reward_std: 303.0782165527344
reward_max: 1319.0
reward_min: 627.0
total_envstep_count: 2755336
total_train_sample_count: 2755301
total_episode_count: 17167
total_duration: 3501.1487337592107
[2024-11-20 00:58:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 215
train_sample_count: 215
avg_envstep_per_episode: 215.0
avg_sample_per_episode: 215.0
avg_envstep_per_sec: 798.193062358166
avg_train_sample_per_sec: 798.193062358166
avg_episode_per_sec: 3.7125258714333307
collect_time: 0.2693583922726767
reward_mean: 1653.0
reward_std: 0.0
reward_max: 1653.0
reward_min: 1653.0
total_envstep_count: 2756319
total_train_sample_count: 2756284
total_episode_count: 17168
total_duration: 3501.4180921514835
[2024-11-20 00:58:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1706
train_sample_count: 1706
avg_envstep_per_episode: 213.25
avg_sample_per_episode: 213.25
avg_envstep_per_sec: 810.0464281359931
avg_train_sample_per_sec: 810.0464281359931
avg_episode_per_sec: 3.7985764508135667
collect_time: 2.106052123364948
reward_mean: 1139.375
reward_std: 677.0520629882812
reward_max: 2303.0
reward_min: 244.0
total_envstep_count: 2757360
total_train_sample_count: 2757318
total_episode_count: 17176
total_duration: 3503.5241442748484
[2024-11-20 00:58:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 863
train_sample_count: 863
avg_envstep_per_episode: 123.28571428571429
avg_sample_per_episode: 123.28571428571429
avg_envstep_per_sec: 813.8160489197164
avg_train_sample_per_sec: 813.8160489197164
avg_episode_per_sec: 6.601057175478581
collect_time: 1.060436201947076
reward_mean: 1095.7142333984375
reward_std: 302.2948913574219
reward_max: 1332.0
reward_min: 627.0
total_envstep_count: 2758361
total_train_sample_count: 2758325
total_episode_count: 17183
total_duration: 3504.5845804767955
[2024-11-20 00:58:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1060
train_sample_count: 1060
avg_envstep_per_episode: 176.66666666666666
avg_sample_per_episode: 176.66666666666666
avg_envstep_per_sec: 806.8173137033469
avg_train_sample_per_sec: 806.8173137033469
avg_episode_per_sec: 4.566890454924605
collect_time: 1.3138042305197035
reward_mean: 797.5
reward_std: 357.46551513671875
reward_max: 1593.0
reward_min: 601.0
total_envstep_count: 2759356
total_train_sample_count: 2759325
total_episode_count: 17189
total_duration: 3505.898384707315
[2024-11-20 00:58:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 715
train_sample_count: 715
avg_envstep_per_episode: 119.16666666666667
avg_sample_per_episode: 119.16666666666667
avg_envstep_per_sec: 811.3018840602568
avg_train_sample_per_sec: 811.3018840602568
avg_episode_per_sec: 6.808127698407749
collect_time: 0.8812995680740903
reward_mean: 924.6666870117188
reward_std: 702.7618408203125
reward_max: 1919.0
reward_min: 243.0
total_envstep_count: 2760391
total_train_sample_count: 2760364
total_episode_count: 17195
total_duration: 3506.779684275389
[2024-11-20 00:58:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 965
train_sample_count: 965
avg_envstep_per_episode: 193.0
avg_sample_per_episode: 193.0
avg_envstep_per_sec: 802.3842771299462
avg_train_sample_per_sec: 802.3842771299462
avg_episode_per_sec: 4.157431487719928
collect_time: 1.20266563977514
reward_mean: 1035.0
reward_std: 513.0594482421875
reward_max: 1663.0
reward_min: 244.0
total_envstep_count: 2761394
total_train_sample_count: 2761341
total_episode_count: 17200
total_duration: 3507.9823499151644
[2024-11-20 00:58:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1234
train_sample_count: 1234
avg_envstep_per_episode: 154.25
avg_sample_per_episode: 154.25
avg_envstep_per_sec: 808.600532806214
avg_train_sample_per_sec: 808.600532806214
avg_episode_per_sec: 5.24214283828988
collect_time: 1.5260934787137168
reward_mean: 910.25
reward_std: 587.8787231445312
reward_max: 2336.0
reward_min: 573.0
total_envstep_count: 2762380
total_train_sample_count: 2762347
total_episode_count: 17208
total_duration: 3509.508443393878
[2024-11-20 00:58:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1044
train_sample_count: 1044
avg_envstep_per_episode: 130.5
avg_sample_per_episode: 130.5
avg_envstep_per_sec: 804.9712435350683
avg_train_sample_per_sec: 804.9712435350683
avg_episode_per_sec: 6.16836201942581
collect_time: 1.2969407396657127
reward_mean: 963.375
reward_std: 466.95794677734375
reward_max: 1677.0
reward_min: 249.0
total_envstep_count: 2763391
total_train_sample_count: 2763343
total_episode_count: 17216
total_duration: 3510.805384133544
[2024-11-20 00:59:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 588
train_sample_count: 588
avg_envstep_per_episode: 117.6
avg_sample_per_episode: 117.6
avg_envstep_per_sec: 799.002466823184
avg_train_sample_per_sec: 799.002466823184
avg_episode_per_sec: 6.794238663462449
collect_time: 0.735917627811432
reward_mean: 902.7999877929688
reward_std: 343.7926025390625
reward_max: 1325.0
reward_min: 607.0
total_envstep_count: 2764378
total_train_sample_count: 2764339
total_episode_count: 17221
total_duration: 3511.5413017613555
[2024-11-20 00:59:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1497
train_sample_count: 1497
avg_envstep_per_episode: 249.5
avg_sample_per_episode: 249.5
avg_envstep_per_sec: 802.1070717468031
avg_train_sample_per_sec: 802.1070717468031
avg_episode_per_sec: 3.2148580029931986
collect_time: 1.866334374461855
reward_mean: 1550.5
reward_std: 690.0125122070312
reward_max: 2985.0
reward_min: 739.0
total_envstep_count: 2765372
total_train_sample_count: 2765332
total_episode_count: 17227
total_duration: 3513.4076361358175
[2024-11-20 00:59:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1138
train_sample_count: 1138
avg_envstep_per_episode: 142.25
avg_sample_per_episode: 142.25
avg_envstep_per_sec: 808.7354991055591
avg_train_sample_per_sec: 808.7354991055591
avg_episode_per_sec: 5.68531106576843
collect_time: 1.4071349671908788
reward_mean: 1134.5
reward_std: 438.0445251464844
reward_max: 1870.0
reward_min: 602.0
total_envstep_count: 2766382
total_train_sample_count: 2766374
total_episode_count: 17235
total_duration: 3514.8147711030083
[2024-11-20 00:59:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 809
train_sample_count: 809
avg_envstep_per_episode: 161.8
avg_sample_per_episode: 161.8
avg_envstep_per_sec: 809.9095960951853
avg_train_sample_per_sec: 809.9095960951853
avg_episode_per_sec: 5.005621731119811
collect_time: 0.9988769165107183
reward_mean: 965.7999877929688
reward_std: 450.0441589355469
reward_max: 1677.0
reward_min: 601.0
total_envstep_count: 2767394
total_train_sample_count: 2767351
total_episode_count: 17240
total_duration: 3515.813648019519
[2024-11-20 00:59:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 721
train_sample_count: 721
avg_envstep_per_episode: 144.2
avg_sample_per_episode: 144.2
avg_envstep_per_sec: 814.8357858167282
avg_train_sample_per_sec: 814.8357858167282
avg_episode_per_sec: 5.65073360483168
collect_time: 0.884840863091605
reward_mean: 953.0
reward_std: 414.6723937988281
reward_max: 1573.0
reward_min: 605.0
total_envstep_count: 2768351
total_train_sample_count: 2768324
total_episode_count: 17245
total_duration: 3516.6984888826105
[2024-11-20 00:59:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1030
train_sample_count: 1030
avg_envstep_per_episode: 206.0
avg_sample_per_episode: 206.0
avg_envstep_per_sec: 803.448089962318
avg_train_sample_per_sec: 803.448089962318
avg_episode_per_sec: 3.9002334464190196
collect_time: 1.2819745455469405
reward_mean: 1382.800048828125
reward_std: 547.8953857421875
reward_max: 2326.0
reward_min: 607.0
total_envstep_count: 2769338
total_train_sample_count: 2769306
total_episode_count: 17250
total_duration: 3517.9804634281572
[2024-11-20 00:59:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1019
train_sample_count: 1019
avg_envstep_per_episode: 169.83333333333334
avg_sample_per_episode: 169.83333333333334
avg_envstep_per_sec: 804.4840939014672
avg_train_sample_per_sec: 804.4840939014672
avg_episode_per_sec: 4.736903398831014
collect_time: 1.2666502765246799
reward_mean: 1203.0
reward_std: 628.4295043945312
reward_max: 2345.0
reward_min: 601.0
total_envstep_count: 2770340
total_train_sample_count: 2770301
total_episode_count: 17256
total_duration: 3519.247113704682
[2024-11-20 00:59:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 504
train_sample_count: 504
avg_envstep_per_episode: 100.8
avg_sample_per_episode: 100.8
avg_envstep_per_sec: 799.9068606520171
avg_train_sample_per_sec: 799.9068606520171
avg_episode_per_sec: 7.935583935039853
collect_time: 0.630073355776923
reward_mean: 754.4000244140625
reward_std: 283.39483642578125
reward_max: 1321.0
reward_min: 602.0
total_envstep_count: 2771327
total_train_sample_count: 2771285
total_episode_count: 17261
total_duration: 3519.8771870604587
[2024-11-20 00:59:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1138
train_sample_count: 1138
avg_envstep_per_episode: 189.66666666666666
avg_sample_per_episode: 189.66666666666666
avg_envstep_per_sec: 819.274043849811
avg_train_sample_per_sec: 819.274043849811
avg_episode_per_sec: 4.319546804129057
collect_time: 1.3890346075807298
reward_mean: 1268.1666259765625
reward_std: 500.5558166503906
reward_max: 2336.0
reward_min: 805.0
total_envstep_count: 2772316
total_train_sample_count: 2772279
total_episode_count: 17267
total_duration: 3521.2662216680396
[2024-11-20 00:59:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1113
train_sample_count: 1113
avg_envstep_per_episode: 556.5
avg_sample_per_episode: 556.5
avg_envstep_per_sec: 816.4531994980427
avg_train_sample_per_sec: 816.4531994980427
avg_episode_per_sec: 1.467121652287588
collect_time: 1.363213471003941
reward_mean: 1240.5
reward_std: 53.5
reward_max: 1294.0
reward_min: 1187.0
total_envstep_count: 2773274
total_train_sample_count: 2773248
total_episode_count: 17269
total_duration: 3522.6294351390434
[2024-11-20 00:59:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1771
train_sample_count: 1771
avg_envstep_per_episode: 196.77777777777777
avg_sample_per_episode: 196.77777777777777
avg_envstep_per_sec: 807.1209258458682
avg_train_sample_per_sec: 807.1209258458682
avg_episode_per_sec: 4.101687370193571
collect_time: 2.1942189122949327
reward_mean: 1297.22216796875
reward_std: 386.267822265625
reward_max: 1696.0
reward_min: 613.0
total_envstep_count: 2774258
total_train_sample_count: 2774227
total_episode_count: 17278
total_duration: 3524.8236540513385
[2024-11-20 00:59:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 866
train_sample_count: 866
avg_envstep_per_episode: 144.33333333333334
avg_sample_per_episode: 144.33333333333334
avg_envstep_per_sec: 805.4348485435603
avg_train_sample_per_sec: 805.4348485435603
avg_episode_per_sec: 5.580380013003881
collect_time: 1.0751955934933255
reward_mean: 995.6666870117188
reward_std: 366.674072265625
reward_max: 1585.0
reward_min: 595.0
total_envstep_count: 2775261
total_train_sample_count: 2775213
total_episode_count: 17284
total_duration: 3525.898849644832
[2024-11-20 01:00:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 13
envstep_count: 976
train_sample_count: 976
avg_envstep_per_episode: 75.07692307692308
avg_sample_per_episode: 75.07692307692308
avg_envstep_per_sec: 804.9769881946395
avg_train_sample_per_sec: 804.9769881946395
avg_episode_per_sec: 10.722029555871222
collect_time: 1.212457019658316
reward_mean: 576.6923217773438
reward_std: 429.005859375
reward_max: 1320.0
reward_min: 243.0
total_envstep_count: 2776265
total_train_sample_count: 2776225
total_episode_count: 17297
total_duration: 3527.1113066644903
[2024-11-20 01:00:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 525
train_sample_count: 525
avg_envstep_per_episode: 105.0
avg_sample_per_episode: 105.0
avg_envstep_per_sec: 801.5426100593259
avg_train_sample_per_sec: 801.5426100593259
avg_episode_per_sec: 7.633739143422151
collect_time: 0.6549870130561647
reward_mean: 612.5999755859375
reward_std: 461.736572265625
reward_max: 1311.0
reward_min: 243.0
total_envstep_count: 2777260
total_train_sample_count: 2777206
total_episode_count: 17302
total_duration: 3527.7662936775464
[2024-11-20 01:00:09][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 731
train_sample_count: 731
avg_envstep_per_episode: 182.75
avg_sample_per_episode: 182.75
avg_envstep_per_sec: 806.8349324684566
avg_train_sample_per_sec: 806.8349324684566
avg_episode_per_sec: 4.4149654307439485
collect_time: 0.9060093590191431
reward_mean: 1300.0
reward_std: 261.10150146484375
reward_max: 1708.0
reward_min: 1050.0
total_envstep_count: 2778232
total_train_sample_count: 2778189
total_episode_count: 17306
total_duration: 3528.6723030365656
[2024-11-20 01:00:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1225
train_sample_count: 1225
avg_envstep_per_episode: 153.125
avg_sample_per_episode: 153.125
avg_envstep_per_sec: 802.7632835684869
avg_train_sample_per_sec: 802.7632835684869
avg_episode_per_sec: 5.242535729426853
collect_time: 1.5259791087536583
reward_mean: 962.875
reward_std: 345.7113952636719
reward_max: 1322.0
reward_min: 610.0
total_envstep_count: 2779209
total_train_sample_count: 2779174
total_episode_count: 17314
total_duration: 3530.1982821453194
[2024-11-20 01:00:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1336
train_sample_count: 1336
avg_envstep_per_episode: 190.85714285714286
avg_sample_per_episode: 190.85714285714286
avg_envstep_per_sec: 810.4354636090657
avg_train_sample_per_sec: 810.4354636090657
avg_episode_per_sec: 4.246293596754087
collect_time: 1.648496468861898
reward_mean: 1077.142822265625
reward_std: 295.4635314941406
reward_max: 1334.0
reward_min: 631.0
total_envstep_count: 2780235
total_train_sample_count: 2780210
total_episode_count: 17321
total_duration: 3531.8467786141814
[2024-11-20 01:00:20][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1148
train_sample_count: 1148
avg_envstep_per_episode: 143.5
avg_sample_per_episode: 143.5
avg_envstep_per_sec: 807.7959492775758
avg_train_sample_per_sec: 807.7959492775758
avg_episode_per_sec: 5.629240064652096
collect_time: 1.4211509738649641
reward_mean: 1056.0
reward_std: 500.37237548828125
reward_max: 1945.0
reward_min: 246.0
total_envstep_count: 2781237
total_train_sample_count: 2781202
total_episode_count: 17329
total_duration: 3533.267929588046
[2024-11-20 01:00:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 799
train_sample_count: 799
avg_envstep_per_episode: 133.16666666666666
avg_sample_per_episode: 133.16666666666666
avg_envstep_per_sec: 801.9075885697652
avg_train_sample_per_sec: 801.9075885697652
avg_episode_per_sec: 6.021834207032029
collect_time: 0.9963741600513458
reward_mean: 1054.8333740234375
reward_std: 409.7647399902344
reward_max: 1688.0
reward_min: 610.0
total_envstep_count: 2782239
total_train_sample_count: 2782205
total_episode_count: 17335
total_duration: 3534.2643037480975
[2024-11-20 01:00:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 929
train_sample_count: 929
avg_envstep_per_episode: 116.125
avg_sample_per_episode: 116.125
avg_envstep_per_sec: 798.8076268486834
avg_train_sample_per_sec: 798.8076268486834
avg_episode_per_sec: 6.878860080505348
collect_time: 1.1629833877086637
reward_mean: 842.875
reward_std: 532.4827270507812
reward_max: 1688.0
reward_min: 143.0
total_envstep_count: 2783247
total_train_sample_count: 2783194
total_episode_count: 17343
total_duration: 3535.427287135806
[2024-11-20 01:00:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1004
train_sample_count: 1004
avg_envstep_per_episode: 251.0
avg_sample_per_episode: 251.0
avg_envstep_per_sec: 803.0696877409276
avg_train_sample_per_sec: 803.0696877409276
avg_episode_per_sec: 3.199480827653098
collect_time: 1.2502028346061707
reward_mean: 1528.0
reward_std: 560.71826171875
reward_max: 2319.0
reward_min: 781.0
total_envstep_count: 2784228
total_train_sample_count: 2784198
total_episode_count: 17347
total_duration: 3536.6774899704124
[2024-11-20 01:00:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1194
train_sample_count: 1194
avg_envstep_per_episode: 199.0
avg_sample_per_episode: 199.0
avg_envstep_per_sec: 800.309540872646
avg_train_sample_per_sec: 800.309540872646
avg_episode_per_sec: 4.021655984284653
collect_time: 1.4919227361679077
reward_mean: 1458.5
reward_std: 243.15957641601562
reward_max: 1697.0
reward_min: 1057.0
total_envstep_count: 2785216
total_train_sample_count: 2785188
total_episode_count: 17353
total_duration: 3538.1694127065803
[2024-11-20 01:00:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 575
train_sample_count: 575
avg_envstep_per_episode: 191.66666666666666
avg_sample_per_episode: 191.66666666666666
avg_envstep_per_sec: 794.6824621160166
avg_train_sample_per_sec: 794.6824621160166
avg_episode_per_sec: 4.146169367561826
collect_time: 0.7235594434397561
reward_mean: 1585.6666259765625
reward_std: 380.1879577636719
reward_max: 1855.0
reward_min: 1048.0
total_envstep_count: 2786486
total_train_sample_count: 2786459
total_episode_count: 17356
total_duration: 3538.89297215002
[2024-11-20 01:01:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 668
train_sample_count: 668
avg_envstep_per_episode: 133.6
avg_sample_per_episode: 133.6
avg_envstep_per_sec: 797.4154597564795
avg_train_sample_per_sec: 797.4154597564795
avg_episode_per_sec: 5.968678590991614
collect_time: 0.8377063572406768
reward_mean: 1058.0
reward_std: 570.9381713867188
reward_max: 1686.0
reward_min: 251.0
total_envstep_count: 2787490
total_train_sample_count: 2787451
total_episode_count: 17361
total_duration: 3539.7306785072606
[2024-11-20 01:01:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1960
train_sample_count: 1960
avg_envstep_per_episode: 392.0
avg_sample_per_episode: 392.0
avg_envstep_per_sec: 805.225740253633
avg_train_sample_per_sec: 805.225740253633
avg_episode_per_sec: 2.0541472965653904
collect_time: 2.434100031852722
reward_mean: 2168.60009765625
reward_std: 315.0394287109375
reward_max: 2585.0
reward_min: 1699.0
total_envstep_count: 2788485
total_train_sample_count: 2788439
total_episode_count: 17366
total_duration: 3542.1647785391133
[2024-11-20 01:01:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 359
train_sample_count: 359
avg_envstep_per_episode: 89.75
avg_sample_per_episode: 89.75
avg_envstep_per_sec: 797.2738476273257
avg_train_sample_per_sec: 797.2738476273257
avg_episode_per_sec: 8.883274068271039
collect_time: 0.4502844299588884
reward_mean: 791.5
reward_std: 543.3389892578125
reward_max: 1696.0
reward_min: 245.0
total_envstep_count: 2789467
total_train_sample_count: 2789434
total_episode_count: 17370
total_duration: 3542.6150629690724
[2024-11-20 01:01:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 572
train_sample_count: 572
avg_envstep_per_episode: 143.0
avg_sample_per_episode: 143.0
avg_envstep_per_sec: 808.8504825444196
avg_train_sample_per_sec: 808.8504825444196
avg_episode_per_sec: 5.656297080730207
collect_time: 0.707176434142249
reward_mean: 943.75
reward_std: 459.4890441894531
reward_max: 1396.0
reward_min: 250.0
total_envstep_count: 2790488
total_train_sample_count: 2790462
total_episode_count: 17374
total_duration: 3543.3222394032146
[2024-11-20 01:01:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1576
train_sample_count: 1576
avg_envstep_per_episode: 262.6666666666667
avg_sample_per_episode: 262.6666666666667
avg_envstep_per_sec: 806.3644233777111
avg_train_sample_per_sec: 806.3644233777111
avg_episode_per_sec: 3.0699153174278337
collect_time: 1.9544513055256434
reward_mean: 1690.8333740234375
reward_std: 599.6453247070312
reward_max: 2350.0
reward_min: 617.0
total_envstep_count: 2791476
total_train_sample_count: 2791438
total_episode_count: 17380
total_duration: 3545.2766907087403
[2024-11-20 01:01:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 812
train_sample_count: 812
avg_envstep_per_episode: 162.4
avg_sample_per_episode: 162.4
avg_envstep_per_sec: 802.4368650645036
avg_train_sample_per_sec: 802.4368650645036
avg_episode_per_sec: 4.941113701136106
collect_time: 1.0119176166398183
reward_mean: 1321.5999755859375
reward_std: 13.807245254516602
reward_max: 1337.0
reward_min: 1296.0
total_envstep_count: 2792512
total_train_sample_count: 2792466
total_episode_count: 17385
total_duration: 3546.28860832538
[2024-11-20 01:01:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 196
train_sample_count: 196
avg_envstep_per_episode: 98.0
avg_sample_per_episode: 98.0
avg_envstep_per_sec: 809.6285048612957
avg_train_sample_per_sec: 809.6285048612957
avg_episode_per_sec: 8.261515355727507
collect_time: 0.24208633814539227
reward_mean: 970.5
reward_std: 360.5
reward_max: 1331.0
reward_min: 610.0
total_envstep_count: 2793486
total_train_sample_count: 2793442
total_episode_count: 17387
total_duration: 3546.5306946635255
[2024-11-20 01:01:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 267
train_sample_count: 267
avg_envstep_per_episode: 133.5
avg_sample_per_episode: 133.5
avg_envstep_per_sec: 803.3528305505722
avg_train_sample_per_sec: 803.3528305505722
avg_episode_per_sec: 6.01762419888069
collect_time: 0.3323570787906647
reward_mean: 987.0
reward_std: 336.0
reward_max: 1323.0
reward_min: 651.0
total_envstep_count: 2794460
total_train_sample_count: 2794429
total_episode_count: 17389
total_duration: 3546.863051742316
[2024-11-20 01:01:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 135
train_sample_count: 135
avg_envstep_per_episode: 135.0
avg_sample_per_episode: 135.0
avg_envstep_per_sec: 823.3048897197972
avg_train_sample_per_sec: 823.3048897197972
avg_episode_per_sec: 6.098554738665165
collect_time: 0.16397327610424586
reward_mean: 1319.0
reward_std: 0.0
reward_max: 1319.0
reward_min: 1319.0
total_envstep_count: 2795419
total_train_sample_count: 2795392
total_episode_count: 17390
total_duration: 3547.0270250184203
[2024-11-20 01:01:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 685
train_sample_count: 685
avg_envstep_per_episode: 685.0
avg_sample_per_episode: 685.0
avg_envstep_per_sec: 816.1527455693429
avg_train_sample_per_sec: 816.1527455693429
avg_episode_per_sec: 1.1914638621450262
collect_time: 0.8393036765711649
reward_mean: 2283.0
reward_std: 0.0
reward_max: 2283.0
reward_min: 2283.0
total_envstep_count: 2797146
total_train_sample_count: 2797121
total_episode_count: 17391
total_duration: 3547.8663286949914
[2024-11-20 01:01:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 98
train_sample_count: 98
avg_envstep_per_episode: 49.0
avg_sample_per_episode: 49.0
avg_envstep_per_sec: 818.1721076961318
avg_train_sample_per_sec: 818.1721076961318
avg_episode_per_sec: 16.69738995298228
collect_time: 0.11977919936180115
reward_mean: 449.0
reward_std: 205.0
reward_max: 654.0
reward_min: 244.0
total_envstep_count: 2798160
total_train_sample_count: 2798107
total_episode_count: 17393
total_duration: 3547.986107894353
[2024-11-20 01:01:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 94
train_sample_count: 94
avg_envstep_per_episode: 94.0
avg_sample_per_episode: 94.0
avg_envstep_per_sec: 826.6748216319751
avg_train_sample_per_sec: 826.6748216319751
avg_episode_per_sec: 8.79441299608484
collect_time: 0.11370855569839478
reward_mean: 648.0
reward_std: 0.0
reward_max: 648.0
reward_min: 648.0
total_envstep_count: 2799135
total_train_sample_count: 2799077
total_episode_count: 17394
total_duration: 3548.0998164500515
[2024-11-20 01:01:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 160
train_sample_count: 160
avg_envstep_per_episode: 160.0
avg_sample_per_episode: 160.0
avg_envstep_per_sec: 833.9352396882103
avg_train_sample_per_sec: 833.9352396882103
avg_episode_per_sec: 5.212095248051314
collect_time: 0.19186142086982727
reward_mean: 1319.0
reward_std: 0.0
reward_max: 1319.0
reward_min: 1319.0
total_envstep_count: 2800094
total_train_sample_count: 2800041
total_episode_count: 17395
total_duration: 3548.2916778709214
[2024-11-20 01:01:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 836
train_sample_count: 836
avg_envstep_per_episode: 836.0
avg_sample_per_episode: 836.0
avg_envstep_per_sec: 815.7589884619482
avg_train_sample_per_sec: 815.7589884619482
avg_episode_per_sec: 0.9757882637104643
collect_time: 1.024812489748001
reward_mean: 2251.0
reward_std: 0.0
reward_max: 2251.0
reward_min: 2251.0
total_envstep_count: 2801061
total_train_sample_count: 2801009
total_episode_count: 17396
total_duration: 3549.3164903606694
[2024-11-20 01:01:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 2824
train_sample_count: 2824
avg_envstep_per_episode: 706.0
avg_sample_per_episode: 706.0
avg_envstep_per_sec: 818.9283155477822
avg_train_sample_per_sec: 818.9283155477822
avg_episode_per_sec: 1.159955121172496
collect_time: 3.448409276349204
reward_mean: 904.0
reward_std: 205.15481567382812
reward_max: 1116.0
reward_min: 649.0
total_envstep_count: 2802025
total_train_sample_count: 2801985
total_episode_count: 17400
total_duration: 3552.7648996370185
[2024-11-20 01:01:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2903
train_sample_count: 2903
avg_envstep_per_episode: 483.8333333333333
avg_sample_per_episode: 483.8333333333333
avg_envstep_per_sec: 818.4954796999152
avg_train_sample_per_sec: 818.4954796999152
avg_episode_per_sec: 1.6916889005165316
collect_time: 3.5467514140265335
reward_mean: 1431.5
reward_std: 660.36474609375
reward_max: 2233.0
reward_min: 252.0
total_envstep_count: 2803019
total_train_sample_count: 2802968
total_episode_count: 17406
total_duration: 3556.311651051045
[2024-11-20 01:01:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 3849
train_sample_count: 3849
avg_envstep_per_episode: 962.25
avg_sample_per_episode: 962.25
avg_envstep_per_sec: 814.1245833074257
avg_train_sample_per_sec: 814.1245833074257
avg_episode_per_sec: 0.8460634796647708
collect_time: 4.727777638605662
reward_mean: 1056.25
reward_std: 330.3387451171875
reward_max: 1329.0
reward_min: 514.0
total_envstep_count: 2804033
total_train_sample_count: 2804009
total_episode_count: 17410
total_duration: 3561.039428689651
[2024-11-20 01:02:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1044
train_sample_count: 1044
avg_envstep_per_episode: 174.0
avg_sample_per_episode: 174.0
avg_envstep_per_sec: 815.0075703943884
avg_train_sample_per_sec: 815.0075703943884
avg_episode_per_sec: 4.683951553990738
collect_time: 1.28096969638552
reward_mean: 1222.1666259765625
reward_std: 389.09014892578125
reward_max: 1693.0
reward_min: 650.0
total_envstep_count: 2805027
total_train_sample_count: 2804993
total_episode_count: 17416
total_duration: 3562.3203983860362
[2024-11-20 01:02:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1379
train_sample_count: 1379
avg_envstep_per_episode: 153.22222222222223
avg_sample_per_episode: 153.22222222222223
avg_envstep_per_sec: 809.9860496896727
avg_train_sample_per_sec: 809.9860496896727
avg_episode_per_sec: 5.286348402615703
collect_time: 1.7024984572614945
reward_mean: 1086.111083984375
reward_std: 391.28802490234375
reward_max: 1685.0
reward_min: 622.0
total_envstep_count: 2806026
total_train_sample_count: 2805976
total_episode_count: 17425
total_duration: 3564.0228968432975
[2024-11-20 01:02:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 523
train_sample_count: 523
avg_envstep_per_episode: 174.33333333333334
avg_sample_per_episode: 174.33333333333334
avg_envstep_per_sec: 813.3095831114559
avg_train_sample_per_sec: 813.3095831114559
avg_episode_per_sec: 4.665255734864948
collect_time: 0.6430515646934509
reward_mean: 1084.0
reward_std: 341.5386657714844
reward_max: 1328.0
reward_min: 601.0
total_envstep_count: 2806983
total_train_sample_count: 2806943
total_episode_count: 17428
total_duration: 3564.665948407991
[2024-11-20 01:02:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1137
train_sample_count: 1137
avg_envstep_per_episode: 162.42857142857142
avg_sample_per_episode: 162.42857142857142
avg_envstep_per_sec: 804.1186341600022
avg_train_sample_per_sec: 804.1186341600022
avg_episode_per_sec: 4.95059845129289
collect_time: 1.4139704661709924
reward_mean: 1294.5714111328125
reward_std: 598.5537109375
reward_max: 1926.0
reward_min: 249.0
total_envstep_count: 2807954
total_train_sample_count: 2807924
total_episode_count: 17435
total_duration: 3566.079918874162
[2024-11-20 01:02:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 929
train_sample_count: 929
avg_envstep_per_episode: 185.8
avg_sample_per_episode: 185.8
avg_envstep_per_sec: 813.6578725191071
avg_train_sample_per_sec: 813.6578725191071
avg_episode_per_sec: 4.379213522707788
collect_time: 1.141757526568004
reward_mean: 1401.800048828125
reward_std: 157.61141967773438
reward_max: 1717.0
reward_min: 1321.0
total_envstep_count: 2808981
total_train_sample_count: 2808937
total_episode_count: 17440
total_duration: 3567.2216764007303
[2024-11-20 01:02:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 767
train_sample_count: 767
avg_envstep_per_episode: 153.4
avg_sample_per_episode: 153.4
avg_envstep_per_sec: 811.7818427458551
avg_train_sample_per_sec: 811.7818427458551
avg_episode_per_sec: 5.291928570703098
collect_time: 0.9448351263999939
reward_mean: 1054.4000244140625
reward_std: 495.0323486328125
reward_max: 1680.0
reward_min: 650.0
total_envstep_count: 2809968
total_train_sample_count: 2809920
total_episode_count: 17445
total_duration: 3568.1665115271303
[2024-11-20 01:02:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 406
train_sample_count: 406
avg_envstep_per_episode: 135.33333333333334
avg_sample_per_episode: 135.33333333333334
avg_envstep_per_sec: 818.9310313376128
avg_train_sample_per_sec: 818.9310313376128
avg_episode_per_sec: 6.051214517273001
collect_time: 0.495768244777407
reward_mean: 1228.0
reward_std: 433.0319519042969
reward_max: 1698.0
reward_min: 653.0
total_envstep_count: 2810942
total_train_sample_count: 2810890
total_episode_count: 17448
total_duration: 3568.662279771908
[2024-11-20 01:02:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1779
train_sample_count: 1779
avg_envstep_per_episode: 197.66666666666666
avg_sample_per_episode: 197.66666666666666
avg_envstep_per_sec: 814.228657513858
avg_train_sample_per_sec: 814.228657513858
avg_episode_per_sec: 4.119200628231996
collect_time: 2.184889936730975
reward_mean: 1109.4444580078125
reward_std: 633.1314086914062
reward_max: 2350.0
reward_min: 245.0
total_envstep_count: 2811942
total_train_sample_count: 2811913
total_episode_count: 17457
total_duration: 3570.847169708639
[2024-11-20 01:02:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 849
train_sample_count: 849
avg_envstep_per_episode: 141.5
avg_sample_per_episode: 141.5
avg_envstep_per_sec: 807.9928459157107
avg_train_sample_per_sec: 807.9928459157107
avg_episode_per_sec: 5.710196790923751
collect_time: 1.0507518776825495
reward_mean: 1224.6666259765625
reward_std: 393.3876953125
reward_max: 1934.0
reward_min: 633.0
total_envstep_count: 2812937
total_train_sample_count: 2812894
total_episode_count: 17463
total_duration: 3571.8979215863214
[2024-11-20 01:02:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 689
train_sample_count: 689
avg_envstep_per_episode: 98.42857142857143
avg_sample_per_episode: 98.42857142857143
avg_envstep_per_sec: 803.9427317732554
avg_train_sample_per_sec: 803.9427317732554
avg_episode_per_sec: 8.167778116709417
collect_time: 0.8570262193679811
reward_mean: 838.7142944335938
reward_std: 378.310791015625
reward_max: 1330.0
reward_min: 243.0
total_envstep_count: 2813900
total_train_sample_count: 2813871
total_episode_count: 17470
total_duration: 3572.7549478056894
[2024-11-20 01:02:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1731
train_sample_count: 1731
avg_envstep_per_episode: 216.375
avg_sample_per_episode: 216.375
avg_envstep_per_sec: 814.2503366898007
avg_train_sample_per_sec: 814.2503366898007
avg_episode_per_sec: 3.7631442481331057
collect_time: 2.1258818351087116
reward_mean: 1466.875
reward_std: 800.564697265625
reward_max: 2995.0
reward_min: 619.0
total_envstep_count: 2814893
total_train_sample_count: 2814858
total_episode_count: 17478
total_duration: 3574.8808296407983
[2024-11-20 01:02:41][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 793
train_sample_count: 793
avg_envstep_per_episode: 88.11111111111111
avg_sample_per_episode: 88.11111111111111
avg_envstep_per_sec: 813.9080343160708
avg_train_sample_per_sec: 813.9080343160708
avg_episode_per_sec: 9.237291688328673
collect_time: 0.9743115518774306
reward_mean: 736.111083984375
reward_std: 450.5513916015625
reward_max: 1695.0
reward_min: 243.0
total_envstep_count: 2815910
total_train_sample_count: 2815879
total_episode_count: 17487
total_duration: 3575.8551411926755
[2024-11-20 01:02:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 720
train_sample_count: 720
avg_envstep_per_episode: 180.0
avg_sample_per_episode: 180.0
avg_envstep_per_sec: 806.5507682953775
avg_train_sample_per_sec: 806.5507682953775
avg_episode_per_sec: 4.480837601640986
collect_time: 0.8926902413368224
reward_mean: 1387.0
reward_std: 109.4554672241211
reward_max: 1576.0
reward_min: 1311.0
total_envstep_count: 2816883
total_train_sample_count: 2816863
total_episode_count: 17491
total_duration: 3576.7478314340124
[2024-11-20 01:02:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 939
train_sample_count: 939
avg_envstep_per_episode: 187.8
avg_sample_per_episode: 187.8
avg_envstep_per_sec: 810.6018720534022
avg_train_sample_per_sec: 810.6018720534022
avg_episode_per_sec: 4.316303898047935
collect_time: 1.1583985090255737
reward_mean: 1374.199951171875
reward_std: 687.2959594726562
reward_max: 2349.0
reward_min: 207.0
total_envstep_count: 2817887
total_train_sample_count: 2817850
total_episode_count: 17496
total_duration: 3577.906229943038
[2024-11-20 01:02:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1533
train_sample_count: 1533
avg_envstep_per_episode: 191.625
avg_sample_per_episode: 191.625
avg_envstep_per_sec: 810.1032135648348
avg_train_sample_per_sec: 810.1032135648348
avg_episode_per_sec: 4.227544493489027
collect_time: 1.8923514613083432
reward_mean: 1240.375
reward_std: 571.0269165039062
reward_max: 2339.0
reward_min: 249.0
total_envstep_count: 2818865
total_train_sample_count: 2818831
total_episode_count: 17504
total_duration: 3579.7985814043464
[2024-11-20 01:02:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 638
train_sample_count: 638
avg_envstep_per_episode: 159.5
avg_sample_per_episode: 159.5
avg_envstep_per_sec: 814.1214342631769
avg_train_sample_per_sec: 814.1214342631769
avg_episode_per_sec: 5.1042096192048705
collect_time: 0.7836668746812002
reward_mean: 1221.0
reward_std: 333.4636535644531
reward_max: 1701.0
reward_min: 815.0
total_envstep_count: 2819821
total_train_sample_count: 2819793
total_episode_count: 17508
total_duration: 3580.5822482790277
[2024-11-20 01:02:58][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 695
train_sample_count: 695
avg_envstep_per_episode: 139.0
avg_sample_per_episode: 139.0
avg_envstep_per_sec: 803.2187428856028
avg_train_sample_per_sec: 803.2187428856028
avg_episode_per_sec: 5.778552107090667
collect_time: 0.8652686533473788
reward_mean: 937.7999877929688
reward_std: 307.30987548828125
reward_max: 1315.0
reward_min: 622.0
total_envstep_count: 2820809
total_train_sample_count: 2820788
total_episode_count: 17513
total_duration: 3581.447516932375
[2024-11-20 01:03:02][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1080
train_sample_count: 1080
avg_envstep_per_episode: 216.0
avg_sample_per_episode: 216.0
avg_envstep_per_sec: 823.7624376540772
avg_train_sample_per_sec: 823.7624376540772
avg_episode_per_sec: 3.813714989139246
collect_time: 1.3110575945604415
reward_mean: 1369.5999755859375
reward_std: 674.7985229492188
reward_max: 2334.0
reward_min: 589.0
total_envstep_count: 2821812
total_train_sample_count: 2821772
total_episode_count: 17518
total_duration: 3582.7585745269353
[2024-11-20 01:03:05][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 110
train_sample_count: 110
avg_envstep_per_episode: 110.0
avg_sample_per_episode: 110.0
avg_envstep_per_sec: 812.0765638317848
avg_train_sample_per_sec: 812.0765638317848
avg_episode_per_sec: 7.38251421665259
collect_time: 0.13545520816530499
reward_mean: 580.0
reward_std: 0.0
reward_max: 580.0
reward_min: 580.0
total_envstep_count: 2822771
total_train_sample_count: 2822734
total_episode_count: 17519
total_duration: 3582.8940297351005
[2024-11-20 01:03:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1595
train_sample_count: 1595
avg_envstep_per_episode: 319.0
avg_sample_per_episode: 319.0
avg_envstep_per_sec: 819.437786272582
avg_train_sample_per_sec: 819.437786272582
avg_episode_per_sec: 2.568770489882702
collect_time: 1.9464564933663322
reward_mean: 1924.199951171875
reward_std: 192.85890197753906
reward_max: 2282.0
reward_min: 1699.0
total_envstep_count: 2823774
total_train_sample_count: 2823729
total_episode_count: 17524
total_duration: 3584.840486228467
[2024-11-20 01:03:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 940
train_sample_count: 940
avg_envstep_per_episode: 235.0
avg_sample_per_episode: 235.0
avg_envstep_per_sec: 812.5276195447511
avg_train_sample_per_sec: 812.5276195447511
avg_episode_per_sec: 3.457564338488303
collect_time: 1.156883750643049
reward_mean: 1190.0
reward_std: 351.4150085449219
reward_max: 1571.0
reward_min: 617.0
total_envstep_count: 2824731
total_train_sample_count: 2824705
total_episode_count: 17528
total_duration: 3585.99736997911
[2024-11-20 01:03:16][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1199
train_sample_count: 1199
avg_envstep_per_episode: 239.8
avg_sample_per_episode: 239.8
avg_envstep_per_sec: 805.2162336701218
avg_train_sample_per_sec: 805.2162336701218
avg_episode_per_sec: 3.3578658618437105
collect_time: 1.489041017634528
reward_mean: 1266.800048828125
reward_std: 589.9174194335938
reward_max: 1850.0
reward_min: 252.0
total_envstep_count: 2825703
total_train_sample_count: 2825676
total_episode_count: 17533
total_duration: 3587.4864109967443
[2024-11-20 01:03:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1127
train_sample_count: 1127
avg_envstep_per_episode: 281.75
avg_sample_per_episode: 281.75
avg_envstep_per_sec: 803.4561176372005
avg_train_sample_per_sec: 803.4561176372005
avg_episode_per_sec: 2.851663239173737
collect_time: 1.4026901721954346
reward_mean: 1966.25
reward_std: 417.0709533691406
reward_max: 2339.0
reward_min: 1328.0
total_envstep_count: 2826676
total_train_sample_count: 2826659
total_episode_count: 17537
total_duration: 3588.8891011689398
[2024-11-20 01:03:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 866
train_sample_count: 866
avg_envstep_per_episode: 173.2
avg_sample_per_episode: 173.2
avg_envstep_per_sec: 812.0834111729613
avg_train_sample_per_sec: 812.0834111729613
avg_episode_per_sec: 4.6887032977653655
collect_time: 1.0663929198469433
reward_mean: 1278.4000244140625
reward_std: 351.10089111328125
reward_max: 1587.0
reward_min: 613.0
total_envstep_count: 2827673
total_train_sample_count: 2827633
total_episode_count: 17542
total_duration: 3589.9554940887865
[2024-11-20 01:03:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 838
train_sample_count: 838
avg_envstep_per_episode: 209.5
avg_sample_per_episode: 209.5
avg_envstep_per_sec: 821.2311744606044
avg_train_sample_per_sec: 821.2311744606044
avg_episode_per_sec: 3.9199578733203073
collect_time: 1.0204191293035236
reward_mean: 1569.0
reward_std: 7.516648292541504
reward_max: 1580.0
reward_min: 1559.0
total_envstep_count: 2828662
total_train_sample_count: 2828603
total_episode_count: 17546
total_duration: 3590.97591321809
[2024-11-20 01:03:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1226
train_sample_count: 1226
avg_envstep_per_episode: 245.2
avg_sample_per_episode: 245.2
avg_envstep_per_sec: 818.5648345020612
avg_train_sample_per_sec: 818.5648345020612
avg_episode_per_sec: 3.3383557687686016
collect_time: 1.4977433042866843
reward_mean: 1731.800048828125
reward_std: 512.481201171875
reward_max: 2611.0
reward_min: 1068.0
total_envstep_count: 2829641
total_train_sample_count: 2829613
total_episode_count: 17551
total_duration: 3592.473656522377
[2024-11-20 01:03:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 838
train_sample_count: 838
avg_envstep_per_episode: 167.6
avg_sample_per_episode: 167.6
avg_envstep_per_sec: 808.3547047351229
avg_train_sample_per_sec: 808.3547047351229
avg_episode_per_sec: 4.823118763336056
collect_time: 1.0366736224719457
reward_mean: 1500.5999755859375
reward_std: 574.5396728515625
reward_max: 2356.0
reward_min: 647.0
total_envstep_count: 2830660
total_train_sample_count: 2830631
total_episode_count: 17556
total_duration: 3593.510330144849
[2024-11-20 01:03:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1173
train_sample_count: 1173
avg_envstep_per_episode: 234.6
avg_sample_per_episode: 234.6
avg_envstep_per_sec: 666.4491442583181
avg_train_sample_per_sec: 666.4491442583181
avg_episode_per_sec: 2.840789191211927
collect_time: 1.7600742833954948
reward_mean: 1283.4000244140625
reward_std: 638.3737182617188
reward_max: 2312.0
reward_min: 581.0
total_envstep_count: 2831632
total_train_sample_count: 2831600
total_episode_count: 17561
total_duration: 3595.2704044282445
[2024-11-20 01:03:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1114
train_sample_count: 1114
avg_envstep_per_episode: 139.25
avg_sample_per_episode: 139.25
avg_envstep_per_sec: 807.0185894739407
avg_train_sample_per_sec: 807.0185894739407
avg_episode_per_sec: 5.795465633565104
collect_time: 1.3803895158427104
reward_mean: 1057.625
reward_std: 431.2278747558594
reward_max: 1678.0
reward_min: 610.0
total_envstep_count: 2832625
total_train_sample_count: 2832594
total_episode_count: 17569
total_duration: 3596.650793944087
[2024-11-20 01:03:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 676
train_sample_count: 676
avg_envstep_per_episode: 135.2
avg_sample_per_episode: 135.2
avg_envstep_per_sec: 811.9919569724723
avg_train_sample_per_sec: 811.9919569724723
avg_episode_per_sec: 6.005857669914735
collect_time: 0.8325205615588597
reward_mean: 954.2000122070312
reward_std: 796.7437133789062
reward_max: 2341.0
reward_min: 243.0
total_envstep_count: 2833636
total_train_sample_count: 2833582
total_episode_count: 17574
total_duration: 3597.483314505646
[2024-11-20 01:03:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1319
train_sample_count: 1319
avg_envstep_per_episode: 219.83333333333334
avg_sample_per_episode: 219.83333333333334
avg_envstep_per_sec: 813.3792951970039
avg_train_sample_per_sec: 813.3792951970039
avg_episode_per_sec: 3.6999816309188955
collect_time: 1.621629672391074
reward_mean: 1275.3333740234375
reward_std: 620.4081420898438
reward_max: 2343.0
reward_min: 243.0
total_envstep_count: 2834615
total_train_sample_count: 2834565
total_episode_count: 17580
total_duration: 3599.104944178037
[2024-11-20 01:03:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 533
train_sample_count: 533
avg_envstep_per_episode: 177.66666666666666
avg_sample_per_episode: 177.66666666666666
avg_envstep_per_sec: 812.050304085603
avg_train_sample_per_sec: 812.050304085603
avg_episode_per_sec: 4.570639610237916
collect_time: 0.6563632786273956
reward_mean: 1391.6666259765625
reward_std: 122.83683013916016
reward_max: 1565.0
reward_min: 1295.0
total_envstep_count: 2835588
total_train_sample_count: 2835554
total_episode_count: 17583
total_duration: 3599.7613074566643
[2024-11-20 01:03:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 853
train_sample_count: 853
avg_envstep_per_episode: 213.25
avg_sample_per_episode: 213.25
avg_envstep_per_sec: 818.166353607992
avg_train_sample_per_sec: 818.166353607992
avg_episode_per_sec: 3.8366534753012527
collect_time: 1.042575261422566
reward_mean: 1319.25
reward_std: 643.4008178710938
reward_max: 2346.0
reward_min: 599.0
total_envstep_count: 2836568
total_train_sample_count: 2836539
total_episode_count: 17587
total_duration: 3600.8038827180867
[2024-11-20 01:03:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1182
train_sample_count: 1182
avg_envstep_per_episode: 197.0
avg_sample_per_episode: 197.0
avg_envstep_per_sec: 817.2558167342521
avg_train_sample_per_sec: 817.2558167342521
avg_episode_per_sec: 4.148506683930214
collect_time: 1.4463035634585788
reward_mean: 1230.1666259765625
reward_std: 670.367919921875
reward_max: 2343.0
reward_min: 247.0
total_envstep_count: 2837538
total_train_sample_count: 2837505
total_episode_count: 17593
total_duration: 3602.250186281545
[2024-11-20 01:04:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 682
train_sample_count: 682
avg_envstep_per_episode: 136.4
avg_sample_per_episode: 136.4
avg_envstep_per_sec: 821.5082409443662
avg_train_sample_per_sec: 821.5082409443662
avg_episode_per_sec: 6.022787690207963
collect_time: 0.8301803512232644
reward_mean: 772.2000122070312
reward_std: 270.9940185546875
reward_max: 1302.0
reward_min: 582.0
total_envstep_count: 2838511
total_train_sample_count: 2838475
total_episode_count: 17598
total_duration: 3603.0803666327683
[2024-11-20 01:04:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 613
train_sample_count: 613
avg_envstep_per_episode: 306.5
avg_sample_per_episode: 306.5
avg_envstep_per_sec: 818.0840996218031
avg_train_sample_per_sec: 818.0840996218031
avg_episode_per_sec: 2.669116148847645
collect_time: 0.7493117153644562
reward_mean: 1464.0
reward_std: 850.0
reward_max: 2314.0
reward_min: 614.0
total_envstep_count: 2839485
total_train_sample_count: 2839448
total_episode_count: 17600
total_duration: 3603.829678348133
[2024-11-20 01:04:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1190
train_sample_count: 1190
avg_envstep_per_episode: 198.33333333333334
avg_sample_per_episode: 198.33333333333334
avg_envstep_per_sec: 811.2955343464812
avg_train_sample_per_sec: 811.2955343464812
avg_episode_per_sec: 4.090565719394023
collect_time: 1.4667897820472717
reward_mean: 1217.6666259765625
reward_std: 261.7146301269531
reward_max: 1580.0
reward_min: 751.0
total_envstep_count: 2840479
total_train_sample_count: 2840446
total_episode_count: 17606
total_duration: 3605.29646813018
[2024-11-20 01:04:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 911
train_sample_count: 911
avg_envstep_per_episode: 227.75
avg_sample_per_episode: 227.75
avg_envstep_per_sec: 824.167357723075
avg_train_sample_per_sec: 824.167357723075
avg_episode_per_sec: 3.6187370262264547
collect_time: 1.1053580215999057
reward_mean: 944.5
reward_std: 329.28521728515625
reward_max: 1305.0
reward_min: 613.0
total_envstep_count: 2841483
total_train_sample_count: 2841429
total_episode_count: 17610
total_duration: 3606.40182615178
[2024-11-20 01:04:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1358
train_sample_count: 1358
avg_envstep_per_episode: 150.88888888888889
avg_sample_per_episode: 150.88888888888889
avg_envstep_per_sec: 814.0682969221033
avg_train_sample_per_sec: 814.0682969221033
avg_episode_per_sec: 5.395150715978594
collect_time: 1.6681647045271737
reward_mean: 1140.4444580078125
reward_std: 361.72491455078125
reward_max: 1695.0
reward_min: 610.0
total_envstep_count: 2842470
total_train_sample_count: 2842415
total_episode_count: 17619
total_duration: 3608.069990856307
[2024-11-20 01:04:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 606
train_sample_count: 606
avg_envstep_per_episode: 121.2
avg_sample_per_episode: 121.2
avg_envstep_per_sec: 804.1379498718634
avg_train_sample_per_sec: 804.1379498718634
avg_episode_per_sec: 6.634801566599533
collect_time: 0.7536020406654903
reward_mean: 895.2000122070312
reward_std: 344.42205810546875
reward_max: 1319.0
reward_min: 607.0
total_envstep_count: 2843426
total_train_sample_count: 2843393
total_episode_count: 17624
total_duration: 3608.8235928969725
[2024-11-20 01:04:23][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1915
train_sample_count: 1915
avg_envstep_per_episode: 383.0
avg_sample_per_episode: 383.0
avg_envstep_per_sec: 807.549807753099
avg_train_sample_per_sec: 807.549807753099
avg_episode_per_sec: 2.108485137736551
collect_time: 2.3713707583291184
reward_mean: 1461.800048828125
reward_std: 269.7149658203125
reward_max: 1853.0
reward_min: 1114.0
total_envstep_count: 2844413
total_train_sample_count: 2844384
total_episode_count: 17629
total_duration: 3611.1949636553018
[2024-11-20 01:04:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1134
train_sample_count: 1134
avg_envstep_per_episode: 162.0
avg_sample_per_episode: 162.0
avg_envstep_per_sec: 802.9789429414228
avg_train_sample_per_sec: 802.9789429414228
avg_episode_per_sec: 4.956660141613721
collect_time: 1.4122412673064642
reward_mean: 1206.4285888671875
reward_std: 618.9700927734375
reward_max: 2359.0
reward_min: 246.0
total_envstep_count: 2845415
total_train_sample_count: 2845374
total_episode_count: 17636
total_duration: 3612.607204922608
[2024-11-20 01:04:30][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 462
train_sample_count: 462
avg_envstep_per_episode: 231.0
avg_sample_per_episode: 231.0
avg_envstep_per_sec: 795.2922603293346
avg_train_sample_per_sec: 795.2922603293346
avg_episode_per_sec: 3.4428236377893273
collect_time: 0.580918516431536
reward_mean: 1683.5
reward_std: 14.5
reward_max: 1698.0
reward_min: 1669.0
total_envstep_count: 2846381
total_train_sample_count: 2846340
total_episode_count: 17638
total_duration: 3613.18812343904
[2024-11-20 01:04:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1072
train_sample_count: 1072
avg_envstep_per_episode: 214.4
avg_sample_per_episode: 214.4
avg_envstep_per_sec: 808.6367436010373
avg_train_sample_per_sec: 808.6367436010373
avg_episode_per_sec: 3.7716266026167786
collect_time: 1.3256879661764418
reward_mean: 1724.5999755859375
reward_std: 332.980224609375
reward_max: 2332.0
reward_min: 1320.0
total_envstep_count: 2847376
total_train_sample_count: 2847340
total_episode_count: 17643
total_duration: 3614.513811405216
[2024-11-20 01:04:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1353
train_sample_count: 1353
avg_envstep_per_episode: 193.28571428571428
avg_sample_per_episode: 193.28571428571428
avg_envstep_per_sec: 809.1936965834274
avg_train_sample_per_sec: 809.1936965834274
avg_episode_per_sec: 4.18651579902734
collect_time: 1.6720347745077948
reward_mean: 1445.5714111328125
reward_std: 484.65948486328125
reward_max: 2359.0
reward_min: 719.0
total_envstep_count: 2848362
total_train_sample_count: 2848321
total_episode_count: 17650
total_duration: 3616.1858461797237
[2024-11-20 01:04:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 619
train_sample_count: 619
avg_envstep_per_episode: 123.8
avg_sample_per_episode: 123.8
avg_envstep_per_sec: 811.6666394879257
avg_train_sample_per_sec: 811.6666394879257
avg_episode_per_sec: 6.55627333996709
collect_time: 0.7626283622923351
reward_mean: 860.7999877929688
reward_std: 409.6556396484375
reward_max: 1329.0
reward_min: 248.0
total_envstep_count: 2849334
total_train_sample_count: 2849300
total_episode_count: 17655
total_duration: 3616.948474542016
[2024-11-20 01:04:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1229
train_sample_count: 1229
avg_envstep_per_episode: 204.83333333333334
avg_sample_per_episode: 204.83333333333334
avg_envstep_per_sec: 807.9907252598767
avg_train_sample_per_sec: 807.9907252598767
avg_episode_per_sec: 3.9446251843443942
collect_time: 1.5210570636249725
reward_mean: 1554.8333740234375
reward_std: 173.9668731689453
reward_max: 1717.0
reward_min: 1306.0
total_envstep_count: 2850322
total_train_sample_count: 2850289
total_episode_count: 17661
total_duration: 3618.469531605641
[2024-11-20 01:04:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 813
train_sample_count: 813
avg_envstep_per_episode: 203.25
avg_sample_per_episode: 203.25
avg_envstep_per_sec: 807.9206248093357
avg_train_sample_per_sec: 807.9206248093357
avg_episode_per_sec: 3.975009224154173
collect_time: 1.0062869730449857
reward_mean: 1523.5
reward_std: 657.5950317382812
reward_max: 2349.0
reward_min: 582.0
total_envstep_count: 2851326
total_train_sample_count: 2851294
total_episode_count: 17665
total_duration: 3619.475818578686
[2024-11-20 01:04:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1557
train_sample_count: 1557
avg_envstep_per_episode: 222.42857142857142
avg_sample_per_episode: 222.42857142857142
avg_envstep_per_sec: 807.4273955360384
avg_train_sample_per_sec: 807.4273955360384
avg_episode_per_sec: 3.6300525168608018
collect_time: 1.9283467573778967
reward_mean: 1621.4285888671875
reward_std: 348.6282653808594
reward_max: 2347.0
reward_min: 1265.0
total_envstep_count: 2852319
total_train_sample_count: 2852275
total_episode_count: 17672
total_duration: 3621.4041653360637
[2024-11-20 01:04:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 767
train_sample_count: 767
avg_envstep_per_episode: 153.4
avg_sample_per_episode: 153.4
avg_envstep_per_sec: 801.7629705039161
avg_train_sample_per_sec: 801.7629705039161
avg_episode_per_sec: 5.226616496114185
collect_time: 0.9566418358257838
reward_mean: 1130.4000244140625
reward_std: 441.3110656738281
reward_max: 1703.0
reward_min: 602.0
total_envstep_count: 2853292
total_train_sample_count: 2853246
total_episode_count: 17677
total_duration: 3622.3608071718895
[2024-11-20 01:04:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1120
train_sample_count: 1120
avg_envstep_per_episode: 160.0
avg_sample_per_episode: 160.0
avg_envstep_per_sec: 817.9418307412446
avg_train_sample_per_sec: 817.9418307412446
avg_episode_per_sec: 5.112136442132779
collect_time: 1.3692905264241355
reward_mean: 1011.2857055664062
reward_std: 319.8507385253906
reward_max: 1566.0
reward_min: 619.0
total_envstep_count: 2854301
total_train_sample_count: 2854270
total_episode_count: 17684
total_duration: 3623.730097698314
[2024-11-20 01:05:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 387
train_sample_count: 387
avg_envstep_per_episode: 193.5
avg_sample_per_episode: 193.5
avg_envstep_per_sec: 807.7555974706634
avg_train_sample_per_sec: 807.7555974706634
avg_episode_per_sec: 4.174447532148131
collect_time: 0.4791053150381361
reward_mean: 1510.0
reward_std: 207.0
reward_max: 1717.0
reward_min: 1303.0
total_envstep_count: 2855307
total_train_sample_count: 2855257
total_episode_count: 17686
total_duration: 3624.2092030133517
[2024-11-20 01:05:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1371
train_sample_count: 1371
avg_envstep_per_episode: 228.5
avg_sample_per_episode: 228.5
avg_envstep_per_sec: 803.5684035248673
avg_train_sample_per_sec: 803.5684035248673
avg_episode_per_sec: 3.516710737526772
collect_time: 1.7061397561005183
reward_mean: 1795.0
reward_std: 320.702880859375
reward_max: 2337.0
reward_min: 1284.0
total_envstep_count: 2856294
total_train_sample_count: 2856244
total_episode_count: 17692
total_duration: 3625.9153427694523
[2024-11-20 01:05:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1046
train_sample_count: 1046
avg_envstep_per_episode: 209.2
avg_sample_per_episode: 209.2
avg_envstep_per_sec: 806.1800266822235
avg_train_sample_per_sec: 806.1800266822235
avg_episode_per_sec: 3.8536330147333815
collect_time: 1.2974769473075867
reward_mean: 1512.4000244140625
reward_std: 511.97601318359375
reward_max: 2335.0
reward_min: 744.0
total_envstep_count: 2857249
total_train_sample_count: 2857218
total_episode_count: 17697
total_duration: 3627.21281971676
[2024-11-20 01:05:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1017
train_sample_count: 1017
avg_envstep_per_episode: 145.28571428571428
avg_sample_per_episode: 145.28571428571428
avg_envstep_per_sec: 803.7154679299466
avg_train_sample_per_sec: 803.7154679299466
avg_episode_per_sec: 5.531964872674165
collect_time: 1.2653731831482478
reward_mean: 981.4285888671875
reward_std: 329.2024230957031
reward_max: 1402.0
reward_min: 583.0
total_envstep_count: 2858250
total_train_sample_count: 2858211
total_episode_count: 17704
total_duration: 3628.478192899908
[2024-11-20 01:05:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 848
train_sample_count: 848
avg_envstep_per_episode: 169.6
avg_sample_per_episode: 169.6
avg_envstep_per_sec: 806.2985368227074
avg_train_sample_per_sec: 806.2985368227074
avg_episode_per_sec: 4.754118731265963
collect_time: 1.0517196314675468
reward_mean: 1121.4000244140625
reward_std: 401.9759521484375
reward_max: 1847.0
reward_min: 605.0
total_envstep_count: 2859222
total_train_sample_count: 2859191
total_episode_count: 17709
total_duration: 3629.529912531376
[2024-11-20 01:05:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 948
train_sample_count: 948
avg_envstep_per_episode: 189.6
avg_sample_per_episode: 189.6
avg_envstep_per_sec: 804.3904916045284
avg_train_sample_per_sec: 804.3904916045284
avg_episode_per_sec: 4.242565883990129
collect_time: 1.1785320809909274
reward_mean: 1320.5999755859375
reward_std: 642.2866821289062
reward_max: 2347.0
reward_min: 617.0
total_envstep_count: 2860258
total_train_sample_count: 2860223
total_episode_count: 17714
total_duration: 3630.7084446123667
[2024-11-20 01:05:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 936
train_sample_count: 936
avg_envstep_per_episode: 187.2
avg_sample_per_episode: 187.2
avg_envstep_per_sec: 813.3769202371938
avg_train_sample_per_sec: 813.3769202371938
avg_episode_per_sec: 4.344962180754241
collect_time: 1.150758002485548
reward_mean: 1403.4000244140625
reward_std: 261.97833251953125
reward_max: 1686.0
reward_min: 1022.0
total_envstep_count: 2861229
total_train_sample_count: 2861195
total_episode_count: 17719
total_duration: 3631.859202614852
[2024-11-20 01:05:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1177
train_sample_count: 1177
avg_envstep_per_episode: 168.14285714285714
avg_sample_per_episode: 168.14285714285714
avg_envstep_per_sec: 803.8540091838111
avg_train_sample_per_sec: 803.8540091838111
avg_episode_per_sec: 4.780780003642037
collect_time: 1.4641962179115842
reward_mean: 1286.7142333984375
reward_std: 458.36968994140625
reward_max: 1836.0
reward_min: 249.0
total_envstep_count: 2862270
total_train_sample_count: 2862228
total_episode_count: 17726
total_duration: 3633.323398832764
[2024-11-20 01:05:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1235
train_sample_count: 1235
avg_envstep_per_episode: 176.42857142857142
avg_sample_per_episode: 176.42857142857142
avg_envstep_per_sec: 811.0656323788509
avg_train_sample_per_sec: 811.0656323788509
avg_episode_per_sec: 4.597133138989438
collect_time: 1.5226881163460866
reward_mean: 1346.857177734375
reward_std: 489.9178771972656
reward_max: 2330.0
reward_min: 653.0
total_envstep_count: 2863247
total_train_sample_count: 2863211
total_episode_count: 17733
total_duration: 3634.84608694911
[2024-11-20 01:05:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 552
train_sample_count: 552
avg_envstep_per_episode: 138.0
avg_sample_per_episode: 138.0
avg_envstep_per_sec: 814.9489195429501
avg_train_sample_per_sec: 814.9489195429501
avg_episode_per_sec: 5.905426953209783
collect_time: 0.677343066249575
reward_mean: 1024.25
reward_std: 427.31158447265625
reward_max: 1571.0
reward_min: 592.0
total_envstep_count: 2864211
total_train_sample_count: 2864183
total_episode_count: 17737
total_duration: 3635.5234300153597
[2024-11-20 01:05:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1450
train_sample_count: 1450
avg_envstep_per_episode: 161.11111111111111
avg_sample_per_episode: 161.11111111111111
avg_envstep_per_sec: 812.7048221043466
avg_train_sample_per_sec: 812.7048221043466
avg_episode_per_sec: 5.044374757889048
collect_time: 1.7841656165463584
reward_mean: 1293.0
reward_std: 503.8227233886719
reward_max: 1842.0
reward_min: 248.0
total_envstep_count: 2865218
total_train_sample_count: 2865165
total_episode_count: 17746
total_duration: 3637.307595631906
[2024-11-20 01:05:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 694
train_sample_count: 694
avg_envstep_per_episode: 138.8
avg_sample_per_episode: 138.8
avg_envstep_per_sec: 813.8443910788789
avg_train_sample_per_sec: 813.8443910788789
avg_episode_per_sec: 5.863432212383853
collect_time: 0.8527428678103854
reward_mean: 1181.199951171875
reward_std: 393.9763488769531
reward_max: 1577.0
reward_min: 623.0
total_envstep_count: 2866189
total_train_sample_count: 2866147
total_episode_count: 17751
total_duration: 3638.1603384997165
[2024-11-20 01:05:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 917
train_sample_count: 917
avg_envstep_per_episode: 183.4
avg_sample_per_episode: 183.4
avg_envstep_per_sec: 809.5222215092815
avg_train_sample_per_sec: 809.5222215092815
avg_episode_per_sec: 4.413970673442102
collect_time: 1.1327669279915946
reward_mean: 1369.800048828125
reward_std: 195.62759399414062
reward_max: 1575.0
reward_min: 1046.0
total_envstep_count: 2867184
total_train_sample_count: 2867148
total_episode_count: 17756
total_duration: 3639.2931054277083
[2024-11-20 01:05:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1399
train_sample_count: 1399
avg_envstep_per_episode: 174.875
avg_sample_per_episode: 174.875
avg_envstep_per_sec: 816.0593513292465
avg_train_sample_per_sec: 816.0593513292465
avg_episode_per_sec: 4.666529528687614
collect_time: 1.7143360929829732
reward_mean: 1405.625
reward_std: 534.5830078125
reward_max: 2367.0
reward_min: 622.0
total_envstep_count: 2868200
total_train_sample_count: 2868163
total_episode_count: 17764
total_duration: 3641.0074415206914
[2024-11-20 01:05:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 565
train_sample_count: 565
avg_envstep_per_episode: 113.0
avg_sample_per_episode: 113.0
avg_envstep_per_sec: 815.0380317323182
avg_train_sample_per_sec: 815.0380317323182
avg_episode_per_sec: 7.21272594453379
collect_time: 0.6932191848754883
reward_mean: 878.7999877929688
reward_std: 272.54901123046875
reward_max: 1328.0
reward_min: 616.0
total_envstep_count: 2869195
total_train_sample_count: 2869148
total_episode_count: 17769
total_duration: 3641.700660705567
[2024-11-20 01:05:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 629
train_sample_count: 629
avg_envstep_per_episode: 209.66666666666666
avg_sample_per_episode: 209.66666666666666
avg_envstep_per_sec: 812.1016673422539
avg_train_sample_per_sec: 812.1016673422539
avg_episode_per_sec: 3.8732988903446133
collect_time: 0.7745335655553
reward_mean: 1359.0
reward_std: 391.9821472167969
reward_max: 1694.0
reward_min: 809.0
total_envstep_count: 2870168
total_train_sample_count: 2870137
total_episode_count: 17772
total_duration: 3642.4751942711223
[2024-11-20 01:05:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 981
train_sample_count: 981
avg_envstep_per_episode: 245.25
avg_sample_per_episode: 245.25
avg_envstep_per_sec: 806.0006736707463
avg_train_sample_per_sec: 806.0006736707463
avg_episode_per_sec: 3.2864451525820444
collect_time: 1.2171205707958768
reward_mean: 1468.0
reward_std: 173.94395446777344
reward_max: 1712.0
reward_min: 1295.0
total_envstep_count: 2871172
total_train_sample_count: 2871118
total_episode_count: 17776
total_duration: 3643.6923148419182
[2024-11-20 01:06:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1054
train_sample_count: 1054
avg_envstep_per_episode: 263.5
avg_sample_per_episode: 263.5
avg_envstep_per_sec: 814.6812471936618
avg_train_sample_per_sec: 814.6812471936618
avg_episode_per_sec: 3.09176943906513
collect_time: 1.29375753232411
reward_mean: 1650.5
reward_std: 720.317138671875
reward_max: 2347.0
reward_min: 649.0
total_envstep_count: 2872114
total_train_sample_count: 2872088
total_episode_count: 17780
total_duration: 3644.986072374242
[2024-11-20 01:06:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 416
train_sample_count: 416
avg_envstep_per_episode: 138.66666666666666
avg_sample_per_episode: 138.66666666666666
avg_envstep_per_sec: 826.8641147808383
avg_train_sample_per_sec: 826.8641147808383
avg_episode_per_sec: 5.962962366207969
collect_time: 0.503105640411377
reward_mean: 1200.3333740234375
reward_std: 535.8665161132812
reward_max: 1921.0
reward_min: 637.0
total_envstep_count: 2873119
total_train_sample_count: 2873080
total_episode_count: 17783
total_duration: 3645.4891780146536
[2024-11-20 01:06:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2210
train_sample_count: 2210
avg_envstep_per_episode: 315.7142857142857
avg_sample_per_episode: 315.7142857142857
avg_envstep_per_sec: 812.9530007722462
avg_train_sample_per_sec: 812.9530007722462
avg_episode_per_sec: 2.574964255839694
collect_time: 2.7184843378407617
reward_mean: 1925.857177734375
reward_std: 428.77813720703125
reward_max: 2353.0
reward_min: 1042.0
total_envstep_count: 2874120
total_train_sample_count: 2874078
total_episode_count: 17790
total_duration: 3648.2076623524945
[2024-11-20 01:06:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 77
train_sample_count: 77
avg_envstep_per_episode: 77.0
avg_sample_per_episode: 77.0
avg_envstep_per_sec: 813.6083003001642
avg_train_sample_per_sec: 813.6083003001642
avg_episode_per_sec: 10.566341562339794
collect_time: 0.09464013576507568
reward_mean: 651.0
reward_std: 0.0
reward_max: 651.0
reward_min: 651.0
total_envstep_count: 2875095
total_train_sample_count: 2875043
total_episode_count: 17791
total_duration: 3648.3023024882596
[2024-11-20 01:06:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 908
train_sample_count: 908
avg_envstep_per_episode: 227.0
avg_sample_per_episode: 227.0
avg_envstep_per_sec: 776.5780096083445
avg_train_sample_per_sec: 776.5780096083445
avg_episode_per_sec: 3.4210485004772884
collect_time: 1.1692321811403548
reward_mean: 1673.25
reward_std: 409.50665283203125
reward_max: 2362.0
reward_min: 1315.0
total_envstep_count: 2876067
total_train_sample_count: 2876023
total_episode_count: 17795
total_duration: 3649.4715346693997
[2024-11-20 01:06:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 793
train_sample_count: 793
avg_envstep_per_episode: 198.25
avg_sample_per_episode: 198.25
avg_envstep_per_sec: 758.1603346294548
avg_train_sample_per_sec: 758.1603346294548
avg_episode_per_sec: 3.824263982998511
collect_time: 1.0459528991154263
reward_mean: 1718.5
reward_std: 424.9173583984375
reward_max: 2350.0
reward_min: 1316.0
total_envstep_count: 2877047
total_train_sample_count: 2877008
total_episode_count: 17799
total_duration: 3650.517487568515
[2024-11-20 01:06:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 2096
train_sample_count: 2096
avg_envstep_per_episode: 262.0
avg_sample_per_episode: 262.0
avg_envstep_per_sec: 747.5535464843558
avg_train_sample_per_sec: 747.5535464843558
avg_episode_per_sec: 2.8532578110089917
collect_time: 2.8038125293595453
reward_mean: 1609.75
reward_std: 746.1419677734375
reward_max: 2353.0
reward_min: 171.0
total_envstep_count: 2878063
total_train_sample_count: 2878024
total_episode_count: 17807
total_duration: 3653.321300097875
[2024-11-20 01:06:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 323
train_sample_count: 323
avg_envstep_per_episode: 64.6
avg_sample_per_episode: 64.6
avg_envstep_per_sec: 735.8144882340398
avg_train_sample_per_sec: 735.8144882340398
avg_episode_per_sec: 11.390317155325693
collect_time: 0.43896933964320595
reward_mean: 557.0
reward_std: 155.4232940673828
reward_max: 653.0
reward_min: 248.0
total_envstep_count: 2879050
total_train_sample_count: 2879007
total_episode_count: 17812
total_duration: 3653.760269437518
[2024-11-20 01:06:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1299
train_sample_count: 1299
avg_envstep_per_episode: 216.5
avg_sample_per_episode: 216.5
avg_envstep_per_sec: 734.7159600284093
avg_train_sample_per_sec: 734.7159600284093
avg_episode_per_sec: 3.3936072056739457
collect_time: 1.7680301921708241
reward_mean: 1384.8333740234375
reward_std: 615.9884643554688
reward_max: 2323.0
reward_min: 241.0
total_envstep_count: 2880030
total_train_sample_count: 2880006
total_episode_count: 17818
total_duration: 3655.528299629689
[2024-11-20 01:06:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1165
train_sample_count: 1165
avg_envstep_per_episode: 145.625
avg_sample_per_episode: 145.625
avg_envstep_per_sec: 736.2862641236899
avg_train_sample_per_sec: 736.2862641236899
avg_episode_per_sec: 5.056043015441647
collect_time: 1.582265019416809
reward_mean: 916.75
reward_std: 511.97796630859375
reward_max: 1917.0
reward_min: 233.0
total_envstep_count: 2881033
total_train_sample_count: 2880979
total_episode_count: 17826
total_duration: 3657.110564649106
[2024-11-20 01:06:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 711
train_sample_count: 711
avg_envstep_per_episode: 142.2
avg_sample_per_episode: 142.2
avg_envstep_per_sec: 725.91907395695
avg_train_sample_per_sec: 725.91907395695
avg_episode_per_sec: 5.104916131905415
collect_time: 0.9794480204582215
reward_mean: 1170.4000244140625
reward_std: 457.8941345214844
reward_max: 1685.0
reward_min: 617.0
total_envstep_count: 2881988
total_train_sample_count: 2881954
total_episode_count: 17831
total_duration: 3658.090012669564
[2024-11-20 01:06:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1155
train_sample_count: 1155
avg_envstep_per_episode: 192.5
avg_sample_per_episode: 192.5
avg_envstep_per_sec: 728.0674664795264
avg_train_sample_per_sec: 728.0674664795264
avg_episode_per_sec: 3.7821686570365007
collect_time: 1.5863914447171348
reward_mean: 1482.8333740234375
reward_std: 772.1514282226562
reward_max: 2625.0
reward_min: 623.0
total_envstep_count: 2883024
total_train_sample_count: 2882989
total_episode_count: 17837
total_duration: 3659.6764041142815
[2024-11-20 01:06:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 977
train_sample_count: 977
avg_envstep_per_episode: 195.4
avg_sample_per_episode: 195.4
avg_envstep_per_sec: 728.8824510742953
avg_train_sample_per_sec: 728.8824510742953
avg_episode_per_sec: 3.730207016756885
collect_time: 1.3404081804411752
reward_mean: 1535.5999755859375
reward_std: 512.73486328125
reward_max: 2343.0
reward_min: 750.0
total_envstep_count: 2884013
total_train_sample_count: 2883966
total_episode_count: 17842
total_duration: 3661.0168122947225
[2024-11-20 01:06:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1188
train_sample_count: 1188
avg_envstep_per_episode: 169.71428571428572
avg_sample_per_episode: 169.71428571428572
avg_envstep_per_sec: 711.0491453803778
avg_train_sample_per_sec: 711.0491453803778
avg_episode_per_sec: 4.189683516551048
collect_time: 1.6707705897944312
reward_mean: 1262.7142333984375
reward_std: 699.8413696289062
reward_max: 2329.0
reward_min: 625.0
total_envstep_count: 2884990
total_train_sample_count: 2884950
total_episode_count: 17849
total_duration: 3662.687582884517
[2024-11-20 01:06:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 708
train_sample_count: 708
avg_envstep_per_episode: 118.0
avg_sample_per_episode: 118.0
avg_envstep_per_sec: 713.0191313092856
avg_train_sample_per_sec: 713.0191313092856
avg_episode_per_sec: 6.042535011095641
collect_time: 0.9929607340267727
reward_mean: 1032.0
reward_std: 557.547607421875
reward_max: 1923.0
reward_min: 625.0
total_envstep_count: 2886008
total_train_sample_count: 2885970
total_episode_count: 17855
total_duration: 3663.6805436185437
[2024-11-20 01:06:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 234
train_sample_count: 234
avg_envstep_per_episode: 234.0
avg_sample_per_episode: 234.0
avg_envstep_per_sec: 711.2372718926465
avg_train_sample_per_sec: 711.2372718926465
avg_episode_per_sec: 3.039475520908746
collect_time: 0.3290041301931653
reward_mean: 1422.0
reward_std: 0.0
reward_max: 1422.0
reward_min: 1422.0
total_envstep_count: 2886975
total_train_sample_count: 2886936
total_episode_count: 17856
total_duration: 3664.0095477487366
[2024-11-20 01:06:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1453
train_sample_count: 1453
avg_envstep_per_episode: 181.625
avg_sample_per_episode: 181.625
avg_envstep_per_sec: 720.6492132869952
avg_train_sample_per_sec: 720.6492132869952
avg_episode_per_sec: 3.967786446177537
collect_time: 2.0162375441619327
reward_mean: 1260.5
reward_std: 480.86041259765625
reward_max: 1701.0
reward_min: 617.0
total_envstep_count: 2887968
total_train_sample_count: 2887933
total_episode_count: 17864
total_duration: 3666.0257852928985
[2024-11-20 01:07:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1195
train_sample_count: 1195
avg_envstep_per_episode: 298.75
avg_sample_per_episode: 298.75
avg_envstep_per_sec: 718.6401286198245
avg_train_sample_per_sec: 718.6401286198245
avg_episode_per_sec: 2.405489970275563
collect_time: 1.6628628884043013
reward_mean: 2065.75
reward_std: 571.5721435546875
reward_max: 2998.0
reward_min: 1441.0
total_envstep_count: 2888948
total_train_sample_count: 2888912
total_episode_count: 17868
total_duration: 3667.6886481813026
[2024-11-20 01:07:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 615
train_sample_count: 615
avg_envstep_per_episode: 153.75
avg_sample_per_episode: 153.75
avg_envstep_per_sec: 723.0556126337062
avg_train_sample_per_sec: 723.0556126337062
avg_episode_per_sec: 4.702800732576951
collect_time: 0.8505569824150632
reward_mean: 1443.0
reward_std: 663.7578735351562
reward_max: 2368.0
reward_min: 630.0
total_envstep_count: 2889937
total_train_sample_count: 2889899
total_episode_count: 17872
total_duration: 3668.5392051637177
[2024-11-20 01:07:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1077
train_sample_count: 1077
avg_envstep_per_episode: 269.25
avg_sample_per_episode: 269.25
avg_envstep_per_sec: 713.8304778692525
avg_train_sample_per_sec: 713.8304778692525
avg_episode_per_sec: 2.6511809763017733
collect_time: 1.5087615805012837
reward_mean: 1963.0
reward_std: 424.7110900878906
reward_max: 2348.0
reward_min: 1313.0
total_envstep_count: 2890909
total_train_sample_count: 2890880
total_episode_count: 17876
total_duration: 3670.047966744219
[2024-11-20 01:07:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 953
train_sample_count: 953
avg_envstep_per_episode: 317.6666666666667
avg_sample_per_episode: 317.6666666666667
avg_envstep_per_sec: 728.2041153893032
avg_train_sample_per_sec: 728.2041153893032
avg_episode_per_sec: 2.2923529340691604
collect_time: 1.3086990032877241
reward_mean: 2082.333251953125
reward_std: 365.1213073730469
reward_max: 2345.0
reward_min: 1566.0
total_envstep_count: 2891891
total_train_sample_count: 2891869
total_episode_count: 17879
total_duration: 3671.3566657475067
[2024-11-20 01:07:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1047
train_sample_count: 1047
avg_envstep_per_episode: 209.4
avg_sample_per_episode: 209.4
avg_envstep_per_sec: 780.0123930404493
avg_train_sample_per_sec: 780.0123930404493
avg_episode_per_sec: 3.7249875503364342
collect_time: 1.342286365372794
reward_mean: 1358.4000244140625
reward_std: 439.27239990234375
reward_max: 1914.0
reward_min: 602.0
total_envstep_count: 2892902
total_train_sample_count: 2892856
total_episode_count: 17884
total_duration: 3672.6989521128794
[2024-11-20 01:07:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 977
train_sample_count: 977
avg_envstep_per_episode: 195.4
avg_sample_per_episode: 195.4
avg_envstep_per_sec: 809.0343053340024
avg_train_sample_per_sec: 809.0343053340024
avg_episode_per_sec: 4.140400743776881
collect_time: 1.2076125741004944
reward_mean: 1362.0
reward_std: 536.18017578125
reward_max: 2349.0
reward_min: 770.0
total_envstep_count: 2893900
total_train_sample_count: 2893881
total_episode_count: 17889
total_duration: 3673.90656468698
[2024-11-20 01:07:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1794
train_sample_count: 1794
avg_envstep_per_episode: 256.2857142857143
avg_sample_per_episode: 256.2857142857143
avg_envstep_per_sec: 793.9202916694579
avg_train_sample_per_sec: 793.9202916694579
avg_episode_per_sec: 3.0977937802041278
collect_time: 2.259672688586371
reward_mean: 1287.142822265625
reward_std: 785.682861328125
reward_max: 3002.0
reward_min: 179.0
total_envstep_count: 2894941
total_train_sample_count: 2894883
total_episode_count: 17896
total_duration: 3676.166237375566
[2024-11-20 01:07:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 877
train_sample_count: 877
avg_envstep_per_episode: 125.28571428571429
avg_sample_per_episode: 125.28571428571429
avg_envstep_per_sec: 803.7174744558126
avg_train_sample_per_sec: 803.7174744558126
avg_episode_per_sec: 6.4150767630452545
collect_time: 1.0911794602870941
reward_mean: 1051.142822265625
reward_std: 322.9079895019531
reward_max: 1338.0
reward_min: 617.0
total_envstep_count: 2895910
total_train_sample_count: 2895856
total_episode_count: 17903
total_duration: 3677.2574168358533
[2024-11-20 01:07:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 426
train_sample_count: 426
avg_envstep_per_episode: 106.5
avg_sample_per_episode: 106.5
avg_envstep_per_sec: 799.9200380203649
avg_train_sample_per_sec: 799.9200380203649
avg_episode_per_sec: 7.51098627249169
collect_time: 0.5325532300131661
reward_mean: 614.5
reward_std: 284.447265625
reward_max: 1044.0
reward_min: 245.0
total_envstep_count: 2896890
total_train_sample_count: 2896858
total_episode_count: 17907
total_duration: 3677.7899700658663
[2024-11-20 01:07:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1150
train_sample_count: 1150
avg_envstep_per_episode: 287.5
avg_sample_per_episode: 287.5
avg_envstep_per_sec: 802.0308651790663
avg_train_sample_per_sec: 802.0308651790663
avg_episode_per_sec: 2.789672574535883
collect_time: 1.4338600294930595
reward_mean: 1825.25
reward_std: 523.267333984375
reward_max: 2353.0
reward_min: 1298.0
total_envstep_count: 2897903
total_train_sample_count: 2897864
total_episode_count: 17911
total_duration: 3679.2238300953595
[2024-11-20 01:07:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 956
train_sample_count: 956
avg_envstep_per_episode: 159.33333333333334
avg_sample_per_episode: 159.33333333333334
avg_envstep_per_sec: 797.623897765668
avg_train_sample_per_sec: 797.623897765668
avg_episode_per_sec: 5.006007726562769
collect_time: 1.198559875999178
reward_mean: 1136.0
reward_std: 809.0663452148438
reward_max: 2346.0
reward_min: 234.0
total_envstep_count: 2898890
total_train_sample_count: 2898856
total_episode_count: 17917
total_duration: 3680.422389971359
[2024-11-20 01:07:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1051
train_sample_count: 1051
avg_envstep_per_episode: 150.14285714285714
avg_sample_per_episode: 150.14285714285714
avg_envstep_per_sec: 791.4215817112936
avg_train_sample_per_sec: 791.4215817112936
avg_episode_per_sec: 5.271123760208425
collect_time: 1.3279900678566525
reward_mean: 1026.0
reward_std: 405.8233337402344
reward_max: 1574.0
reward_min: 624.0
total_envstep_count: 2899923
total_train_sample_count: 2899883
total_episode_count: 17924
total_duration: 3681.7503800392155
[2024-11-20 01:07:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1171
train_sample_count: 1171
avg_envstep_per_episode: 390.3333333333333
avg_sample_per_episode: 390.3333333333333
avg_envstep_per_sec: 792.5975976270377
avg_train_sample_per_sec: 792.5975976270377
avg_episode_per_sec: 2.0305660058762705
collect_time: 1.4774205769811357
reward_mean: 2070.333251953125
reward_std: 350.75665283203125
reward_max: 2341.0
reward_min: 1575.0
total_envstep_count: 2900880
total_train_sample_count: 2900850
total_episode_count: 17927
total_duration: 3683.227800616197
[2024-11-20 01:07:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 866
train_sample_count: 866
avg_envstep_per_episode: 144.33333333333334
avg_sample_per_episode: 144.33333333333334
avg_envstep_per_sec: 803.6766496337436
avg_train_sample_per_sec: 803.6766496337436
avg_episode_per_sec: 5.5681984963076925
collect_time: 1.0775477928774697
reward_mean: 1288.0
reward_std: 507.1574401855469
reward_max: 1865.0
reward_min: 630.0
total_envstep_count: 2901874
total_train_sample_count: 2901836
total_episode_count: 17933
total_duration: 3684.305348409074
[2024-11-20 01:07:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 853
train_sample_count: 853
avg_envstep_per_episode: 142.16666666666666
avg_sample_per_episode: 142.16666666666666
avg_envstep_per_sec: 808.7513371692811
avg_train_sample_per_sec: 808.7513371692811
avg_episode_per_sec: 5.688755009397053
collect_time: 1.0547123210770744
reward_mean: 942.0
reward_std: 339.1292724609375
reward_max: 1439.0
reward_min: 606.0
total_envstep_count: 2902892
total_train_sample_count: 2902845
total_episode_count: 17939
total_duration: 3685.3600607301514
[2024-11-20 01:08:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 815
train_sample_count: 815
avg_envstep_per_episode: 163.0
avg_sample_per_episode: 163.0
avg_envstep_per_sec: 798.8462150204276
avg_train_sample_per_sec: 798.8462150204276
avg_episode_per_sec: 4.9008970246652
collect_time: 1.0202213951519559
reward_mean: 1008.0
reward_std: 663.9268188476562
reward_max: 2328.0
reward_min: 624.0
total_envstep_count: 2903880
total_train_sample_count: 2903852
total_episode_count: 17944
total_duration: 3686.3802821253034
[2024-11-20 01:08:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1756
train_sample_count: 1756
avg_envstep_per_episode: 292.6666666666667
avg_sample_per_episode: 292.6666666666667
avg_envstep_per_sec: 805.3238099562302
avg_train_sample_per_sec: 805.3238099562302
avg_episode_per_sec: 2.751675888233133
collect_time: 2.1804893612861633
reward_mean: 1813.6666259765625
reward_std: 871.5673217773438
reward_max: 2987.0
reward_min: 596.0
total_envstep_count: 2904898
total_train_sample_count: 2904864
total_episode_count: 17950
total_duration: 3688.5607714865896
[2024-11-20 01:08:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 383
train_sample_count: 383
avg_envstep_per_episode: 95.75
avg_sample_per_episode: 95.75
avg_envstep_per_sec: 798.3206991984582
avg_train_sample_per_sec: 798.3206991984582
avg_episode_per_sec: 8.337552994239772
collect_time: 0.47975707054138184
reward_mean: 725.25
reward_std: 190.3895721435547
reward_max: 1055.0
reward_min: 613.0
total_envstep_count: 2905886
total_train_sample_count: 2905859
total_episode_count: 17954
total_duration: 3689.040528557131
[2024-11-20 01:08:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1331
train_sample_count: 1331
avg_envstep_per_episode: 221.83333333333334
avg_sample_per_episode: 221.83333333333334
avg_envstep_per_sec: 802.193328199631
avg_train_sample_per_sec: 802.193328199631
avg_episode_per_sec: 3.6161983239652784
collect_time: 1.6592010344777788
reward_mean: 1409.8333740234375
reward_std: 694.0670776367188
reward_max: 2346.0
reward_min: 604.0
total_envstep_count: 2906897
total_train_sample_count: 2906866
total_episode_count: 17960
total_duration: 3690.699729591609
[2024-11-20 01:08:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 563
train_sample_count: 563
avg_envstep_per_episode: 140.75
avg_sample_per_episode: 140.75
avg_envstep_per_sec: 808.7860912491365
avg_train_sample_per_sec: 808.7860912491365
avg_episode_per_sec: 5.746259973350881
collect_time: 0.6961049480097635
reward_mean: 996.75
reward_std: 535.1006469726562
reward_max: 1914.0
reward_min: 609.0
total_envstep_count: 2907871
total_train_sample_count: 2907849
total_episode_count: 17964
total_duration: 3691.3958345396186
[2024-11-20 01:08:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 908
train_sample_count: 908
avg_envstep_per_episode: 302.6666666666667
avg_sample_per_episode: 302.6666666666667
avg_envstep_per_sec: 802.0639882371955
avg_train_sample_per_sec: 802.0639882371955
avg_episode_per_sec: 2.6499911505634213
collect_time: 1.1320792521749223
reward_mean: 2264.333251953125
reward_std: 535.7637939453125
reward_max: 3021.0
reward_min: 1852.0
total_envstep_count: 2908876
total_train_sample_count: 2908829
total_episode_count: 17967
total_duration: 3692.5279137917937
[2024-11-20 01:08:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1510
train_sample_count: 1510
avg_envstep_per_episode: 215.71428571428572
avg_sample_per_episode: 215.71428571428572
avg_envstep_per_sec: 809.304982055339
avg_train_sample_per_sec: 809.304982055339
avg_episode_per_sec: 3.7517449499254125
collect_time: 1.8657984733581543
reward_mean: 1599.0
reward_std: 720.224365234375
reward_max: 2348.0
reward_min: 607.0
total_envstep_count: 2909901
total_train_sample_count: 2909859
total_episode_count: 17974
total_duration: 3694.393712265152
[2024-11-20 01:08:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1099
train_sample_count: 1099
avg_envstep_per_episode: 157.0
avg_sample_per_episode: 157.0
avg_envstep_per_sec: 797.1491544836376
avg_train_sample_per_sec: 797.1491544836376
avg_episode_per_sec: 5.07738314957731
collect_time: 1.3786629438400266
reward_mean: 1187.5714111328125
reward_std: 747.58447265625
reward_max: 2351.0
reward_min: 617.0
total_envstep_count: 2910910
total_train_sample_count: 2910886
total_episode_count: 17981
total_duration: 3695.772375208992
[2024-11-20 01:08:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 1136
train_sample_count: 1136
avg_envstep_per_episode: 126.22222222222223
avg_sample_per_episode: 126.22222222222223
avg_envstep_per_sec: 800.9009831357874
avg_train_sample_per_sec: 800.9009831357874
avg_episode_per_sec: 6.3451662396321185
collect_time: 1.4184025540238334
reward_mean: 902.6666870117188
reward_std: 405.783203125
reward_max: 1706.0
reward_min: 586.0
total_envstep_count: 2911909
total_train_sample_count: 2911878
total_episode_count: 17990
total_duration: 3697.190777763016
[2024-11-20 01:08:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 315
train_sample_count: 315
avg_envstep_per_episode: 157.5
avg_sample_per_episode: 157.5
avg_envstep_per_sec: 805.6810926512156
avg_train_sample_per_sec: 805.6810926512156
avg_episode_per_sec: 5.115435508896607
collect_time: 0.3909735537710644
reward_mean: 1067.0
reward_std: 253.0
reward_max: 1320.0
reward_min: 814.0
total_envstep_count: 2912883
total_train_sample_count: 2912853
total_episode_count: 17992
total_duration: 3697.5817513167867
[2024-11-20 01:08:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1295
train_sample_count: 1295
avg_envstep_per_episode: 259.0
avg_sample_per_episode: 259.0
avg_envstep_per_sec: 807.5990612869017
avg_train_sample_per_sec: 807.5990612869017
avg_episode_per_sec: 3.1181430937718213
collect_time: 1.6035184562206268
reward_mean: 1568.199951171875
reward_std: 509.74322509765625
reward_max: 2321.0
reward_min: 800.0
total_envstep_count: 2913870
total_train_sample_count: 2913836
total_episode_count: 17997
total_duration: 3699.1852697730073
[2024-11-20 01:08:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1167
train_sample_count: 1167
avg_envstep_per_episode: 145.875
avg_sample_per_episode: 145.875
avg_envstep_per_sec: 795.4431279422736
avg_train_sample_per_sec: 795.4431279422736
avg_episode_per_sec: 5.452909188978739
collect_time: 1.4671067723206113
reward_mean: 1133.125
reward_std: 510.2052001953125
reward_max: 1848.0
reward_min: 588.0
total_envstep_count: 2914887
total_train_sample_count: 2914847
total_episode_count: 18005
total_duration: 3700.652376545328
[2024-11-20 01:08:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 358
train_sample_count: 358
avg_envstep_per_episode: 89.5
avg_sample_per_episode: 89.5
avg_envstep_per_sec: 810.8223386602053
avg_train_sample_per_sec: 810.8223386602053
avg_episode_per_sec: 9.059467471063746
collect_time: 0.4415270558425359
reward_mean: 789.5
reward_std: 303.401123046875
reward_max: 1315.0
reward_min: 612.0
total_envstep_count: 2915861
total_train_sample_count: 2915829
total_episode_count: 18009
total_duration: 3701.0939036011705
[2024-11-20 01:08:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 769
train_sample_count: 769
avg_envstep_per_episode: 153.8
avg_sample_per_episode: 153.8
avg_envstep_per_sec: 806.430870906551
avg_train_sample_per_sec: 806.430870906551
avg_episode_per_sec: 5.24337367299448
collect_time: 0.9535845262663705
reward_mean: 1247.4000244140625
reward_std: 553.119384765625
reward_max: 1859.0
reward_min: 616.0
total_envstep_count: 2916840
total_train_sample_count: 2916802
total_episode_count: 18014
total_duration: 3702.0474881274367
[2024-11-20 01:08:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1571
train_sample_count: 1571
avg_envstep_per_episode: 261.8333333333333
avg_sample_per_episode: 261.8333333333333
avg_envstep_per_sec: 801.806022817055
avg_train_sample_per_sec: 801.806022817055
avg_episode_per_sec: 3.062276344304475
collect_time: 1.9593267639478047
reward_mean: 1393.5
reward_std: 505.26422119140625
reward_max: 2272.0
reward_min: 614.0
total_envstep_count: 2917843
total_train_sample_count: 2917821
total_episode_count: 18020
total_duration: 3704.0068148913847
[2024-11-20 01:08:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 349
train_sample_count: 349
avg_envstep_per_episode: 116.33333333333333
avg_sample_per_episode: 116.33333333333333
avg_envstep_per_sec: 800.9206015342168
avg_train_sample_per_sec: 800.9206015342168
avg_episode_per_sec: 6.88470431118238
collect_time: 0.43574856150717967
reward_mean: 825.6666870117188
reward_std: 176.52447509765625
reward_max: 1047.0
reward_min: 615.0
total_envstep_count: 2918865
total_train_sample_count: 2918818
total_episode_count: 18023
total_duration: 3704.442563452892
[2024-11-20 01:08:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 227
train_sample_count: 227
avg_envstep_per_episode: 227.0
avg_sample_per_episode: 227.0
avg_envstep_per_sec: 805.1998971624968
avg_train_sample_per_sec: 805.1998971624968
avg_episode_per_sec: 3.5471361108480033
collect_time: 0.2819175720214844
reward_mean: 1687.0
reward_std: 0.0
reward_max: 1687.0
reward_min: 1687.0
total_envstep_count: 2919848
total_train_sample_count: 2919825
total_episode_count: 18024
total_duration: 3704.7244810249135
[2024-11-20 01:09:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 626
train_sample_count: 626
avg_envstep_per_episode: 313.0
avg_sample_per_episode: 313.0
avg_envstep_per_sec: 804.2055966323397
avg_train_sample_per_sec: 804.2055966323397
avg_episode_per_sec: 2.569346954096932
collect_time: 0.7784079128787631
reward_mean: 2125.5
reward_std: 201.5
reward_max: 2327.0
reward_min: 1924.0
total_envstep_count: 2920814
total_train_sample_count: 2920799
total_episode_count: 18026
total_duration: 3705.5028889377922
[2024-11-20 01:09:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1075
train_sample_count: 1075
avg_envstep_per_episode: 268.75
avg_sample_per_episode: 268.75
avg_envstep_per_sec: 798.4097392611756
avg_train_sample_per_sec: 798.4097392611756
avg_episode_per_sec: 2.9708269367857696
collect_time: 1.3464264614241463
reward_mean: 1497.0
reward_std: 834.0917358398438
reward_max: 2338.0
reward_min: 582.0
total_envstep_count: 2921836
total_train_sample_count: 2921778
total_episode_count: 18030
total_duration: 3706.8493153992163
[2024-11-20 01:09:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1972
train_sample_count: 1972
avg_envstep_per_episode: 493.0
avg_sample_per_episode: 493.0
avg_envstep_per_sec: 802.9996541144328
avg_train_sample_per_sec: 802.9996541144328
avg_episode_per_sec: 1.628802543842663
collect_time: 2.455791842369806
reward_mean: 1464.0
reward_std: 557.240966796875
reward_max: 2306.0
reward_min: 817.0
total_envstep_count: 2922848
total_train_sample_count: 2922814
total_episode_count: 18034
total_duration: 3709.305107241586
[2024-11-20 01:09:12][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 498
train_sample_count: 498
avg_envstep_per_episode: 166.0
avg_sample_per_episode: 166.0
avg_envstep_per_sec: 815.2371633692183
avg_train_sample_per_sec: 815.2371633692183
avg_episode_per_sec: 4.9110672492121585
collect_time: 0.6108651842389788
reward_mean: 1267.3333740234375
reward_std: 360.72735595703125
reward_max: 1693.0
reward_min: 811.0
total_envstep_count: 2923861
total_train_sample_count: 2923804
total_episode_count: 18037
total_duration: 3709.915972425825
[2024-11-20 01:09:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1150
train_sample_count: 1150
avg_envstep_per_episode: 287.5
avg_sample_per_episode: 287.5
avg_envstep_per_sec: 809.7980459504124
avg_train_sample_per_sec: 809.7980459504124
avg_episode_per_sec: 2.816688855479695
collect_time: 1.4201071560382843
reward_mean: 1819.0
reward_std: 553.2345581054688
reward_max: 2345.0
reward_min: 1025.0
total_envstep_count: 2924857
total_train_sample_count: 2924822
total_episode_count: 18041
total_duration: 3711.3360795818635
[2024-11-20 01:09:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 744
train_sample_count: 744
avg_envstep_per_episode: 148.8
avg_sample_per_episode: 148.8
avg_envstep_per_sec: 811.1992746644859
avg_train_sample_per_sec: 811.1992746644859
avg_episode_per_sec: 5.451608028659179
collect_time: 0.9171605833939143
reward_mean: 965.2000122070312
reward_std: 301.3724670410156
reward_max: 1357.0
reward_min: 610.0
total_envstep_count: 2925868
total_train_sample_count: 2925818
total_episode_count: 18046
total_duration: 3712.2532401652575
[2024-11-20 01:09:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 384
train_sample_count: 384
avg_envstep_per_episode: 192.0
avg_sample_per_episode: 192.0
avg_envstep_per_sec: 804.0505128890916
avg_train_sample_per_sec: 804.0505128890916
avg_episode_per_sec: 4.187763087964019
collect_time: 0.477581935269492
reward_mean: 1449.0
reward_std: 118.0
reward_max: 1567.0
reward_min: 1331.0
total_envstep_count: 2926826
total_train_sample_count: 2926790
total_episode_count: 18048
total_duration: 3712.730822100527
[2024-11-20 01:09:26][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 2310
train_sample_count: 2310
avg_envstep_per_episode: 385.0
avg_sample_per_episode: 385.0
avg_envstep_per_sec: 813.7595931458143
avg_train_sample_per_sec: 813.7595931458143
avg_episode_per_sec: 2.113661280898219
collect_time: 2.8386762127989815
reward_mean: 1537.5
reward_std: 318.1355895996094
reward_max: 2128.0
reward_min: 1155.0
total_envstep_count: 2927852
total_train_sample_count: 2927804
total_episode_count: 18054
total_duration: 3715.5694983133258
[2024-11-20 01:09:29][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1323
train_sample_count: 1323
avg_envstep_per_episode: 330.75
avg_sample_per_episode: 330.75
avg_envstep_per_sec: 811.6050478468974
avg_train_sample_per_sec: 811.6050478468974
avg_episode_per_sec: 2.4538323442083065
collect_time: 1.6301032177039554
reward_mean: 1195.5
reward_std: 771.2763671875
reward_max: 2495.0
reward_min: 605.0
total_envstep_count: 2928816
total_train_sample_count: 2928791
total_episode_count: 18058
total_duration: 3717.1996015310297
[2024-11-20 01:09:33][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 756
train_sample_count: 756
avg_envstep_per_episode: 151.2
avg_sample_per_episode: 151.2
avg_envstep_per_sec: 810.6096742640177
avg_train_sample_per_sec: 810.6096742640177
avg_episode_per_sec: 5.3611750943387415
collect_time: 0.9326313563755579
reward_mean: 972.4000244140625
reward_std: 385.3671569824219
reward_max: 1565.0
reward_min: 623.0
total_envstep_count: 2929797
total_train_sample_count: 2929763
total_episode_count: 18063
total_duration: 3718.1322328874053
[2024-11-20 01:09:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1213
train_sample_count: 1213
avg_envstep_per_episode: 173.28571428571428
avg_sample_per_episode: 173.28571428571428
avg_envstep_per_sec: 807.2292563480258
avg_train_sample_per_sec: 807.2292563480258
avg_episode_per_sec: 4.658371635973768
collect_time: 1.5026710075991494
reward_mean: 1240.4285888671875
reward_std: 549.6380615234375
reward_max: 1854.0
reward_min: 236.0
total_envstep_count: 2930807
total_train_sample_count: 2930760
total_episode_count: 18070
total_duration: 3719.6349038950043
[2024-11-20 01:09:40][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 92
train_sample_count: 92
avg_envstep_per_episode: 92.0
avg_sample_per_episode: 92.0
avg_envstep_per_sec: 815.0664597919094
avg_train_sample_per_sec: 815.0664597919094
avg_episode_per_sec: 8.859418041216406
collect_time: 0.112874231168202
reward_mean: 584.0
reward_std: 0.0
reward_max: 584.0
reward_min: 584.0
total_envstep_count: 2931766
total_train_sample_count: 2931728
total_episode_count: 18071
total_duration: 3719.7477781261723
[2024-11-20 01:09:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 692
train_sample_count: 692
avg_envstep_per_episode: 230.66666666666666
avg_sample_per_episode: 230.66666666666666
avg_envstep_per_sec: 811.7796247513589
avg_train_sample_per_sec: 811.7796247513589
avg_episode_per_sec: 3.5192758298469315
collect_time: 0.8524481015545982
reward_mean: 1292.0
reward_std: 393.1725769042969
reward_max: 1575.0
reward_min: 736.0
total_envstep_count: 2932724
total_train_sample_count: 2932696
total_episode_count: 18074
total_duration: 3720.600226227727
[2024-11-20 01:09:47][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1252
train_sample_count: 1252
avg_envstep_per_episode: 250.4
avg_sample_per_episode: 250.4
avg_envstep_per_sec: 814.1121686121955
avg_train_sample_per_sec: 814.1121686121955
avg_episode_per_sec: 3.2512466797611643
collect_time: 1.537871620484761
reward_mean: 1152.199951171875
reward_std: 464.9590759277344
reward_max: 1889.0
reward_min: 579.0
total_envstep_count: 2933720
total_train_sample_count: 2933684
total_episode_count: 18079
total_duration: 3722.1380978482116
[2024-11-20 01:09:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 633
train_sample_count: 633
avg_envstep_per_episode: 158.25
avg_sample_per_episode: 158.25
avg_envstep_per_sec: 823.6149593984062
avg_train_sample_per_sec: 823.6149593984062
avg_episode_per_sec: 5.204517910890402
collect_time: 0.7685630193778447
reward_mean: 756.5
reward_std: 167.9054718017578
reward_max: 1034.0
reward_min: 603.0
total_envstep_count: 2934724
total_train_sample_count: 2934677
total_episode_count: 18083
total_duration: 3722.9066608675894
[2024-11-20 01:09:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1538
train_sample_count: 1538
avg_envstep_per_episode: 307.6
avg_sample_per_episode: 307.6
avg_envstep_per_sec: 811.0120740277104
avg_train_sample_per_sec: 811.0120740277104
avg_episode_per_sec: 2.636580214654455
collect_time: 1.8963959344795773
reward_mean: 1377.5999755859375
reward_std: 650.9542236328125
reward_max: 2245.0
reward_min: 613.0
total_envstep_count: 2935719
total_train_sample_count: 2935675
total_episode_count: 18088
total_duration: 3724.803056802069
[2024-11-20 01:09:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 849
train_sample_count: 849
avg_envstep_per_episode: 212.25
avg_sample_per_episode: 212.25
avg_envstep_per_sec: 816.6822897431033
avg_train_sample_per_sec: 816.6822897431033
avg_episode_per_sec: 3.847737525291417
collect_time: 1.0395719494138445
reward_mean: 1401.25
reward_std: 456.04681396484375
reward_max: 1846.0
reward_min: 638.0
total_envstep_count: 2936699
total_train_sample_count: 2936668
total_episode_count: 18092
total_duration: 3725.842628751483
[2024-11-20 01:10:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 911
train_sample_count: 911
avg_envstep_per_episode: 182.2
avg_sample_per_episode: 182.2
avg_envstep_per_sec: 811.7893500838603
avg_train_sample_per_sec: 811.7893500838603
avg_episode_per_sec: 4.455484907156204
collect_time: 1.1222123077937534
reward_mean: 1374.5999755859375
reward_std: 647.2064819335938
reward_max: 2360.0
reward_min: 619.0
total_envstep_count: 2937710
total_train_sample_count: 2937675
total_episode_count: 18097
total_duration: 3726.9648410592768
[2024-11-20 01:10:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1247
train_sample_count: 1247
avg_envstep_per_episode: 155.875
avg_sample_per_episode: 155.875
avg_envstep_per_sec: 806.4092550172235
avg_train_sample_per_sec: 806.4092550172235
avg_episode_per_sec: 5.1734354772556435
collect_time: 1.54636122073446
reward_mean: 1040.375
reward_std: 431.12030029296875
reward_max: 1580.0
reward_min: 245.0
total_envstep_count: 2938726
total_train_sample_count: 2938670
total_episode_count: 18105
total_duration: 3728.5112022800113
[2024-11-20 01:10:08][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 473
train_sample_count: 473
avg_envstep_per_episode: 157.66666666666666
avg_sample_per_episode: 157.66666666666666
avg_envstep_per_sec: 803.6137743875802
avg_train_sample_per_sec: 803.6137743875802
avg_episode_per_sec: 5.09691611662313
collect_time: 0.588591205222266
reward_mean: 1317.3333740234375
reward_std: 214.82603454589844
reward_max: 1576.0
reward_min: 1050.0
total_envstep_count: 2939707
total_train_sample_count: 2939659
total_episode_count: 18108
total_duration: 3729.0997934852335
[2024-11-20 01:10:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 9
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 355.8888888888889
avg_sample_per_episode: 355.8888888888889
avg_envstep_per_sec: 808.0896205388294
avg_train_sample_per_sec: 808.0896205388294
avg_episode_per_sec: 2.270623348376355
collect_time: 3.963669274534498
reward_mean: 1370.888916015625
reward_std: 421.31842041015625
reward_max: 1897.0
reward_min: 634.0
total_envstep_count: 2940714
total_train_sample_count: 2940678
total_episode_count: 18117
total_duration: 3733.063462759768
[2024-11-20 01:10:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 703
train_sample_count: 703
avg_envstep_per_episode: 140.6
avg_sample_per_episode: 140.6
avg_envstep_per_sec: 805.8340807539046
avg_train_sample_per_sec: 805.8340807539046
avg_episode_per_sec: 5.731394599956647
collect_time: 0.8723880222865514
reward_mean: 1109.5999755859375
reward_std: 387.3409729003906
reward_max: 1732.0
reward_min: 637.0
total_envstep_count: 2941710
total_train_sample_count: 2941681
total_episode_count: 18122
total_duration: 3733.9358507820543
[2024-11-20 01:10:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 980
train_sample_count: 980
avg_envstep_per_episode: 196.0
avg_sample_per_episode: 196.0
avg_envstep_per_sec: 815.7650669337247
avg_train_sample_per_sec: 815.7650669337247
avg_episode_per_sec: 4.162066668029208
collect_time: 1.2013262638023923
reward_mean: 1347.4000244140625
reward_std: 209.45701599121094
reward_max: 1721.0
reward_min: 1073.0
total_envstep_count: 2942698
total_train_sample_count: 2942661
total_episode_count: 18127
total_duration: 3735.137177045857
[2024-11-20 01:10:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 613
train_sample_count: 613
avg_envstep_per_episode: 87.57142857142857
avg_sample_per_episode: 87.57142857142857
avg_envstep_per_sec: 799.201873740129
avg_train_sample_per_sec: 799.201873740129
avg_episode_per_sec: 9.126285670768194
collect_time: 0.7670152187347411
reward_mean: 718.0
reward_std: 425.95172119140625
reward_max: 1709.0
reward_min: 234.0
total_envstep_count: 2943715
total_train_sample_count: 2943682
total_episode_count: 18134
total_duration: 3735.9041922645915
[2024-11-20 01:10:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 980
train_sample_count: 980
avg_envstep_per_episode: 163.33333333333334
avg_sample_per_episode: 163.33333333333334
avg_envstep_per_sec: 807.20720777335
avg_train_sample_per_sec: 807.20720777335
avg_episode_per_sec: 4.942084945551122
collect_time: 1.2140624991485052
reward_mean: 949.8333129882812
reward_std: 694.09423828125
reward_max: 2319.0
reward_min: 236.0
total_envstep_count: 2944687
total_train_sample_count: 2944650
total_episode_count: 18140
total_duration: 3737.11825476374
[2024-11-20 01:10:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 658
train_sample_count: 658
avg_envstep_per_episode: 219.33333333333334
avg_sample_per_episode: 219.33333333333334
avg_envstep_per_sec: 805.3434914325013
avg_train_sample_per_sec: 805.3434914325013
avg_episode_per_sec: 3.6717788363183947
collect_time: 0.8170426743371146
reward_mean: 1343.6666259765625
reward_std: 459.87701416015625
reward_max: 1916.0
reward_min: 790.0
total_envstep_count: 2945668
total_train_sample_count: 2945632
total_episode_count: 18143
total_duration: 3737.935297438077
[2024-11-20 01:10:52][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 694
train_sample_count: 694
avg_envstep_per_episode: 138.8
avg_sample_per_episode: 138.8
avg_envstep_per_sec: 812.9788858559452
avg_train_sample_per_sec: 812.9788858559452
avg_episode_per_sec: 5.857196583976551
collect_time: 0.8536507061549596
reward_mean: 1230.4000244140625
reward_std: 501.50555419921875
reward_max: 1698.0
reward_min: 611.0
total_envstep_count: 2946687
total_train_sample_count: 2946650
total_episode_count: 18148
total_duration: 3738.788948144232
[2024-11-20 01:10:56][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 465
train_sample_count: 465
avg_envstep_per_episode: 155.0
avg_sample_per_episode: 155.0
avg_envstep_per_sec: 802.7385162446549
avg_train_sample_per_sec: 802.7385162446549
avg_episode_per_sec: 5.178958169320354
collect_time: 0.5792670845985413
reward_mean: 1225.3333740234375
reward_std: 133.62718200683594
reward_max: 1333.0
reward_min: 1037.0
total_envstep_count: 2947669
total_train_sample_count: 2947631
total_episode_count: 18151
total_duration: 3739.3682152288306
[2024-11-20 01:10:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 859
train_sample_count: 859
avg_envstep_per_episode: 171.8
avg_sample_per_episode: 171.8
avg_envstep_per_sec: 807.2897396654353
avg_train_sample_per_sec: 807.2897396654353
avg_episode_per_sec: 4.699008961964116
collect_time: 1.0640541527952467
reward_mean: 1124.199951171875
reward_std: 674.27099609375
reward_max: 2318.0
reward_min: 619.0
total_envstep_count: 2948640
total_train_sample_count: 2948610
total_episode_count: 18156
total_duration: 3740.4322693816257
[2024-11-20 01:11:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 905
train_sample_count: 905
avg_envstep_per_episode: 301.6666666666667
avg_sample_per_episode: 301.6666666666667
avg_envstep_per_sec: 806.6136622325555
avg_train_sample_per_sec: 806.6136622325555
avg_episode_per_sec: 2.673857443864825
collect_time: 1.1219745491232191
reward_mean: 1820.3333740234375
reward_std: 977.134033203125
reward_max: 3003.0
reward_min: 610.0
total_envstep_count: 2949653
total_train_sample_count: 2949611
total_episode_count: 18159
total_duration: 3741.5542439307487
[2024-11-20 01:11:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1285
train_sample_count: 1285
avg_envstep_per_episode: 257.0
avg_sample_per_episode: 257.0
avg_envstep_per_sec: 800.6417010975066
avg_train_sample_per_sec: 800.6417010975066
avg_episode_per_sec: 3.115337358356057
collect_time: 1.60496261715889
reward_mean: 1583.4000244140625
reward_std: 772.7288208007812
reward_max: 2984.0
reward_min: 615.0
total_envstep_count: 2950656
total_train_sample_count: 2950620
total_episode_count: 18164
total_duration: 3743.1592065479076
[2024-11-20 01:11:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 135
train_sample_count: 135
avg_envstep_per_episode: 67.5
avg_sample_per_episode: 67.5
avg_envstep_per_sec: 786.9862084921608
avg_train_sample_per_sec: 786.9862084921608
avg_episode_per_sec: 11.659054940624605
collect_time: 0.17154049021857126
reward_mean: 622.0
reward_std: 15.0
reward_max: 637.0
reward_min: 607.0
total_envstep_count: 2951607
total_train_sample_count: 2951583
total_episode_count: 18166
total_duration: 3743.330747038126
[2024-11-20 01:11:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2576
train_sample_count: 2576
avg_envstep_per_episode: 515.2
avg_sample_per_episode: 515.2
avg_envstep_per_sec: 808.4027157400831
avg_train_sample_per_sec: 808.4027157400831
avg_episode_per_sec: 1.5691046501166208
collect_time: 3.1865306113447462
reward_mean: 1489.800048828125
reward_std: 529.9431762695312
reward_max: 2321.0
reward_min: 806.0
total_envstep_count: 2952619
total_train_sample_count: 2952587
total_episode_count: 18171
total_duration: 3746.5172776494705
[2024-11-20 01:11:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 169
train_sample_count: 169
avg_envstep_per_episode: 169.0
avg_sample_per_episode: 169.0
avg_envstep_per_sec: 802.1607586628342
avg_train_sample_per_sec: 802.1607586628342
avg_episode_per_sec: 4.746513364868841
collect_time: 0.21068096160888672
reward_mean: 1433.0
reward_std: 0.0
reward_max: 1433.0
reward_min: 1433.0
total_envstep_count: 2953786
total_train_sample_count: 2953752
total_episode_count: 18172
total_duration: 3746.7279586110794
[2024-11-20 01:11:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1378
train_sample_count: 1378
avg_envstep_per_episode: 275.6
avg_sample_per_episode: 275.6
avg_envstep_per_sec: 799.3491362735436
avg_train_sample_per_sec: 799.3491362735436
avg_episode_per_sec: 2.9003959951870235
collect_time: 1.7239025320325578
reward_mean: 1650.199951171875
reward_std: 767.0067749023438
reward_max: 2352.0
reward_min: 234.0
total_envstep_count: 2954758
total_train_sample_count: 2954734
total_episode_count: 18177
total_duration: 3748.451861143112
[2024-11-20 01:11:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 900
train_sample_count: 900
avg_envstep_per_episode: 450.0
avg_sample_per_episode: 450.0
avg_envstep_per_sec: 807.4657899112756
avg_train_sample_per_sec: 807.4657899112756
avg_episode_per_sec: 1.7943684220250566
collect_time: 1.1145983040332794
reward_mean: 2206.5
reward_std: 766.5
reward_max: 2973.0
reward_min: 1440.0
total_envstep_count: 2955740
total_train_sample_count: 2955706
total_episode_count: 18179
total_duration: 3749.5664594471455
[2024-11-20 01:11:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1403
train_sample_count: 1403
avg_envstep_per_episode: 280.6
avg_sample_per_episode: 280.6
avg_envstep_per_sec: 804.551173554625
avg_train_sample_per_sec: 804.551173554625
avg_episode_per_sec: 2.867252934977281
collect_time: 1.743829412119729
reward_mean: 1893.800048828125
reward_std: 221.87779235839844
reward_max: 2302.0
reward_min: 1694.0
total_envstep_count: 2956735
total_train_sample_count: 2956689
total_episode_count: 18184
total_duration: 3751.3102888592653
[2024-11-20 01:11:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 546
train_sample_count: 546
avg_envstep_per_episode: 273.0
avg_sample_per_episode: 273.0
avg_envstep_per_sec: 802.2244207573317
avg_train_sample_per_sec: 802.2244207573317
avg_episode_per_sec: 2.938550991785098
collect_time: 0.6806075530392783
reward_mean: 1663.0
reward_std: 643.0
reward_max: 2306.0
reward_min: 1020.0
total_envstep_count: 2957694
total_train_sample_count: 2957655
total_episode_count: 18186
total_duration: 3751.9908964123047
[2024-11-20 01:11:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 430
train_sample_count: 430
avg_envstep_per_episode: 215.0
avg_sample_per_episode: 215.0
avg_envstep_per_sec: 815.6005629032858
avg_train_sample_per_sec: 815.6005629032858
avg_episode_per_sec: 3.793490990247841
collect_time: 0.5272188612392971
reward_mean: 1621.0
reward_std: 69.0
reward_max: 1690.0
reward_min: 1552.0
total_envstep_count: 2958668
total_train_sample_count: 2958625
total_episode_count: 18188
total_duration: 3752.518115273544
[2024-11-20 01:11:38][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1215
train_sample_count: 1215
avg_envstep_per_episode: 243.0
avg_sample_per_episode: 243.0
avg_envstep_per_sec: 810.602457311194
avg_train_sample_per_sec: 810.602457311194
avg_episode_per_sec: 3.3358125815275477
collect_time: 1.4988851674965449
reward_mean: 1663.4000244140625
reward_std: 653.8139038085938
reward_max: 2351.0
reward_min: 621.0
total_envstep_count: 2959632
total_train_sample_count: 2959600
total_episode_count: 18193
total_duration: 3754.0170004410406
[2024-11-20 01:11:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 475
train_sample_count: 475
avg_envstep_per_episode: 158.33333333333334
avg_sample_per_episode: 158.33333333333334
avg_envstep_per_sec: 806.576787813416
avg_train_sample_per_sec: 806.576787813416
avg_episode_per_sec: 5.094169186189996
collect_time: 0.5889085914407457
reward_mean: 1439.3333740234375
reward_std: 720.7284545898438
reward_max: 2365.0
reward_min: 607.0
total_envstep_count: 2960630
total_train_sample_count: 2960579
total_episode_count: 18196
total_duration: 3754.6059090324816
[2024-11-20 01:11:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 476
train_sample_count: 476
avg_envstep_per_episode: 158.66666666666666
avg_sample_per_episode: 158.66666666666666
avg_envstep_per_sec: 812.5738352375635
avg_train_sample_per_sec: 812.5738352375635
avg_episode_per_sec: 5.121263667463635
collect_time: 0.5857929204191481
reward_mean: 1412.0
reward_std: 116.67333221435547
reward_max: 1577.0
reward_min: 1329.0
total_envstep_count: 2961604
total_train_sample_count: 2961571
total_episode_count: 18199
total_duration: 3755.1917019529005
[2024-11-20 01:11:49][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 264
train_sample_count: 264
avg_envstep_per_episode: 132.0
avg_sample_per_episode: 132.0
avg_envstep_per_sec: 821.0704188694401
avg_train_sample_per_sec: 821.0704188694401
avg_episode_per_sec: 6.220230445980607
collect_time: 0.32153149587767466
reward_mean: 1192.5
reward_std: 136.5
reward_max: 1329.0
reward_min: 1056.0
total_envstep_count: 2962579
total_train_sample_count: 2962543
total_episode_count: 18201
total_duration: 3755.513233448778
[2024-11-20 01:11:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 2797
train_sample_count: 2797
avg_envstep_per_episode: 699.25
avg_sample_per_episode: 699.25
avg_envstep_per_sec: 806.9032165660128
avg_train_sample_per_sec: 806.9032165660128
avg_episode_per_sec: 1.1539552614458533
collect_time: 3.4663388899394443
reward_mean: 1527.5
reward_std: 645.7756958007812
reward_max: 2318.0
reward_min: 654.0
total_envstep_count: 2963551
total_train_sample_count: 2963516
total_episode_count: 18205
total_duration: 3758.9795723387174
[2024-11-20 01:11:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 906
train_sample_count: 906
avg_envstep_per_episode: 226.5
avg_sample_per_episode: 226.5
avg_envstep_per_sec: 807.2453116689654
avg_train_sample_per_sec: 807.2453116689654
avg_episode_per_sec: 3.5639969610108846
collect_time: 1.1223354126725877
reward_mean: 1741.25
reward_std: 398.8134765625
reward_max: 2314.0
reward_min: 1327.0
total_envstep_count: 2964517
total_train_sample_count: 2964506
total_episode_count: 18209
total_duration: 3760.10190775139
[2024-11-20 01:12:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 742
train_sample_count: 742
avg_envstep_per_episode: 185.5
avg_sample_per_episode: 185.5
avg_envstep_per_sec: 808.985847459574
avg_train_sample_per_sec: 808.985847459574
avg_episode_per_sec: 4.361109689809024
collect_time: 0.9171977511474064
reward_mean: 1349.5
reward_std: 411.3262023925781
reward_max: 1905.0
reward_min: 746.0
total_envstep_count: 2965545
total_train_sample_count: 2965488
total_episode_count: 18213
total_duration: 3761.0191055025375
[2024-11-20 01:12:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 618
train_sample_count: 618
avg_envstep_per_episode: 154.5
avg_sample_per_episode: 154.5
avg_envstep_per_sec: 800.3307660190708
avg_train_sample_per_sec: 800.3307660190708
avg_episode_per_sec: 5.180134407890426
collect_time: 0.7721807360649108
reward_mean: 1278.25
reward_std: 632.9187622070312
reward_max: 1848.0
reward_min: 232.0
total_envstep_count: 2966517
total_train_sample_count: 2966466
total_episode_count: 18217
total_duration: 3761.7912862386024
[2024-11-20 01:12:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 519
train_sample_count: 519
avg_envstep_per_episode: 259.5
avg_sample_per_episode: 259.5
avg_envstep_per_sec: 803.8264405515943
avg_train_sample_per_sec: 803.8264405515943
avg_episode_per_sec: 3.0975970734165483
collect_time: 0.6456617670399802
reward_mean: 2036.5
reward_std: 313.5
reward_max: 2350.0
reward_min: 1723.0
total_envstep_count: 2967477
total_train_sample_count: 2967441
total_episode_count: 18219
total_duration: 3762.4369480056425
[2024-11-20 01:12:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1222
train_sample_count: 1222
avg_envstep_per_episode: 244.4
avg_sample_per_episode: 244.4
avg_envstep_per_sec: 806.9196760718519
avg_train_sample_per_sec: 806.9196760718519
avg_episode_per_sec: 3.3016353358095416
collect_time: 1.5144010441643851
reward_mean: 1920.0
reward_std: 386.5762634277344
reward_max: 2351.0
reward_min: 1346.0
total_envstep_count: 2968440
total_train_sample_count: 2968411
total_episode_count: 18224
total_duration: 3763.951349049807
[2024-11-20 01:12:14][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 82
train_sample_count: 82
avg_envstep_per_episode: 82.0
avg_sample_per_episode: 82.0
avg_envstep_per_sec: 800.0505765130474
avg_train_sample_per_sec: 800.0505765130474
avg_episode_per_sec: 9.75671434772009
collect_time: 0.10249352029391698
reward_mean: 651.0
reward_std: 0.0
reward_max: 651.0
reward_min: 651.0
total_envstep_count: 2969415
total_train_sample_count: 2969393
total_episode_count: 18225
total_duration: 3764.053842570101
[2024-11-20 01:12:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 793
train_sample_count: 793
avg_envstep_per_episode: 264.3333333333333
avg_sample_per_episode: 264.3333333333333
avg_envstep_per_sec: 810.8586983232409
avg_train_sample_per_sec: 810.8586983232409
avg_episode_per_sec: 3.067561279911378
collect_time: 0.977975572858538
reward_mean: 2132.666748046875
reward_std: 313.73272705078125
reward_max: 2358.0
reward_min: 1689.0
total_envstep_count: 2970412
total_train_sample_count: 2970366
total_episode_count: 18228
total_duration: 3765.0318181429598
[2024-11-20 01:12:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1011
train_sample_count: 1011
avg_envstep_per_episode: 252.75
avg_sample_per_episode: 252.75
avg_envstep_per_sec: 815.5782171221391
avg_train_sample_per_sec: 815.5782171221391
avg_episode_per_sec: 3.226817871897682
collect_time: 1.2396113319056374
reward_mean: 1760.0
reward_std: 772.7861938476562
reward_max: 2628.0
reward_min: 725.0
total_envstep_count: 2971368
total_train_sample_count: 2971329
total_episode_count: 18232
total_duration: 3766.2714294748653
[2024-11-20 01:12:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2678
train_sample_count: 2678
avg_envstep_per_episode: 535.6
avg_sample_per_episode: 535.6
avg_envstep_per_sec: 813.6700362060576
avg_train_sample_per_sec: 813.6700362060576
avg_episode_per_sec: 1.5191748248806154
collect_time: 3.29126043830599
reward_mean: 904.4000244140625
reward_std: 737.7014770507812
reward_max: 2340.0
reward_min: 243.0
total_envstep_count: 2972364
total_train_sample_count: 2972327
total_episode_count: 18237
total_duration: 3769.562689913171
[2024-11-20 01:12:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2899
train_sample_count: 2899
avg_envstep_per_episode: 414.14285714285717
avg_sample_per_episode: 414.14285714285717
avg_envstep_per_sec: 809.0211004288324
avg_train_sample_per_sec: 809.0211004288324
avg_episode_per_sec: 1.9534831676446454
collect_time: 3.5833428800106035
reward_mean: 1105.4285888671875
reward_std: 636.78515625
reward_max: 2353.0
reward_min: 583.0
total_envstep_count: 2973391
total_train_sample_count: 2973354
total_episode_count: 18244
total_duration: 3773.146032793182
[2024-11-20 01:12:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1072
train_sample_count: 1072
avg_envstep_per_episode: 214.4
avg_sample_per_episode: 214.4
avg_envstep_per_sec: 805.0772033748632
avg_train_sample_per_sec: 805.0772033748632
avg_episode_per_sec: 3.75502426947231
collect_time: 1.3315493166446686
reward_mean: 1407.800048828125
reward_std: 547.2744750976562
reward_max: 2330.0
reward_min: 610.0
total_envstep_count: 2974411
total_train_sample_count: 2974354
total_episode_count: 18249
total_duration: 3774.4775821098265
[2024-11-20 01:12:35][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1097
train_sample_count: 1097
avg_envstep_per_episode: 182.83333333333334
avg_sample_per_episode: 182.83333333333334
avg_envstep_per_sec: 797.2479185163066
avg_train_sample_per_sec: 797.2479185163066
avg_episode_per_sec: 4.360517330080072
collect_time: 1.3759835234710147
reward_mean: 1671.5
reward_std: 532.7929077148438
reward_max: 2364.0
reward_min: 596.0
total_envstep_count: 2975383
total_train_sample_count: 2975367
total_episode_count: 18255
total_duration: 3775.8535656332974
[2024-11-20 01:12:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 8
envstep_count: 1168
train_sample_count: 1168
avg_envstep_per_episode: 146.0
avg_sample_per_episode: 146.0
avg_envstep_per_sec: 796.0741350161531
avg_train_sample_per_sec: 796.0741350161531
avg_episode_per_sec: 5.452562568603788
collect_time: 1.4672000365597861
reward_mean: 1150.125
reward_std: 532.9649047851562
reward_max: 1863.0
reward_min: 612.0
total_envstep_count: 2976378
total_train_sample_count: 2976343
total_episode_count: 18263
total_duration: 3777.3207656698573
[2024-11-20 01:12:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 620
train_sample_count: 620
avg_envstep_per_episode: 206.66666666666666
avg_sample_per_episode: 206.66666666666666
avg_envstep_per_sec: 697.5262978116933
avg_train_sample_per_sec: 697.5262978116933
avg_episode_per_sec: 3.3751272474759357
collect_time: 0.8888553764138902
reward_mean: 1704.3333740234375
reward_std: 114.05359649658203
reward_max: 1848.0
reward_min: 1569.0
total_envstep_count: 2977359
total_train_sample_count: 2977323
total_episode_count: 18266
total_duration: 3778.2096210462714
[2024-11-20 01:12:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 738
train_sample_count: 738
avg_envstep_per_episode: 147.6
avg_sample_per_episode: 147.6
avg_envstep_per_sec: 705.8100198402418
avg_train_sample_per_sec: 705.8100198402418
avg_episode_per_sec: 4.781910703524673
collect_time: 1.045607145343508
reward_mean: 1308.4000244140625
reward_std: 378.1933898925781
reward_max: 1689.0
reward_min: 607.0
total_envstep_count: 2978363
total_train_sample_count: 2978337
total_episode_count: 18271
total_duration: 3779.255228191615
[2024-11-20 01:12:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 445
train_sample_count: 445
avg_envstep_per_episode: 222.5
avg_sample_per_episode: 222.5
avg_envstep_per_sec: 727.6253644016014
avg_train_sample_per_sec: 727.6253644016014
avg_episode_per_sec: 3.2702263568611296
collect_time: 0.611578460250582
reward_mean: 1835.0
reward_std: 519.0
reward_max: 2354.0
reward_min: 1316.0
total_envstep_count: 2979330
total_train_sample_count: 2979298
total_episode_count: 18273
total_duration: 3779.8668066518658
[2024-11-20 01:12:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 880
train_sample_count: 880
avg_envstep_per_episode: 220.0
avg_sample_per_episode: 220.0
avg_envstep_per_sec: 793.7808545206369
avg_train_sample_per_sec: 793.7808545206369
avg_episode_per_sec: 3.6080947932756224
collect_time: 1.108618323292051
reward_mean: 1652.75
reward_std: 741.5616455078125
reward_max: 2355.0
reward_min: 612.0
total_envstep_count: 2980318
total_train_sample_count: 2980286
total_episode_count: 18277
total_duration: 3780.9754249751577
[2024-11-20 01:12:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 979
train_sample_count: 979
avg_envstep_per_episode: 163.16666666666666
avg_sample_per_episode: 163.16666666666666
avg_envstep_per_sec: 803.2238763081634
avg_train_sample_per_sec: 803.2238763081634
avg_episode_per_sec: 4.9227203859540145
collect_time: 1.2188382702214378
reward_mean: 1285.0
reward_std: 507.6264953613281
reward_max: 1914.0
reward_min: 608.0
total_envstep_count: 2981329
total_train_sample_count: 2981277
total_episode_count: 18283
total_duration: 3782.1942632453793
[2024-11-20 01:13:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 417
train_sample_count: 417
avg_envstep_per_episode: 139.0
avg_sample_per_episode: 139.0
avg_envstep_per_sec: 815.530345902068
avg_train_sample_per_sec: 815.530345902068
avg_episode_per_sec: 5.86712479066236
collect_time: 0.5113237074443272
reward_mean: 856.3333129882812
reward_std: 345.46038818359375
reward_max: 1344.0
reward_min: 587.0
total_envstep_count: 2982295
total_train_sample_count: 2982258
total_episode_count: 18286
total_duration: 3782.7055869528235
[2024-11-20 01:13:24][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1263
train_sample_count: 1263
avg_envstep_per_episode: 315.75
avg_sample_per_episode: 315.75
avg_envstep_per_sec: 809.6176216706713
avg_train_sample_per_sec: 809.6176216706713
avg_episode_per_sec: 2.564109648996584
collect_time: 1.5599956895623888
reward_mean: 1922.5
reward_std: 426.59844970703125
reward_max: 2358.0
reward_min: 1337.0
total_envstep_count: 2983268
total_train_sample_count: 2983233
total_episode_count: 18290
total_duration: 3784.265582642386
[2024-11-20 01:13:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 275
train_sample_count: 275
avg_envstep_per_episode: 275.0
avg_sample_per_episode: 275.0
avg_envstep_per_sec: 791.737567107164
avg_train_sample_per_sec: 791.737567107164
avg_episode_per_sec: 2.8790456985715056
collect_time: 0.34733731406075613
reward_mean: 1929.0
reward_std: 0.0
reward_max: 1929.0
reward_min: 1929.0
total_envstep_count: 2984331
total_train_sample_count: 2984300
total_episode_count: 18291
total_duration: 3784.612919956447
[2024-11-20 01:13:32][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 1436
train_sample_count: 1436
avg_envstep_per_episode: 205.14285714285714
avg_sample_per_episode: 205.14285714285714
avg_envstep_per_sec: 780.7150180241255
avg_train_sample_per_sec: 780.7150180241255
avg_episode_per_sec: 3.805713876162171
collect_time: 1.8393395372799466
reward_mean: 1509.5714111328125
reward_std: 878.8028564453125
reward_max: 3032.0
reward_min: 239.0
total_envstep_count: 2985334
total_train_sample_count: 2985292
total_episode_count: 18298
total_duration: 3786.452259493727
[2024-11-20 01:13:36][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 617
train_sample_count: 617
avg_envstep_per_episode: 205.66666666666666
avg_sample_per_episode: 205.66666666666666
avg_envstep_per_sec: 793.527109743895
avg_train_sample_per_sec: 793.527109743895
avg_episode_per_sec: 3.858316578981661
collect_time: 0.77754117335592
reward_mean: 1743.6666259765625
reward_std: 228.68658447265625
reward_max: 1946.0
reward_min: 1424.0
total_envstep_count: 2986307
total_train_sample_count: 2986269
total_episode_count: 18301
total_duration: 3787.229800667083
[2024-11-20 01:13:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 193
train_sample_count: 193
avg_envstep_per_episode: 193.0
avg_sample_per_episode: 193.0
avg_envstep_per_sec: 785.0984929938521
avg_train_sample_per_sec: 785.0984929938521
avg_episode_per_sec: 4.067867839346384
collect_time: 0.245829028742654
reward_mean: 1306.0
reward_std: 0.0
reward_max: 1306.0
reward_min: 1306.0
total_envstep_count: 2987274
total_train_sample_count: 2987230
total_episode_count: 18302
total_duration: 3787.475629695826
[2024-11-20 01:13:43][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1107
train_sample_count: 1107
avg_envstep_per_episode: 184.5
avg_sample_per_episode: 184.5
avg_envstep_per_sec: 790.7338490969755
avg_train_sample_per_sec: 790.7338490969755
avg_episode_per_sec: 4.285820320308811
collect_time: 1.399965362889426
reward_mean: 955.6666870117188
reward_std: 498.9992370605469
reward_max: 1673.0
reward_min: 582.0
total_envstep_count: 2988260
total_train_sample_count: 2988217
total_episode_count: 18308
total_duration: 3788.875595058715
[2024-11-20 01:13:46][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 549
train_sample_count: 549
avg_envstep_per_episode: 183.0
avg_sample_per_episode: 183.0
avg_envstep_per_sec: 797.9819576051284
avg_train_sample_per_sec: 797.9819576051284
avg_episode_per_sec: 4.360557145383216
collect_time: 0.6879854798316956
reward_mean: 1334.3333740234375
reward_std: 741.5827026367188
reward_max: 2353.0
reward_min: 609.0
total_envstep_count: 2989218
total_train_sample_count: 2989186
total_episode_count: 18311
total_duration: 3789.563580538547
[2024-11-20 01:13:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 307
train_sample_count: 307
avg_envstep_per_episode: 307.0
avg_sample_per_episode: 307.0
avg_envstep_per_sec: 810.5131315122303
avg_train_sample_per_sec: 810.5131315122303
avg_episode_per_sec: 2.640107920235278
collect_time: 0.37877239499773296
reward_mean: 2358.0
reward_std: 0.0
reward_max: 2358.0
reward_min: 2358.0
total_envstep_count: 2990289
total_train_sample_count: 2990249
total_episode_count: 18312
total_duration: 3789.9423529335445
[2024-11-20 01:13:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 998
train_sample_count: 998
avg_envstep_per_episode: 332.6666666666667
avg_sample_per_episode: 332.6666666666667
avg_envstep_per_sec: 816.2538259737756
avg_train_sample_per_sec: 816.2538259737756
avg_episode_per_sec: 2.4536688155524318
collect_time: 1.2226588938917433
reward_mean: 2177.666748046875
reward_std: 454.6649475097656
reward_max: 2622.0
reward_min: 1553.0
total_envstep_count: 2991270
total_train_sample_count: 2991211
total_episode_count: 18315
total_duration: 3791.165011827436
[2024-11-20 01:13:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1307
train_sample_count: 1307
avg_envstep_per_episode: 261.4
avg_sample_per_episode: 261.4
avg_envstep_per_sec: 812.6139769610076
avg_train_sample_per_sec: 812.6139769610076
avg_episode_per_sec: 3.108699223263227
collect_time: 1.6083897607667104
reward_mean: 1800.800048828125
reward_std: 591.0294189453125
reward_max: 2614.0
reward_min: 1042.0
total_envstep_count: 2992243
total_train_sample_count: 2992194
total_episode_count: 18320
total_duration: 3792.773401588203
[2024-11-20 01:14:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 2482
train_sample_count: 2482
avg_envstep_per_episode: 620.5
avg_sample_per_episode: 620.5
avg_envstep_per_sec: 786.7161507067173
avg_train_sample_per_sec: 786.7161507067173
avg_episode_per_sec: 1.2678745378029286
collect_time: 3.1548862925597594
reward_mean: 1191.25
reward_std: 634.2879638671875
reward_max: 1917.0
reward_min: 514.0
total_envstep_count: 2993207
total_train_sample_count: 2993176
total_episode_count: 18324
total_duration: 3795.9282878807626
[2024-11-20 01:14:04][sample_serial_collector.py:365][INFO] collect end:
episode_count: 7
envstep_count: 2970
train_sample_count: 2970
avg_envstep_per_episode: 424.2857142857143
avg_sample_per_episode: 424.2857142857143
avg_envstep_per_sec: 800.4337046071616
avg_train_sample_per_sec: 800.4337046071616
avg_episode_per_sec: 1.8865440849327042
collect_time: 3.7104884300913117
reward_mean: 1484.857177734375
reward_std: 625.2861328125
reward_max: 2583.0
reward_min: 636.0
total_envstep_count: 2994241
total_train_sample_count: 2994202
total_episode_count: 18331
total_duration: 3799.6387763108537
[2024-11-20 01:14:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 579
train_sample_count: 579
avg_envstep_per_episode: 144.75
avg_sample_per_episode: 144.75
avg_envstep_per_sec: 799.9997935000337
avg_train_sample_per_sec: 799.9997935000337
avg_episode_per_sec: 5.526768867012322
collect_time: 0.7237501868179865
reward_mean: 1265.25
reward_std: 383.7742614746094
reward_max: 1578.0
reward_min: 608.0
total_envstep_count: 2995230
total_train_sample_count: 2995177
total_episode_count: 18335
total_duration: 3800.3625264976718
[2024-11-20 01:14:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1127
train_sample_count: 1127
avg_envstep_per_episode: 187.83333333333334
avg_sample_per_episode: 187.83333333333334
avg_envstep_per_sec: 805.4218104996439
avg_train_sample_per_sec: 805.4218104996439
avg_episode_per_sec: 4.287959949421352
collect_time: 1.3992668007101332
reward_mean: 1552.1666259765625
reward_std: 525.529052734375
reward_max: 2346.0
reward_min: 590.0
total_envstep_count: 2996249
total_train_sample_count: 2996220
total_episode_count: 18341
total_duration: 3801.7617932983817
[2024-11-20 01:14:15][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1353
train_sample_count: 1353
avg_envstep_per_episode: 225.5
avg_sample_per_episode: 225.5
avg_envstep_per_sec: 803.8049265958143
avg_train_sample_per_sec: 803.8049265958143
avg_episode_per_sec: 3.5645451290280015
collect_time: 1.6832442241055623
reward_mean: 1482.5
reward_std: 707.8831787109375
reward_max: 2349.0
reward_min: 610.0
total_envstep_count: 2997269
total_train_sample_count: 2997225
total_episode_count: 18347
total_duration: 3803.4450375224874
[2024-11-20 01:14:18][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 379
train_sample_count: 379
avg_envstep_per_episode: 189.5
avg_sample_per_episode: 189.5
avg_envstep_per_sec: 801.9880684556894
avg_train_sample_per_sec: 801.9880684556894
avg_episode_per_sec: 4.23212701032026
collect_time: 0.4725756091730935
reward_mean: 1594.0
reward_std: 270.0
reward_max: 1864.0
reward_min: 1324.0
total_envstep_count: 2998235
total_train_sample_count: 2998192
total_episode_count: 18349
total_duration: 3803.9176131316603
[2024-11-20 01:14:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 400
train_sample_count: 400
avg_envstep_per_episode: 200.0
avg_sample_per_episode: 200.0
avg_envstep_per_sec: 808.450689124366
avg_train_sample_per_sec: 808.450689124366
avg_episode_per_sec: 4.042253445621831
collect_time: 0.49477352840559824
reward_mean: 1514.0
reward_std: 207.0
reward_max: 1721.0
reward_min: 1307.0
total_envstep_count: 2999217
total_train_sample_count: 2999192
total_episode_count: 18351
total_duration: 3804.4123866600657
