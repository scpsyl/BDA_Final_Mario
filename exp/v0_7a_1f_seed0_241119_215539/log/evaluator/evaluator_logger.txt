[2024-11-19 21:55:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 250.0, current episode: 1
[2024-11-19 21:55:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 250.0, current episode: 2
[2024-11-19 21:55:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 250.0, current episode: 3
[2024-11-19 21:55:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 250.0, current episode: 4
[2024-11-19 21:55:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 250.0, current episode: 5
[2024-11-19 21:55:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 250.0, current episode: 6
[2024-11-19 21:55:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 250.0, current episode: 7
[2024-11-19 21:55:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 250.0, current episode: 8
[2024-11-19 21:55:59][interaction_serial_evaluator.py:279][INFO] 
+-------+------------+---------------------+---------------+---------------+
| Name  | train_iter | ckpt_name           | episode_count | envstep_count |
+-------+------------+---------------------+---------------+---------------+
| Value | 0.000000   | iteration_0.pth.tar | 8.000000      | 240.000000    |
+-------+------------+---------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.000000               | 0.365127      | 657.305813          | 21.910194            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 250.000000  | 0.000000   | 250.000000 | 250.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 21:57:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 250.0, current episode: 1
[2024-11-19 21:57:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 250.0, current episode: 2
[2024-11-19 21:57:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 250.0, current episode: 3
[2024-11-19 21:57:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 250.0, current episode: 4
[2024-11-19 21:57:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 250.0, current episode: 5
[2024-11-19 21:57:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 250.0, current episode: 6
[2024-11-19 21:57:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 250.0, current episode: 7
[2024-11-19 21:57:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 250.0, current episode: 8
[2024-11-19 21:57:43][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 2000.000000 | iteration_2000.pth.tar | 8.000000      | 240.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.000000               | 0.457544      | 524.539342          | 17.484645            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 250.000000  | 0.000000   | 250.000000 | 250.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 21:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -415.0, current episode: 1
[2024-11-19 21:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -415.0, current episode: 2
[2024-11-19 21:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -415.0, current episode: 3
[2024-11-19 21:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -415.0, current episode: 4
[2024-11-19 21:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -415.0, current episode: 5
[2024-11-19 21:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -415.0, current episode: 6
[2024-11-19 21:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -415.0, current episode: 7
[2024-11-19 21:59:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -415.0, current episode: 8
[2024-11-19 21:59:05][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 4000.000000 | iteration_4000.pth.tar | 8.000000      | 16040.000000  |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 18.090089     | 886.673356          | 0.442231             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | -415.000000 | 0.000000   | -415.000000 | -415.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 22:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 250.0, current episode: 1
[2024-11-19 22:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 250.0, current episode: 2
[2024-11-19 22:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 250.0, current episode: 3
[2024-11-19 22:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 250.0, current episode: 4
[2024-11-19 22:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 250.0, current episode: 5
[2024-11-19 22:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 250.0, current episode: 6
[2024-11-19 22:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 250.0, current episode: 7
[2024-11-19 22:00:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 250.0, current episode: 8
[2024-11-19 22:00:06][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 6000.000000 | iteration_6000.pth.tar | 8.000000      | 240.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.000000               | 0.282512      | 849.522305          | 28.317410            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 250.000000  | 0.000000   | 250.000000 | 250.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:01:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 231.0, current episode: 1
[2024-11-19 22:01:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 231.0, current episode: 2
[2024-11-19 22:01:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 231.0, current episode: 3
[2024-11-19 22:01:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 231.0, current episode: 4
[2024-11-19 22:01:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 231.0, current episode: 5
[2024-11-19 22:01:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 231.0, current episode: 6
[2024-11-19 22:01:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 231.0, current episode: 7
[2024-11-19 22:01:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 231.0, current episode: 8
[2024-11-19 22:01:09][interaction_serial_evaluator.py:279][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 8000.000000 | iteration_8000.pth.tar | 8.000000      | 320.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 40.000000               | 0.390085      | 820.334068          | 20.508352            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 231.000000  | 0.000000   | 231.000000 | 231.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 231.0, current episode: 1
[2024-11-19 22:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 231.0, current episode: 2
[2024-11-19 22:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 231.0, current episode: 3
[2024-11-19 22:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 231.0, current episode: 4
[2024-11-19 22:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 231.0, current episode: 5
[2024-11-19 22:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 231.0, current episode: 6
[2024-11-19 22:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 231.0, current episode: 7
[2024-11-19 22:02:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 231.0, current episode: 8
[2024-11-19 22:02:13][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 10000.000000 | iteration_10000.pth.tar | 8.000000      | 320.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 40.000000               | 0.394332      | 811.499570          | 20.287489            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 231.000000  | 0.000000   | 231.000000 | 231.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:03:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -415.0, current episode: 1
[2024-11-19 22:03:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -415.0, current episode: 2
[2024-11-19 22:03:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -415.0, current episode: 3
[2024-11-19 22:03:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -415.0, current episode: 4
[2024-11-19 22:03:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -415.0, current episode: 5
[2024-11-19 22:03:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -415.0, current episode: 6
[2024-11-19 22:03:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -415.0, current episode: 7
[2024-11-19 22:03:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -415.0, current episode: 8
[2024-11-19 22:03:41][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 12000.000000 | iteration_12000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 19.728298     | 813.045294          | 0.405509             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | -415.000000 | 0.000000   | -415.000000 | -415.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 22:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 22:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 22:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 22:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 22:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 22:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 22:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 22:05:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 22:05:10][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 14000.000000 | iteration_14000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.171398     | 795.185344          | 0.396601             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:06:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 250.0, current episode: 1
[2024-11-19 22:06:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 250.0, current episode: 2
[2024-11-19 22:06:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 250.0, current episode: 3
[2024-11-19 22:06:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 250.0, current episode: 4
[2024-11-19 22:06:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 250.0, current episode: 5
[2024-11-19 22:06:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 250.0, current episode: 6
[2024-11-19 22:06:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 250.0, current episode: 7
[2024-11-19 22:06:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 250.0, current episode: 8
[2024-11-19 22:06:20][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 16000.000000 | iteration_16000.pth.tar | 8.000000      | 240.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.000000               | 0.306355      | 783.404265          | 26.113475            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 250.000000  | 0.000000   | 250.000000 | 250.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 250.0, current episode: 1
[2024-11-19 22:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 250.0, current episode: 2
[2024-11-19 22:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 250.0, current episode: 3
[2024-11-19 22:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 250.0, current episode: 4
[2024-11-19 22:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 250.0, current episode: 5
[2024-11-19 22:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 250.0, current episode: 6
[2024-11-19 22:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 250.0, current episode: 7
[2024-11-19 22:07:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 250.0, current episode: 8
[2024-11-19 22:07:30][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 18000.000000 | iteration_18000.pth.tar | 8.000000      | 240.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.000000               | 0.306987      | 781.791335          | 26.059711            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 250.000000  | 0.000000   | 250.000000 | 250.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 22:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 22:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 22:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 22:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 22:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 22:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 22:09:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 22:09:00][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 20000.000000 | iteration_20000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.013199     | 801.471075          | 0.399736             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:10:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 252.0, current episode: 1
[2024-11-19 22:10:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 252.0, current episode: 2
[2024-11-19 22:10:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 252.0, current episode: 3
[2024-11-19 22:10:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 252.0, current episode: 4
[2024-11-19 22:10:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 252.0, current episode: 5
[2024-11-19 22:10:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 252.0, current episode: 6
[2024-11-19 22:10:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 252.0, current episode: 7
[2024-11-19 22:10:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 252.0, current episode: 8
[2024-11-19 22:10:10][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 22000.000000 | iteration_22000.pth.tar | 8.000000      | 216.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 27.000000               | 0.295552      | 730.837001          | 27.068037            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 252.000000  | 0.000000   | 252.000000 | 252.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 250.0, current episode: 1
[2024-11-19 22:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 250.0, current episode: 2
[2024-11-19 22:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 250.0, current episode: 3
[2024-11-19 22:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 250.0, current episode: 4
[2024-11-19 22:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 250.0, current episode: 5
[2024-11-19 22:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 250.0, current episode: 6
[2024-11-19 22:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 250.0, current episode: 7
[2024-11-19 22:11:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 250.0, current episode: 8
[2024-11-19 22:11:21][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 24000.000000 | iteration_24000.pth.tar | 8.000000      | 240.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.000000               | 0.310432      | 773.116280          | 25.770543            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 250.000000  | 0.000000   | 250.000000 | 250.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:12:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 229.0, current episode: 1
[2024-11-19 22:12:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 229.0, current episode: 2
[2024-11-19 22:12:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 229.0, current episode: 3
[2024-11-19 22:12:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 229.0, current episode: 4
[2024-11-19 22:12:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 229.0, current episode: 5
[2024-11-19 22:12:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 229.0, current episode: 6
[2024-11-19 22:12:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 229.0, current episode: 7
[2024-11-19 22:12:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 229.0, current episode: 8
[2024-11-19 22:12:31][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 26000.000000 | iteration_26000.pth.tar | 8.000000      | 328.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 41.000000               | 0.423813      | 773.926481          | 18.876256            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 229.000000  | 0.000000   | 229.000000 | 229.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:13:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 236.0, current episode: 1
[2024-11-19 22:13:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 236.0, current episode: 2
[2024-11-19 22:13:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 236.0, current episode: 3
[2024-11-19 22:13:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 236.0, current episode: 4
[2024-11-19 22:13:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 236.0, current episode: 5
[2024-11-19 22:13:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 236.0, current episode: 6
[2024-11-19 22:13:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 236.0, current episode: 7
[2024-11-19 22:13:41][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 236.0, current episode: 8
[2024-11-19 22:13:41][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 28000.000000 | iteration_28000.pth.tar | 8.000000      | 312.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 39.000000               | 0.392816      | 794.265347          | 20.365778            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 236.000000  | 0.000000   | 236.000000 | 236.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:14:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 246.0, current episode: 1
[2024-11-19 22:14:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 246.0, current episode: 2
[2024-11-19 22:14:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 246.0, current episode: 3
[2024-11-19 22:14:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 246.0, current episode: 4
[2024-11-19 22:14:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 246.0, current episode: 5
[2024-11-19 22:14:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 246.0, current episode: 6
[2024-11-19 22:14:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 246.0, current episode: 7
[2024-11-19 22:14:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 246.0, current episode: 8
[2024-11-19 22:14:52][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 30000.000000 | iteration_30000.pth.tar | 8.000000      | 216.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 27.000000               | 0.285492      | 756.588144          | 28.021783            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 246.000000  | 0.000000   | 246.000000 | 246.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:16:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 22:16:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 22:16:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 22:16:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 22:16:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 22:16:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 22:16:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 22:16:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 22:16:22][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 32000.000000 | iteration_32000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.154569     | 795.849312          | 0.396932             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 139.0, current episode: 1
[2024-11-19 22:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 139.0, current episode: 2
[2024-11-19 22:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 139.0, current episode: 3
[2024-11-19 22:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 139.0, current episode: 4
[2024-11-19 22:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 139.0, current episode: 5
[2024-11-19 22:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 139.0, current episode: 6
[2024-11-19 22:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 139.0, current episode: 7
[2024-11-19 22:17:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 139.0, current episode: 8
[2024-11-19 22:17:53][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 34000.000000 | iteration_34000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.248960     | 792.139447          | 0.395082             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 139.000000  | 0.000000   | 139.000000 | 139.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -415.0, current episode: 1
[2024-11-19 22:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -415.0, current episode: 2
[2024-11-19 22:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -415.0, current episode: 3
[2024-11-19 22:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -415.0, current episode: 4
[2024-11-19 22:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -415.0, current episode: 5
[2024-11-19 22:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -415.0, current episode: 6
[2024-11-19 22:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -415.0, current episode: 7
[2024-11-19 22:19:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -415.0, current episode: 8
[2024-11-19 22:19:23][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 36000.000000 | iteration_36000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 19.999677     | 802.012945          | 0.400006             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | -415.000000 | 0.000000   | -415.000000 | -415.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 22:20:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 654.0, current episode: 1
[2024-11-19 22:20:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 654.0, current episode: 2
[2024-11-19 22:20:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 654.0, current episode: 3
[2024-11-19 22:20:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 654.0, current episode: 4
[2024-11-19 22:20:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 654.0, current episode: 5
[2024-11-19 22:20:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 654.0, current episode: 6
[2024-11-19 22:20:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 654.0, current episode: 7
[2024-11-19 22:20:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 654.0, current episode: 8
[2024-11-19 22:20:35][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 38000.000000 | iteration_38000.pth.tar | 8.000000      | 544.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 68.000000               | 0.709424      | 766.819516          | 11.276758            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 654.000000  | 0.000000   | 654.000000 | 654.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:21:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 250.0, current episode: 1
[2024-11-19 22:21:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 250.0, current episode: 2
[2024-11-19 22:21:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 250.0, current episode: 3
[2024-11-19 22:21:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 250.0, current episode: 4
[2024-11-19 22:21:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 250.0, current episode: 5
[2024-11-19 22:21:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 250.0, current episode: 6
[2024-11-19 22:21:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 250.0, current episode: 7
[2024-11-19 22:21:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 250.0, current episode: 8
[2024-11-19 22:21:45][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 40000.000000 | iteration_40000.pth.tar | 8.000000      | 240.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.000000               | 0.310138      | 773.849093          | 25.794970            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 250.000000  | 0.000000   | 250.000000 | 250.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:22:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 231.0, current episode: 1
[2024-11-19 22:22:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 231.0, current episode: 2
[2024-11-19 22:22:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 231.0, current episode: 3
[2024-11-19 22:22:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 231.0, current episode: 4
[2024-11-19 22:22:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 231.0, current episode: 5
[2024-11-19 22:22:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 231.0, current episode: 6
[2024-11-19 22:22:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 231.0, current episode: 7
[2024-11-19 22:22:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 231.0, current episode: 8
[2024-11-19 22:22:56][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 42000.000000 | iteration_42000.pth.tar | 8.000000      | 320.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 40.000000               | 0.424347      | 754.099117          | 18.852478            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 231.000000  | 0.000000   | 231.000000 | 231.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:24:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 22:24:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 22:24:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 22:24:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 22:24:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 22:24:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 22:24:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 22:24:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 22:24:28][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 44000.000000 | iteration_44000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.465611     | 783.753782          | 0.390900             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 139.0, current episode: 1
[2024-11-19 22:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 139.0, current episode: 2
[2024-11-19 22:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 139.0, current episode: 3
[2024-11-19 22:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 139.0, current episode: 4
[2024-11-19 22:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 139.0, current episode: 5
[2024-11-19 22:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 139.0, current episode: 6
[2024-11-19 22:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 139.0, current episode: 7
[2024-11-19 22:25:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 139.0, current episode: 8
[2024-11-19 22:25:59][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 46000.000000 | iteration_46000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.392696     | 786.556122          | 0.392297             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 139.000000  | 0.000000   | 139.000000 | 139.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:27:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 22:27:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 22:27:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 22:27:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 22:27:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 22:27:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 22:27:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 22:27:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 22:27:30][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 48000.000000 | iteration_48000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.153708     | 795.883300          | 0.396949             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:29:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -415.0, current episode: 1
[2024-11-19 22:29:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -415.0, current episode: 2
[2024-11-19 22:29:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -415.0, current episode: 3
[2024-11-19 22:29:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -415.0, current episode: 4
[2024-11-19 22:29:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -415.0, current episode: 5
[2024-11-19 22:29:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -415.0, current episode: 6
[2024-11-19 22:29:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -415.0, current episode: 7
[2024-11-19 22:29:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -415.0, current episode: 8
[2024-11-19 22:29:01][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 50000.000000 | iteration_50000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.018399     | 801.262878          | 0.399632             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | -415.000000 | 0.000000   | -415.000000 | -415.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 22:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -150.0, current episode: 1
[2024-11-19 22:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -150.0, current episode: 2
[2024-11-19 22:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -150.0, current episode: 3
[2024-11-19 22:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -150.0, current episode: 4
[2024-11-19 22:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -150.0, current episode: 5
[2024-11-19 22:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -150.0, current episode: 6
[2024-11-19 22:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -150.0, current episode: 7
[2024-11-19 22:30:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -150.0, current episode: 8
[2024-11-19 22:30:32][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 52000.000000 | iteration_52000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.325227     | 789.167096          | 0.393600             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | -150.000000 | 0.000000   | -150.000000 | -150.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 22:31:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 250.0, current episode: 1
[2024-11-19 22:31:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 250.0, current episode: 2
[2024-11-19 22:31:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 250.0, current episode: 3
[2024-11-19 22:31:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 250.0, current episode: 4
[2024-11-19 22:31:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 250.0, current episode: 5
[2024-11-19 22:31:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 250.0, current episode: 6
[2024-11-19 22:31:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 250.0, current episode: 7
[2024-11-19 22:31:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 250.0, current episode: 8
[2024-11-19 22:31:44][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 54000.000000 | iteration_54000.pth.tar | 8.000000      | 240.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.000000               | 0.317203      | 756.613735          | 25.220458            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 250.000000  | 0.000000   | 250.000000 | 250.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:33:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 139.0, current episode: 1
[2024-11-19 22:33:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 139.0, current episode: 2
[2024-11-19 22:33:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 139.0, current episode: 3
[2024-11-19 22:33:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 139.0, current episode: 4
[2024-11-19 22:33:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 139.0, current episode: 5
[2024-11-19 22:33:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 139.0, current episode: 6
[2024-11-19 22:33:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 139.0, current episode: 7
[2024-11-19 22:33:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 139.0, current episode: 8
[2024-11-19 22:33:15][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 56000.000000 | iteration_56000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.539176     | 780.946626          | 0.389500             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 139.000000  | 0.000000   | 139.000000 | 139.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:34:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 653.0, current episode: 1
[2024-11-19 22:34:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 653.0, current episode: 2
[2024-11-19 22:34:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 653.0, current episode: 3
[2024-11-19 22:34:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 653.0, current episode: 4
[2024-11-19 22:34:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 653.0, current episode: 5
[2024-11-19 22:34:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 653.0, current episode: 6
[2024-11-19 22:34:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 653.0, current episode: 7
[2024-11-19 22:34:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 653.0, current episode: 8
[2024-11-19 22:34:27][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 58000.000000 | iteration_58000.pth.tar | 8.000000      | 584.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 73.000000               | 0.786198      | 742.815066          | 10.175549            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 653.000000  | 0.000000   | 653.000000 | 653.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 267.0, current episode: 1
[2024-11-19 22:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 267.0, current episode: 2
[2024-11-19 22:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 267.0, current episode: 3
[2024-11-19 22:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 267.0, current episode: 4
[2024-11-19 22:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 267.0, current episode: 5
[2024-11-19 22:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 267.0, current episode: 6
[2024-11-19 22:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 267.0, current episode: 7
[2024-11-19 22:35:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 267.0, current episode: 8
[2024-11-19 22:35:59][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 60000.000000 | iteration_60000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.615782     | 778.044694          | 0.388052             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 267.000000  | 0.000000   | 267.000000 | 267.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:37:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 250.0, current episode: 1
[2024-11-19 22:37:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 250.0, current episode: 2
[2024-11-19 22:37:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 250.0, current episode: 3
[2024-11-19 22:37:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 250.0, current episode: 4
[2024-11-19 22:37:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 250.0, current episode: 5
[2024-11-19 22:37:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 250.0, current episode: 6
[2024-11-19 22:37:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 250.0, current episode: 7
[2024-11-19 22:37:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 250.0, current episode: 8
[2024-11-19 22:37:10][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 62000.000000 | iteration_62000.pth.tar | 8.000000      | 240.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.000000               | 0.319209      | 751.857706          | 25.061924            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 250.000000  | 0.000000   | 250.000000 | 250.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 250.0, current episode: 1
[2024-11-19 22:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 250.0, current episode: 2
[2024-11-19 22:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 250.0, current episode: 3
[2024-11-19 22:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 250.0, current episode: 4
[2024-11-19 22:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 250.0, current episode: 5
[2024-11-19 22:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 250.0, current episode: 6
[2024-11-19 22:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 250.0, current episode: 7
[2024-11-19 22:38:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 250.0, current episode: 8
[2024-11-19 22:38:22][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 64000.000000 | iteration_64000.pth.tar | 8.000000      | 240.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.000000               | 0.321307      | 746.949864          | 24.898329            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 250.000000  | 0.000000   | 250.000000 | 250.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:39:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 22:39:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 22:39:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 22:39:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 22:39:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 22:39:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 22:39:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 22:39:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 22:39:54][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 66000.000000 | iteration_66000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.552669     | 780.433917          | 0.389244             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:41:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 22:41:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 22:41:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 22:41:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 22:41:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 22:41:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 22:41:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 22:41:26][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 22:41:26][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 68000.000000 | iteration_68000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.334769     | 788.796764          | 0.393415             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 629.0, current episode: 1
[2024-11-19 22:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 629.0, current episode: 2
[2024-11-19 22:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 629.0, current episode: 3
[2024-11-19 22:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 629.0, current episode: 4
[2024-11-19 22:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 629.0, current episode: 5
[2024-11-19 22:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 629.0, current episode: 6
[2024-11-19 22:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 629.0, current episode: 7
[2024-11-19 22:42:38][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 629.0, current episode: 8
[2024-11-19 22:42:38][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 70000.000000 | iteration_70000.pth.tar | 8.000000      | 528.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 66.000000               | 0.686325      | 769.315014          | 11.656288            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 629.000000  | 0.000000   | 629.000000 | 629.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 653.0, current episode: 1
[2024-11-19 22:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 653.0, current episode: 2
[2024-11-19 22:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 653.0, current episode: 3
[2024-11-19 22:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 653.0, current episode: 4
[2024-11-19 22:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 653.0, current episode: 5
[2024-11-19 22:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 653.0, current episode: 6
[2024-11-19 22:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 653.0, current episode: 7
[2024-11-19 22:43:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 653.0, current episode: 8
[2024-11-19 22:43:51][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 72000.000000 | iteration_72000.pth.tar | 8.000000      | 584.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 73.000000               | 0.760481      | 767.935392          | 10.519663            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 653.000000  | 0.000000   | 653.000000 | 653.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:45:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 809.0, current episode: 1
[2024-11-19 22:45:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 809.0, current episode: 2
[2024-11-19 22:45:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 809.0, current episode: 3
[2024-11-19 22:45:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 809.0, current episode: 4
[2024-11-19 22:45:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 809.0, current episode: 5
[2024-11-19 22:45:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 809.0, current episode: 6
[2024-11-19 22:45:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 809.0, current episode: 7
[2024-11-19 22:45:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 809.0, current episode: 8
[2024-11-19 22:45:05][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 74000.000000 | iteration_74000.pth.tar | 8.000000      | 1384.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 173.000000              | 1.801473      | 768.260136          | 4.440810             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 809.000000  | 0.000000   | 809.000000 | 809.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:46:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 815.0, current episode: 1
[2024-11-19 22:46:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 815.0, current episode: 2
[2024-11-19 22:46:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 815.0, current episode: 3
[2024-11-19 22:46:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 815.0, current episode: 4
[2024-11-19 22:46:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 815.0, current episode: 5
[2024-11-19 22:46:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 815.0, current episode: 6
[2024-11-19 22:46:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 815.0, current episode: 7
[2024-11-19 22:46:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 815.0, current episode: 8
[2024-11-19 22:46:18][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 76000.000000 | iteration_76000.pth.tar | 8.000000      | 1160.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 145.000000              | 1.500818      | 772.911586          | 5.330425             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 815.000000  | 0.000000   | 815.000000 | 815.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:47:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 226.0, current episode: 1
[2024-11-19 22:47:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 226.0, current episode: 2
[2024-11-19 22:47:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 226.0, current episode: 3
[2024-11-19 22:47:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 226.0, current episode: 4
[2024-11-19 22:47:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 226.0, current episode: 5
[2024-11-19 22:47:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 226.0, current episode: 6
[2024-11-19 22:47:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 226.0, current episode: 7
[2024-11-19 22:47:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 226.0, current episode: 8
[2024-11-19 22:47:30][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 78000.000000 | iteration_78000.pth.tar | 8.000000      | 344.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 43.000000               | 0.451081      | 762.613223          | 17.735191            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 226.000000  | 0.000000   | 226.000000 | 226.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:49:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 22:49:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 22:49:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 22:49:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 22:49:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 22:49:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 22:49:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 22:49:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 22:49:03][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 80000.000000 | iteration_80000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.548255     | 780.601566          | 0.389327             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:50:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 22:50:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 22:50:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 22:50:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 22:50:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 22:50:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 22:50:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 22:50:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 22:50:35][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 82000.000000 | iteration_82000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.419576     | 785.520730          | 0.391781             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:51:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 653.0, current episode: 1
[2024-11-19 22:51:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 653.0, current episode: 2
[2024-11-19 22:51:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 653.0, current episode: 3
[2024-11-19 22:51:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 653.0, current episode: 4
[2024-11-19 22:51:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 653.0, current episode: 5
[2024-11-19 22:51:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 653.0, current episode: 6
[2024-11-19 22:51:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 653.0, current episode: 7
[2024-11-19 22:51:48][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 653.0, current episode: 8
[2024-11-19 22:51:48][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 84000.000000 | iteration_84000.pth.tar | 8.000000      | 560.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 70.000000               | 0.733882      | 763.065008          | 10.900929            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 653.000000  | 0.000000   | 653.000000 | 653.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 22:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 22:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 22:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 22:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 22:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 22:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 22:53:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 22:53:20][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 86000.000000 | iteration_86000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.413007     | 785.773520          | 0.391907             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:54:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 637.0, current episode: 1
[2024-11-19 22:54:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 637.0, current episode: 2
[2024-11-19 22:54:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 637.0, current episode: 3
[2024-11-19 22:54:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 637.0, current episode: 4
[2024-11-19 22:54:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 637.0, current episode: 5
[2024-11-19 22:54:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 637.0, current episode: 6
[2024-11-19 22:54:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 637.0, current episode: 7
[2024-11-19 22:54:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 637.0, current episode: 8
[2024-11-19 22:54:35][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 88000.000000 | iteration_88000.pth.tar | 8.000000      | 1216.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 152.000000              | 1.592139      | 763.752408          | 5.024687             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 637.000000  | 0.000000   | 637.000000 | 637.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:55:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 635.0, current episode: 1
[2024-11-19 22:55:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 635.0, current episode: 2
[2024-11-19 22:55:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 635.0, current episode: 3
[2024-11-19 22:55:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 635.0, current episode: 4
[2024-11-19 22:55:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 635.0, current episode: 5
[2024-11-19 22:55:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 635.0, current episode: 6
[2024-11-19 22:55:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 635.0, current episode: 7
[2024-11-19 22:55:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 635.0, current episode: 8
[2024-11-19 22:55:49][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 90000.000000 | iteration_90000.pth.tar | 8.000000      | 712.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 89.000000               | 0.945302      | 753.198441          | 8.462904             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 635.000000  | 0.000000   | 635.000000 | 635.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:57:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 267.0, current episode: 1
[2024-11-19 22:57:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 267.0, current episode: 2
[2024-11-19 22:57:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 267.0, current episode: 3
[2024-11-19 22:57:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 267.0, current episode: 4
[2024-11-19 22:57:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 267.0, current episode: 5
[2024-11-19 22:57:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 267.0, current episode: 6
[2024-11-19 22:57:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 267.0, current episode: 7
[2024-11-19 22:57:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 267.0, current episode: 8
[2024-11-19 22:57:23][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 92000.000000 | iteration_92000.pth.tar | 8.000000      | 16040.000000  |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.915776     | 766.885236          | 0.382486             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 267.000000  | 0.000000   | 267.000000 | 267.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:58:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 622.0, current episode: 1
[2024-11-19 22:58:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 622.0, current episode: 2
[2024-11-19 22:58:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 622.0, current episode: 3
[2024-11-19 22:58:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 622.0, current episode: 4
[2024-11-19 22:58:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 622.0, current episode: 5
[2024-11-19 22:58:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 622.0, current episode: 6
[2024-11-19 22:58:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 622.0, current episode: 7
[2024-11-19 22:58:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 622.0, current episode: 8
[2024-11-19 22:58:36][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 94000.000000 | iteration_94000.pth.tar | 8.000000      | 640.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 80.000000               | 0.828112      | 772.842649          | 9.660533             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 622.000000  | 0.000000   | 622.000000 | 622.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 22:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 231.0, current episode: 1
[2024-11-19 22:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 231.0, current episode: 2
[2024-11-19 22:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 231.0, current episode: 3
[2024-11-19 22:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 231.0, current episode: 4
[2024-11-19 22:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 231.0, current episode: 5
[2024-11-19 22:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 231.0, current episode: 6
[2024-11-19 22:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 231.0, current episode: 7
[2024-11-19 22:59:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 231.0, current episode: 8
[2024-11-19 22:59:49][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 96000.000000 | iteration_96000.pth.tar | 8.000000      | 320.000000    |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 40.000000               | 0.434456      | 736.552708          | 18.413818            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 231.000000  | 0.000000   | 231.000000 | 231.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:01:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1431.0, current episode: 1
[2024-11-19 23:01:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1431.0, current episode: 2
[2024-11-19 23:01:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1431.0, current episode: 3
[2024-11-19 23:01:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1431.0, current episode: 4
[2024-11-19 23:01:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1431.0, current episode: 5
[2024-11-19 23:01:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1431.0, current episode: 6
[2024-11-19 23:01:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1431.0, current episode: 7
[2024-11-19 23:01:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1431.0, current episode: 8
[2024-11-19 23:01:03][interaction_serial_evaluator.py:279][INFO] 
+-------+--------------+-------------------------+---------------+---------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count |
+-------+--------------+-------------------------+---------------+---------------+
| Value | 98000.000000 | iteration_98000.pth.tar | 8.000000      | 1320.000000   |
+-------+--------------+-------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 165.000000              | 1.735562      | 760.560623          | 4.609458             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1431.000000 | 0.000000   | 1431.000000 | 1431.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:02:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 607.0, current episode: 1
[2024-11-19 23:02:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 607.0, current episode: 2
[2024-11-19 23:02:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 607.0, current episode: 3
[2024-11-19 23:02:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 607.0, current episode: 4
[2024-11-19 23:02:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 607.0, current episode: 5
[2024-11-19 23:02:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 607.0, current episode: 6
[2024-11-19 23:02:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 607.0, current episode: 7
[2024-11-19 23:02:16][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 607.0, current episode: 8
[2024-11-19 23:02:16][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 100000.000000 | iteration_100000.pth.tar | 8.000000      | 600.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 75.000000               | 0.774392      | 774.801265          | 10.330684            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 607.000000  | 0.000000   | 607.000000 | 607.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:03:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 23:03:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 23:03:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 23:03:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 23:03:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 23:03:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 23:03:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 23:03:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 23:03:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 102000.000000 | iteration_102000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.209272     | 793.695096          | 0.395858             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:05:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 23:05:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 23:05:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 23:05:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 23:05:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 23:05:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 23:05:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 23:05:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 23:05:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 104000.000000 | iteration_104000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.453556     | 784.215711          | 0.391130             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:06:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 139.0, current episode: 1
[2024-11-19 23:06:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 139.0, current episode: 2
[2024-11-19 23:06:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 139.0, current episode: 3
[2024-11-19 23:06:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 139.0, current episode: 4
[2024-11-19 23:06:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 139.0, current episode: 5
[2024-11-19 23:06:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 139.0, current episode: 6
[2024-11-19 23:06:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 139.0, current episode: 7
[2024-11-19 23:06:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 139.0, current episode: 8
[2024-11-19 23:06:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 106000.000000 | iteration_106000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.225960     | 793.040231          | 0.395531             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 139.000000  | 0.000000   | 139.000000 | 139.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 139.0, current episode: 1
[2024-11-19 23:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 139.0, current episode: 2
[2024-11-19 23:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 139.0, current episode: 3
[2024-11-19 23:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 139.0, current episode: 4
[2024-11-19 23:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 139.0, current episode: 5
[2024-11-19 23:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 139.0, current episode: 6
[2024-11-19 23:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 139.0, current episode: 7
[2024-11-19 23:08:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 139.0, current episode: 8
[2024-11-19 23:08:21][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 108000.000000 | iteration_108000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.272099     | 791.235264          | 0.394631             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 139.000000  | 0.000000   | 139.000000 | 139.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:09:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 818.0, current episode: 1
[2024-11-19 23:09:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 818.0, current episode: 2
[2024-11-19 23:09:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 818.0, current episode: 3
[2024-11-19 23:09:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 818.0, current episode: 4
[2024-11-19 23:09:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 818.0, current episode: 5
[2024-11-19 23:09:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 818.0, current episode: 6
[2024-11-19 23:09:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 818.0, current episode: 7
[2024-11-19 23:09:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 818.0, current episode: 8
[2024-11-19 23:09:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 110000.000000 | iteration_110000.pth.tar | 8.000000      | 1032.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 129.000000              | 1.333103      | 774.133904          | 6.001038             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 818.000000  | 0.000000   | 818.000000 | 818.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:10:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 231.0, current episode: 1
[2024-11-19 23:10:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 231.0, current episode: 2
[2024-11-19 23:10:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 231.0, current episode: 3
[2024-11-19 23:10:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 231.0, current episode: 4
[2024-11-19 23:10:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 231.0, current episode: 5
[2024-11-19 23:10:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 231.0, current episode: 6
[2024-11-19 23:10:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 231.0, current episode: 7
[2024-11-19 23:10:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 231.0, current episode: 8
[2024-11-19 23:10:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 112000.000000 | iteration_112000.pth.tar | 8.000000      | 320.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 40.000000               | 0.420208      | 761.528530          | 19.038213            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 231.000000  | 0.000000   | 231.000000 | 231.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 809.0, current episode: 1
[2024-11-19 23:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 809.0, current episode: 2
[2024-11-19 23:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 809.0, current episode: 3
[2024-11-19 23:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 809.0, current episode: 4
[2024-11-19 23:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 809.0, current episode: 5
[2024-11-19 23:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 809.0, current episode: 6
[2024-11-19 23:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 809.0, current episode: 7
[2024-11-19 23:11:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 809.0, current episode: 8
[2024-11-19 23:11:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 114000.000000 | iteration_114000.pth.tar | 8.000000      | 1376.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 172.000000              | 1.765808      | 779.246621          | 4.530504             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 809.000000  | 0.000000   | 809.000000 | 809.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:13:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 139.0, current episode: 1
[2024-11-19 23:13:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 139.0, current episode: 2
[2024-11-19 23:13:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 139.0, current episode: 3
[2024-11-19 23:13:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 139.0, current episode: 4
[2024-11-19 23:13:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 139.0, current episode: 5
[2024-11-19 23:13:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 139.0, current episode: 6
[2024-11-19 23:13:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 139.0, current episode: 7
[2024-11-19 23:13:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 139.0, current episode: 8
[2024-11-19 23:13:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 116000.000000 | iteration_116000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.534939     | 781.107739          | 0.389580             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 139.000000  | 0.000000   | 139.000000 | 139.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:14:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 650.0, current episode: 1
[2024-11-19 23:14:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 650.0, current episode: 2
[2024-11-19 23:14:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 650.0, current episode: 3
[2024-11-19 23:14:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 650.0, current episode: 4
[2024-11-19 23:14:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 650.0, current episode: 5
[2024-11-19 23:14:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 650.0, current episode: 6
[2024-11-19 23:14:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 650.0, current episode: 7
[2024-11-19 23:14:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 650.0, current episode: 8
[2024-11-19 23:14:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 118000.000000 | iteration_118000.pth.tar | 8.000000      | 704.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 88.000000               | 0.904760      | 778.107001          | 8.842125             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 650.000000  | 0.000000   | 650.000000 | 650.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:15:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 237.0, current episode: 1
[2024-11-19 23:15:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 237.0, current episode: 2
[2024-11-19 23:15:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 237.0, current episode: 3
[2024-11-19 23:15:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 237.0, current episode: 4
[2024-11-19 23:15:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 237.0, current episode: 5
[2024-11-19 23:15:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 237.0, current episode: 6
[2024-11-19 23:15:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 237.0, current episode: 7
[2024-11-19 23:15:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 237.0, current episode: 8
[2024-11-19 23:15:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 120000.000000 | iteration_120000.pth.tar | 8.000000      | 248.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 31.000000               | 0.332970      | 744.812593          | 24.026213            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 237.000000  | 0.000000   | 237.000000 | 237.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1570.0, current episode: 1
[2024-11-19 23:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1570.0, current episode: 2
[2024-11-19 23:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1570.0, current episode: 3
[2024-11-19 23:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1570.0, current episode: 4
[2024-11-19 23:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1570.0, current episode: 5
[2024-11-19 23:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1570.0, current episode: 6
[2024-11-19 23:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1570.0, current episode: 7
[2024-11-19 23:17:05][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1570.0, current episode: 8
[2024-11-19 23:17:05][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 122000.000000 | iteration_122000.pth.tar | 8.000000      | 1840.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 230.000000              | 2.381498      | 772.622914          | 3.359230             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1570.000000 | 0.000000   | 1570.000000 | 1570.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 23:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 23:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 23:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 23:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 23:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 23:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 23:18:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 23:18:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 124000.000000 | iteration_124000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.296896     | 790.268603          | 0.394149             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1684.0, current episode: 1
[2024-11-19 23:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1684.0, current episode: 2
[2024-11-19 23:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1684.0, current episode: 3
[2024-11-19 23:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1684.0, current episode: 4
[2024-11-19 23:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1684.0, current episode: 5
[2024-11-19 23:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1684.0, current episode: 6
[2024-11-19 23:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1684.0, current episode: 7
[2024-11-19 23:19:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1684.0, current episode: 8
[2024-11-19 23:19:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 126000.000000 | iteration_126000.pth.tar | 8.000000      | 2312.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 289.000000              | 2.990636      | 773.079739          | 2.675016             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1684.000000 | 0.000000   | 1684.000000 | 1684.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:21:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 23:21:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 23:21:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 23:21:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 23:21:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 23:21:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 23:21:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 23:21:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 23:21:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 128000.000000 | iteration_128000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.262054     | 791.627534          | 0.394827             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:22:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 23:22:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 23:22:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 23:22:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 23:22:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 23:22:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 23:22:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 23:22:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 23:22:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 130000.000000 | iteration_130000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.608428     | 778.322354          | 0.388191             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:24:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1435.0, current episode: 1
[2024-11-19 23:24:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1435.0, current episode: 2
[2024-11-19 23:24:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1435.0, current episode: 3
[2024-11-19 23:24:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1435.0, current episode: 4
[2024-11-19 23:24:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1435.0, current episode: 5
[2024-11-19 23:24:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1435.0, current episode: 6
[2024-11-19 23:24:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1435.0, current episode: 7
[2024-11-19 23:24:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1435.0, current episode: 8
[2024-11-19 23:24:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 132000.000000 | iteration_132000.pth.tar | 8.000000      | 1344.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 168.000000              | 1.767830      | 760.253937          | 4.525321             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1435.000000 | 0.000000   | 1435.000000 | 1435.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 23:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 23:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 23:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 23:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 23:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 23:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 23:25:43][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 23:25:43][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 134000.000000 | iteration_134000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.604385     | 778.475062          | 0.388267             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:26:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1440.0, current episode: 1
[2024-11-19 23:26:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1440.0, current episode: 2
[2024-11-19 23:26:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1440.0, current episode: 3
[2024-11-19 23:26:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1440.0, current episode: 4
[2024-11-19 23:26:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1440.0, current episode: 5
[2024-11-19 23:26:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1440.0, current episode: 6
[2024-11-19 23:26:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1440.0, current episode: 7
[2024-11-19 23:26:57][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1440.0, current episode: 8
[2024-11-19 23:26:57][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 136000.000000 | iteration_136000.pth.tar | 8.000000      | 1200.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 150.000000              | 1.570850      | 763.917675          | 5.092785             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1440.000000 | 0.000000   | 1440.000000 | 1440.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1106.0, current episode: 1
[2024-11-19 23:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1106.0, current episode: 2
[2024-11-19 23:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1106.0, current episode: 3
[2024-11-19 23:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1106.0, current episode: 4
[2024-11-19 23:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1106.0, current episode: 5
[2024-11-19 23:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1106.0, current episode: 6
[2024-11-19 23:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1106.0, current episode: 7
[2024-11-19 23:28:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1106.0, current episode: 8
[2024-11-19 23:28:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 138000.000000 | iteration_138000.pth.tar | 8.000000      | 1392.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 174.000000              | 1.815573      | 766.700009          | 4.406322             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1106.000000 | 0.000000   | 1106.000000 | 1106.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 23:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 23:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 23:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 23:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 23:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 23:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 23:29:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 23:29:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 140000.000000 | iteration_140000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.263677     | 791.564123          | 0.394795             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 652.0, current episode: 1
[2024-11-19 23:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 652.0, current episode: 2
[2024-11-19 23:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 652.0, current episode: 3
[2024-11-19 23:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 652.0, current episode: 4
[2024-11-19 23:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 652.0, current episode: 5
[2024-11-19 23:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 652.0, current episode: 6
[2024-11-19 23:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 652.0, current episode: 7
[2024-11-19 23:30:55][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 652.0, current episode: 8
[2024-11-19 23:30:55][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 142000.000000 | iteration_142000.pth.tar | 8.000000      | 536.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 67.000000               | 0.707585      | 757.506317          | 11.306064            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 652.000000  | 0.000000   | 652.000000 | 652.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:32:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1067.0, current episode: 1
[2024-11-19 23:32:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1067.0, current episode: 2
[2024-11-19 23:32:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1067.0, current episode: 3
[2024-11-19 23:32:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1067.0, current episode: 4
[2024-11-19 23:32:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1067.0, current episode: 5
[2024-11-19 23:32:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1067.0, current episode: 6
[2024-11-19 23:32:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1067.0, current episode: 7
[2024-11-19 23:32:08][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1067.0, current episode: 8
[2024-11-19 23:32:08][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 144000.000000 | iteration_144000.pth.tar | 8.000000      | 1080.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 135.000000              | 1.412931      | 764.368555          | 5.661989             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1067.000000 | 0.000000   | 1067.000000 | 1067.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 721.0, current episode: 1
[2024-11-19 23:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 721.0, current episode: 2
[2024-11-19 23:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 721.0, current episode: 3
[2024-11-19 23:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 721.0, current episode: 4
[2024-11-19 23:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 721.0, current episode: 5
[2024-11-19 23:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 721.0, current episode: 6
[2024-11-19 23:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 721.0, current episode: 7
[2024-11-19 23:33:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 721.0, current episode: 8
[2024-11-19 23:33:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 146000.000000 | iteration_146000.pth.tar | 8.000000      | 1344.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 168.000000              | 1.749081      | 768.403567          | 4.573831             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 721.000000  | 0.000000   | 721.000000 | 721.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:34:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1430.0, current episode: 1
[2024-11-19 23:34:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1430.0, current episode: 2
[2024-11-19 23:34:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1430.0, current episode: 3
[2024-11-19 23:34:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1430.0, current episode: 4
[2024-11-19 23:34:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1430.0, current episode: 5
[2024-11-19 23:34:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1430.0, current episode: 6
[2024-11-19 23:34:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1430.0, current episode: 7
[2024-11-19 23:34:35][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1430.0, current episode: 8
[2024-11-19 23:34:35][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 148000.000000 | iteration_148000.pth.tar | 8.000000      | 1584.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 198.000000              | 2.044283      | 774.843648          | 3.913352             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1430.000000 | 0.000000   | 1430.000000 | 1430.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:35:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 650.0, current episode: 1
[2024-11-19 23:35:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 650.0, current episode: 2
[2024-11-19 23:35:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 650.0, current episode: 3
[2024-11-19 23:35:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 650.0, current episode: 4
[2024-11-19 23:35:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 650.0, current episode: 5
[2024-11-19 23:35:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 650.0, current episode: 6
[2024-11-19 23:35:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 650.0, current episode: 7
[2024-11-19 23:35:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 650.0, current episode: 8
[2024-11-19 23:35:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 150000.000000 | iteration_150000.pth.tar | 8.000000      | 584.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 73.000000               | 0.752426      | 776.155908          | 10.632273            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 650.000000  | 0.000000   | 650.000000 | 650.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:37:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1263.0, current episode: 1
[2024-11-19 23:37:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1263.0, current episode: 2
[2024-11-19 23:37:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1263.0, current episode: 3
[2024-11-19 23:37:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1263.0, current episode: 4
[2024-11-19 23:37:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1263.0, current episode: 5
[2024-11-19 23:37:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1263.0, current episode: 6
[2024-11-19 23:37:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1263.0, current episode: 7
[2024-11-19 23:37:18][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1263.0, current episode: 8
[2024-11-19 23:37:18][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 152000.000000 | iteration_152000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.216205     | 793.422914          | 0.395722             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1263.000000 | 0.000000   | 1263.000000 | 1263.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-19 23:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-19 23:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-19 23:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-19 23:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-19 23:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-19 23:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-19 23:38:50][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-19 23:38:50][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 154000.000000 | iteration_154000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.160822     | 795.602494          | 0.396809             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1436.0, current episode: 1
[2024-11-19 23:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1436.0, current episode: 2
[2024-11-19 23:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1436.0, current episode: 3
[2024-11-19 23:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1436.0, current episode: 4
[2024-11-19 23:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1436.0, current episode: 5
[2024-11-19 23:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1436.0, current episode: 6
[2024-11-19 23:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1436.0, current episode: 7
[2024-11-19 23:40:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1436.0, current episode: 8
[2024-11-19 23:40:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 156000.000000 | iteration_156000.pth.tar | 8.000000      | 1688.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 211.000000              | 2.176634      | 775.509400          | 3.675400             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1436.000000 | 0.000000   | 1436.000000 | 1436.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:41:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 639.0, current episode: 1
[2024-11-19 23:41:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 639.0, current episode: 2
[2024-11-19 23:41:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 639.0, current episode: 3
[2024-11-19 23:41:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 639.0, current episode: 4
[2024-11-19 23:41:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 639.0, current episode: 5
[2024-11-19 23:41:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 639.0, current episode: 6
[2024-11-19 23:41:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 639.0, current episode: 7
[2024-11-19 23:41:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 639.0, current episode: 8
[2024-11-19 23:41:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 158000.000000 | iteration_158000.pth.tar | 8.000000      | 576.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 72.000000               | 0.748002      | 770.051118          | 10.695154            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 639.000000  | 0.000000   | 639.000000 | 639.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:42:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1242.0, current episode: 1
[2024-11-19 23:42:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1242.0, current episode: 2
[2024-11-19 23:42:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1242.0, current episode: 3
[2024-11-19 23:42:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1242.0, current episode: 4
[2024-11-19 23:42:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1242.0, current episode: 5
[2024-11-19 23:42:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1242.0, current episode: 6
[2024-11-19 23:42:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1242.0, current episode: 7
[2024-11-19 23:42:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1242.0, current episode: 8
[2024-11-19 23:42:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 160000.000000 | iteration_160000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.377653     | 787.136758          | 0.392587             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1242.000000 | 0.000000   | 1242.000000 | 1242.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 809.0, current episode: 1
[2024-11-19 23:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 809.0, current episode: 2
[2024-11-19 23:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 809.0, current episode: 3
[2024-11-19 23:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 809.0, current episode: 4
[2024-11-19 23:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 809.0, current episode: 5
[2024-11-19 23:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 809.0, current episode: 6
[2024-11-19 23:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 809.0, current episode: 7
[2024-11-19 23:44:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 809.0, current episode: 8
[2024-11-19 23:44:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 162000.000000 | iteration_162000.pth.tar | 8.000000      | 1392.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 174.000000              | 1.803243      | 771.942482          | 4.436451             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 809.000000  | 0.000000   | 809.000000 | 809.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1574.0, current episode: 1
[2024-11-19 23:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1574.0, current episode: 2
[2024-11-19 23:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1574.0, current episode: 3
[2024-11-19 23:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1574.0, current episode: 4
[2024-11-19 23:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1574.0, current episode: 5
[2024-11-19 23:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1574.0, current episode: 6
[2024-11-19 23:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1574.0, current episode: 7
[2024-11-19 23:45:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1574.0, current episode: 8
[2024-11-19 23:45:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 164000.000000 | iteration_164000.pth.tar | 8.000000      | 1264.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 158.000000              | 1.640390      | 770.548281          | 4.876888             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1574.000000 | 0.000000   | 1574.000000 | 1574.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 604.0, current episode: 1
[2024-11-19 23:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 604.0, current episode: 2
[2024-11-19 23:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 604.0, current episode: 3
[2024-11-19 23:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 604.0, current episode: 4
[2024-11-19 23:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 604.0, current episode: 5
[2024-11-19 23:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 604.0, current episode: 6
[2024-11-19 23:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 604.0, current episode: 7
[2024-11-19 23:46:27][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 604.0, current episode: 8
[2024-11-19 23:46:27][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 166000.000000 | iteration_166000.pth.tar | 8.000000      | 1192.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 149.000000              | 1.512547      | 788.074428          | 5.289090             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 604.000000  | 0.000000   | 604.000000 | 604.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:47:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 653.0, current episode: 1
[2024-11-19 23:47:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 653.0, current episode: 2
[2024-11-19 23:47:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 653.0, current episode: 3
[2024-11-19 23:47:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 653.0, current episode: 4
[2024-11-19 23:47:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 653.0, current episode: 5
[2024-11-19 23:47:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 653.0, current episode: 6
[2024-11-19 23:47:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 653.0, current episode: 7
[2024-11-19 23:47:39][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 653.0, current episode: 8
[2024-11-19 23:47:39][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 168000.000000 | iteration_168000.pth.tar | 8.000000      | 536.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 67.000000               | 0.696935      | 769.081307          | 11.478825            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 653.000000  | 0.000000   | 653.000000 | 653.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:49:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 23.0, current episode: 1
[2024-11-19 23:49:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 23.0, current episode: 2
[2024-11-19 23:49:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 23.0, current episode: 3
[2024-11-19 23:49:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 23.0, current episode: 4
[2024-11-19 23:49:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 23.0, current episode: 5
[2024-11-19 23:49:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 23.0, current episode: 6
[2024-11-19 23:49:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 23.0, current episode: 7
[2024-11-19 23:49:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 23.0, current episode: 8
[2024-11-19 23:49:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 170000.000000 | iteration_170000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.180948     | 794.809025          | 0.396413             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 23.000000   | 0.000000   | 23.000000  | 23.000000  |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:50:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 652.0, current episode: 1
[2024-11-19 23:50:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 652.0, current episode: 2
[2024-11-19 23:50:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 652.0, current episode: 3
[2024-11-19 23:50:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 652.0, current episode: 4
[2024-11-19 23:50:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 652.0, current episode: 5
[2024-11-19 23:50:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 652.0, current episode: 6
[2024-11-19 23:50:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 652.0, current episode: 7
[2024-11-19 23:50:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 652.0, current episode: 8
[2024-11-19 23:50:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 172000.000000 | iteration_172000.pth.tar | 8.000000      | 528.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 66.000000               | 0.683369      | 772.642418          | 11.706703            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 652.000000  | 0.000000   | 652.000000 | 652.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1771.0, current episode: 1
[2024-11-19 23:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1771.0, current episode: 2
[2024-11-19 23:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1771.0, current episode: 3
[2024-11-19 23:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1771.0, current episode: 4
[2024-11-19 23:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1771.0, current episode: 5
[2024-11-19 23:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1771.0, current episode: 6
[2024-11-19 23:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1771.0, current episode: 7
[2024-11-19 23:51:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1771.0, current episode: 8
[2024-11-19 23:51:54][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 174000.000000 | iteration_174000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.008804     | 801.647121          | 0.399824             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1771.000000 | 0.000000   | 1771.000000 | 1771.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:53:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1692.0, current episode: 1
[2024-11-19 23:53:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1692.0, current episode: 2
[2024-11-19 23:53:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1692.0, current episode: 3
[2024-11-19 23:53:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1692.0, current episode: 4
[2024-11-19 23:53:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1692.0, current episode: 5
[2024-11-19 23:53:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1692.0, current episode: 6
[2024-11-19 23:53:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1692.0, current episode: 7
[2024-11-19 23:53:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1692.0, current episode: 8
[2024-11-19 23:53:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 176000.000000 | iteration_176000.pth.tar | 8.000000      | 1696.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 212.000000              | 2.194141      | 772.967676          | 3.646074             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1692.000000 | 0.000000   | 1692.000000 | 1692.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1863.0, current episode: 1
[2024-11-19 23:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1863.0, current episode: 2
[2024-11-19 23:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1863.0, current episode: 3
[2024-11-19 23:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1863.0, current episode: 4
[2024-11-19 23:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1863.0, current episode: 5
[2024-11-19 23:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1863.0, current episode: 6
[2024-11-19 23:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1863.0, current episode: 7
[2024-11-19 23:54:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1863.0, current episode: 8
[2024-11-19 23:54:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 178000.000000 | iteration_178000.pth.tar | 8.000000      | 1400.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 175.000000              | 1.796448      | 779.315734          | 4.453233             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1863.000000 | 0.000000   | 1863.000000 | 1863.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-19 23:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 738.0, current episode: 1
[2024-11-19 23:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 738.0, current episode: 2
[2024-11-19 23:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 738.0, current episode: 3
[2024-11-19 23:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 738.0, current episode: 4
[2024-11-19 23:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 738.0, current episode: 5
[2024-11-19 23:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 738.0, current episode: 6
[2024-11-19 23:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 738.0, current episode: 7
[2024-11-19 23:55:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 738.0, current episode: 8
[2024-11-19 23:55:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 180000.000000 | iteration_180000.pth.tar | 8.000000      | 1096.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 137.000000              | 1.425629      | 768.783260          | 5.611557             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 738.000000  | 0.000000   | 738.000000 | 738.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:56:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 652.0, current episode: 1
[2024-11-19 23:56:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 652.0, current episode: 2
[2024-11-19 23:56:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 652.0, current episode: 3
[2024-11-19 23:56:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 652.0, current episode: 4
[2024-11-19 23:56:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 652.0, current episode: 5
[2024-11-19 23:56:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 652.0, current episode: 6
[2024-11-19 23:56:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 652.0, current episode: 7
[2024-11-19 23:56:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 652.0, current episode: 8
[2024-11-19 23:56:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 182000.000000 | iteration_182000.pth.tar | 8.000000      | 536.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 67.000000               | 0.682895      | 784.893788          | 11.714833            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 652.000000  | 0.000000   | 652.000000 | 652.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:57:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 653.0, current episode: 1
[2024-11-19 23:57:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 653.0, current episode: 2
[2024-11-19 23:57:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 653.0, current episode: 3
[2024-11-19 23:57:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 653.0, current episode: 4
[2024-11-19 23:57:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 653.0, current episode: 5
[2024-11-19 23:57:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 653.0, current episode: 6
[2024-11-19 23:57:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 653.0, current episode: 7
[2024-11-19 23:57:53][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 653.0, current episode: 8
[2024-11-19 23:57:53][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 184000.000000 | iteration_184000.pth.tar | 8.000000      | 536.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 67.000000               | 0.692696      | 773.788640          | 11.549084            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 653.000000  | 0.000000   | 653.000000 | 653.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-19 23:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 139.0, current episode: 1
[2024-11-19 23:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 139.0, current episode: 2
[2024-11-19 23:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 139.0, current episode: 3
[2024-11-19 23:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 139.0, current episode: 4
[2024-11-19 23:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 139.0, current episode: 5
[2024-11-19 23:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 139.0, current episode: 6
[2024-11-19 23:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 139.0, current episode: 7
[2024-11-19 23:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 139.0, current episode: 8
[2024-11-19 23:59:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 186000.000000 | iteration_186000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.117614     | 797.311269          | 0.397661             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 139.000000  | 0.000000   | 139.000000 | 139.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 139.0, current episode: 1
[2024-11-20 00:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 139.0, current episode: 2
[2024-11-20 00:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 139.0, current episode: 3
[2024-11-20 00:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 139.0, current episode: 4
[2024-11-20 00:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 139.0, current episode: 5
[2024-11-20 00:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 139.0, current episode: 6
[2024-11-20 00:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 139.0, current episode: 7
[2024-11-20 00:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 139.0, current episode: 8
[2024-11-20 00:00:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 188000.000000 | iteration_188000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 19.966311     | 803.353228          | 0.400675             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 139.000000  | 0.000000   | 139.000000 | 139.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:02:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1705.0, current episode: 1
[2024-11-20 00:02:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1705.0, current episode: 2
[2024-11-20 00:02:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1705.0, current episode: 3
[2024-11-20 00:02:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1705.0, current episode: 4
[2024-11-20 00:02:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1705.0, current episode: 5
[2024-11-20 00:02:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1705.0, current episode: 6
[2024-11-20 00:02:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1705.0, current episode: 7
[2024-11-20 00:02:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1705.0, current episode: 8
[2024-11-20 00:02:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 190000.000000 | iteration_190000.pth.tar | 8.000000      | 1368.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 171.000000              | 1.742282      | 785.177180          | 4.591679             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1705.000000 | 0.000000   | 1705.000000 | 1705.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1334.0, current episode: 1
[2024-11-20 00:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1334.0, current episode: 2
[2024-11-20 00:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1334.0, current episode: 3
[2024-11-20 00:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1334.0, current episode: 4
[2024-11-20 00:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1334.0, current episode: 5
[2024-11-20 00:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1334.0, current episode: 6
[2024-11-20 00:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1334.0, current episode: 7
[2024-11-20 00:03:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1334.0, current episode: 8
[2024-11-20 00:03:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 192000.000000 | iteration_192000.pth.tar | 8.000000      | 1144.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 143.000000              | 1.470748      | 777.835524          | 5.439409             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1334.000000 | 0.000000   | 1334.000000 | 1334.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:04:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -122.0, current episode: 1
[2024-11-20 00:04:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -122.0, current episode: 2
[2024-11-20 00:04:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -122.0, current episode: 3
[2024-11-20 00:04:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -122.0, current episode: 4
[2024-11-20 00:04:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -122.0, current episode: 5
[2024-11-20 00:04:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -122.0, current episode: 6
[2024-11-20 00:04:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -122.0, current episode: 7
[2024-11-20 00:04:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -122.0, current episode: 8
[2024-11-20 00:04:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 194000.000000 | iteration_194000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 19.923708     | 805.071016          | 0.401532             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | -122.000000 | 0.000000   | -122.000000 | -122.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:05:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 651.0, current episode: 1
[2024-11-20 00:05:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 651.0, current episode: 2
[2024-11-20 00:05:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 651.0, current episode: 3
[2024-11-20 00:05:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 651.0, current episode: 4
[2024-11-20 00:05:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 651.0, current episode: 5
[2024-11-20 00:05:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 651.0, current episode: 6
[2024-11-20 00:05:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 651.0, current episode: 7
[2024-11-20 00:05:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 651.0, current episode: 8
[2024-11-20 00:05:54][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 196000.000000 | iteration_196000.pth.tar | 8.000000      | 536.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 67.000000               | 0.687918      | 779.162152          | 11.629286            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 651.000000  | 0.000000   | 651.000000 | 651.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:07:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1035.0, current episode: 1
[2024-11-20 00:07:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1035.0, current episode: 2
[2024-11-20 00:07:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1035.0, current episode: 3
[2024-11-20 00:07:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1035.0, current episode: 4
[2024-11-20 00:07:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1035.0, current episode: 5
[2024-11-20 00:07:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1035.0, current episode: 6
[2024-11-20 00:07:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1035.0, current episode: 7
[2024-11-20 00:07:06][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1035.0, current episode: 8
[2024-11-20 00:07:06][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 198000.000000 | iteration_198000.pth.tar | 8.000000      | 1464.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 183.000000              | 1.846073      | 793.034664          | 4.333523             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1035.000000 | 0.000000   | 1035.000000 | 1035.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 131.0, current episode: 1
[2024-11-20 00:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 131.0, current episode: 2
[2024-11-20 00:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 131.0, current episode: 3
[2024-11-20 00:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 131.0, current episode: 4
[2024-11-20 00:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 131.0, current episode: 5
[2024-11-20 00:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 131.0, current episode: 6
[2024-11-20 00:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 131.0, current episode: 7
[2024-11-20 00:08:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 131.0, current episode: 8
[2024-11-20 00:08:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 200000.000000 | iteration_200000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.013694     | 801.451254          | 0.399726             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 131.000000  | 0.000000   | 131.000000 | 131.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1695.0, current episode: 1
[2024-11-20 00:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1695.0, current episode: 2
[2024-11-20 00:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1695.0, current episode: 3
[2024-11-20 00:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1695.0, current episode: 4
[2024-11-20 00:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1695.0, current episode: 5
[2024-11-20 00:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1695.0, current episode: 6
[2024-11-20 00:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1695.0, current episode: 7
[2024-11-20 00:09:49][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1695.0, current episode: 8
[2024-11-20 00:09:49][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 202000.000000 | iteration_202000.pth.tar | 8.000000      | 1384.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 173.000000              | 1.770725      | 781.600541          | 4.517922             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1695.000000 | 0.000000   | 1695.000000 | 1695.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:11:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-20 00:11:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-20 00:11:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-20 00:11:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-20 00:11:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-20 00:11:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-20 00:11:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-20 00:11:19][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-20 00:11:19][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 204000.000000 | iteration_204000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 19.788525     | 810.570759          | 0.404275             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:12:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1434.0, current episode: 1
[2024-11-20 00:12:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1434.0, current episode: 2
[2024-11-20 00:12:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1434.0, current episode: 3
[2024-11-20 00:12:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1434.0, current episode: 4
[2024-11-20 00:12:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1434.0, current episode: 5
[2024-11-20 00:12:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1434.0, current episode: 6
[2024-11-20 00:12:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1434.0, current episode: 7
[2024-11-20 00:12:30][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1434.0, current episode: 8
[2024-11-20 00:12:30][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 206000.000000 | iteration_206000.pth.tar | 8.000000      | 1240.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 155.000000              | 1.598388      | 775.781621          | 5.005043             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1434.000000 | 0.000000   | 1434.000000 | 1434.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-20 00:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-20 00:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-20 00:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-20 00:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-20 00:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-20 00:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-20 00:14:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-20 00:14:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 208000.000000 | iteration_208000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 23.193382     | 691.576588          | 0.344926             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:15:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 267.0, current episode: 1
[2024-11-20 00:15:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 267.0, current episode: 2
[2024-11-20 00:15:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 267.0, current episode: 3
[2024-11-20 00:15:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 267.0, current episode: 4
[2024-11-20 00:15:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 267.0, current episode: 5
[2024-11-20 00:15:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 267.0, current episode: 6
[2024-11-20 00:15:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 267.0, current episode: 7
[2024-11-20 00:15:46][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 267.0, current episode: 8
[2024-11-20 00:15:46][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 210000.000000 | iteration_210000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 22.485557     | 713.346792          | 0.355784             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 267.000000  | 0.000000   | 267.000000 | 267.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:17:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 626.0, current episode: 1
[2024-11-20 00:17:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 626.0, current episode: 2
[2024-11-20 00:17:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 626.0, current episode: 3
[2024-11-20 00:17:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 626.0, current episode: 4
[2024-11-20 00:17:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 626.0, current episode: 5
[2024-11-20 00:17:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 626.0, current episode: 6
[2024-11-20 00:17:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 626.0, current episode: 7
[2024-11-20 00:17:04][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 626.0, current episode: 8
[2024-11-20 00:17:04][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 212000.000000 | iteration_212000.pth.tar | 8.000000      | 520.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 65.000000               | 0.727768      | 714.513003          | 10.992508            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 626.000000  | 0.000000   | 626.000000 | 626.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 654.0, current episode: 1
[2024-11-20 00:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 654.0, current episode: 2
[2024-11-20 00:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 654.0, current episode: 3
[2024-11-20 00:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 654.0, current episode: 4
[2024-11-20 00:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 654.0, current episode: 5
[2024-11-20 00:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 654.0, current episode: 6
[2024-11-20 00:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 654.0, current episode: 7
[2024-11-20 00:18:20][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 654.0, current episode: 8
[2024-11-20 00:18:20][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 214000.000000 | iteration_214000.pth.tar | 8.000000      | 544.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 68.000000               | 0.759886      | 715.896609          | 10.527891            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 654.000000  | 0.000000   | 654.000000 | 654.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:19:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 620.0, current episode: 1
[2024-11-20 00:19:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 620.0, current episode: 2
[2024-11-20 00:19:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 620.0, current episode: 3
[2024-11-20 00:19:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 620.0, current episode: 4
[2024-11-20 00:19:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 620.0, current episode: 5
[2024-11-20 00:19:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 620.0, current episode: 6
[2024-11-20 00:19:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 620.0, current episode: 7
[2024-11-20 00:19:37][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 620.0, current episode: 8
[2024-11-20 00:19:37][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 216000.000000 | iteration_216000.pth.tar | 8.000000      | 496.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 62.000000               | 0.678583      | 730.935261          | 11.789278            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 620.000000  | 0.000000   | 620.000000 | 620.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 267.0, current episode: 1
[2024-11-20 00:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 267.0, current episode: 2
[2024-11-20 00:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 267.0, current episode: 3
[2024-11-20 00:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 267.0, current episode: 4
[2024-11-20 00:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 267.0, current episode: 5
[2024-11-20 00:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 267.0, current episode: 6
[2024-11-20 00:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 267.0, current episode: 7
[2024-11-20 00:21:15][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 267.0, current episode: 8
[2024-11-20 00:21:15][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 218000.000000 | iteration_218000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 23.227393     | 690.563941          | 0.344421             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 267.000000  | 0.000000   | 267.000000 | 267.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1706.0, current episode: 1
[2024-11-20 00:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1706.0, current episode: 2
[2024-11-20 00:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1706.0, current episode: 3
[2024-11-20 00:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1706.0, current episode: 4
[2024-11-20 00:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1706.0, current episode: 5
[2024-11-20 00:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1706.0, current episode: 6
[2024-11-20 00:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1706.0, current episode: 7
[2024-11-20 00:22:31][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1706.0, current episode: 8
[2024-11-20 00:22:31][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 220000.000000 | iteration_220000.pth.tar | 8.000000      | 1328.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 166.000000              | 1.969504      | 674.281566          | 4.061937             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1706.000000 | 0.000000   | 1706.000000 | 1706.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1687.0, current episode: 1
[2024-11-20 00:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1687.0, current episode: 2
[2024-11-20 00:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1687.0, current episode: 3
[2024-11-20 00:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1687.0, current episode: 4
[2024-11-20 00:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1687.0, current episode: 5
[2024-11-20 00:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1687.0, current episode: 6
[2024-11-20 00:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1687.0, current episode: 7
[2024-11-20 00:23:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1687.0, current episode: 8
[2024-11-20 00:23:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 222000.000000 | iteration_222000.pth.tar | 8.000000      | 1728.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 216.000000              | 2.523752      | 684.694794          | 3.169883             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1687.000000 | 0.000000   | 1687.000000 | 1687.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:25:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1431.0, current episode: 1
[2024-11-20 00:25:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1431.0, current episode: 2
[2024-11-20 00:25:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1431.0, current episode: 3
[2024-11-20 00:25:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1431.0, current episode: 4
[2024-11-20 00:25:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1431.0, current episode: 5
[2024-11-20 00:25:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1431.0, current episode: 6
[2024-11-20 00:25:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1431.0, current episode: 7
[2024-11-20 00:25:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1431.0, current episode: 8
[2024-11-20 00:25:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 224000.000000 | iteration_224000.pth.tar | 8.000000      | 1360.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 170.000000              | 2.106505      | 645.619191          | 3.797760             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1431.000000 | 0.000000   | 1431.000000 | 1431.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:27:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-20 00:27:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-20 00:27:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-20 00:27:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-20 00:27:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-20 00:27:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-20 00:27:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-20 00:27:00][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-20 00:27:00][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 226000.000000 | iteration_226000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 23.077336     | 695.054220          | 0.346660             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:28:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 139.0, current episode: 1
[2024-11-20 00:28:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 139.0, current episode: 2
[2024-11-20 00:28:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 139.0, current episode: 3
[2024-11-20 00:28:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 139.0, current episode: 4
[2024-11-20 00:28:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 139.0, current episode: 5
[2024-11-20 00:28:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 139.0, current episode: 6
[2024-11-20 00:28:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 139.0, current episode: 7
[2024-11-20 00:28:34][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 139.0, current episode: 8
[2024-11-20 00:28:34][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 228000.000000 | iteration_228000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.494710     | 782.640976          | 0.390345             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 139.000000  | 0.000000   | 139.000000 | 139.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:29:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1849.0, current episode: 1
[2024-11-20 00:29:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1849.0, current episode: 2
[2024-11-20 00:29:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1849.0, current episode: 3
[2024-11-20 00:29:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1849.0, current episode: 4
[2024-11-20 00:29:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1849.0, current episode: 5
[2024-11-20 00:29:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1849.0, current episode: 6
[2024-11-20 00:29:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1849.0, current episode: 7
[2024-11-20 00:29:47][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1849.0, current episode: 8
[2024-11-20 00:29:47][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 230000.000000 | iteration_230000.pth.tar | 8.000000      | 1656.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 207.000000              | 2.266822      | 730.538293          | 3.529170             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1849.000000 | 0.000000   | 1849.000000 | 1849.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:31:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 568.0, current episode: 1
[2024-11-20 00:31:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 568.0, current episode: 2
[2024-11-20 00:31:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 568.0, current episode: 3
[2024-11-20 00:31:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 568.0, current episode: 4
[2024-11-20 00:31:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 568.0, current episode: 5
[2024-11-20 00:31:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 568.0, current episode: 6
[2024-11-20 00:31:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 568.0, current episode: 7
[2024-11-20 00:31:09][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 568.0, current episode: 8
[2024-11-20 00:31:09][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 232000.000000 | iteration_232000.pth.tar | 8.000000      | 824.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 103.000000              | 1.234412      | 667.524448          | 6.480820             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 568.000000  | 0.000000   | 568.000000 | 568.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:32:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1332.0, current episode: 1
[2024-11-20 00:32:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1332.0, current episode: 2
[2024-11-20 00:32:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1332.0, current episode: 3
[2024-11-20 00:32:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1332.0, current episode: 4
[2024-11-20 00:32:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1332.0, current episode: 5
[2024-11-20 00:32:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1332.0, current episode: 6
[2024-11-20 00:32:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1332.0, current episode: 7
[2024-11-20 00:32:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1332.0, current episode: 8
[2024-11-20 00:32:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 234000.000000 | iteration_234000.pth.tar | 8.000000      | 1056.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 132.000000              | 1.375172      | 767.903732          | 5.817453             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1332.000000 | 0.000000   | 1332.000000 | 1332.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:33:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1654.0, current episode: 1
[2024-11-20 00:33:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1654.0, current episode: 2
[2024-11-20 00:33:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1654.0, current episode: 3
[2024-11-20 00:33:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1654.0, current episode: 4
[2024-11-20 00:33:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1654.0, current episode: 5
[2024-11-20 00:33:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1654.0, current episode: 6
[2024-11-20 00:33:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1654.0, current episode: 7
[2024-11-20 00:33:36][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1654.0, current episode: 8
[2024-11-20 00:33:36][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 236000.000000 | iteration_236000.pth.tar | 8.000000      | 1672.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 209.000000              | 2.173523      | 769.258123          | 3.680661             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1654.000000 | 0.000000   | 1654.000000 | 1654.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:34:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1920.0, current episode: 1
[2024-11-20 00:34:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1920.0, current episode: 2
[2024-11-20 00:34:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1920.0, current episode: 3
[2024-11-20 00:34:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1920.0, current episode: 4
[2024-11-20 00:34:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1920.0, current episode: 5
[2024-11-20 00:34:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1920.0, current episode: 6
[2024-11-20 00:34:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1920.0, current episode: 7
[2024-11-20 00:34:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1920.0, current episode: 8
[2024-11-20 00:34:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 238000.000000 | iteration_238000.pth.tar | 8.000000      | 1696.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 212.000000              | 2.235624      | 758.624860          | 3.578419             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1920.000000 | 0.000000   | 1920.000000 | 1920.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1573.0, current episode: 1
[2024-11-20 00:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1573.0, current episode: 2
[2024-11-20 00:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1573.0, current episode: 3
[2024-11-20 00:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1573.0, current episode: 4
[2024-11-20 00:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1573.0, current episode: 5
[2024-11-20 00:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1573.0, current episode: 6
[2024-11-20 00:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1573.0, current episode: 7
[2024-11-20 00:36:03][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1573.0, current episode: 8
[2024-11-20 00:36:03][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 240000.000000 | iteration_240000.pth.tar | 8.000000      | 1512.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 189.000000              | 1.943808      | 777.854476          | 4.115632             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1573.000000 | 0.000000   | 1573.000000 | 1573.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:37:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 649.0, current episode: 1
[2024-11-20 00:37:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 649.0, current episode: 2
[2024-11-20 00:37:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 649.0, current episode: 3
[2024-11-20 00:37:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 649.0, current episode: 4
[2024-11-20 00:37:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 649.0, current episode: 5
[2024-11-20 00:37:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 649.0, current episode: 6
[2024-11-20 00:37:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 649.0, current episode: 7
[2024-11-20 00:37:14][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 649.0, current episode: 8
[2024-11-20 00:37:14][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 242000.000000 | iteration_242000.pth.tar | 8.000000      | 688.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 86.000000               | 0.879288      | 782.451293          | 9.098271             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 649.000000  | 0.000000   | 649.000000 | 649.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:38:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -415.0, current episode: 1
[2024-11-20 00:38:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -415.0, current episode: 2
[2024-11-20 00:38:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -415.0, current episode: 3
[2024-11-20 00:38:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -415.0, current episode: 4
[2024-11-20 00:38:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -415.0, current episode: 5
[2024-11-20 00:38:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -415.0, current episode: 6
[2024-11-20 00:38:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -415.0, current episode: 7
[2024-11-20 00:38:45][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -415.0, current episode: 8
[2024-11-20 00:38:45][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 244000.000000 | iteration_244000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 19.937844     | 804.500244          | 0.401247             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | -415.000000 | 0.000000   | -415.000000 | -415.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1945.0, current episode: 1
[2024-11-20 00:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1945.0, current episode: 2
[2024-11-20 00:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1945.0, current episode: 3
[2024-11-20 00:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1945.0, current episode: 4
[2024-11-20 00:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1945.0, current episode: 5
[2024-11-20 00:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1945.0, current episode: 6
[2024-11-20 00:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1945.0, current episode: 7
[2024-11-20 00:39:56][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1945.0, current episode: 8
[2024-11-20 00:39:56][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 246000.000000 | iteration_246000.pth.tar | 8.000000      | 1680.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 210.000000              | 2.148846      | 781.815103          | 3.722929             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1945.000000 | 0.000000   | 1945.000000 | 1945.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:41:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1689.0, current episode: 1
[2024-11-20 00:41:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1689.0, current episode: 2
[2024-11-20 00:41:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1689.0, current episode: 3
[2024-11-20 00:41:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1689.0, current episode: 4
[2024-11-20 00:41:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1689.0, current episode: 5
[2024-11-20 00:41:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1689.0, current episode: 6
[2024-11-20 00:41:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1689.0, current episode: 7
[2024-11-20 00:41:07][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1689.0, current episode: 8
[2024-11-20 00:41:07][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 248000.000000 | iteration_248000.pth.tar | 8.000000      | 1416.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 177.000000              | 1.815604      | 779.905763          | 4.406247             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1689.000000 | 0.000000   | 1689.000000 | 1689.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 608.0, current episode: 1
[2024-11-20 00:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 608.0, current episode: 2
[2024-11-20 00:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 608.0, current episode: 3
[2024-11-20 00:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 608.0, current episode: 4
[2024-11-20 00:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 608.0, current episode: 5
[2024-11-20 00:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 608.0, current episode: 6
[2024-11-20 00:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 608.0, current episode: 7
[2024-11-20 00:42:17][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 608.0, current episode: 8
[2024-11-20 00:42:17][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 250000.000000 | iteration_250000.pth.tar | 8.000000      | 504.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 63.000000               | 0.652862      | 771.985137          | 12.253732            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 608.000000  | 0.000000   | 608.000000 | 608.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:43:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1704.0, current episode: 1
[2024-11-20 00:43:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1704.0, current episode: 2
[2024-11-20 00:43:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1704.0, current episode: 3
[2024-11-20 00:43:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1704.0, current episode: 4
[2024-11-20 00:43:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1704.0, current episode: 5
[2024-11-20 00:43:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1704.0, current episode: 6
[2024-11-20 00:43:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1704.0, current episode: 7
[2024-11-20 00:43:28][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1704.0, current episode: 8
[2024-11-20 00:43:28][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 252000.000000 | iteration_252000.pth.tar | 8.000000      | 1304.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 163.000000              | 1.652740      | 788.992823          | 4.840447             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1704.000000 | 0.000000   | 1704.000000 | 1704.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 610.0, current episode: 1
[2024-11-20 00:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 610.0, current episode: 2
[2024-11-20 00:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 610.0, current episode: 3
[2024-11-20 00:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 610.0, current episode: 4
[2024-11-20 00:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 610.0, current episode: 5
[2024-11-20 00:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 610.0, current episode: 6
[2024-11-20 00:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 610.0, current episode: 7
[2024-11-20 00:44:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 610.0, current episode: 8
[2024-11-20 00:44:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 254000.000000 | iteration_254000.pth.tar | 8.000000      | 720.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 90.000000               | 0.902586      | 797.707934          | 8.863421             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 610.000000  | 0.000000   | 610.000000 | 610.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:45:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1578.0, current episode: 1
[2024-11-20 00:45:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1578.0, current episode: 2
[2024-11-20 00:45:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1578.0, current episode: 3
[2024-11-20 00:45:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1578.0, current episode: 4
[2024-11-20 00:45:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1578.0, current episode: 5
[2024-11-20 00:45:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1578.0, current episode: 6
[2024-11-20 00:45:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1578.0, current episode: 7
[2024-11-20 00:45:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1578.0, current episode: 8
[2024-11-20 00:45:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 256000.000000 | iteration_256000.pth.tar | 8.000000      | 1304.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 163.000000              | 1.689267      | 771.932587          | 4.735783             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1578.000000 | 0.000000   | 1578.000000 | 1578.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 637.0, current episode: 1
[2024-11-20 00:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 637.0, current episode: 2
[2024-11-20 00:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 637.0, current episode: 3
[2024-11-20 00:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 637.0, current episode: 4
[2024-11-20 00:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 637.0, current episode: 5
[2024-11-20 00:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 637.0, current episode: 6
[2024-11-20 00:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 637.0, current episode: 7
[2024-11-20 00:47:01][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 637.0, current episode: 8
[2024-11-20 00:47:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 258000.000000 | iteration_258000.pth.tar | 8.000000      | 632.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 79.000000               | 0.807870      | 782.304400          | 9.902587             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 637.000000  | 0.000000   | 637.000000 | 637.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:48:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1509.0, current episode: 1
[2024-11-20 00:48:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1509.0, current episode: 2
[2024-11-20 00:48:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1509.0, current episode: 3
[2024-11-20 00:48:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1509.0, current episode: 4
[2024-11-20 00:48:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1509.0, current episode: 5
[2024-11-20 00:48:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1509.0, current episode: 6
[2024-11-20 00:48:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1509.0, current episode: 7
[2024-11-20 00:48:13][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1509.0, current episode: 8
[2024-11-20 00:48:13][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 260000.000000 | iteration_260000.pth.tar | 8.000000      | 1896.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 237.000000              | 2.380394      | 796.506723          | 3.360788             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1509.000000 | 0.000000   | 1509.000000 | 1509.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 636.0, current episode: 1
[2024-11-20 00:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 636.0, current episode: 2
[2024-11-20 00:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 636.0, current episode: 3
[2024-11-20 00:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 636.0, current episode: 4
[2024-11-20 00:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 636.0, current episode: 5
[2024-11-20 00:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 636.0, current episode: 6
[2024-11-20 00:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 636.0, current episode: 7
[2024-11-20 00:49:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 636.0, current episode: 8
[2024-11-20 00:49:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 262000.000000 | iteration_262000.pth.tar | 8.000000      | 600.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 75.000000               | 0.762119      | 787.278817          | 10.497051            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 636.000000  | 0.000000   | 636.000000 | 636.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:50:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 245.0, current episode: 1
[2024-11-20 00:50:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 245.0, current episode: 2
[2024-11-20 00:50:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 245.0, current episode: 3
[2024-11-20 00:50:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 245.0, current episode: 4
[2024-11-20 00:50:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 245.0, current episode: 5
[2024-11-20 00:50:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 245.0, current episode: 6
[2024-11-20 00:50:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 245.0, current episode: 7
[2024-11-20 00:50:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 245.0, current episode: 8
[2024-11-20 00:50:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 264000.000000 | iteration_264000.pth.tar | 8.000000      | 272.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 34.000000               | 0.363618      | 748.037497          | 22.001103            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 245.000000  | 0.000000   | 245.000000 | 245.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1664.0, current episode: 1
[2024-11-20 00:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1664.0, current episode: 2
[2024-11-20 00:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1664.0, current episode: 3
[2024-11-20 00:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1664.0, current episode: 4
[2024-11-20 00:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1664.0, current episode: 5
[2024-11-20 00:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1664.0, current episode: 6
[2024-11-20 00:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1664.0, current episode: 7
[2024-11-20 00:51:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1664.0, current episode: 8
[2024-11-20 00:51:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 266000.000000 | iteration_266000.pth.tar | 8.000000      | 1464.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 183.000000              | 1.845048      | 793.475108          | 4.335930             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1664.000000 | 0.000000   | 1664.000000 | 1664.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-20 00:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-20 00:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-20 00:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-20 00:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-20 00:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-20 00:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-20 00:53:12][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-20 00:53:12][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 268000.000000 | iteration_268000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.048234     | 800.070471          | 0.399038             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:54:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 623.0, current episode: 1
[2024-11-20 00:54:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 623.0, current episode: 2
[2024-11-20 00:54:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 623.0, current episode: 3
[2024-11-20 00:54:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 623.0, current episode: 4
[2024-11-20 00:54:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 623.0, current episode: 5
[2024-11-20 00:54:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 623.0, current episode: 6
[2024-11-20 00:54:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 623.0, current episode: 7
[2024-11-20 00:54:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 623.0, current episode: 8
[2024-11-20 00:54:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 270000.000000 | iteration_270000.pth.tar | 8.000000      | 552.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 69.000000               | 0.709699      | 777.794884          | 11.272390            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 623.000000  | 0.000000   | 623.000000 | 623.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:55:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1331.0, current episode: 1
[2024-11-20 00:55:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1331.0, current episode: 2
[2024-11-20 00:55:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1331.0, current episode: 3
[2024-11-20 00:55:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1331.0, current episode: 4
[2024-11-20 00:55:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1331.0, current episode: 5
[2024-11-20 00:55:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1331.0, current episode: 6
[2024-11-20 00:55:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1331.0, current episode: 7
[2024-11-20 00:55:33][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1331.0, current episode: 8
[2024-11-20 00:55:33][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 272000.000000 | iteration_272000.pth.tar | 8.000000      | 1088.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 136.000000              | 1.393171      | 780.952324          | 5.742296             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1331.000000 | 0.000000   | 1331.000000 | 1331.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 00:56:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 632.0, current episode: 1
[2024-11-20 00:56:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 632.0, current episode: 2
[2024-11-20 00:56:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 632.0, current episode: 3
[2024-11-20 00:56:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 632.0, current episode: 4
[2024-11-20 00:56:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 632.0, current episode: 5
[2024-11-20 00:56:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 632.0, current episode: 6
[2024-11-20 00:56:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 632.0, current episode: 7
[2024-11-20 00:56:44][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 632.0, current episode: 8
[2024-11-20 00:56:44][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 274000.000000 | iteration_274000.pth.tar | 8.000000      | 592.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 74.000000               | 0.757186      | 781.842062          | 10.565433            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 632.000000  | 0.000000   | 632.000000 | 632.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:57:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 652.0, current episode: 1
[2024-11-20 00:57:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 652.0, current episode: 2
[2024-11-20 00:57:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 652.0, current episode: 3
[2024-11-20 00:57:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 652.0, current episode: 4
[2024-11-20 00:57:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 652.0, current episode: 5
[2024-11-20 00:57:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 652.0, current episode: 6
[2024-11-20 00:57:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 652.0, current episode: 7
[2024-11-20 00:57:54][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 652.0, current episode: 8
[2024-11-20 00:57:54][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 276000.000000 | iteration_276000.pth.tar | 8.000000      | 616.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 77.000000               | 0.798497      | 771.448937          | 10.018817            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 652.000000  | 0.000000   | 652.000000 | 652.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 00:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -21.0, current episode: 1
[2024-11-20 00:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -21.0, current episode: 2
[2024-11-20 00:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -21.0, current episode: 3
[2024-11-20 00:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -21.0, current episode: 4
[2024-11-20 00:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -21.0, current episode: 5
[2024-11-20 00:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -21.0, current episode: 6
[2024-11-20 00:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -21.0, current episode: 7
[2024-11-20 00:59:23][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -21.0, current episode: 8
[2024-11-20 00:59:23][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 278000.000000 | iteration_278000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 19.934804     | 804.622892          | 0.401308             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -21.000000  | 0.000000   | -21.000000 | -21.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 01:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1675.0, current episode: 1
[2024-11-20 01:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1675.0, current episode: 2
[2024-11-20 01:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1675.0, current episode: 3
[2024-11-20 01:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1675.0, current episode: 4
[2024-11-20 01:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1675.0, current episode: 5
[2024-11-20 01:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1675.0, current episode: 6
[2024-11-20 01:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1675.0, current episode: 7
[2024-11-20 01:00:52][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1675.0, current episode: 8
[2024-11-20 01:00:52][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 280000.000000 | iteration_280000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 19.972523     | 803.103335          | 0.400550             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1675.000000 | 0.000000   | 1675.000000 | 1675.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 01:02:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1331.0, current episode: 1
[2024-11-20 01:02:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1331.0, current episode: 2
[2024-11-20 01:02:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1331.0, current episode: 3
[2024-11-20 01:02:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1331.0, current episode: 4
[2024-11-20 01:02:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1331.0, current episode: 5
[2024-11-20 01:02:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1331.0, current episode: 6
[2024-11-20 01:02:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1331.0, current episode: 7
[2024-11-20 01:02:02][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1331.0, current episode: 8
[2024-11-20 01:02:02][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 282000.000000 | iteration_282000.pth.tar | 8.000000      | 1056.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 132.000000              | 1.335073      | 790.967988          | 5.992182             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1331.000000 | 0.000000   | 1331.000000 | 1331.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 01:03:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 739.0, current episode: 1
[2024-11-20 01:03:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 739.0, current episode: 2
[2024-11-20 01:03:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 739.0, current episode: 3
[2024-11-20 01:03:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 739.0, current episode: 4
[2024-11-20 01:03:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 739.0, current episode: 5
[2024-11-20 01:03:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 739.0, current episode: 6
[2024-11-20 01:03:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 739.0, current episode: 7
[2024-11-20 01:03:11][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 739.0, current episode: 8
[2024-11-20 01:03:11][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 284000.000000 | iteration_284000.pth.tar | 8.000000      | 544.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 68.000000               | 0.689023      | 789.523970          | 11.610647            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 739.000000  | 0.000000   | 739.000000 | 739.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 01:04:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1031.0, current episode: 1
[2024-11-20 01:04:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1031.0, current episode: 2
[2024-11-20 01:04:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1031.0, current episode: 3
[2024-11-20 01:04:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1031.0, current episode: 4
[2024-11-20 01:04:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1031.0, current episode: 5
[2024-11-20 01:04:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1031.0, current episode: 6
[2024-11-20 01:04:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1031.0, current episode: 7
[2024-11-20 01:04:21][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1031.0, current episode: 8
[2024-11-20 01:04:21][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 286000.000000 | iteration_286000.pth.tar | 8.000000      | 1432.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 179.000000              | 1.797904      | 796.482904          | 4.449625             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1031.000000 | 0.000000   | 1031.000000 | 1031.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 01:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1577.0, current episode: 1
[2024-11-20 01:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1577.0, current episode: 2
[2024-11-20 01:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1577.0, current episode: 3
[2024-11-20 01:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1577.0, current episode: 4
[2024-11-20 01:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1577.0, current episode: 5
[2024-11-20 01:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1577.0, current episode: 6
[2024-11-20 01:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1577.0, current episode: 7
[2024-11-20 01:05:32][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1577.0, current episode: 8
[2024-11-20 01:05:32][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 288000.000000 | iteration_288000.pth.tar | 8.000000      | 1272.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 159.000000              | 1.614470      | 787.874656          | 4.955187             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1577.000000 | 0.000000   | 1577.000000 | 1577.000000 |
+-------+-------------+------------+-------------+-------------+


[2024-11-20 01:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 625.0, current episode: 1
[2024-11-20 01:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 625.0, current episode: 2
[2024-11-20 01:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 625.0, current episode: 3
[2024-11-20 01:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 625.0, current episode: 4
[2024-11-20 01:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 625.0, current episode: 5
[2024-11-20 01:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 625.0, current episode: 6
[2024-11-20 01:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 625.0, current episode: 7
[2024-11-20 01:06:42][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 625.0, current episode: 8
[2024-11-20 01:06:42][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 290000.000000 | iteration_290000.pth.tar | 8.000000      | 576.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 72.000000               | 0.850459      | 677.281058          | 9.406681             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 625.000000  | 0.000000   | 625.000000 | 625.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 01:07:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 594.0, current episode: 1
[2024-11-20 01:07:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 594.0, current episode: 2
[2024-11-20 01:07:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 594.0, current episode: 3
[2024-11-20 01:07:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 594.0, current episode: 4
[2024-11-20 01:07:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 594.0, current episode: 5
[2024-11-20 01:07:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 594.0, current episode: 6
[2024-11-20 01:07:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 594.0, current episode: 7
[2024-11-20 01:07:59][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 594.0, current episode: 8
[2024-11-20 01:07:59][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 292000.000000 | iteration_292000.pth.tar | 8.000000      | 2928.000000   |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 366.000000              | 3.686159      | 794.322836          | 2.170281             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 594.000000  | 0.000000   | 594.000000 | 594.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 01:09:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 819.0, current episode: 1
[2024-11-20 01:09:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 819.0, current episode: 2
[2024-11-20 01:09:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 819.0, current episode: 3
[2024-11-20 01:09:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 819.0, current episode: 4
[2024-11-20 01:09:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 819.0, current episode: 5
[2024-11-20 01:09:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 819.0, current episode: 6
[2024-11-20 01:09:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 819.0, current episode: 7
[2024-11-20 01:09:10][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 819.0, current episode: 8
[2024-11-20 01:09:10][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 294000.000000 | iteration_294000.pth.tar | 8.000000      | 976.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 122.000000              | 1.269232      | 768.969075          | 6.303025             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 819.000000  | 0.000000   | 819.000000 | 819.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 01:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: -34.0, current episode: 1
[2024-11-20 01:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: -34.0, current episode: 2
[2024-11-20 01:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: -34.0, current episode: 3
[2024-11-20 01:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: -34.0, current episode: 4
[2024-11-20 01:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: -34.0, current episode: 5
[2024-11-20 01:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: -34.0, current episode: 6
[2024-11-20 01:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: -34.0, current episode: 7
[2024-11-20 01:10:40][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: -34.0, current episode: 8
[2024-11-20 01:10:40][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 296000.000000 | iteration_296000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 19.906842     | 805.753118          | 0.401872             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -34.000000  | 0.000000   | -34.000000 | -34.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 01:11:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 624.0, current episode: 1
[2024-11-20 01:11:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 624.0, current episode: 2
[2024-11-20 01:11:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 624.0, current episode: 3
[2024-11-20 01:11:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 624.0, current episode: 4
[2024-11-20 01:11:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 624.0, current episode: 5
[2024-11-20 01:11:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 624.0, current episode: 6
[2024-11-20 01:11:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 624.0, current episode: 7
[2024-11-20 01:11:51][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 624.0, current episode: 8
[2024-11-20 01:11:51][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 298000.000000 | iteration_298000.pth.tar | 8.000000      | 640.000000    |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 80.000000               | 0.819555      | 780.911550          | 9.761394             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 624.000000  | 0.000000   | 624.000000 | 624.000000 |
+-------+-------------+------------+------------+------------+


[2024-11-20 01:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 0 finish episode, final reward: 1771.0, current episode: 1
[2024-11-20 01:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 1 finish episode, final reward: 1771.0, current episode: 2
[2024-11-20 01:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 2 finish episode, final reward: 1771.0, current episode: 3
[2024-11-20 01:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 3 finish episode, final reward: 1771.0, current episode: 4
[2024-11-20 01:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 4 finish episode, final reward: 1771.0, current episode: 5
[2024-11-20 01:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 5 finish episode, final reward: 1771.0, current episode: 6
[2024-11-20 01:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 6 finish episode, final reward: 1771.0, current episode: 7
[2024-11-20 01:13:22][interaction_serial_evaluator.py:253][INFO] [EVALUATOR]env 7 finish episode, final reward: 1771.0, current episode: 8
[2024-11-20 01:13:22][interaction_serial_evaluator.py:279][INFO] 
+-------+---------------+--------------------------+---------------+---------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count |
+-------+---------------+--------------------------+---------------+---------------+
| Value | 300000.000000 | iteration_300000.pth.tar | 8.000000      | 16040.000000  |
+-------+---------------+--------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 2005.000000             | 20.279376     | 790.951348          | 0.394489             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1771.000000 | 0.000000   | 1771.000000 | 1771.000000 |
+-------+-------------+------------+-------------+-------------+


