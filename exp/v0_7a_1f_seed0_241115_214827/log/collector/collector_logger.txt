[2024-11-15 21:48:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 235
train_sample_count: 235
avg_envstep_per_episode: 58.75
avg_sample_per_episode: 58.75
avg_envstep_per_sec: 854.6641373858312
avg_train_sample_per_sec: 854.6641373858312
avg_episode_per_sec: 14.547474678907765
collect_time: 0.27496181215558735
reward_mean: 325.0
reward_std: 176.28244018554688
reward_max: 630.0
reward_min: 210.0
total_envstep_count: 1149
total_train_sample_count: 1135
total_episode_count: 4
total_duration: 0.27496181215558735
[2024-11-15 21:48:51][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 773
train_sample_count: 773
avg_envstep_per_episode: 193.25
avg_sample_per_episode: 193.25
avg_envstep_per_sec: 854.117202154462
avg_train_sample_per_sec: 854.117202154462
avg_episode_per_sec: 4.419752663153749
collect_time: 0.9050280196326119
reward_mean: 642.75
reward_std: 49.89175796508789
reward_max: 727.0
reward_min: 597.0
total_envstep_count: 2154
total_train_sample_count: 2124
total_episode_count: 8
total_duration: 1.1799898317881992
[2024-11-15 21:48:54][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 327
train_sample_count: 327
avg_envstep_per_episode: 109.0
avg_sample_per_episode: 109.0
avg_envstep_per_sec: 859.2444507729141
avg_train_sample_per_sec: 859.2444507729141
avg_episode_per_sec: 7.8829766125955425
collect_time: 0.3805669035230364
reward_mean: 385.6666564941406
reward_std: 224.3885498046875
reward_max: 703.0
reward_min: 227.0
total_envstep_count: 3160
total_train_sample_count: 3135
total_episode_count: 11
total_duration: 1.5605567353112355
[2024-11-15 21:48:57][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 586
train_sample_count: 586
avg_envstep_per_episode: 195.33333333333334
avg_sample_per_episode: 195.33333333333334
avg_envstep_per_sec: 863.933624925612
avg_train_sample_per_sec: 863.933624925612
avg_episode_per_sec: 4.422868386991188
collect_time: 0.6782928492341722
reward_mean: 509.6666564941406
reward_std: 210.09573364257812
reward_max: 690.0
reward_min: 215.0
total_envstep_count: 4150
total_train_sample_count: 4117
total_episode_count: 14
total_duration: 2.2388495845454077
[2024-11-15 21:49:00][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 596
train_sample_count: 596
avg_envstep_per_episode: 198.66666666666666
avg_sample_per_episode: 198.66666666666666
avg_envstep_per_sec: 863.7216094191691
avg_train_sample_per_sec: 863.7216094191691
avg_episode_per_sec: 4.347591993720649
collect_time: 0.6900371525968824
reward_mean: 454.6666564941406
reward_std: 163.92750549316406
reward_max: 578.0
reward_min: 223.0
total_envstep_count: 5155
total_train_sample_count: 5097
total_episode_count: 17
total_duration: 2.92888673714229
[2024-11-15 21:49:03][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 1037
train_sample_count: 1037
avg_envstep_per_episode: 259.25
avg_sample_per_episode: 259.25
avg_envstep_per_sec: 857.5234741500819
avg_train_sample_per_sec: 857.5234741500819
avg_episode_per_sec: 3.307708675603016
collect_time: 1.2092963414532796
reward_mean: 461.75
reward_std: 245.28286743164062
reward_max: 759.0
reward_min: 201.0
total_envstep_count: 6152
total_train_sample_count: 6122
total_episode_count: 21
total_duration: 4.13818307859557
[2024-11-15 21:49:06][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 51
train_sample_count: 51
avg_envstep_per_episode: 51.0
avg_sample_per_episode: 51.0
avg_envstep_per_sec: 853.578331486124
avg_train_sample_per_sec: 853.578331486124
avg_episode_per_sec: 16.736830029139686
collect_time: 0.05974847078323364
reward_mean: 227.0
reward_std: 0.0
reward_max: 227.0
reward_min: 227.0
total_envstep_count: 7112
total_train_sample_count: 7085
total_episode_count: 22
total_duration: 4.197931549378803
[2024-11-15 21:49:10][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1639
train_sample_count: 1639
avg_envstep_per_episode: 546.3333333333334
avg_sample_per_episode: 546.3333333333334
avg_envstep_per_sec: 862.0639175712379
avg_train_sample_per_sec: 862.0639175712379
avg_episode_per_sec: 1.5779083299046452
collect_time: 1.901251132999148
reward_mean: 723.0
reward_std: 112.93656158447266
reward_max: 871.0
reward_min: 597.0
total_envstep_count: 8125
total_train_sample_count: 8064
total_episode_count: 25
total_duration: 6.099182682377951
