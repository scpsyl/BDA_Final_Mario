[2024-11-19 21:44:21][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 235
train_sample_count: 235
avg_envstep_per_episode: 58.75
avg_sample_per_episode: 58.75
avg_envstep_per_sec: 576.1990582189546
avg_train_sample_per_sec: 576.1990582189546
avg_episode_per_sec: 9.807643544152418
collect_time: 0.4078451650483268
reward_mean: 325.0
reward_std: 176.28244018554688
reward_max: 630.0
reward_min: 210.0
total_envstep_count: 1149
total_train_sample_count: 1135
total_episode_count: 4
total_duration: 0.4078451650483268
[2024-11-19 21:44:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 4
envstep_count: 773
train_sample_count: 773
avg_envstep_per_episode: 193.25
avg_sample_per_episode: 193.25
avg_envstep_per_sec: 604.9725546334558
avg_train_sample_per_sec: 604.9725546334558
avg_episode_per_sec: 3.1305177471330183
collect_time: 1.2777439142976488
reward_mean: 642.75
reward_std: 49.89175796508789
reward_max: 727.0
reward_min: 597.0
total_envstep_count: 2154
total_train_sample_count: 2124
total_episode_count: 8
total_duration: 1.6855890793459756
[2024-11-19 21:44:31][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 327
train_sample_count: 327
avg_envstep_per_episode: 109.0
avg_sample_per_episode: 109.0
avg_envstep_per_sec: 537.6892444929397
avg_train_sample_per_sec: 537.6892444929397
avg_episode_per_sec: 4.93292884855908
collect_time: 0.6081579710756029
reward_mean: 385.6666564941406
reward_std: 224.3885498046875
reward_max: 703.0
reward_min: 227.0
total_envstep_count: 3160
total_train_sample_count: 3135
total_episode_count: 11
total_duration: 2.2937470504215787
[2024-11-19 21:44:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 586
train_sample_count: 586
avg_envstep_per_episode: 195.33333333333334
avg_sample_per_episode: 195.33333333333334
avg_envstep_per_sec: 506.6835024249877
avg_train_sample_per_sec: 506.6835024249877
avg_episode_per_sec: 2.593942845179118
collect_time: 1.1565405172961098
reward_mean: 509.6666564941406
reward_std: 210.09573364257812
reward_max: 690.0
reward_min: 215.0
total_envstep_count: 4149
total_train_sample_count: 4117
total_episode_count: 14
total_duration: 3.4502875677176883
[2024-11-19 21:44:44][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 254
train_sample_count: 254
avg_envstep_per_episode: 254.0
avg_sample_per_episode: 254.0
avg_envstep_per_sec: 457.960112985609
avg_train_sample_per_sec: 457.960112985609
avg_episode_per_sec: 1.802992570809484
collect_time: 0.5546334556170872
reward_mean: 774.0
reward_std: 0.0
reward_max: 774.0
reward_min: 774.0
total_envstep_count: 5492
total_train_sample_count: 5463
total_episode_count: 15
total_duration: 4.004921023334775
[2024-11-19 21:44:50][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1310
train_sample_count: 1310
avg_envstep_per_episode: 262.0
avg_sample_per_episode: 262.0
avg_envstep_per_sec: 457.64686388354863
avg_train_sample_per_sec: 457.64686388354863
avg_episode_per_sec: 1.74674375528072
collect_time: 2.8624690856252397
reward_mean: 541.7999877929688
reward_std: 285.0981750488281
reward_max: 961.0
reward_min: 213.0
total_envstep_count: 6511
total_train_sample_count: 6473
total_episode_count: 20
total_duration: 6.867390108960015
[2024-11-19 21:44:55][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 904
train_sample_count: 904
avg_envstep_per_episode: 301.3333333333333
avg_sample_per_episode: 301.3333333333333
avg_envstep_per_sec: 453.79091684029396
avg_train_sample_per_sec: 453.79091684029396
avg_episode_per_sec: 1.5059433080983207
collect_time: 1.9921068634305685
reward_mean: 734.3333129882812
reward_std: 151.2841339111328
reward_max: 948.0
reward_min: 618.0
total_envstep_count: 7476
total_train_sample_count: 7449
total_episode_count: 23
total_duration: 8.859496972390584
[2024-11-19 21:45:01][sample_serial_collector.py:365][INFO] collect end:
episode_count: 6
envstep_count: 1446
train_sample_count: 1446
avg_envstep_per_episode: 241.0
avg_sample_per_episode: 241.0
avg_envstep_per_sec: 465.675120191115
avg_train_sample_per_sec: 465.675120191115
avg_episode_per_sec: 1.9322619095067013
collect_time: 3.1051691131932397
reward_mean: 498.1666564941406
reward_std: 188.47760009765625
reward_max: 706.0
reward_min: 235.0
total_envstep_count: 8488
total_train_sample_count: 8439
total_episode_count: 29
total_duration: 11.964666085583824
[2024-11-19 21:45:07][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 171
train_sample_count: 171
avg_envstep_per_episode: 85.5
avg_sample_per_episode: 85.5
avg_envstep_per_sec: 444.4983721580606
avg_train_sample_per_sec: 444.4983721580606
avg_episode_per_sec: 5.1988113702697145
collect_time: 0.3847033211163112
reward_mean: 416.0
reward_std: 179.0
reward_max: 595.0
reward_min: 237.0
total_envstep_count: 9447
total_train_sample_count: 9414
total_episode_count: 31
total_duration: 12.349369406700134
[2024-11-19 21:45:13][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 2114
train_sample_count: 2114
avg_envstep_per_episode: 422.8
avg_sample_per_episode: 422.8
avg_envstep_per_sec: 464.9682996130246
avg_train_sample_per_sec: 464.9682996130246
avg_episode_per_sec: 1.0997358079778254
collect_time: 4.546546510287694
reward_mean: 546.5999755859375
reward_std: 195.55624389648438
reward_max: 757.0
reward_min: 177.0
total_envstep_count: 10427
total_train_sample_count: 10388
total_episode_count: 36
total_duration: 16.89591591698783
[2024-11-19 21:45:19][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 146
train_sample_count: 146
avg_envstep_per_episode: 73.0
avg_sample_per_episode: 73.0
avg_envstep_per_sec: 443.6608998924052
avg_train_sample_per_sec: 443.6608998924052
avg_episode_per_sec: 6.077546573868565
collect_time: 0.32908016017505104
reward_mean: 428.0
reward_std: 190.0
reward_max: 618.0
reward_min: 238.0
total_envstep_count: 11417
total_train_sample_count: 11374
total_episode_count: 38
total_duration: 17.224996077162878
[2024-11-19 21:45:25][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 346
train_sample_count: 346
avg_envstep_per_episode: 115.33333333333333
avg_sample_per_episode: 115.33333333333333
avg_envstep_per_sec: 437.2370103868548
avg_train_sample_per_sec: 437.2370103868548
avg_episode_per_sec: 3.7910723443946948
collect_time: 0.7913328281470708
reward_mean: 384.6666564941406
reward_std: 217.32362365722656
reward_max: 692.0
reward_min: 229.0
total_envstep_count: 12382
total_train_sample_count: 12356
total_episode_count: 41
total_duration: 18.016328905309948
[2024-11-19 21:45:37][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 811
train_sample_count: 811
avg_envstep_per_episode: 811.0
avg_sample_per_episode: 811.0
avg_envstep_per_sec: 447.98283389919874
avg_train_sample_per_sec: 447.98283389919874
avg_episode_per_sec: 0.55238327237879
collect_time: 1.810337224176952
reward_mean: 1303.0
reward_std: 0.0
reward_max: 1303.0
reward_min: 1303.0
total_envstep_count: 14429
total_train_sample_count: 14391
total_episode_count: 42
total_duration: 19.8266661294869
[2024-11-19 21:45:42][sample_serial_collector.py:365][INFO] collect end:
episode_count: 3
envstep_count: 1143
train_sample_count: 1143
avg_envstep_per_episode: 381.0
avg_sample_per_episode: 381.0
avg_envstep_per_sec: 448.98836659947125
avg_train_sample_per_sec: 448.98836659947125
avg_episode_per_sec: 1.1784471564290584
collect_time: 2.5457229741982053
reward_mean: 815.6666870117188
reward_std: 442.78387451171875
reward_max: 1293.0
reward_min: 226.0
total_envstep_count: 15418
total_train_sample_count: 15390
total_episode_count: 45
total_duration: 22.372389103685105
[2024-11-19 21:45:48][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 711
train_sample_count: 711
avg_envstep_per_episode: 355.5
avg_sample_per_episode: 355.5
avg_envstep_per_sec: 442.37475859873706
avg_train_sample_per_sec: 442.37475859873706
avg_episode_per_sec: 1.2443734419092463
collect_time: 1.607234558888844
reward_mean: 733.0
reward_std: 498.0
reward_max: 1231.0
reward_min: 235.0
total_envstep_count: 16408
total_train_sample_count: 16377
total_episode_count: 47
total_duration: 23.97962366257395
[2024-11-19 21:45:53][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 830
train_sample_count: 830
avg_envstep_per_episode: 830.0
avg_sample_per_episode: 830.0
avg_envstep_per_sec: 447.8525384939252
avg_train_sample_per_sec: 447.8525384939252
avg_episode_per_sec: 0.539581371679428
collect_time: 1.8532885909080503
reward_mean: 678.0
reward_std: 0.0
reward_max: 678.0
reward_min: 678.0
total_envstep_count: 17367
total_train_sample_count: 17339
total_episode_count: 48
total_duration: 25.832912253482
[2024-11-19 21:45:59][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 2317
train_sample_count: 2317
avg_envstep_per_episode: 1158.5
avg_sample_per_episode: 1158.5
avg_envstep_per_sec: 452.5071778775121
avg_train_sample_per_sec: 452.5071778775121
avg_episode_per_sec: 0.39059747766725256
collect_time: 5.120360766138349
reward_mean: 725.5
reward_std: 285.5
reward_max: 1011.0
reward_min: 440.0
total_envstep_count: 18341
total_train_sample_count: 18300
total_episode_count: 50
total_duration: 30.953273019620347
[2024-11-19 21:46:11][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 528
train_sample_count: 528
avg_envstep_per_episode: 528.0
avg_sample_per_episode: 528.0
avg_envstep_per_sec: 446.4291253785933
avg_train_sample_per_sec: 446.4291253785933
avg_episode_per_sec: 0.8455097071564267
collect_time: 1.1827185324260165
reward_mean: 738.0
reward_std: 0.0
reward_max: 738.0
reward_min: 738.0
total_envstep_count: 20164
total_train_sample_count: 20124
total_episode_count: 51
total_duration: 32.13599155204636
[2024-11-19 21:46:17][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 410
train_sample_count: 410
avg_envstep_per_episode: 410.0
avg_sample_per_episode: 410.0
avg_envstep_per_sec: 451.70339150089234
avg_train_sample_per_sec: 451.70339150089234
avg_episode_per_sec: 1.1017155890265666
collect_time: 0.9076752747808183
reward_mean: 652.0
reward_std: 0.0
reward_max: 652.0
reward_min: 652.0
total_envstep_count: 21123
total_train_sample_count: 21086
total_episode_count: 52
total_duration: 33.043666826827184
[2024-11-19 21:46:22][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 1894
train_sample_count: 1894
avg_envstep_per_episode: 1894.0
avg_sample_per_episode: 1894.0
avg_envstep_per_sec: 450.6339574764712
avg_train_sample_per_sec: 450.6339574764712
avg_episode_per_sec: 0.23792711587986864
collect_time: 4.202967771462031
reward_mean: 700.0
reward_std: 0.0
reward_max: 700.0
reward_min: 700.0
total_envstep_count: 22083
total_train_sample_count: 22056
total_episode_count: 53
total_duration: 37.24663459828922
[2024-11-19 21:46:28][sample_serial_collector.py:365][INFO] collect end:
episode_count: 2
envstep_count: 1321
train_sample_count: 1321
avg_envstep_per_episode: 660.5
avg_sample_per_episode: 660.5
avg_envstep_per_sec: 451.0181561121293
avg_train_sample_per_sec: 451.0181561121293
avg_episode_per_sec: 0.6828435368843745
collect_time: 2.928928651979991
reward_mean: 827.0
reward_std: 47.0
reward_max: 874.0
reward_min: 780.0
total_envstep_count: 23082
total_train_sample_count: 23041
total_episode_count: 55
total_duration: 40.17556325026921
[2024-11-19 21:46:34][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 98
train_sample_count: 98
avg_envstep_per_episode: 98.0
avg_sample_per_episode: 98.0
avg_envstep_per_sec: 453.43149970300266
avg_train_sample_per_sec: 453.43149970300266
avg_episode_per_sec: 4.626852037785741
collect_time: 0.21612966912133352
reward_mean: 623.0
reward_std: 0.0
reward_max: 623.0
reward_min: 623.0
total_envstep_count: 24041
total_train_sample_count: 24003
total_episode_count: 56
total_duration: 40.39169291939054
[2024-11-19 21:46:39][sample_serial_collector.py:365][INFO] collect end:
episode_count: 5
envstep_count: 1719
train_sample_count: 1719
avg_envstep_per_episode: 343.8
avg_sample_per_episode: 343.8
avg_envstep_per_sec: 449.07774394603166
avg_train_sample_per_sec: 449.07774394603166
avg_episode_per_sec: 1.3062179870448856
collect_time: 3.8278450071811676
reward_mean: 691.7999877929688
reward_std: 298.35845947265625
reward_max: 1160.0
reward_min: 223.0
total_envstep_count: 25028
total_train_sample_count: 24978
total_episode_count: 61
total_duration: 44.21953792657171
[2024-11-19 21:46:45][sample_serial_collector.py:365][INFO] collect end:
episode_count: 1
envstep_count: 155
train_sample_count: 155
avg_envstep_per_episode: 155.0
avg_sample_per_episode: 155.0
avg_envstep_per_sec: 453.0064781943428
avg_train_sample_per_sec: 453.0064781943428
avg_episode_per_sec: 2.922622439963502
collect_time: 0.3421584623200553
reward_mean: 636.0
reward_std: 0.0
reward_max: 636.0
reward_min: 636.0
total_envstep_count: 25995
total_train_sample_count: 25949
total_episode_count: 62
total_duration: 44.56169638889177
